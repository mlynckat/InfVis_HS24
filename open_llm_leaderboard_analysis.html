<!DOCTYPE html>
<html>
<head>
  <style>
    #vis.vega-embed {
      width: 100%;
      display: flex;
    }

    #vis.vega-embed details,
    #vis.vega-embed details summary {
      position: relative;
    }
  </style>
  <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/vega@5"></script>
  <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/vega-lite@5.20.1"></script>
  <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/vega-embed@6"></script>
</head>
<body>
  <div id="vis"></div>
  <script>
    (function(vegaEmbed) {
      var spec = {"config": {"view": {"continuousWidth": 300, "continuousHeight": 300}}, "vconcat": [{"data": {"name": "data-a49611ca96c737e9821cda5c734db455"}, "mark": {"type": "bar"}, "encoding": {"color": {"field": "eval_name", "type": "nominal"}, "x": {"field": "eval_name", "sort": "-y", "type": "nominal"}, "y": {"aggregate": "count", "type": "quantitative"}}, "height": 200, "title": "Distribution of eval_name", "width": 300}, {"data": {"name": "data-a49611ca96c737e9821cda5c734db455"}, "mark": {"type": "bar"}, "encoding": {"color": {"field": "Precision", "type": "nominal"}, "x": {"field": "Precision", "sort": "-y", "type": "nominal"}, "y": {"aggregate": "count", "type": "quantitative"}}, "height": 200, "title": "Distribution of Precision", "width": 300}, {"data": {"name": "data-a49611ca96c737e9821cda5c734db455"}, "mark": {"type": "bar"}, "encoding": {"color": {"field": "Type", "type": "nominal"}, "x": {"field": "Type", "sort": "-y", "type": "nominal"}, "y": {"aggregate": "count", "type": "quantitative"}}, "height": 200, "title": "Distribution of Type", "width": 300}, {"data": {"name": "data-a49611ca96c737e9821cda5c734db455"}, "mark": {"type": "bar"}, "encoding": {"color": {"field": "T", "type": "nominal"}, "x": {"field": "T", "sort": "-y", "type": "nominal"}, "y": {"aggregate": "count", "type": "quantitative"}}, "height": 200, "title": "Distribution of T", "width": 300}, {"data": {"name": "data-a49611ca96c737e9821cda5c734db455"}, "mark": {"type": "bar"}, "encoding": {"color": {"field": "Weight type", "type": "nominal"}, "x": {"field": "Weight type", "sort": "-y", "type": "nominal"}, "y": {"aggregate": "count", "type": "quantitative"}}, "height": 200, "title": "Distribution of Weight type", "width": 300}, {"data": {"name": "data-a49611ca96c737e9821cda5c734db455"}, "mark": {"type": "bar"}, "encoding": {"color": {"field": "Architecture", "type": "nominal"}, "x": {"field": "Architecture", "sort": "-y", "type": "nominal"}, "y": {"aggregate": "count", "type": "quantitative"}}, "height": 200, "title": "Distribution of Architecture", "width": 300}, {"data": {"name": "data-a49611ca96c737e9821cda5c734db455"}, "mark": {"type": "bar"}, "encoding": {"color": {"field": "fullname", "type": "nominal"}, "x": {"field": "fullname", "sort": "-y", "type": "nominal"}, "y": {"aggregate": "count", "type": "quantitative"}}, "height": 200, "title": "Distribution of fullname", "width": 300}, {"data": {"name": "data-a49611ca96c737e9821cda5c734db455"}, "mark": {"type": "bar"}, "encoding": {"x": {"bin": {"maxbins": 30}, "field": "Average \u2b06\ufe0f", "type": "quantitative"}, "y": {"aggregate": "count", "type": "quantitative"}}, "height": 200, "title": "Distribution of Average \u2b06\ufe0f", "width": 300}, {"data": {"name": "data-a49611ca96c737e9821cda5c734db455"}, "mark": {"type": "bar"}, "encoding": {"color": {"field": "Hub License", "type": "nominal"}, "x": {"field": "Hub License", "sort": "-y", "type": "nominal"}, "y": {"aggregate": "count", "type": "quantitative"}}, "height": 200, "title": "Distribution of Hub License", "width": 300}, {"data": {"name": "data-a49611ca96c737e9821cda5c734db455"}, "mark": {"type": "bar"}, "encoding": {"x": {"bin": {"maxbins": 30}, "field": "Hub \u2764\ufe0f", "type": "quantitative"}, "y": {"aggregate": "count", "type": "quantitative"}}, "height": 200, "title": "Distribution of Hub \u2764\ufe0f", "width": 300}, {"data": {"name": "data-a49611ca96c737e9821cda5c734db455"}, "mark": {"type": "bar"}, "encoding": {"x": {"bin": {"maxbins": 30}, "field": "#Params (B)", "type": "quantitative"}, "y": {"aggregate": "count", "type": "quantitative"}}, "height": 200, "title": "Distribution of #Params (B)", "width": 300}, {"data": {"name": "data-a49611ca96c737e9821cda5c734db455"}, "mark": {"type": "arc"}, "encoding": {"color": {"field": "Available on the hub", "type": "nominal"}, "theta": {"aggregate": "count", "type": "quantitative"}}, "height": 200, "title": "Distribution of Available on the hub", "width": 200}, {"data": {"name": "data-a49611ca96c737e9821cda5c734db455"}, "mark": {"type": "arc"}, "encoding": {"color": {"field": "Not_Merged", "type": "nominal"}, "theta": {"aggregate": "count", "type": "quantitative"}}, "height": 200, "title": "Distribution of Not_Merged", "width": 200}, {"data": {"name": "data-a49611ca96c737e9821cda5c734db455"}, "mark": {"type": "arc"}, "encoding": {"color": {"field": "MoE", "type": "nominal"}, "theta": {"aggregate": "count", "type": "quantitative"}}, "height": 200, "title": "Distribution of MoE", "width": 200}, {"data": {"name": "data-a49611ca96c737e9821cda5c734db455"}, "mark": {"type": "arc"}, "encoding": {"color": {"field": "Flagged", "type": "nominal"}, "theta": {"aggregate": "count", "type": "quantitative"}}, "height": 200, "title": "Distribution of Flagged", "width": 200}, {"data": {"name": "data-a49611ca96c737e9821cda5c734db455"}, "mark": {"type": "arc"}, "encoding": {"color": {"field": "Chat Template", "type": "nominal"}, "theta": {"aggregate": "count", "type": "quantitative"}}, "height": 200, "title": "Distribution of Chat Template", "width": 200}, {"data": {"name": "data-a49611ca96c737e9821cda5c734db455"}, "mark": {"type": "bar"}, "encoding": {"x": {"bin": {"maxbins": 30}, "field": "IFEval Raw", "type": "quantitative"}, "y": {"aggregate": "count", "type": "quantitative"}}, "height": 200, "title": "Distribution of IFEval Raw", "width": 300}, {"data": {"name": "data-a49611ca96c737e9821cda5c734db455"}, "mark": {"type": "bar"}, "encoding": {"x": {"bin": {"maxbins": 30}, "field": "IFEval", "type": "quantitative"}, "y": {"aggregate": "count", "type": "quantitative"}}, "height": 200, "title": "Distribution of IFEval", "width": 300}, {"data": {"name": "data-a49611ca96c737e9821cda5c734db455"}, "mark": {"type": "bar"}, "encoding": {"x": {"bin": {"maxbins": 30}, "field": "BBH Raw", "type": "quantitative"}, "y": {"aggregate": "count", "type": "quantitative"}}, "height": 200, "title": "Distribution of BBH Raw", "width": 300}, {"data": {"name": "data-a49611ca96c737e9821cda5c734db455"}, "mark": {"type": "bar"}, "encoding": {"x": {"bin": {"maxbins": 30}, "field": "BBH", "type": "quantitative"}, "y": {"aggregate": "count", "type": "quantitative"}}, "height": 200, "title": "Distribution of BBH", "width": 300}, {"data": {"name": "data-a49611ca96c737e9821cda5c734db455"}, "mark": {"type": "bar"}, "encoding": {"x": {"bin": {"maxbins": 30}, "field": "MATH Lvl 5 Raw", "type": "quantitative"}, "y": {"aggregate": "count", "type": "quantitative"}}, "height": 200, "title": "Distribution of MATH Lvl 5 Raw", "width": 300}, {"data": {"name": "data-a49611ca96c737e9821cda5c734db455"}, "mark": {"type": "bar"}, "encoding": {"x": {"bin": {"maxbins": 30}, "field": "MATH Lvl 5", "type": "quantitative"}, "y": {"aggregate": "count", "type": "quantitative"}}, "height": 200, "title": "Distribution of MATH Lvl 5", "width": 300}, {"data": {"name": "data-a49611ca96c737e9821cda5c734db455"}, "mark": {"type": "bar"}, "encoding": {"x": {"bin": {"maxbins": 30}, "field": "GPQA Raw", "type": "quantitative"}, "y": {"aggregate": "count", "type": "quantitative"}}, "height": 200, "title": "Distribution of GPQA Raw", "width": 300}, {"data": {"name": "data-a49611ca96c737e9821cda5c734db455"}, "mark": {"type": "bar"}, "encoding": {"x": {"bin": {"maxbins": 30}, "field": "GPQA", "type": "quantitative"}, "y": {"aggregate": "count", "type": "quantitative"}}, "height": 200, "title": "Distribution of GPQA", "width": 300}, {"data": {"name": "data-a49611ca96c737e9821cda5c734db455"}, "mark": {"type": "bar"}, "encoding": {"x": {"bin": {"maxbins": 30}, "field": "MUSR Raw", "type": "quantitative"}, "y": {"aggregate": "count", "type": "quantitative"}}, "height": 200, "title": "Distribution of MUSR Raw", "width": 300}, {"data": {"name": "data-a49611ca96c737e9821cda5c734db455"}, "mark": {"type": "bar"}, "encoding": {"x": {"bin": {"maxbins": 30}, "field": "MUSR", "type": "quantitative"}, "y": {"aggregate": "count", "type": "quantitative"}}, "height": 200, "title": "Distribution of MUSR", "width": 300}, {"data": {"name": "data-a49611ca96c737e9821cda5c734db455"}, "mark": {"type": "bar"}, "encoding": {"x": {"bin": {"maxbins": 30}, "field": "MMLU-PRO Raw", "type": "quantitative"}, "y": {"aggregate": "count", "type": "quantitative"}}, "height": 200, "title": "Distribution of MMLU-PRO Raw", "width": 300}, {"data": {"name": "data-a49611ca96c737e9821cda5c734db455"}, "mark": {"type": "bar"}, "encoding": {"x": {"bin": {"maxbins": 30}, "field": "MMLU-PRO", "type": "quantitative"}, "y": {"aggregate": "count", "type": "quantitative"}}, "height": 200, "title": "Distribution of MMLU-PRO", "width": 300}, {"data": {"name": "data-a49611ca96c737e9821cda5c734db455"}, "mark": {"type": "line"}, "encoding": {"x": {"field": "Upload To Hub Date", "type": "temporal"}, "y": {"aggregate": "count", "type": "quantitative"}}, "height": 200, "title": "Time Series of Upload To Hub Date", "width": 400}, {"data": {"name": "data-a49611ca96c737e9821cda5c734db455"}, "mark": {"type": "line"}, "encoding": {"x": {"field": "Submission Date", "type": "temporal"}, "y": {"aggregate": "count", "type": "quantitative"}}, "height": 200, "title": "Time Series of Submission Date", "width": 400}, {"data": {"name": "data-a49611ca96c737e9821cda5c734db455"}, "mark": {"type": "bar"}, "encoding": {"x": {"bin": {"maxbins": 30}, "field": "Generation", "type": "quantitative"}, "y": {"aggregate": "count", "type": "quantitative"}}, "height": 200, "title": "Distribution of Generation", "width": 300}, {"data": {"name": "data-a49611ca96c737e9821cda5c734db455"}, "mark": {"type": "bar"}, "encoding": {"color": {"field": "Base Model", "type": "nominal"}, "x": {"field": "Base Model", "sort": "-y", "type": "nominal"}, "y": {"aggregate": "count", "type": "quantitative"}}, "height": 200, "title": "Distribution of Base Model", "width": 300}, {"data": {"name": "data-a49611ca96c737e9821cda5c734db455"}, "mark": {"type": "circle"}, "encoding": {"color": {"field": "Architecture", "type": "nominal"}, "tooltip": [{"field": "Architecture", "type": "nominal"}, {"field": "#Params (B)", "type": "quantitative"}, {"field": "Average \u2b06\ufe0f", "type": "quantitative"}], "x": {"field": "#Params (B)", "scale": {"type": "log"}, "type": "quantitative"}, "y": {"field": "Average \u2b06\ufe0f", "type": "quantitative"}}, "height": 300, "title": "Number of Parameters vs Average Score", "width": 400}, {"data": {"name": "data-622652e47e42a7364f5e71ddd4cfec7c"}, "mark": {"type": "boxplot"}, "encoding": {"color": {"field": "Task", "type": "nominal"}, "x": {"field": "Task", "type": "nominal"}, "y": {"field": "Score", "type": "quantitative"}}, "height": 300, "title": "Distribution of Scores Across Different Tasks", "width": 400}], "$schema": "https://vega.github.io/schema/vega-lite/v5.20.1.json", "datasets": {"data-a49611ca96c737e9821cda5c734db455": [{"eval_name": "0-hero_Matter-0.2-7B-DPO_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/0-hero/Matter-0.2-7B-DPO\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">0-hero/Matter-0.2-7B-DPO</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/0-hero__Matter-0.2-7B-DPO-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "0-hero/Matter-0.2-7B-DPO", "Model sha": "26a66f0d862e2024ce4ad0a09c37052ac36e8af6", "Average \u2b06\ufe0f": 8.805656367208497, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 3, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3302792147058693, "IFEval": 33.02792147058693, "BBH Raw": 0.3596254301656297, "BBH": 10.055525080241036, "MATH Lvl 5 Raw": 0.0083081570996978, "MATH Lvl 5": 0.8308157099697886, "GPQA Raw": 0.259228187919463, "GPQA": 1.230425055928408, "MUSR Raw": 0.381375, "MUSR": 5.871874999999999, "MMLU-PRO Raw": 0.1163563829787234, "MMLU-PRO": 1.8173758865248215, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-13T00:00:00", "Submission Date": "2024-08-05T00:00:00", "Generation": 0, "Base Model": "0-hero/Matter-0.2-7B-DPO"}, {"eval_name": "01-ai_Yi-1.5-34B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/01-ai/Yi-1.5-34B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">01-ai/Yi-1.5-34B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/01-ai__Yi-1.5-34B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "01-ai/Yi-1.5-34B", "Model sha": "4b486f81c935a2dadde84c6baa1e1370d40a098f", "Average \u2b06\ufe0f": 25.4324962083918, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 46, "#Params (B)": 34, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2841172533322695, "IFEval": 28.411725333226947, "BBH Raw": 0.5976391706360018, "BBH": 42.74936268839652, "MATH Lvl 5 Raw": 0.1404833836858006, "MATH Lvl 5": 14.04833836858006, "GPQA Raw": 0.3657718120805369, "GPQA": 15.436241610738255, "MUSR Raw": 0.4236041666666667, "MUSR": 11.217187500000003, "MMLU-PRO Raw": 0.4665890957446808, "MMLU-PRO": 40.732121749408975, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-05-11T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "01-ai/Yi-1.5-34B"}, {"eval_name": "01-ai_Yi-1.5-34B-32K_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/01-ai/Yi-1.5-34B-32K\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">01-ai/Yi-1.5-34B-32K</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/01-ai__Yi-1.5-34B-32K-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "01-ai/Yi-1.5-34B-32K", "Model sha": "2c03a29761e4174f20347a60fbe229be4383d48b", "Average \u2b06\ufe0f": 26.40062187124731, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 35, "#Params (B)": 34, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3118691737922047, "IFEval": 31.186917379220468, "BBH Raw": 0.6015685776542417, "BBH": 43.38184666762572, "MATH Lvl 5 Raw": 0.134441087613293, "MATH Lvl 5": 13.444108761329304, "GPQA Raw": 0.3632550335570469, "GPQA": 15.100671140939594, "MUSR Raw": 0.4398229166666667, "MUSR": 14.07786458333333, "MMLU-PRO Raw": 0.4709109042553192, "MMLU-PRO": 41.21232269503546, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-05-15T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "01-ai/Yi-1.5-34B-32K"}, {"eval_name": "01-ai_Yi-1.5-34B-Chat_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/01-ai/Yi-1.5-34B-Chat\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">01-ai/Yi-1.5-34B-Chat</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/01-ai__Yi-1.5-34B-Chat-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "01-ai/Yi-1.5-34B-Chat", "Model sha": "f3128b2d02d82989daae566c0a7eadc621ca3254", "Average \u2b06\ufe0f": 32.627882895328185, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 238, "#Params (B)": 34, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6066758423205982, "IFEval": 60.66758423205982, "BBH Raw": 0.6083748310271819, "BBH": 44.262825981005655, "MATH Lvl 5 Raw": 0.2333836858006042, "MATH Lvl 5": 23.338368580060425, "GPQA Raw": 0.3649328859060403, "GPQA": 15.324384787472036, "MUSR Raw": 0.4281979166666667, "MUSR": 13.058072916666664, "MMLU-PRO Raw": 0.4520445478723404, "MMLU-PRO": 39.11606087470449, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-05-10T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "01-ai/Yi-1.5-34B-Chat"}, {"eval_name": "01-ai_Yi-1.5-34B-Chat-16K_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/01-ai/Yi-1.5-34B-Chat-16K\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">01-ai/Yi-1.5-34B-Chat-16K</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/01-ai__Yi-1.5-34B-Chat-16K-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "01-ai/Yi-1.5-34B-Chat-16K", "Model sha": "ff74452e11f0f749ab872dc19b1dd3813c25c4d8", "Average \u2b06\ufe0f": 28.97555887090761, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 26, "#Params (B)": 34, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.456449997118756, "IFEval": 45.6449997118756, "BBH Raw": 0.6100218256499571, "BBH": 44.53615654671034, "MATH Lvl 5 Raw": 0.1880664652567975, "MATH Lvl 5": 18.80664652567976, "GPQA Raw": 0.3380872483221476, "GPQA": 11.74496644295302, "MUSR Raw": 0.4397604166666666, "MUSR": 13.73671875, "MMLU-PRO Raw": 0.4544547872340425, "MMLU-PRO": 39.38386524822696, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-05-15T00:00:00", "Submission Date": "2024-07-15T00:00:00", "Generation": 0, "Base Model": "01-ai/Yi-1.5-34B-Chat-16K"}, {"eval_name": "01-ai_Yi-1.5-6B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/01-ai/Yi-1.5-6B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">01-ai/Yi-1.5-6B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/01-ai__Yi-1.5-6B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "01-ai/Yi-1.5-6B", "Model sha": "cab51fce425b4c1fb19fccfdd96bd5d0908c1657", "Average \u2b06\ufe0f": 16.53170006907082, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 28, "#Params (B)": 6, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2616601727859856, "IFEval": 26.166017278598567, "BBH Raw": 0.4492582019892905, "BBH": 22.027904536694773, "MATH Lvl 5 Raw": 0.0536253776435045, "MATH Lvl 5": 5.362537764350453, "GPQA Raw": 0.313758389261745, "GPQA": 8.501118568232664, "MUSR Raw": 0.43740625, "MUSR": 13.309114583333336, "MMLU-PRO Raw": 0.3144115691489361, "MMLU-PRO": 23.823507683215126, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-05-11T00:00:00", "Submission Date": "2024-08-10T00:00:00", "Generation": 0, "Base Model": "01-ai/Yi-1.5-6B"}, {"eval_name": "01-ai_Yi-1.5-6B-Chat_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/01-ai/Yi-1.5-6B-Chat\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">01-ai/Yi-1.5-6B-Chat</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/01-ai__Yi-1.5-6B-Chat-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "01-ai/Yi-1.5-6B-Chat", "Model sha": "3f64d3f159c6ad8494227bb77e2a7baef8cd808b", "Average \u2b06\ufe0f": 22.048528999300476, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 41, "#Params (B)": 6, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4802302335580704, "IFEval": 48.02302335580704, "BBH Raw": 0.4554861043778055, "BBH": 23.550511456633718, "MATH Lvl 5 Raw": 0.1253776435045317, "MATH Lvl 5": 12.537764350453172, "GPQA Raw": 0.3179530201342282, "GPQA": 9.060402684563762, "MUSR Raw": 0.4432395833333333, "MUSR": 14.704947916666669, "MMLU-PRO Raw": 0.3197307180851064, "MMLU-PRO": 24.414524231678485, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-05-11T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "01-ai/Yi-1.5-6B-Chat"}, {"eval_name": "01-ai_Yi-1.5-9B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/01-ai/Yi-1.5-9B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">01-ai/Yi-1.5-9B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/01-ai__Yi-1.5-9B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "01-ai/Yi-1.5-9B", "Model sha": "8cfde9604384c50137bee480b8cef8a08e5ae81d", "Average \u2b06\ufe0f": 21.95249164510121, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 46, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2935843561749491, "IFEval": 29.35843561749492, "BBH Raw": 0.514294179104191, "BBH": 30.50071699492122, "MATH Lvl 5 Raw": 0.1019637462235649, "MATH Lvl 5": 10.196374622356496, "GPQA Raw": 0.3791946308724832, "GPQA": 17.225950782997764, "MUSR Raw": 0.4327812499999999, "MUSR": 12.030989583333332, "MMLU-PRO Raw": 0.3916223404255319, "MMLU-PRO": 32.402482269503544, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-05-11T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "01-ai/Yi-1.5-9B"}, {"eval_name": "01-ai_Yi-1.5-9B-32K_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/01-ai/Yi-1.5-9B-32K\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">01-ai/Yi-1.5-9B-32K</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/01-ai__Yi-1.5-9B-32K-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "01-ai/Yi-1.5-9B-32K", "Model sha": "116561dfae63af90f9d163b43077629e0e916bb1", "Average \u2b06\ufe0f": 19.608376416791774, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 18, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2303111300238921, "IFEval": 23.031113002389212, "BBH Raw": 0.496332115988265, "BBH": 28.937011582169664, "MATH Lvl 5 Raw": 0.0959214501510574, "MATH Lvl 5": 9.59214501510574, "GPQA Raw": 0.3590604026845637, "GPQA": 14.5413870246085, "MUSR Raw": 0.4186145833333333, "MUSR": 10.82682291666667, "MMLU-PRO Raw": 0.3764960106382978, "MMLU-PRO": 30.72177895981088, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-05-15T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "01-ai/Yi-1.5-9B-32K"}, {"eval_name": "01-ai_Yi-1.5-9B-Chat_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/01-ai/Yi-1.5-9B-Chat\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">01-ai/Yi-1.5-9B-Chat</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/01-ai__Yi-1.5-9B-Chat-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "01-ai/Yi-1.5-9B-Chat", "Model sha": "bc87d8557c98dc1e5fdef6ec23ed31088c4d3f35", "Average \u2b06\ufe0f": 27.70559528169099, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 131, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6045525871354672, "IFEval": 60.455258713546726, "BBH Raw": 0.555906430281685, "BBH": 36.95293138417893, "MATH Lvl 5 Raw": 0.1163141993957704, "MATH Lvl 5": 11.63141993957704, "GPQA Raw": 0.3347315436241611, "GPQA": 11.297539149888143, "MUSR Raw": 0.42590625, "MUSR": 12.838281249999996, "MMLU-PRO Raw": 0.3975232712765957, "MMLU-PRO": 33.05814125295508, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-05-10T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "01-ai/Yi-1.5-9B-Chat"}, {"eval_name": "01-ai_Yi-1.5-9B-Chat-16K_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/01-ai/Yi-1.5-9B-Chat-16K\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">01-ai/Yi-1.5-9B-Chat-16K</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/01-ai__Yi-1.5-9B-Chat-16K-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "01-ai/Yi-1.5-9B-Chat-16K", "Model sha": "2b397e5f0fab87984efa66856c5c4ed4bbe68b50", "Average \u2b06\ufe0f": 22.896812289511804, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 31, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4214040966856829, "IFEval": 42.14040966856828, "BBH Raw": 0.5153383364651778, "BBH": 31.49760894701832, "MATH Lvl 5 Raw": 0.1261329305135951, "MATH Lvl 5": 12.613293051359516, "GPQA Raw": 0.3087248322147651, "GPQA": 7.829977628635347, "MUSR Raw": 0.4099062499999999, "MUSR": 10.03828125, "MMLU-PRO Raw": 0.3993517287234042, "MMLU-PRO": 33.261303191489354, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-05-15T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "01-ai/Yi-1.5-9B-Chat-16K"}, {"eval_name": "01-ai_Yi-34B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/01-ai/Yi-34B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">01-ai/Yi-34B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/01-ai__Yi-34B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "01-ai/Yi-34B", "Model sha": "e1e7da8c75cfd5c44522228599fd4d2990cedd1c", "Average \u2b06\ufe0f": 22.259833967577137, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1279, "#Params (B)": 34, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3045751938190667, "IFEval": 30.45751938190668, "BBH Raw": 0.5457099951794562, "BBH": 35.542431259008794, "MATH Lvl 5 Raw": 0.0445619335347432, "MATH Lvl 5": 4.45619335347432, "GPQA Raw": 0.3666107382550335, "GPQA": 15.548098434004473, "MUSR Raw": 0.4118541666666667, "MUSR": 9.648437500000004, "MMLU-PRO Raw": 0.441156914893617, "MMLU-PRO": 37.90632387706855, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-11-01T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "01-ai/Yi-34B"}, {"eval_name": "01-ai_Yi-34B-200K_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/01-ai/Yi-34B-200K\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">01-ai/Yi-34B-200K</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/01-ai__Yi-34B-200K-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "01-ai/Yi-34B-200K", "Model sha": "8ac1a1ebe011df28b78ccd08012aeb2222443c77", "Average \u2b06\ufe0f": 19.79947735007302, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 314, "#Params (B)": 34, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1542485050776384, "IFEval": 15.424850507763844, "BBH Raw": 0.5441817925289527, "BBH": 36.02211028900003, "MATH Lvl 5 Raw": 0.0445619335347432, "MATH Lvl 5": 4.45619335347432, "GPQA Raw": 0.3565436241610738, "GPQA": 14.205816554809845, "MUSR Raw": 0.3817187499999999, "MUSR": 9.414843749999998, "MMLU-PRO Raw": 0.4534574468085106, "MMLU-PRO": 39.27304964539008, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-11-06T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "01-ai/Yi-34B-200K"}, {"eval_name": "01-ai_Yi-34B-Chat_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/01-ai/Yi-34B-Chat\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">01-ai/Yi-34B-Chat</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/01-ai__Yi-34B-Chat-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "01-ai/Yi-34B-Chat", "Model sha": "2e528b6a80fb064a0a746c5ca43114b135e30464", "Average \u2b06\ufe0f": 23.89937161554255, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 343, "#Params (B)": 34, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4698887839820565, "IFEval": 46.98887839820566, "BBH Raw": 0.5560872910766164, "BBH": 37.623987597243485, "MATH Lvl 5 Raw": 0.0430513595166163, "MATH Lvl 5": 4.305135951661631, "GPQA Raw": 0.3380872483221476, "GPQA": 11.74496644295302, "MUSR Raw": 0.39784375, "MUSR": 8.363802083333338, "MMLU-PRO Raw": 0.4093251329787234, "MMLU-PRO": 34.369459219858165, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-11-22T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "01-ai/Yi-34B-Chat"}, {"eval_name": "01-ai_Yi-6B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/01-ai/Yi-6B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">01-ai/Yi-6B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/01-ai__Yi-6B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "01-ai/Yi-6B", "Model sha": "7f7fb7662fd8ec09029364f408053c954986c8e5", "Average \u2b06\ufe0f": 13.599029368558334, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 371, "#Params (B)": 6, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2893378458046871, "IFEval": 28.93378458046871, "BBH Raw": 0.4309230591000865, "BBH": 19.408504737915056, "MATH Lvl 5 Raw": 0.0151057401812688, "MATH Lvl 5": 1.5105740181268883, "GPQA Raw": 0.2692953020134228, "GPQA": 2.572706935123044, "MUSR Raw": 0.3936874999999999, "MUSR": 7.044270833333335, "MMLU-PRO Raw": 0.2991190159574468, "MMLU-PRO": 22.12433510638298, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-11-01T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "01-ai/Yi-6B"}, {"eval_name": "01-ai_Yi-6B-200K_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/01-ai/Yi-6B-200K\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">01-ai/Yi-6B-200K</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/01-ai__Yi-6B-200K-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "01-ai/Yi-6B-200K", "Model sha": "4a74338e778a599f313e9fa8f5bc08c717604420", "Average \u2b06\ufe0f": 11.895393364291047, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 173, "#Params (B)": 6, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.0843306870215472, "IFEval": 8.433068702154728, "BBH Raw": 0.428929481096033, "BBH": 20.148020103768047, "MATH Lvl 5 Raw": 0.0120845921450151, "MATH Lvl 5": 1.2084592145015105, "GPQA Raw": 0.2818791946308724, "GPQA": 4.250559284116329, "MUSR Raw": 0.4587395833333333, "MUSR": 16.842447916666668, "MMLU-PRO Raw": 0.2844082446808511, "MMLU-PRO": 20.489804964539008, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-11-06T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "01-ai/Yi-6B-200K"}, {"eval_name": "01-ai_Yi-6B-Chat_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/01-ai/Yi-6B-Chat\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">01-ai/Yi-6B-Chat</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/01-ai__Yi-6B-Chat-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "01-ai/Yi-6B-Chat", "Model sha": "01f7fabb6cfb26efeb764da4a0a19cad2c754232", "Average \u2b06\ufe0f": 14.004356953877243, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 62, "#Params (B)": 6, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3395213588833184, "IFEval": 33.95213588833185, "BBH Raw": 0.4132601920754868, "BBH": 17.00016656742376, "MATH Lvl 5 Raw": 0.0067975830815709, "MATH Lvl 5": 0.6797583081570997, "GPQA Raw": 0.2944630872483221, "GPQA": 5.92841163310962, "MUSR Raw": 0.3687916666666666, "MUSR": 3.5656250000000003, "MMLU-PRO Raw": 0.3061003989361702, "MMLU-PRO": 22.90004432624113, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-11-22T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "01-ai/Yi-6B-Chat"}, {"eval_name": "01-ai_Yi-9B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/01-ai/Yi-9B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">01-ai/Yi-9B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/01-ai__Yi-9B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "01-ai/Yi-9B", "Model sha": "b4a466d95091696285409f1dcca3028543cb39da", "Average \u2b06\ufe0f": 17.61045749866248, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 184, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2708779372066118, "IFEval": 27.08779372066118, "BBH Raw": 0.4939607512530807, "BBH": 27.62695611207793, "MATH Lvl 5 Raw": 0.0438066465256797, "MATH Lvl 5": 4.380664652567976, "GPQA Raw": 0.3179530201342282, "GPQA": 9.060402684563762, "MUSR Raw": 0.4054062499999999, "MUSR": 8.909114583333334, "MMLU-PRO Raw": 0.3573803191489361, "MMLU-PRO": 28.59781323877068, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-03-01T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "01-ai/Yi-9B"}, {"eval_name": "01-ai_Yi-9B-200K_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/01-ai/Yi-9B-200K\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">01-ai/Yi-9B-200K</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/01-ai__Yi-9B-200K-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "01-ai/Yi-9B-200K", "Model sha": "8c93accd5589dbb74ee938e103613508c4a9b88d", "Average \u2b06\ufe0f": 17.59108250111942, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 75, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2327092115586643, "IFEval": 23.270921155866432, "BBH Raw": 0.4793302602023641, "BBH": 26.49249509714754, "MATH Lvl 5 Raw": 0.0581570996978852, "MATH Lvl 5": 5.81570996978852, "GPQA Raw": 0.3154362416107382, "GPQA": 8.7248322147651, "MUSR Raw": 0.42940625, "MUSR": 12.109114583333332, "MMLU-PRO Raw": 0.3622007978723404, "MMLU-PRO": 29.1334219858156, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-03-15T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "01-ai/Yi-9B-200K"}, {"eval_name": "01-ai_Yi-Coder-9B-Chat_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/01-ai/Yi-Coder-9B-Chat\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">01-ai/Yi-Coder-9B-Chat</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/01-ai__Yi-Coder-9B-Chat-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "01-ai/Yi-Coder-9B-Chat", "Model sha": "356a1f8d4e4a606d0b879e54191ca809918576b8", "Average \u2b06\ufe0f": 16.809755679415748, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 178, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4817041006750976, "IFEval": 48.17041006750976, "BBH Raw": 0.4814200033911167, "BBH": 25.94315294491389, "MATH Lvl 5 Raw": 0.0294561933534743, "MATH Lvl 5": 2.9456193353474323, "GPQA Raw": 0.24748322147651, "GPQA": 0.0, "MUSR Raw": 0.3991770833333333, "MUSR": 7.963802083333333, "MMLU-PRO Raw": 0.2425199468085106, "MMLU-PRO": 15.83554964539007, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-08-21T00:00:00", "Submission Date": "2024-09-12T00:00:00", "Generation": 1, "Base Model": "01-ai/Yi-Coder-9B"}, {"eval_name": "152334H_miqu-1-70b-sf_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/152334H/miqu-1-70b-sf\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">152334H/miqu-1-70b-sf</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/152334H__miqu-1-70b-sf-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "152334H/miqu-1-70b-sf", "Model sha": "1dca4cce36f01f2104ee2e6b97bac6ff7bb300c1", "Average \u2b06\ufe0f": 28.820469156246716, "Hub License": null, "Hub \u2764\ufe0f": 219, "#Params (B)": 68, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.5181740005407873, "IFEval": 51.81740005407873, "BBH Raw": 0.6102361685099691, "BBH": 43.807147003691966, "MATH Lvl 5 Raw": 0.1080060422960725, "MATH Lvl 5": 10.80060422960725, "GPQA Raw": 0.3506711409395973, "GPQA": 13.422818791946312, "MUSR Raw": 0.4582083333333333, "MUSR": 17.209374999999998, "MMLU-PRO Raw": 0.4227892287234042, "MMLU-PRO": 35.865469858156025, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-01-30T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "152334H/miqu-1-70b-sf"}, {"eval_name": "1TuanPham_T-VisStar-7B-v0.1_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/1TuanPham/T-VisStar-7B-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">1TuanPham/T-VisStar-7B-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/1TuanPham__T-VisStar-7B-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "1TuanPham/T-VisStar-7B-v0.1", "Model sha": "b111b59971c14b46c888b96723ff7f3c7b6fd92f", "Average \u2b06\ufe0f": 18.943398741811773, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3607040430502178, "IFEval": 36.07040430502179, "BBH Raw": 0.5052203113352468, "BBH": 30.24383447882599, "MATH Lvl 5 Raw": 0.0453172205438066, "MATH Lvl 5": 4.531722054380665, "GPQA Raw": 0.285234899328859, "GPQA": 4.697986577181204, "MUSR Raw": 0.4375, "MUSR": 13.554166666666667, "MMLU-PRO Raw": 0.3210605053191489, "MMLU-PRO": 24.562278368794324, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-19T00:00:00", "Submission Date": "2024-09-22T00:00:00", "Generation": 0, "Base Model": "1TuanPham/T-VisStar-7B-v0.1"}, {"eval_name": "1TuanPham_T-VisStar-v0.1_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/1TuanPham/T-VisStar-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">1TuanPham/T-VisStar-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/1TuanPham__T-VisStar-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "1TuanPham/T-VisStar-v0.1", "Model sha": "c9779bd9630a533f7e42fd8effcca69623d48c9c", "Average \u2b06\ufe0f": 18.943398741811773, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3607040430502178, "IFEval": 36.07040430502179, "BBH Raw": 0.5052203113352468, "BBH": 30.24383447882599, "MATH Lvl 5 Raw": 0.0453172205438066, "MATH Lvl 5": 4.531722054380665, "GPQA Raw": 0.285234899328859, "GPQA": 4.697986577181204, "MUSR Raw": 0.4375, "MUSR": 13.554166666666667, "MMLU-PRO Raw": 0.3210605053191489, "MMLU-PRO": 24.562278368794324, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-19T00:00:00", "Submission Date": "2024-09-20T00:00:00", "Generation": 0, "Base Model": "1TuanPham/T-VisStar-v0.1"}, {"eval_name": "3rd-Degree-Burn_Llama-3.1-8B-Squareroot_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/3rd-Degree-Burn/Llama-3.1-8B-Squareroot\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">3rd-Degree-Burn/Llama-3.1-8B-Squareroot</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/3rd-Degree-Burn__Llama-3.1-8B-Squareroot-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "3rd-Degree-Burn/Llama-3.1-8B-Squareroot", "Model sha": "2bec01c2c5d53276eac2222c80190eb44ab2e6af", "Average \u2b06\ufe0f": 10.30480826562249, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 2, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2213438121960841, "IFEval": 22.13438121960841, "BBH Raw": 0.3460942332632887, "BBH": 8.618063681935197, "MATH Lvl 5 Raw": 0.2107250755287009, "MATH Lvl 5": 21.07250755287009, "GPQA Raw": 0.2567114093959731, "GPQA": 0.8948545861297527, "MUSR Raw": 0.3089166666666667, "MUSR": 0.7812499999999996, "MMLU-PRO Raw": 0.1749501329787234, "MMLU-PRO": 8.32779255319149, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-10T00:00:00", "Submission Date": "2024-10-10T00:00:00", "Generation": 1, "Base Model": "3rd-Degree-Burn/Llama-3.1-8B-Squareroot (Merge)"}, {"eval_name": "3rd-Degree-Burn_Llama-Squared-8B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/3rd-Degree-Burn/Llama-Squared-8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">3rd-Degree-Burn/Llama-Squared-8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/3rd-Degree-Burn__Llama-Squared-8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "3rd-Degree-Burn/Llama-Squared-8B", "Model sha": "f30737e92b3a3fa0ef2a3f3ade487cc94ad34400", "Average \u2b06\ufe0f": 12.183191857780235, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.275524497222924, "IFEval": 27.55244972229241, "BBH Raw": 0.4431025683868353, "BBH": 21.277103190106818, "MATH Lvl 5 Raw": 0.0422960725075528, "MATH Lvl 5": 4.229607250755287, "GPQA Raw": 0.2718120805369127, "GPQA": 2.9082774049217, "MUSR Raw": 0.3089479166666666, "MUSR": 1.9518229166666672, "MMLU-PRO Raw": 0.2366190159574468, "MMLU-PRO": 15.179890661938533, "Maintainer's Highlight": false, "Upload To Hub Date": "", "Submission Date": "2024-10-08T00:00:00", "Generation": 0, "Base Model": "Removed"}, {"eval_name": "4season_final_model_test_v2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/4season/final_model_test_v2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">4season/final_model_test_v2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/4season__final_model_test_v2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "4season/final_model_test_v2", "Model sha": "cf690c35d9cf0b0b6bf034fa16dbf88c56fe861c", "Average \u2b06\ufe0f": 21.91554017959572, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 21, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3191132860809319, "IFEval": 31.911328608093196, "BBH Raw": 0.6342049783295018, "BBH": 47.410670136906425, "MATH Lvl 5 Raw": 0.0135951661631419, "MATH Lvl 5": 1.3595166163141994, "GPQA Raw": 0.3271812080536913, "GPQA": 10.290827740492167, "MUSR Raw": 0.4314479166666667, "MUSR": 12.430989583333334, "MMLU-PRO Raw": 0.3528091755319149, "MMLU-PRO": 28.08990839243498, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-20T00:00:00", "Submission Date": "2024-06-27T00:00:00", "Generation": 0, "Base Model": "4season/final_model_test_v2"}, {"eval_name": "AALF_gemma-2-27b-it-SimPO-37K_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/AALF/gemma-2-27b-it-SimPO-37K\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">AALF/gemma-2-27b-it-SimPO-37K</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/AALF__gemma-2-27b-it-SimPO-37K-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "AALF/gemma-2-27b-it-SimPO-37K", "Model sha": "27f15219df2000a16955c9403c3f38b5f3413b3d", "Average \u2b06\ufe0f": 9.298079394862366, "Hub License": "gemma", "Hub \u2764\ufe0f": 16, "#Params (B)": 27, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.240652579599906, "IFEval": 24.065257959990603, "BBH Raw": 0.3911343917952534, "BBH": 15.307880971954305, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2802013422818792, "GPQA": 4.026845637583895, "MUSR Raw": 0.3487604166666667, "MUSR": 1.5950520833333328, "MMLU-PRO Raw": 0.1971409574468085, "MMLU-PRO": 10.793439716312056, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-13T00:00:00", "Submission Date": "2024-09-05T00:00:00", "Generation": 2, "Base Model": "google/gemma-2-27b"}, {"eval_name": "AALF_gemma-2-27b-it-SimPO-37K-100steps_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/AALF/gemma-2-27b-it-SimPO-37K-100steps\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">AALF/gemma-2-27b-it-SimPO-37K-100steps</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/AALF__gemma-2-27b-it-SimPO-37K-100steps-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "AALF/gemma-2-27b-it-SimPO-37K-100steps", "Model sha": "d5cbf18b2eb90b77f5ddbb74cfcaeedfa692c90c", "Average \u2b06\ufe0f": 9.89433609242818, "Hub License": "gemma", "Hub \u2764\ufe0f": 9, "#Params (B)": 27, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2567642743476199, "IFEval": 25.67642743476199, "BBH Raw": 0.3930823076988501, "BBH": 15.261078322847055, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2885906040268456, "GPQA": 5.145413870246088, "MUSR Raw": 0.3329166666666667, "MUSR": 0.7812499999999996, "MMLU-PRO Raw": 0.2125166223404255, "MMLU-PRO": 12.501846926713949, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-13T00:00:00", "Submission Date": "2024-09-21T00:00:00", "Generation": 2, "Base Model": "google/gemma-2-27b"}, {"eval_name": "AELLM_gemma-2-aeria-infinity-9b_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/AELLM/gemma-2-aeria-infinity-9b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">AELLM/gemma-2-aeria-infinity-9b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/AELLM__gemma-2-aeria-infinity-9b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "AELLM/gemma-2-aeria-infinity-9b", "Model sha": "24e1de07258925d5ddb52134b66e2eb0d698dc11", "Average \u2b06\ufe0f": 28.34402863967889, "Hub License": null, "Hub \u2764\ufe0f": 1, "#Params (B)": 9, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.759399504426034, "IFEval": 75.93995044260342, "BBH Raw": 0.5983336669577649, "BBH": 42.0902142313775, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.3338926174496644, "GPQA": 11.185682326621922, "MUSR Raw": 0.40196875, "MUSR": 9.046093750000004, "MMLU-PRO Raw": 0.386220079787234, "MMLU-PRO": 31.80223108747045, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-09T00:00:00", "Submission Date": "2024-10-09T00:00:00", "Generation": 1, "Base Model": "AELLM/gemma-2-aeria-infinity-9b (Merge)"}, {"eval_name": "AELLM_gemma-2-lyco-infinity-9b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/AELLM/gemma-2-lyco-infinity-9b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">AELLM/gemma-2-lyco-infinity-9b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/AELLM__gemma-2-lyco-infinity-9b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "AELLM/gemma-2-lyco-infinity-9b", "Model sha": "2941a682fcbcfea3f1485c9e0691cc1d9edc742e", "Average \u2b06\ufe0f": 27.20493693940108, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 10, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7316475839660989, "IFEval": 73.1647583966099, "BBH Raw": 0.5839534871023703, "BBH": 39.78753882674737, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.3280201342281879, "GPQA": 10.402684563758392, "MUSR Raw": 0.4006354166666666, "MUSR": 8.912760416666671, "MMLU-PRO Raw": 0.378656914893617, "MMLU-PRO": 30.961879432624112, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-09T00:00:00", "Submission Date": "2024-10-09T00:00:00", "Generation": 1, "Base Model": "AELLM/gemma-2-lyco-infinity-9b (Merge)"}, {"eval_name": "AGI-0_Artificium-llama3.1-8B-001_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/AGI-0/Artificium-llama3.1-8B-001\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">AGI-0/Artificium-llama3.1-8B-001</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/AGI-0__Artificium-llama3.1-8B-001-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "AGI-0/Artificium-llama3.1-8B-001", "Model sha": "6bf3dcca3b75a06a4e04e5f944e709cccf4673fd", "Average \u2b06\ufe0f": 18.9379407847592, "Hub License": "unknown", "Hub \u2764\ufe0f": 34, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5247687247614108, "IFEval": 52.47687247614108, "BBH Raw": 0.4256215022592355, "BBH": 19.34889807323965, "MATH Lvl 5 Raw": 0.1027190332326284, "MATH Lvl 5": 10.27190332326284, "GPQA Raw": 0.2659395973154362, "GPQA": 2.1252796420581683, "MUSR Raw": 0.3794583333333333, "MUSR": 5.165625000000001, "MMLU-PRO Raw": 0.3181515957446808, "MMLU-PRO": 24.23906619385342, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-16T00:00:00", "Submission Date": "2024-09-08T00:00:00", "Generation": 0, "Base Model": "AGI-0/Artificium-llama3.1-8B-001"}, {"eval_name": "AI-MO_NuminaMath-7B-CoT_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/AI-MO/NuminaMath-7B-CoT\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">AI-MO/NuminaMath-7B-CoT</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/AI-MO__NuminaMath-7B-CoT-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "AI-MO/NuminaMath-7B-CoT", "Model sha": "ff7e3044218efe64128bd9c21f9ec66c3de04324", "Average \u2b06\ufe0f": 12.94625177995661, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 12, "#Params (B)": 6, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2688544173903022, "IFEval": 26.88544173903022, "BBH Raw": 0.4314193495860012, "BBH": 19.152364282090307, "MATH Lvl 5 Raw": 0.0793051359516616, "MATH Lvl 5": 7.930513595166164, "GPQA Raw": 0.2659395973154362, "GPQA": 2.1252796420581683, "MUSR Raw": 0.33034375, "MUSR": 0.8263020833333333, "MMLU-PRO Raw": 0.2868184840425531, "MMLU-PRO": 20.75760933806146, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-15T00:00:00", "Submission Date": "2024-09-10T00:00:00", "Generation": 1, "Base Model": "deepseek-ai/deepseek-math-7b-base"}, {"eval_name": "AI-MO_NuminaMath-7B-TIR_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/AI-MO/NuminaMath-7B-TIR\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">AI-MO/NuminaMath-7B-TIR</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/AI-MO__NuminaMath-7B-TIR-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "AI-MO/NuminaMath-7B-TIR", "Model sha": "c6e394cc0579423c9cde6df6cc192c07dae73388", "Average \u2b06\ufe0f": 11.790546947805865, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 308, "#Params (B)": 6, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2756242325917454, "IFEval": 27.562423259174547, "BBH Raw": 0.4143691337589789, "BBH": 16.87354725795866, "MATH Lvl 5 Raw": 0.0173716012084592, "MATH Lvl 5": 1.7371601208459215, "GPQA Raw": 0.2583892617449664, "GPQA": 1.1185682326621946, "MUSR Raw": 0.3509270833333333, "MUSR": 4.199218749999999, "MMLU-PRO Raw": 0.2732712765957447, "MMLU-PRO": 19.25236406619385, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-04T00:00:00", "Submission Date": "2024-07-11T00:00:00", "Generation": 1, "Base Model": "deepseek-ai/deepseek-math-7b-base"}, {"eval_name": "AI-Sweden-Models_Llama-3-8B-instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/AI-Sweden-Models/Llama-3-8B-instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">AI-Sweden-Models/Llama-3-8B-instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/AI-Sweden-Models__Llama-3-8B-instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "AI-Sweden-Models/Llama-3-8B-instruct", "Model sha": "4e1c955228bdb4d69c1c4560e8d5872312a8f033", "Average \u2b06\ufe0f": 13.777204414945189, "Hub License": "llama3", "Hub \u2764\ufe0f": 9, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2401284148282113, "IFEval": 24.012841482821138, "BBH Raw": 0.4173460154515302, "BBH": 18.388095615027524, "MATH Lvl 5 Raw": 0.0045317220543806, "MATH Lvl 5": 0.4531722054380665, "GPQA Raw": 0.2659395973154362, "GPQA": 2.1252796420581683, "MUSR Raw": 0.47709375, "MUSR": 19.93671875, "MMLU-PRO Raw": 0.2597240691489361, "MMLU-PRO": 17.747118794326237, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-01T00:00:00", "Submission Date": "2024-06-27T00:00:00", "Generation": 2, "Base Model": "meta-llama/Meta-Llama-3-8B"}, {"eval_name": "AI-Sweden-Models_gpt-sw3-40b_float16", "Precision": "float16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "GPT2LMHeadModel", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/AI-Sweden-Models/gpt-sw3-40b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">AI-Sweden-Models/gpt-sw3-40b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/AI-Sweden-Models__gpt-sw3-40b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "AI-Sweden-Models/gpt-sw3-40b", "Model sha": "1af27994df1287a7fac1b10d60e40ca43a22a385", "Average \u2b06\ufe0f": 4.684080733022823, "Hub License": "other", "Hub \u2764\ufe0f": 10, "#Params (B)": 39, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1470298807164989, "IFEval": 14.702988071649887, "BBH Raw": 0.3267744702957652, "BBH": 6.894934050796576, "MATH Lvl 5 Raw": 0.0060422960725075, "MATH Lvl 5": 0.6042296072507553, "GPQA Raw": 0.2348993288590604, "GPQA": 0.0, "MUSR Raw": 0.3632395833333333, "MUSR": 2.83828125, "MMLU-PRO Raw": 0.1275764627659574, "MMLU-PRO": 3.064051418439715, "Maintainer's Highlight": false, "Upload To Hub Date": "2023-02-22T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "AI-Sweden-Models/gpt-sw3-40b"}, {"eval_name": "AbacusResearch_Jallabi-34B_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/AbacusResearch/Jallabi-34B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">AbacusResearch/Jallabi-34B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/AbacusResearch__Jallabi-34B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "AbacusResearch/Jallabi-34B", "Model sha": "f65696da4ed82c9a20e94b200d9dccffa07af682", "Average \u2b06\ufe0f": 25.97208393481522, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 2, "#Params (B)": 34, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3528604103777976, "IFEval": 35.28604103777975, "BBH Raw": 0.6023380603196266, "BBH": 43.61576498719506, "MATH Lvl 5 Raw": 0.039274924471299, "MATH Lvl 5": 3.927492447129909, "GPQA Raw": 0.3389261744966443, "GPQA": 11.85682326621924, "MUSR Raw": 0.4821770833333333, "MUSR": 20.23880208333333, "MMLU-PRO Raw": 0.4681682180851064, "MMLU-PRO": 40.90757978723404, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-03-01T00:00:00", "Submission Date": "2024-06-27T00:00:00", "Generation": 0, "Base Model": "AbacusResearch/Jallabi-34B"}, {"eval_name": "Alibaba-NLP_gte-Qwen2-7B-instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Alibaba-NLP/gte-Qwen2-7B-instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Alibaba-NLP/gte-Qwen2-7B-instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Alibaba-NLP__gte-Qwen2-7B-instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Alibaba-NLP/gte-Qwen2-7B-instruct", "Model sha": "e26182b2122f4435e8b3ebecbf363990f409b45b", "Average \u2b06\ufe0f": 13.343239502630691, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 175, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2255404548819354, "IFEval": 22.55404548819355, "BBH Raw": 0.4495144990818469, "BBH": 21.92548248566236, "MATH Lvl 5 Raw": 0.0347432024169184, "MATH Lvl 5": 3.474320241691843, "GPQA Raw": 0.2449664429530201, "GPQA": 0.0, "MUSR Raw": 0.3558541666666666, "MUSR": 6.315104166666665, "MMLU-PRO Raw": 0.3321143617021276, "MMLU-PRO": 25.790484633569736, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-15T00:00:00", "Submission Date": "2024-08-05T00:00:00", "Generation": 0, "Base Model": "Alibaba-NLP/gte-Qwen2-7B-instruct"}, {"eval_name": "ArliAI_ArliAI-RPMax-12B-v1.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/ArliAI/ArliAI-RPMax-12B-v1.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">ArliAI/ArliAI-RPMax-12B-v1.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/ArliAI__ArliAI-RPMax-12B-v1.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "ArliAI/ArliAI-RPMax-12B-v1.1", "Model sha": "645db1cf8ad952eb57854a133e8e15303b898b04", "Average \u2b06\ufe0f": 20.636460758007644, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 38, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5348852156721942, "IFEval": 53.48852156721942, "BBH Raw": 0.475181760840119, "BBH": 24.80906331793277, "MATH Lvl 5 Raw": 0.0921450151057401, "MATH Lvl 5": 9.214501510574015, "GPQA Raw": 0.2818791946308724, "GPQA": 4.250559284116329, "MUSR Raw": 0.36184375, "MUSR": 5.563802083333336, "MMLU-PRO Raw": 0.3384308510638298, "MMLU-PRO": 26.492316784869978, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-31T00:00:00", "Submission Date": "2024-09-05T00:00:00", "Generation": 0, "Base Model": "ArliAI/ArliAI-RPMax-12B-v1.1"}, {"eval_name": "ArliAI_Llama-3.1-8B-ArliAI-RPMax-v1.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/ArliAI/Llama-3.1-8B-ArliAI-RPMax-v1.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">ArliAI/Llama-3.1-8B-ArliAI-RPMax-v1.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/ArliAI__Llama-3.1-8B-ArliAI-RPMax-v1.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "ArliAI/Llama-3.1-8B-ArliAI-RPMax-v1.1", "Model sha": "540bd352e59c63900af91b95a932b33aaee70c76", "Average \u2b06\ufe0f": 23.64002846469784, "Hub License": "llama3", "Hub \u2764\ufe0f": 26, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6359016298975606, "IFEval": 63.59016298975607, "BBH Raw": 0.5015613456039083, "BBH": 28.787014099442825, "MATH Lvl 5 Raw": 0.1132930513595166, "MATH Lvl 5": 11.329305135951662, "GPQA Raw": 0.2835570469798658, "GPQA": 4.4742729306487705, "MUSR Raw": 0.3576875, "MUSR": 5.3109375000000005, "MMLU-PRO Raw": 0.3551363031914893, "MMLU-PRO": 28.34847813238771, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-23T00:00:00", "Submission Date": "2024-09-19T00:00:00", "Generation": 0, "Base Model": "ArliAI/Llama-3.1-8B-ArliAI-RPMax-v1.1"}, {"eval_name": "Artples_L-MChat-7b_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Artples/L-MChat-7b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Artples/L-MChat-7b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Artples__L-MChat-7b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Artples/L-MChat-7b", "Model sha": "e10137f5cbfc1b73068d6473e4a87241cca0b3f4", "Average \u2b06\ufe0f": 21.024495458341278, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5296646231997766, "IFEval": 52.96646231997766, "BBH Raw": 0.4600330167467941, "BBH": 24.20155738881327, "MATH Lvl 5 Raw": 0.0793051359516616, "MATH Lvl 5": 7.930513595166164, "GPQA Raw": 0.3053691275167785, "GPQA": 7.38255033557047, "MUSR Raw": 0.4028645833333333, "MUSR": 8.124739583333334, "MMLU-PRO Raw": 0.3298703457446808, "MMLU-PRO": 25.54114952718676, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-02T00:00:00", "Submission Date": "2024-07-07T00:00:00", "Generation": 1, "Base Model": "Artples/L-MChat-7b (Merge)"}, {"eval_name": "Artples_L-MChat-Small_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "PhiForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Artples/L-MChat-Small\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Artples/L-MChat-Small</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Artples__L-MChat-Small-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Artples/L-MChat-Small", "Model sha": "52484c277f6062c12dc6d6b6397ee0d0c21b0126", "Average \u2b06\ufe0f": 14.866272594915294, "Hub License": "mit", "Hub \u2764\ufe0f": 1, "#Params (B)": 2, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3287056122200206, "IFEval": 32.87056122200207, "BBH Raw": 0.4822562766525726, "BBH": 26.856515500031357, "MATH Lvl 5 Raw": 0.0158610271903323, "MATH Lvl 5": 1.5861027190332326, "GPQA Raw": 0.2676174496644295, "GPQA": 2.348993288590602, "MUSR Raw": 0.36959375, "MUSR": 9.265885416666665, "MMLU-PRO Raw": 0.2464261968085106, "MMLU-PRO": 16.269577423167846, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-11T00:00:00", "Submission Date": "2024-07-07T00:00:00", "Generation": 1, "Base Model": "Artples/L-MChat-Small (Merge)"}, {"eval_name": "Aryanne_SuperHeart_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Aryanne/SuperHeart\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Aryanne/SuperHeart</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Aryanne__SuperHeart-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Aryanne/SuperHeart", "Model sha": "02b5050d7e600ce3db81a19638f6043c895d60cf", "Average \u2b06\ufe0f": 25.26767259596917, "Hub License": "llama3.1", "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.5192234382549413, "IFEval": 51.92234382549414, "BBH Raw": 0.5215375046264326, "BBH": 31.893554212659296, "MATH Lvl 5 Raw": 0.1389728096676737, "MATH Lvl 5": 13.897280966767372, "GPQA Raw": 0.3011744966442953, "GPQA": 6.823266219239373, "MUSR Raw": 0.4435729166666666, "MUSR": 14.713281249999996, "MMLU-PRO Raw": 0.3912067819148936, "MMLU-PRO": 32.35630910165484, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-23T00:00:00", "Submission Date": "2024-09-23T00:00:00", "Generation": 1, "Base Model": "Aryanne/SuperHeart (Merge)"}, {"eval_name": "AtAndDev_Qwen2.5-1.5B-continuous-learnt_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/AtAndDev/Qwen2.5-1.5B-continuous-learnt\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">AtAndDev/Qwen2.5-1.5B-continuous-learnt</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/AtAndDev__Qwen2.5-1.5B-continuous-learnt-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "AtAndDev/Qwen2.5-1.5B-continuous-learnt", "Model sha": "01c0981db9cf0f146fe050065f17343af75a8aa6", "Average \u2b06\ufe0f": 16.518524239214223, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 1, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4605214165081982, "IFEval": 46.05214165081983, "BBH Raw": 0.4257747085793333, "BBH": 19.53766599736009, "MATH Lvl 5 Raw": 0.0747734138972809, "MATH Lvl 5": 7.477341389728097, "GPQA Raw": 0.2659395973154362, "GPQA": 2.1252796420581683, "MUSR Raw": 0.3636458333333333, "MUSR": 3.789062500000001, "MMLU-PRO Raw": 0.2811668882978723, "MMLU-PRO": 20.12965425531915, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-13T00:00:00", "Submission Date": "2024-10-13T00:00:00", "Generation": 0, "Base Model": "AtAndDev/Qwen2.5-1.5B-continuous-learnt"}, {"eval_name": "Azure99_blossom-v5-32b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Azure99/blossom-v5-32b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Azure99/blossom-v5-32b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Azure99__blossom-v5-32b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Azure99/blossom-v5-32b", "Model sha": "ccd4d86e3de01187043683dea1e28df904f7408e", "Average \u2b06\ufe0f": 26.22667403875295, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 4, "#Params (B)": 32, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5235441960664371, "IFEval": 52.3544196066437, "BBH Raw": 0.5954545257004673, "BBH": 42.883055884713976, "MATH Lvl 5 Raw": 0.0966767371601208, "MATH Lvl 5": 9.667673716012084, "GPQA Raw": 0.311241610738255, "GPQA": 8.165548098434002, "MUSR Raw": 0.4019999999999999, "MUSR": 8.350000000000001, "MMLU-PRO Raw": 0.4234541223404255, "MMLU-PRO": 35.93934692671394, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-29T00:00:00", "Submission Date": "2024-09-21T00:00:00", "Generation": 0, "Base Model": "Azure99/blossom-v5-32b"}, {"eval_name": "Azure99_blossom-v5-llama3-8b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Azure99/blossom-v5-llama3-8b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Azure99/blossom-v5-llama3-8b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Azure99__blossom-v5-llama3-8b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Azure99/blossom-v5-llama3-8b", "Model sha": "91ea35e2e65516988021e4bb3b908e3e497e05c2", "Average \u2b06\ufe0f": 14.410141056732575, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 4, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.434293230849701, "IFEval": 43.4293230849701, "BBH Raw": 0.4184909197087261, "BBH": 18.306535405618444, "MATH Lvl 5 Raw": 0.0400302114803625, "MATH Lvl 5": 4.003021148036254, "GPQA Raw": 0.2651006711409396, "GPQA": 2.0134228187919474, "MUSR Raw": 0.3670208333333333, "MUSR": 5.3109375000000005, "MMLU-PRO Raw": 0.2205784574468085, "MMLU-PRO": 13.397606382978722, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-20T00:00:00", "Submission Date": "2024-09-21T00:00:00", "Generation": 0, "Base Model": "Azure99/blossom-v5-llama3-8b"}, {"eval_name": "Azure99_blossom-v5.1-34b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Azure99/blossom-v5.1-34b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Azure99/blossom-v5.1-34b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Azure99__blossom-v5.1-34b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Azure99/blossom-v5.1-34b", "Model sha": "2c803204f5dbf4ce37e2df98eb0205cdc53de10d", "Average \u2b06\ufe0f": 28.38528793460612, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 5, "#Params (B)": 34, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5696562897556262, "IFEval": 56.96562897556262, "BBH Raw": 0.6109110096611161, "BBH": 44.14770458838461, "MATH Lvl 5 Raw": 0.1442598187311178, "MATH Lvl 5": 14.425981873111782, "GPQA Raw": 0.3095637583892617, "GPQA": 7.941834451901568, "MUSR Raw": 0.3927916666666666, "MUSR": 7.298958333333334, "MMLU-PRO Raw": 0.4557845744680851, "MMLU-PRO": 39.53161938534279, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-19T00:00:00", "Submission Date": "2024-07-27T00:00:00", "Generation": 0, "Base Model": "Azure99/blossom-v5.1-34b"}, {"eval_name": "Azure99_blossom-v5.1-9b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Azure99/blossom-v5.1-9b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Azure99/blossom-v5.1-9b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Azure99__blossom-v5.1-9b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Azure99/blossom-v5.1-9b", "Model sha": "6044a3dc1e04529fe883aa513d37f266a320d793", "Average \u2b06\ufe0f": 24.68268181951471, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 2, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5085816744016985, "IFEval": 50.85816744016986, "BBH Raw": 0.5343292377916368, "BBH": 34.20124449031171, "MATH Lvl 5 Raw": 0.1049848942598187, "MATH Lvl 5": 10.498489425981871, "GPQA Raw": 0.3355704697986577, "GPQA": 11.409395973154364, "MUSR Raw": 0.3993958333333333, "MUSR": 8.024479166666667, "MMLU-PRO Raw": 0.397938829787234, "MMLU-PRO": 33.10431442080379, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-15T00:00:00", "Submission Date": "2024-07-24T00:00:00", "Generation": 0, "Base Model": "Azure99/blossom-v5.1-9b"}, {"eval_name": "BAAI_Gemma2-9B-IT-Simpo-Infinity-Preference_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/BAAI/Gemma2-9B-IT-Simpo-Infinity-Preference\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">BAAI/Gemma2-9B-IT-Simpo-Infinity-Preference</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/BAAI__Gemma2-9B-IT-Simpo-Infinity-Preference-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "BAAI/Gemma2-9B-IT-Simpo-Infinity-Preference", "Model sha": "028a91b1a4f14d365c6db08093b03348455c7bad", "Average \u2b06\ufe0f": 20.984068550093443, "Hub License": null, "Hub \u2764\ufe0f": 13, "#Params (B)": 9, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.31763831079314, "IFEval": 31.763831079313995, "BBH Raw": 0.5979459664230056, "BBH": 42.19084405906616, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.3397651006711409, "GPQA": 11.968680089485462, "MUSR Raw": 0.3965729166666666, "MUSR": 8.104947916666669, "MMLU-PRO Raw": 0.3868849734042553, "MMLU-PRO": 31.876108156028373, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-28T00:00:00", "Submission Date": "2024-09-05T00:00:00", "Generation": 2, "Base Model": "google/gemma-2-9b"}, {"eval_name": "BAAI_Infinity-Instruct-3M-0613-Llama3-70B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/BAAI/Infinity-Instruct-3M-0613-Llama3-70B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">BAAI/Infinity-Instruct-3M-0613-Llama3-70B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/BAAI__Infinity-Instruct-3M-0613-Llama3-70B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "BAAI/Infinity-Instruct-3M-0613-Llama3-70B", "Model sha": "9fc53668064bdda22975ca72c5a287f8241c95b3", "Average \u2b06\ufe0f": 34.47048862926395, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 5, "#Params (B)": 70, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6821134589555713, "IFEval": 68.21134589555712, "BBH Raw": 0.6641614484348598, "BBH": 51.32716098252212, "MATH Lvl 5 Raw": 0.1487915407854985, "MATH Lvl 5": 14.879154078549847, "GPQA Raw": 0.3582214765100671, "GPQA": 14.429530201342288, "MUSR Raw": 0.4522604166666666, "MUSR": 16.53255208333333, "MMLU-PRO Raw": 0.4729886968085106, "MMLU-PRO": 41.44318853427896, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-27T00:00:00", "Submission Date": "2024-06-28T00:00:00", "Generation": 0, "Base Model": "BAAI/Infinity-Instruct-3M-0613-Llama3-70B"}, {"eval_name": "BAAI_Infinity-Instruct-3M-0613-Mistral-7B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/BAAI/Infinity-Instruct-3M-0613-Mistral-7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">BAAI/Infinity-Instruct-3M-0613-Mistral-7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/BAAI__Infinity-Instruct-3M-0613-Mistral-7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "BAAI/Infinity-Instruct-3M-0613-Mistral-7B", "Model sha": "c7a742e539ec264b9eaeefe2aed29e92e8a7ebd6", "Average \u2b06\ufe0f": 22.041767671653208, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 11, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5319873491225504, "IFEval": 53.19873491225504, "BBH Raw": 0.4958233376325889, "BBH": 28.992936470320583, "MATH Lvl 5 Raw": 0.066465256797583, "MATH Lvl 5": 6.646525679758309, "GPQA Raw": 0.2961409395973154, "GPQA": 6.152125279642054, "MUSR Raw": 0.4350833333333333, "MUSR": 13.252083333333331, "MMLU-PRO Raw": 0.3160738031914893, "MMLU-PRO": 24.00820035460993, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-21T00:00:00", "Submission Date": "2024-06-27T00:00:00", "Generation": 0, "Base Model": "BAAI/Infinity-Instruct-3M-0613-Mistral-7B"}, {"eval_name": "BAAI_Infinity-Instruct-3M-0625-Llama3-70B_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/BAAI/Infinity-Instruct-3M-0625-Llama3-70B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">BAAI/Infinity-Instruct-3M-0625-Llama3-70B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/BAAI__Infinity-Instruct-3M-0625-Llama3-70B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "BAAI/Infinity-Instruct-3M-0625-Llama3-70B", "Model sha": "6d8ceada57e55cff3503191adc4d6379ff321fe2", "Average \u2b06\ufe0f": 35.877866389384245, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 3, "#Params (B)": 70, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7442120240960651, "IFEval": 74.42120240960651, "BBH Raw": 0.6670337872930245, "BBH": 52.02816164280523, "MATH Lvl 5 Raw": 0.1631419939577039, "MATH Lvl 5": 16.314199395770395, "GPQA Raw": 0.3573825503355705, "GPQA": 14.317673378076066, "MUSR Raw": 0.46165625, "MUSR": 18.34036458333333, "MMLU-PRO Raw": 0.4586103723404255, "MMLU-PRO": 39.84559692671394, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-09T00:00:00", "Submission Date": "2024-08-30T00:00:00", "Generation": 0, "Base Model": "BAAI/Infinity-Instruct-3M-0625-Llama3-70B"}, {"eval_name": "BAAI_Infinity-Instruct-3M-0625-Llama3-8B_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/BAAI/Infinity-Instruct-3M-0625-Llama3-8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">BAAI/Infinity-Instruct-3M-0625-Llama3-8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/BAAI__Infinity-Instruct-3M-0625-Llama3-8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "BAAI/Infinity-Instruct-3M-0625-Llama3-8B", "Model sha": "7be7c0ff1e35c3bb781c47222da99a1724f5f1da", "Average \u2b06\ufe0f": 21.470890468346145, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 3, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6050268842227512, "IFEval": 60.50268842227513, "BBH Raw": 0.4954985723563075, "BBH": 28.9882222457564, "MATH Lvl 5 Raw": 0.052870090634441, "MATH Lvl 5": 5.287009063444108, "GPQA Raw": 0.2751677852348993, "GPQA": 3.355704697986576, "MUSR Raw": 0.3712083333333333, "MUSR": 5.667708333333335, "MMLU-PRO Raw": 0.3252160904255319, "MMLU-PRO": 25.02401004728132, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-09T00:00:00", "Submission Date": "2024-07-13T00:00:00", "Generation": 0, "Base Model": "BAAI/Infinity-Instruct-3M-0625-Llama3-8B"}, {"eval_name": "BAAI_Infinity-Instruct-3M-0625-Mistral-7B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/BAAI/Infinity-Instruct-3M-0625-Mistral-7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">BAAI/Infinity-Instruct-3M-0625-Mistral-7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/BAAI__Infinity-Instruct-3M-0625-Mistral-7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "BAAI/Infinity-Instruct-3M-0625-Mistral-7B", "Model sha": "302e3ae0bcc50dae3fb69fc1b08b518398e8c407", "Average \u2b06\ufe0f": 22.692367814235983, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 3, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5867420666054957, "IFEval": 58.67420666054956, "BBH Raw": 0.4939670574681802, "BBH": 28.82328942958971, "MATH Lvl 5 Raw": 0.0672205438066465, "MATH Lvl 5": 6.722054380664652, "GPQA Raw": 0.2869127516778523, "GPQA": 4.921700223713646, "MUSR Raw": 0.4272395833333333, "MUSR": 12.23828125, "MMLU-PRO Raw": 0.3229720744680851, "MMLU-PRO": 24.774674940898343, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-09T00:00:00", "Submission Date": "2024-08-05T00:00:00", "Generation": 0, "Base Model": "BAAI/Infinity-Instruct-3M-0625-Mistral-7B"}, {"eval_name": "BAAI_Infinity-Instruct-3M-0625-Qwen2-7B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/BAAI/Infinity-Instruct-3M-0625-Qwen2-7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">BAAI/Infinity-Instruct-3M-0625-Qwen2-7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/BAAI__Infinity-Instruct-3M-0625-Qwen2-7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "BAAI/Infinity-Instruct-3M-0625-Qwen2-7B", "Model sha": "503c24156d7682458686a7b5324f7f886e63470d", "Average \u2b06\ufe0f": 24.00947568501149, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 8, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5553930238434022, "IFEval": 55.53930238434022, "BBH Raw": 0.5345911997776569, "BBH": 34.65682860864863, "MATH Lvl 5 Raw": 0.0611782477341389, "MATH Lvl 5": 6.117824773413897, "GPQA Raw": 0.3129194630872483, "GPQA": 8.389261744966444, "MUSR Raw": 0.3887604166666666, "MUSR": 6.461718749999999, "MMLU-PRO Raw": 0.3960272606382978, "MMLU-PRO": 32.89191784869976, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-09T00:00:00", "Submission Date": "2024-08-05T00:00:00", "Generation": 0, "Base Model": "BAAI/Infinity-Instruct-3M-0625-Qwen2-7B"}, {"eval_name": "BAAI_Infinity-Instruct-3M-0625-Yi-1.5-9B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/BAAI/Infinity-Instruct-3M-0625-Yi-1.5-9B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">BAAI/Infinity-Instruct-3M-0625-Yi-1.5-9B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/BAAI__Infinity-Instruct-3M-0625-Yi-1.5-9B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "BAAI/Infinity-Instruct-3M-0625-Yi-1.5-9B", "Model sha": "a42c86c61b98ca4fdf238d688fe6ea11cf414d29", "Average \u2b06\ufe0f": 27.742140673256547, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 3, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5185984299436606, "IFEval": 51.85984299436606, "BBH Raw": 0.5509115146247398, "BBH": 35.37870748220464, "MATH Lvl 5 Raw": 0.1397280966767371, "MATH Lvl 5": 13.972809667673715, "GPQA Raw": 0.3540268456375839, "GPQA": 13.870246085011187, "MUSR Raw": 0.45753125, "MUSR": 16.724739583333335, "MMLU-PRO Raw": 0.4118184840425531, "MMLU-PRO": 34.64649822695036, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-09T00:00:00", "Submission Date": "2024-08-05T00:00:00", "Generation": 0, "Base Model": "BAAI/Infinity-Instruct-3M-0625-Yi-1.5-9B"}, {"eval_name": "BAAI_Infinity-Instruct-7M-0729-Llama3_1-8B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/BAAI/Infinity-Instruct-7M-0729-Llama3_1-8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">BAAI/Infinity-Instruct-7M-0729-Llama3_1-8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/BAAI__Infinity-Instruct-7M-0729-Llama3_1-8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "BAAI/Infinity-Instruct-7M-0729-Llama3_1-8B", "Model sha": "0aca33fd7500a781d041e8bf7e5e3789b03f54f4", "Average \u2b06\ufe0f": 22.94389900442672, "Hub License": "llama3.1", "Hub \u2764\ufe0f": 8, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6131952109292234, "IFEval": 61.31952109292233, "BBH Raw": 0.5077335431381055, "BBH": 30.88880460756557, "MATH Lvl 5 Raw": 0.0974320241691842, "MATH Lvl 5": 9.743202416918429, "GPQA Raw": 0.2927852348993288, "GPQA": 5.7046979865771785, "MUSR Raw": 0.35784375, "MUSR": 5.297135416666668, "MMLU-PRO Raw": 0.3223902925531915, "MMLU-PRO": 24.710032505910167, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-02T00:00:00", "Submission Date": "2024-08-05T00:00:00", "Generation": 0, "Base Model": "BAAI/Infinity-Instruct-7M-0729-Llama3_1-8B"}, {"eval_name": "BAAI_Infinity-Instruct-7M-0729-mistral-7B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/BAAI/Infinity-Instruct-7M-0729-mistral-7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">BAAI/Infinity-Instruct-7M-0729-mistral-7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/BAAI__Infinity-Instruct-7M-0729-mistral-7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "BAAI/Infinity-Instruct-7M-0729-mistral-7B", "Model sha": "36651591cb13346ecbde23832013e024029700fa", "Average \u2b06\ufe0f": 22.76327714114969, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 3, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6161928128476886, "IFEval": 61.61928128476886, "BBH Raw": 0.4963813586525743, "BBH": 28.697915491520025, "MATH Lvl 5 Raw": 0.0558912386706948, "MATH Lvl 5": 5.589123867069486, "GPQA Raw": 0.2902684563758389, "GPQA": 5.369127516778524, "MUSR Raw": 0.4061875, "MUSR": 10.04010416666667, "MMLU-PRO Raw": 0.3273769946808511, "MMLU-PRO": 25.26411052009456, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-25T00:00:00", "Submission Date": "2024-08-05T00:00:00", "Generation": 0, "Base Model": "BAAI/Infinity-Instruct-7M-0729-mistral-7B"}, {"eval_name": "BAAI_Infinity-Instruct-7M-Gen-Llama3_1-70B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/BAAI/Infinity-Instruct-7M-Gen-Llama3_1-70B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">BAAI/Infinity-Instruct-7M-Gen-Llama3_1-70B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/BAAI__Infinity-Instruct-7M-Gen-Llama3_1-70B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "BAAI/Infinity-Instruct-7M-Gen-Llama3_1-70B", "Model sha": "1ef63c4993a8c723c9695c827295c17080a64435", "Average \u2b06\ufe0f": 36.79210721550283, "Hub License": "llama3.1", "Hub \u2764\ufe0f": 12, "#Params (B)": 70, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7335458804859993, "IFEval": 73.35458804859994, "BBH Raw": 0.6695200461367471, "BBH": 52.49894685232329, "MATH Lvl 5 Raw": 0.2107250755287009, "MATH Lvl 5": 21.07250755287009, "GPQA Raw": 0.3758389261744966, "GPQA": 16.778523489932887, "MUSR Raw": 0.45390625, "MUSR": 16.97161458333333, "MMLU-PRO Raw": 0.460688164893617, "MMLU-PRO": 40.07646276595744, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-25T00:00:00", "Submission Date": "2024-09-26T00:00:00", "Generation": 0, "Base Model": "BAAI/Infinity-Instruct-7M-Gen-Llama3_1-70B"}, {"eval_name": "BAAI_Infinity-Instruct-7M-Gen-Llama3_1-8B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/BAAI/Infinity-Instruct-7M-Gen-Llama3_1-8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">BAAI/Infinity-Instruct-7M-Gen-Llama3_1-8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/BAAI__Infinity-Instruct-7M-Gen-Llama3_1-8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "BAAI/Infinity-Instruct-7M-Gen-Llama3_1-8B", "Model sha": "56f9c2845ae024eb8b1dd9ea0d8891cbaf33c596", "Average \u2b06\ufe0f": 22.94389900442672, "Hub License": "llama3.1", "Hub \u2764\ufe0f": 8, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6131952109292234, "IFEval": 61.31952109292233, "BBH Raw": 0.5077335431381055, "BBH": 30.88880460756557, "MATH Lvl 5 Raw": 0.0974320241691842, "MATH Lvl 5": 9.743202416918429, "GPQA Raw": 0.2927852348993288, "GPQA": 5.7046979865771785, "MUSR Raw": 0.35784375, "MUSR": 5.297135416666668, "MMLU-PRO Raw": 0.3223902925531915, "MMLU-PRO": 24.710032505910167, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-02T00:00:00", "Submission Date": "2024-08-29T00:00:00", "Generation": 0, "Base Model": "BAAI/Infinity-Instruct-7M-Gen-Llama3_1-8B"}, {"eval_name": "BAAI_Infinity-Instruct-7M-Gen-mistral-7B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/BAAI/Infinity-Instruct-7M-Gen-mistral-7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">BAAI/Infinity-Instruct-7M-Gen-mistral-7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/BAAI__Infinity-Instruct-7M-Gen-mistral-7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "BAAI/Infinity-Instruct-7M-Gen-mistral-7B", "Model sha": "82c83d670a8954f4250547b53a057dea1fbd460d", "Average \u2b06\ufe0f": 22.73788156112572, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 3, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6146690780462506, "IFEval": 61.46690780462506, "BBH Raw": 0.4963813586525743, "BBH": 28.697915491520025, "MATH Lvl 5 Raw": 0.0558912386706948, "MATH Lvl 5": 5.589123867069486, "GPQA Raw": 0.2902684563758389, "GPQA": 5.369127516778524, "MUSR Raw": 0.4061875, "MUSR": 10.04010416666667, "MMLU-PRO Raw": 0.3273769946808511, "MMLU-PRO": 25.26411052009456, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-25T00:00:00", "Submission Date": "2024-08-29T00:00:00", "Generation": 0, "Base Model": "BAAI/Infinity-Instruct-7M-Gen-mistral-7B"}, {"eval_name": "BAAI_OPI-Llama-3.1-8B-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/BAAI/OPI-Llama-3.1-8B-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">BAAI/OPI-Llama-3.1-8B-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/BAAI__OPI-Llama-3.1-8B-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "BAAI/OPI-Llama-3.1-8B-Instruct", "Model sha": "48504799d009b4e1b29e6d2948a7cde68acdc3b0", "Average \u2b06\ufe0f": 8.305018294278616, "Hub License": "llama3.1", "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2074551080023227, "IFEval": 20.745510800232275, "BBH Raw": 0.3551224419497605, "BBH": 9.76871171424153, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2743288590604026, "GPQA": 3.243847874720355, "MUSR Raw": 0.3233020833333333, "MUSR": 3.579427083333334, "MMLU-PRO Raw": 0.2124335106382978, "MMLU-PRO": 12.492612293144209, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-06T00:00:00", "Submission Date": "2024-09-21T00:00:00", "Generation": 2, "Base Model": "meta-llama/Meta-Llama-3.1-8B"}, {"eval_name": "BEE-spoke-data_Meta-Llama-3-8Bee_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/BEE-spoke-data/Meta-Llama-3-8Bee\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">BEE-spoke-data/Meta-Llama-3-8Bee</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/BEE-spoke-data__Meta-Llama-3-8Bee-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "BEE-spoke-data/Meta-Llama-3-8Bee", "Model sha": "8143e34e77a49a30ec2617c5c9cc22cb3cda2287", "Average \u2b06\ufe0f": 14.494166359049911, "Hub License": "llama3", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1950657588531762, "IFEval": 19.506575885317623, "BBH Raw": 0.4626364190575274, "BBH": 24.19903269979749, "MATH Lvl 5 Raw": 0.0385196374622356, "MATH Lvl 5": 3.8519637462235647, "GPQA Raw": 0.313758389261745, "GPQA": 8.501118568232664, "MUSR Raw": 0.36540625, "MUSR": 6.242447916666666, "MMLU-PRO Raw": 0.3219747340425531, "MMLU-PRO": 24.66385933806146, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-28T00:00:00", "Submission Date": "2024-07-04T00:00:00", "Generation": 1, "Base Model": "meta-llama/Meta-Llama-3-8B"}, {"eval_name": "BEE-spoke-data_smol_llama-101M-GQA_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/BEE-spoke-data/smol_llama-101M-GQA\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">BEE-spoke-data/smol_llama-101M-GQA</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/BEE-spoke-data__smol_llama-101M-GQA-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "BEE-spoke-data/smol_llama-101M-GQA", "Model sha": "bb26643db413bada7e0c3c50752bf9da82403dba", "Average \u2b06\ufe0f": 3.918894933596659, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 26, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1384371246071534, "IFEval": 13.843712460715349, "BBH Raw": 0.3017560771912554, "BBH": 3.1980040943527936, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2575503355704698, "GPQA": 1.0067114093959737, "MUSR Raw": 0.3712708333333334, "MUSR": 4.275520833333334, "MMLU-PRO Raw": 0.1107047872340425, "MMLU-PRO": 1.1894208037825047, "Maintainer's Highlight": false, "Upload To Hub Date": "2023-10-26T00:00:00", "Submission Date": "2024-07-06T00:00:00", "Generation": 0, "Base Model": "BEE-spoke-data/smol_llama-101M-GQA"}, {"eval_name": "BEE-spoke-data_smol_llama-220M-GQA_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/BEE-spoke-data/smol_llama-220M-GQA\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">BEE-spoke-data/smol_llama-220M-GQA</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/BEE-spoke-data__smol_llama-220M-GQA-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "BEE-spoke-data/smol_llama-220M-GQA", "Model sha": "8845b1d3c0bc73522ef2700aab467183cbdca9f7", "Average \u2b06\ufe0f": 6.401567328738996, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 11, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2386046800267734, "IFEval": 23.860468002677344, "BBH Raw": 0.3031673138870895, "BBH": 3.03784275772053, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2558724832214765, "GPQA": 0.7829977628635317, "MUSR Raw": 0.405875, "MUSR": 9.067708333333334, "MMLU-PRO Raw": 0.1149434840425532, "MMLU-PRO": 1.6603871158392434, "Maintainer's Highlight": false, "Upload To Hub Date": "2023-12-22T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "BEE-spoke-data/smol_llama-220M-GQA"}, {"eval_name": "BEE-spoke-data_smol_llama-220M-GQA-fineweb_edu_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe9 continuously pretrained", "T": "\ud83d\udfe9", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/BEE-spoke-data/smol_llama-220M-GQA-fineweb_edu\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">BEE-spoke-data/smol_llama-220M-GQA-fineweb_edu</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/BEE-spoke-data__smol_llama-220M-GQA-fineweb_edu-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "BEE-spoke-data/smol_llama-220M-GQA-fineweb_edu", "Model sha": "dec16b41d5e94070dbc1f8449a554373fd4cc1d1", "Average \u2b06\ufe0f": 6.516557780898393, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1988124842085666, "IFEval": 19.88124842085666, "BBH Raw": 0.2929051716451059, "BBH": 2.314902449149024, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.259228187919463, "GPQA": 1.230425055928408, "MUSR Raw": 0.4367604166666667, "MUSR": 14.261718750000002, "MMLU-PRO Raw": 0.1126994680851063, "MMLU-PRO": 1.4110520094562635, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-08T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "BEE-spoke-data/smol_llama-220M-GQA"}, {"eval_name": "BEE-spoke-data_smol_llama-220M-openhermes_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/BEE-spoke-data/smol_llama-220M-openhermes\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">BEE-spoke-data/smol_llama-220M-openhermes</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/BEE-spoke-data__smol_llama-220M-openhermes-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "BEE-spoke-data/smol_llama-220M-openhermes", "Model sha": "fb4bcd4b7eee363baacb4176a26cea2aaeb173f4", "Average \u2b06\ufe0f": 4.761771603157545, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 5, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1555229014570229, "IFEval": 15.552290145702292, "BBH Raw": 0.3027519140192772, "BBH": 3.107692077087363, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2676174496644295, "GPQA": 2.348993288590602, "MUSR Raw": 0.3847291666666666, "MUSR": 6.224479166666669, "MMLU-PRO Raw": 0.1120345744680851, "MMLU-PRO": 1.337174940898345, "Maintainer's Highlight": false, "Upload To Hub Date": "2023-12-30T00:00:00", "Submission Date": "2024-09-21T00:00:00", "Generation": 1, "Base Model": "BEE-spoke-data/smol_llama-220M-GQA"}, {"eval_name": "BEE-spoke-data_tFINE-900m-e16-d32-flan_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "T5ForConditionalGeneration", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/BEE-spoke-data/tFINE-900m-e16-d32-flan\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">BEE-spoke-data/tFINE-900m-e16-d32-flan</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/BEE-spoke-data__tFINE-900m-e16-d32-flan-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "BEE-spoke-data/tFINE-900m-e16-d32-flan", "Model sha": "d9ffec9798402d13d8f2c56ec3de3ad092445297", "Average \u2b06\ufe0f": 4.433887493354263, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1505771353342464, "IFEval": 15.057713533424646, "BBH Raw": 0.3028043484762061, "BBH": 4.411893932611097, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2332214765100671, "GPQA": 0.0, "MUSR Raw": 0.3724166666666667, "MUSR": 3.718750000000001, "MMLU-PRO Raw": 0.1307347074468085, "MMLU-PRO": 3.4149674940898342, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-06T00:00:00", "Submission Date": "2024-09-13T00:00:00", "Generation": 1, "Base Model": "pszemraj/tFINE-900m-e16-d32-1024ctx"}, {"eval_name": "BEE-spoke-data_tFINE-900m-e16-d32-flan-infinity-instruct-7m-T2T_en-1024_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "T5ForConditionalGeneration", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/BEE-spoke-data/tFINE-900m-e16-d32-flan-infinity-instruct-7m-T2T_en-1024\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">BEE-spoke-data/tFINE-900m-e16-d32-flan-infinity-instruct-7m-T2T_en-1024</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/BEE-spoke-data__tFINE-900m-e16-d32-flan-infinity-instruct-7m-T2T_en-1024-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "BEE-spoke-data/tFINE-900m-e16-d32-flan-infinity-instruct-7m-T2T_en-1024", "Model sha": "b1e2f12f5224be9f7da0cb5ff30e1bbb3f10f6ca", "Average \u2b06\ufe0f": 5.823652685243958, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1320673590517604, "IFEval": 13.206735905176044, "BBH Raw": 0.3137786304497592, "BBH": 4.737018282627999, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2541946308724832, "GPQA": 0.5592841163310973, "MUSR Raw": 0.4392708333333333, "MUSR": 13.808854166666668, "MMLU-PRO Raw": 0.1236702127659574, "MMLU-PRO": 2.6300236406619386, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-10T00:00:00", "Submission Date": "2024-09-14T00:00:00", "Generation": 2, "Base Model": "pszemraj/tFINE-900m-e16-d32-1024ctx"}, {"eval_name": "BEE-spoke-data_tFINE-900m-e16-d32-instruct_2e_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "T5ForConditionalGeneration", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/BEE-spoke-data/tFINE-900m-e16-d32-instruct_2e\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">BEE-spoke-data/tFINE-900m-e16-d32-instruct_2e</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/BEE-spoke-data__tFINE-900m-e16-d32-instruct_2e-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "BEE-spoke-data/tFINE-900m-e16-d32-instruct_2e", "Model sha": "4c626138c9f4e0c3eafe74b2755eb89334c7ca59", "Average \u2b06\ufe0f": 5.681552326682065, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1402855534426433, "IFEval": 14.02855534426433, "BBH Raw": 0.3134567463880902, "BBH": 5.013070335904381, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.259228187919463, "GPQA": 1.230425055928408, "MUSR Raw": 0.4206979166666666, "MUSR": 11.187239583333335, "MMLU-PRO Raw": 0.1236702127659574, "MMLU-PRO": 2.6300236406619386, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-17T00:00:00", "Submission Date": "2024-09-22T00:00:00", "Generation": 3, "Base Model": "pszemraj/tFINE-900m-e16-d32-1024ctx"}, {"eval_name": "BEE-spoke-data_tFINE-900m-instruct-orpo_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "T5ForConditionalGeneration", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/BEE-spoke-data/tFINE-900m-instruct-orpo\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">BEE-spoke-data/tFINE-900m-instruct-orpo</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/BEE-spoke-data__tFINE-900m-instruct-orpo-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "BEE-spoke-data/tFINE-900m-instruct-orpo", "Model sha": "e0a21c79bac74442252d36e2c01403afa3f0971b", "Average \u2b06\ufe0f": 3.4319574717820847, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.1329915734695053, "IFEval": 13.299157346950537, "BBH Raw": 0.3022093376704509, "BBH": 3.267300577931774, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.259228187919463, "GPQA": 1.230425055928408, "MUSR Raw": 0.3408541666666667, "MUSR": 1.1067708333333328, "MMLU-PRO Raw": 0.1151928191489361, "MMLU-PRO": 1.6880910165484628, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-22T00:00:00", "Submission Date": "2024-09-23T00:00:00", "Generation": 0, "Base Model": "BEE-spoke-data/tFINE-900m-instruct-orpo"}, {"eval_name": "Ba2han_Llama-Phi-3_DoRA_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Ba2han/Llama-Phi-3_DoRA\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Ba2han/Llama-Phi-3_DoRA</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Ba2han__Llama-Phi-3_DoRA-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Ba2han/Llama-Phi-3_DoRA", "Model sha": "36f99064a7be8ba475c2ee5c5424e95c263ccb87", "Average \u2b06\ufe0f": 25.142603963893578, "Hub License": "mit", "Hub \u2764\ufe0f": 5, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5130531434371911, "IFEval": 51.30531434371911, "BBH Raw": 0.5514558259029191, "BBH": 37.24916418079274, "MATH Lvl 5 Raw": 0.1019637462235649, "MATH Lvl 5": 10.196374622356496, "GPQA Raw": 0.3263422818791946, "GPQA": 10.17897091722595, "MUSR Raw": 0.4069270833333333, "MUSR": 9.532552083333336, "MMLU-PRO Raw": 0.3915392287234042, "MMLU-PRO": 32.393247635933804, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-15T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "Ba2han/Llama-Phi-3_DoRA"}, {"eval_name": "BenevolenceMessiah_Yi-Coder-9B-Chat-Instruct-TIES-MoE-v1.0_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/BenevolenceMessiah/Yi-Coder-9B-Chat-Instruct-TIES-MoE-v1.0\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">BenevolenceMessiah/Yi-Coder-9B-Chat-Instruct-TIES-MoE-v1.0</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/BenevolenceMessiah__Yi-Coder-9B-Chat-Instruct-TIES-MoE-v1.0-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "BenevolenceMessiah/Yi-Coder-9B-Chat-Instruct-TIES-MoE-v1.0", "Model sha": "d90f6e36584dc9b367461701e83c833bdeb736f2", "Average \u2b06\ufe0f": 15.045915423915163, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 28, "Available on the hub": true, "Not_Merged": false, "MoE": false, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3011531624977283, "IFEval": 30.115316249772825, "BBH Raw": 0.4908666248538678, "BBH": 26.877991478721707, "MATH Lvl 5 Raw": 0.0400302114803625, "MATH Lvl 5": 4.003021148036254, "GPQA Raw": 0.2625838926174497, "GPQA": 1.6778523489932915, "MUSR Raw": 0.4079791666666666, "MUSR": 8.930729166666667, "MMLU-PRO Raw": 0.2680352393617021, "MMLU-PRO": 18.67058215130024, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-21T00:00:00", "Submission Date": "2024-09-22T00:00:00", "Generation": 1, "Base Model": "BenevolenceMessiah/Yi-Coder-9B-Chat-Instruct-TIES-MoE-v1.0 (Merge)"}, {"eval_name": "BlackBeenie_llama-3-luminous-merged_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/BlackBeenie/llama-3-luminous-merged\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">BlackBeenie/llama-3-luminous-merged</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/BlackBeenie__llama-3-luminous-merged-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "BlackBeenie/llama-3-luminous-merged", "Model sha": "64288dd8e3305f2dc11d84fe0c653f351b2e8a9d", "Average \u2b06\ufe0f": 21.48010798383413, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4323450666453897, "IFEval": 43.234506664538976, "BBH Raw": 0.5153924501559338, "BBH": 30.64368722878725, "MATH Lvl 5 Raw": 0.0785498489425981, "MATH Lvl 5": 7.854984894259818, "GPQA Raw": 0.2927852348993288, "GPQA": 5.7046979865771785, "MUSR Raw": 0.4148958333333333, "MUSR": 10.628645833333335, "MMLU-PRO Raw": 0.3773271276595745, "MMLU-PRO": 30.814125295508276, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-15T00:00:00", "Submission Date": "2024-10-11T00:00:00", "Generation": 1, "Base Model": "BlackBeenie/llama-3-luminous-merged (Merge)"}, {"eval_name": "BoltMonkey_NeuralDaredevil-SuperNova-Lite-7B-DARETIES-abliterated_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/BoltMonkey/NeuralDaredevil-SuperNova-Lite-7B-DARETIES-abliterated\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">BoltMonkey/NeuralDaredevil-SuperNova-Lite-7B-DARETIES-abliterated</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/BoltMonkey__NeuralDaredevil-SuperNova-Lite-7B-DARETIES-abliterated-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "BoltMonkey/NeuralDaredevil-SuperNova-Lite-7B-DARETIES-abliterated", "Model sha": "969e4c9b41e733a367f5ea18ed50a6171b5e2357", "Average \u2b06\ufe0f": 27.499695445081997, "Hub License": "llama3.1", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7998909559967553, "IFEval": 79.98909559967552, "BBH Raw": 0.5151987922850448, "BBH": 30.75990006920939, "MATH Lvl 5 Raw": 0.1027190332326284, "MATH Lvl 5": 10.27190332326284, "GPQA Raw": 0.2810402684563758, "GPQA": 4.138702460850116, "MUSR Raw": 0.401875, "MUSR": 9.467708333333327, "MMLU-PRO Raw": 0.3733377659574468, "MMLU-PRO": 30.37086288416076, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-01T00:00:00", "Submission Date": "2024-10-10T00:00:00", "Generation": 1, "Base Model": "BoltMonkey/NeuralDaredevil-SuperNova-Lite-7B-DARETIES-abliterated (Merge)"}, {"eval_name": "BoltMonkey_NeuralDaredevil-SuperNova-Lite-7B-DARETIES-abliterated_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/BoltMonkey/NeuralDaredevil-SuperNova-Lite-7B-DARETIES-abliterated\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">BoltMonkey/NeuralDaredevil-SuperNova-Lite-7B-DARETIES-abliterated</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/BoltMonkey__NeuralDaredevil-SuperNova-Lite-7B-DARETIES-abliterated-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "BoltMonkey/NeuralDaredevil-SuperNova-Lite-7B-DARETIES-abliterated", "Model sha": "969e4c9b41e733a367f5ea18ed50a6171b5e2357", "Average \u2b06\ufe0f": 21.345510590269537, "Hub License": "llama3.1", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4590231696343479, "IFEval": 45.9023169634348, "BBH Raw": 0.5185441912447182, "BBH": 30.793784752659278, "MATH Lvl 5 Raw": 0.093655589123867, "MATH Lvl 5": 9.365558912386708, "GPQA Raw": 0.2743288590604026, "GPQA": 3.243847874720355, "MUSR Raw": 0.4082604166666666, "MUSR": 9.532552083333336, "MMLU-PRO Raw": 0.3631150265957447, "MMLU-PRO": 29.235002955082745, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-01T00:00:00", "Submission Date": "2024-10-01T00:00:00", "Generation": 1, "Base Model": "BoltMonkey/NeuralDaredevil-SuperNova-Lite-7B-DARETIES-abliterated (Merge)"}, {"eval_name": "BoltMonkey_SuperNeuralDreadDevil-8b_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/BoltMonkey/SuperNeuralDreadDevil-8b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">BoltMonkey/SuperNeuralDreadDevil-8b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/BoltMonkey__SuperNeuralDreadDevil-8b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "BoltMonkey/SuperNeuralDreadDevil-8b", "Model sha": "804d5864127e603abec179a159b43f446246fafc", "Average \u2b06\ufe0f": 27.47611035649425, "Hub License": null, "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7709898624538447, "IFEval": 77.09898624538445, "BBH Raw": 0.5286196012035721, "BBH": 32.61215762394777, "MATH Lvl 5 Raw": 0.1148036253776435, "MATH Lvl 5": 11.48036253776435, "GPQA Raw": 0.2919463087248322, "GPQA": 5.592841163310966, "MUSR Raw": 0.3976874999999999, "MUSR": 8.3109375, "MMLU-PRO Raw": 0.3678523936170212, "MMLU-PRO": 29.76137706855792, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-13T00:00:00", "Submission Date": "2024-10-13T00:00:00", "Generation": 1, "Base Model": "BoltMonkey/SuperNeuralDreadDevil-8b (Merge)"}, {"eval_name": "Casual-Autopsy_L3-Umbral-Mind-RP-v2.0-8B_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Casual-Autopsy/L3-Umbral-Mind-RP-v2.0-8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Casual-Autopsy/L3-Umbral-Mind-RP-v2.0-8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Casual-Autopsy__L3-Umbral-Mind-RP-v2.0-8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Casual-Autopsy/L3-Umbral-Mind-RP-v2.0-8B", "Model sha": "b46c066ea8387264858dc3461f382e7b42fd9c48", "Average \u2b06\ufe0f": 25.76086952422173, "Hub License": "llama3", "Hub \u2764\ufe0f": 12, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7122634609502786, "IFEval": 71.22634609502786, "BBH Raw": 0.5262406145493724, "BBH": 32.48627762381486, "MATH Lvl 5 Raw": 0.1012084592145015, "MATH Lvl 5": 10.120845921450153, "GPQA Raw": 0.2869127516778523, "GPQA": 4.921700223713646, "MUSR Raw": 0.3686666666666667, "MUSR": 5.550000000000002, "MMLU-PRO Raw": 0.3723404255319149, "MMLU-PRO": 30.26004728132387, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-26T00:00:00", "Submission Date": "2024-07-02T00:00:00", "Generation": 1, "Base Model": "Casual-Autopsy/L3-Umbral-Mind-RP-v2.0-8B (Merge)"}, {"eval_name": "CausalLM_14B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/CausalLM/14B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">CausalLM/14B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/CausalLM__14B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "CausalLM/14B", "Model sha": "cc054cf5953252d0709cb3267d1a85246e489e95", "Average \u2b06\ufe0f": 16.530645612803767, "Hub License": "wtfpl", "Hub \u2764\ufe0f": 302, "#Params (B)": 14, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2788213052478535, "IFEval": 27.882130524785342, "BBH Raw": 0.4700462397700626, "BBH": 24.780942674518663, "MATH Lvl 5 Raw": 0.0332326283987915, "MATH Lvl 5": 3.3232628398791544, "GPQA Raw": 0.3028523489932886, "GPQA": 7.046979865771815, "MUSR Raw": 0.4154791666666667, "MUSR": 11.468229166666667, "MMLU-PRO Raw": 0.3221409574468085, "MMLU-PRO": 24.682328605200944, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-10-22T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "CausalLM/14B"}, {"eval_name": "CausalLM_34b-beta_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/CausalLM/34b-beta\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">CausalLM/34b-beta</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/CausalLM__34b-beta-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "CausalLM/34b-beta", "Model sha": "0429951eb30ccdfff3515e711aaa7649a8a7364c", "Average \u2b06\ufe0f": 23.18453999406236, "Hub License": "gpl-3.0", "Hub \u2764\ufe0f": 62, "#Params (B)": 34, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3043247472262486, "IFEval": 30.43247472262486, "BBH Raw": 0.5590996102136266, "BBH": 36.677226262739055, "MATH Lvl 5 Raw": 0.0415407854984894, "MATH Lvl 5": 4.154078549848943, "GPQA Raw": 0.3464765100671141, "GPQA": 12.863534675615217, "MUSR Raw": 0.3748645833333333, "MUSR": 6.924739583333334, "MMLU-PRO Raw": 0.5324966755319149, "MMLU-PRO": 48.05518617021277, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-02-06T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "CausalLM/34b-beta"}, {"eval_name": "Changgil_K2S3-14b-v0.2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Changgil/K2S3-14b-v0.2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Changgil/K2S3-14b-v0.2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Changgil__K2S3-14b-v0.2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Changgil/K2S3-14b-v0.2", "Model sha": "b4f0e1eed2640df2b75847ff37e6ebb1be217b6c", "Average \u2b06\ufe0f": 15.074374892167752, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 14, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3242840108689389, "IFEval": 32.428401086893885, "BBH Raw": 0.4613311786298187, "BBH": 24.283946726650168, "MATH Lvl 5 Raw": 0.0453172205438066, "MATH Lvl 5": 4.531722054380665, "GPQA Raw": 0.2810402684563758, "GPQA": 4.138702460850116, "MUSR Raw": 0.3922604166666666, "MUSR": 6.7992187500000005, "MMLU-PRO Raw": 0.2643783244680851, "MMLU-PRO": 18.26425827423168, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-17T00:00:00", "Submission Date": "2024-06-27T00:00:00", "Generation": 0, "Base Model": "Changgil/K2S3-14b-v0.2"}, {"eval_name": "Changgil_K2S3-v0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Changgil/K2S3-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Changgil/K2S3-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Changgil__K2S3-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Changgil/K2S3-v0.1", "Model sha": "d544e389f091983bb4f11314edb526d81753c919", "Average \u2b06\ufe0f": 14.751167178103769, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 14, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3276561745058666, "IFEval": 32.76561745058666, "BBH Raw": 0.4655492067228615, "BBH": 24.559557672503782, "MATH Lvl 5 Raw": 0.0407854984894259, "MATH Lvl 5": 4.078549848942599, "GPQA Raw": 0.2642617449664429, "GPQA": 1.9015659955257265, "MUSR Raw": 0.4014062499999999, "MUSR": 7.842447916666667, "MMLU-PRO Raw": 0.2562333776595745, "MMLU-PRO": 17.359264184397162, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-29T00:00:00", "Submission Date": "2024-06-27T00:00:00", "Generation": 0, "Base Model": "Changgil/K2S3-v0.1"}, {"eval_name": "ClaudioItaly_Albacus_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/ClaudioItaly/Albacus\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">ClaudioItaly/Albacus</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/ClaudioItaly__Albacus-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "ClaudioItaly/Albacus", "Model sha": "a53faf62d0f99b67478ed9d262872c821a3ba83c", "Average \u2b06\ufe0f": 20.392281011024497, "Hub License": "mit", "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4667415790103592, "IFEval": 46.674157901035926, "BBH Raw": 0.5113043406568835, "BBH": 31.63886474402479, "MATH Lvl 5 Raw": 0.0641993957703927, "MATH Lvl 5": 6.419939577039275, "GPQA Raw": 0.2718120805369127, "GPQA": 2.9082774049217, "MUSR Raw": 0.4135312499999999, "MUSR": 10.658072916666663, "MMLU-PRO Raw": 0.3164893617021276, "MMLU-PRO": 24.054373522458626, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-08T00:00:00", "Submission Date": "2024-09-08T00:00:00", "Generation": 1, "Base Model": "ClaudioItaly/Albacus (Merge)"}, {"eval_name": "ClaudioItaly_Book-Gut12B_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/ClaudioItaly/Book-Gut12B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">ClaudioItaly/Book-Gut12B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/ClaudioItaly__Book-Gut12B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "ClaudioItaly/Book-Gut12B", "Model sha": "ae54351faca8170c93bf1de3a51bf16650f5bcf5", "Average \u2b06\ufe0f": 23.15492389275521, "Hub License": "mit", "Hub \u2764\ufe0f": 1, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3998468508003209, "IFEval": 39.984685080032094, "BBH Raw": 0.5417370194443233, "BBH": 34.63219258973313, "MATH Lvl 5 Raw": 0.0876132930513595, "MATH Lvl 5": 8.761329305135952, "GPQA Raw": 0.3070469798657718, "GPQA": 7.606263982102905, "MUSR Raw": 0.4635416666666667, "MUSR": 18.276041666666668, "MMLU-PRO Raw": 0.3670212765957447, "MMLU-PRO": 29.669030732860524, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-12T00:00:00", "Submission Date": "2024-09-17T00:00:00", "Generation": 1, "Base Model": "ClaudioItaly/Book-Gut12B (Merge)"}, {"eval_name": "ClaudioItaly_Evolutionstory-7B-v2.2_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/ClaudioItaly/Evolutionstory-7B-v2.2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">ClaudioItaly/Evolutionstory-7B-v2.2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/ClaudioItaly__Evolutionstory-7B-v2.2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "ClaudioItaly/Evolutionstory-7B-v2.2", "Model sha": "9f838721d24a5195bed59a5ed8d9af536f7f2459", "Average \u2b06\ufe0f": 20.697542281215387, "Hub License": "mit", "Hub \u2764\ufe0f": 1, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4813794066410457, "IFEval": 48.137940664104576, "BBH Raw": 0.5108043406568835, "BBH": 31.62386474402479, "MATH Lvl 5 Raw": 0.0641993957703927, "MATH Lvl 5": 6.419939577039275, "GPQA Raw": 0.2751677852348993, "GPQA": 3.355704697986576, "MUSR Raw": 0.4135312499999999, "MUSR": 10.658072916666663, "MMLU-PRO Raw": 0.315907579787234, "MMLU-PRO": 23.98973108747045, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-30T00:00:00", "Submission Date": "2024-09-01T00:00:00", "Generation": 1, "Base Model": "ClaudioItaly/Evolutionstory-7B-v2.2 (Merge)"}, {"eval_name": "CohereForAI_aya-23-35B_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "CohereForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/CohereForAI/aya-23-35B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">CohereForAI/aya-23-35B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/CohereForAI__aya-23-35B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "CohereForAI/aya-23-35B", "Model sha": "31d6fd858f20539a55401c7ad913086f54d9ca2c", "Average \u2b06\ufe0f": 24.616939161944696, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 250, "#Params (B)": 34, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6461932117891638, "IFEval": 64.61932117891638, "BBH Raw": 0.5399551450731271, "BBH": 34.85836046775463, "MATH Lvl 5 Raw": 0.0264350453172205, "MATH Lvl 5": 2.643504531722054, "GPQA Raw": 0.2944630872483221, "GPQA": 5.92841163310962, "MUSR Raw": 0.4309895833333333, "MUSR": 13.47369791666666, "MMLU-PRO Raw": 0.3356050531914893, "MMLU-PRO": 26.17833924349881, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-05-19T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "CohereForAI/aya-23-35B"}, {"eval_name": "CohereForAI_aya-23-8B_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "CohereForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/CohereForAI/aya-23-8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">CohereForAI/aya-23-8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/CohereForAI__aya-23-8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "CohereForAI/aya-23-8B", "Model sha": "ec151d218a24031eb039d92fb83d10445427efc9", "Average \u2b06\ufe0f": 15.973218797715552, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 375, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4698887839820565, "IFEval": 46.98887839820566, "BBH Raw": 0.4296161519220307, "BBH": 20.20376064673937, "MATH Lvl 5 Raw": 0.0143504531722054, "MATH Lvl 5": 1.4350453172205435, "GPQA Raw": 0.2843959731543624, "GPQA": 4.586129753914992, "MUSR Raw": 0.3940625, "MUSR": 8.424479166666664, "MMLU-PRO Raw": 0.2278091755319149, "MMLU-PRO": 14.2010195035461, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-05-19T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "CohereForAI/aya-23-8B"}, {"eval_name": "CohereForAI_c4ai-command-r-plus_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "CohereForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/CohereForAI/c4ai-command-r-plus\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">CohereForAI/c4ai-command-r-plus</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/CohereForAI__c4ai-command-r-plus-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "CohereForAI/c4ai-command-r-plus", "Model sha": "fa1bd7fb1572ceb861bbbbecfa8af83b29fa8cca", "Average \u2b06\ufe0f": 30.86054191171216, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 1669, "#Params (B)": 103, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7664186580495308, "IFEval": 76.64186580495308, "BBH Raw": 0.581542357407793, "BBH": 39.91995423143177, "MATH Lvl 5 Raw": 0.0755287009063444, "MATH Lvl 5": 7.552870090634441, "GPQA Raw": 0.3053691275167785, "GPQA": 7.38255033557047, "MUSR Raw": 0.48071875, "MUSR": 20.42317708333333, "MMLU-PRO Raw": 0.3991855053191489, "MMLU-PRO": 33.242833924349874, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-04-03T00:00:00", "Submission Date": "2024-06-13T00:00:00", "Generation": 0, "Base Model": "CohereForAI/c4ai-command-r-plus"}, {"eval_name": "CohereForAI_c4ai-command-r-plus-08-2024_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "CohereForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/CohereForAI/c4ai-command-r-plus-08-2024\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">CohereForAI/c4ai-command-r-plus-08-2024</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/CohereForAI__c4ai-command-r-plus-08-2024-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "CohereForAI/c4ai-command-r-plus-08-2024", "Model sha": "2d8cf3ab0af78b9e43546486b096f86adf3ba4d0", "Average \u2b06\ufe0f": 33.42088849285897, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 146, "#Params (B)": 103, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7539539532883859, "IFEval": 75.39539532883859, "BBH Raw": 0.5995999913027185, "BBH": 42.83686540770696, "MATH Lvl 5 Raw": 0.1102719033232628, "MATH Lvl 5": 11.027190332326285, "GPQA Raw": 0.3506711409395973, "GPQA": 13.422818791946312, "MUSR Raw": 0.4829479166666666, "MUSR": 19.835156249999997, "MMLU-PRO Raw": 0.4420711436170212, "MMLU-PRO": 38.0079048463357, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-08-21T00:00:00", "Submission Date": "2024-09-19T00:00:00", "Generation": 0, "Base Model": "CohereForAI/c4ai-command-r-plus-08-2024"}, {"eval_name": "CohereForAI_c4ai-command-r-v01_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "CohereForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/CohereForAI/c4ai-command-r-v01\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">CohereForAI/c4ai-command-r-v01</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/CohereForAI__c4ai-command-r-v01-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "CohereForAI/c4ai-command-r-v01", "Model sha": "16881ccde1c68bbc7041280e6a66637bc46bfe88", "Average \u2b06\ufe0f": 25.34997846133653, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 1056, "#Params (B)": 34, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6748194789824333, "IFEval": 67.48194789824333, "BBH Raw": 0.5406415512767856, "BBH": 34.556659257058264, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.3070469798657718, "GPQA": 7.606263982102905, "MUSR Raw": 0.4516979166666666, "MUSR": 16.12890625, "MMLU-PRO Raw": 0.3369348404255319, "MMLU-PRO": 26.326093380614655, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-03-11T00:00:00", "Submission Date": "2024-06-13T00:00:00", "Generation": 0, "Base Model": "CohereForAI/c4ai-command-r-v01"}, {"eval_name": "Columbia-NLP_LION-Gemma-2b-dpo-v1.0_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "GemmaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Columbia-NLP/LION-Gemma-2b-dpo-v1.0\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Columbia-NLP/LION-Gemma-2b-dpo-v1.0</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Columbia-NLP__LION-Gemma-2b-dpo-v1.0-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Columbia-NLP/LION-Gemma-2b-dpo-v1.0", "Model sha": "a5f780075831374f8850324448acf94976dea504", "Average \u2b06\ufe0f": 11.483994762243412, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 2, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3278312654866864, "IFEval": 32.78312654866864, "BBH Raw": 0.3919956361320746, "BBH": 14.585976093815775, "MATH Lvl 5 Raw": 0.0430513595166163, "MATH Lvl 5": 4.305135951661631, "GPQA Raw": 0.2491610738255033, "GPQA": 0.0, "MUSR Raw": 0.4120104166666666, "MUSR": 9.834635416666668, "MMLU-PRO Raw": 0.1665558510638297, "MMLU-PRO": 7.395094562647753, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-28T00:00:00", "Submission Date": "2024-07-04T00:00:00", "Generation": 0, "Base Model": "Columbia-NLP/LION-Gemma-2b-dpo-v1.0"}, {"eval_name": "Columbia-NLP_LION-Gemma-2b-dpo-v1.0_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "GemmaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Columbia-NLP/LION-Gemma-2b-dpo-v1.0\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Columbia-NLP/LION-Gemma-2b-dpo-v1.0</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Columbia-NLP__LION-Gemma-2b-dpo-v1.0-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Columbia-NLP/LION-Gemma-2b-dpo-v1.0", "Model sha": "a5f780075831374f8850324448acf94976dea504", "Average \u2b06\ufe0f": 11.085858961176552, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 2, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3102457036219453, "IFEval": 31.02457036219453, "BBH Raw": 0.388103091595545, "BBH": 14.243045647726928, "MATH Lvl 5 Raw": 0.0430513595166163, "MATH Lvl 5": 4.305135951661631, "GPQA Raw": 0.2533557046979866, "GPQA": 0.4474272930648763, "MUSR Raw": 0.4080729166666666, "MUSR": 9.109114583333335, "MMLU-PRO Raw": 0.1664727393617021, "MMLU-PRO": 7.385859929078014, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-28T00:00:00", "Submission Date": "2024-07-04T00:00:00", "Generation": 0, "Base Model": "Columbia-NLP/LION-Gemma-2b-dpo-v1.0"}, {"eval_name": "Columbia-NLP_LION-Gemma-2b-odpo-v1.0_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "GemmaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Columbia-NLP/LION-Gemma-2b-odpo-v1.0\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Columbia-NLP/LION-Gemma-2b-odpo-v1.0</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Columbia-NLP__LION-Gemma-2b-odpo-v1.0-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Columbia-NLP/LION-Gemma-2b-odpo-v1.0", "Model sha": "090d9f59c3b47ab8dd099ddd278c058aa6d2d529", "Average \u2b06\ufe0f": 11.356089829780892, "Hub License": null, "Hub \u2764\ufe0f": 4, "#Params (B)": 2, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.306648581319787, "IFEval": 30.664858131978704, "BBH Raw": 0.3895836210706875, "BBH": 14.02392166541634, "MATH Lvl 5 Raw": 0.0370090634441087, "MATH Lvl 5": 3.700906344410876, "GPQA Raw": 0.2424496644295302, "GPQA": 0.0, "MUSR Raw": 0.4279166666666666, "MUSR": 12.056250000000004, "MMLU-PRO Raw": 0.1692154255319149, "MMLU-PRO": 7.690602836879433, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-28T00:00:00", "Submission Date": "2024-07-13T00:00:00", "Generation": 0, "Base Model": "Columbia-NLP/LION-Gemma-2b-odpo-v1.0"}, {"eval_name": "Columbia-NLP_LION-Gemma-2b-sft-v1.0_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "GemmaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Columbia-NLP/LION-Gemma-2b-sft-v1.0\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Columbia-NLP/LION-Gemma-2b-sft-v1.0</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Columbia-NLP__LION-Gemma-2b-sft-v1.0-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Columbia-NLP/LION-Gemma-2b-sft-v1.0", "Model sha": "44d6f26fa7e3b0d238064d844569bf8a07b7515e", "Average \u2b06\ufe0f": 12.326311880225887, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 2, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3692469314751526, "IFEval": 36.924693147515256, "BBH Raw": 0.387877927616119, "BBH": 14.11717086360044, "MATH Lvl 5 Raw": 0.0513595166163142, "MATH Lvl 5": 5.13595166163142, "GPQA Raw": 0.2558724832214765, "GPQA": 0.7829977628635317, "MUSR Raw": 0.4027395833333333, "MUSR": 8.309114583333335, "MMLU-PRO Raw": 0.1781914893617021, "MMLU-PRO": 8.687943262411347, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-02T00:00:00", "Submission Date": "2024-07-04T00:00:00", "Generation": 0, "Base Model": "Columbia-NLP/LION-Gemma-2b-sft-v1.0"}, {"eval_name": "Columbia-NLP_LION-LLaMA-3-8b-dpo-v1.0_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Columbia-NLP/LION-LLaMA-3-8b-dpo-v1.0\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Columbia-NLP/LION-LLaMA-3-8b-dpo-v1.0</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Columbia-NLP__LION-LLaMA-3-8b-dpo-v1.0-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Columbia-NLP/LION-LLaMA-3-8b-dpo-v1.0", "Model sha": "3cddd4a6f5939a0a4db1092a0275342b7b9912f3", "Average \u2b06\ufe0f": 21.34482022645467, "Hub License": null, "Hub \u2764\ufe0f": 2, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4957424079220912, "IFEval": 49.57424079220912, "BBH Raw": 0.5028481044452986, "BBH": 30.356398875749075, "MATH Lvl 5 Raw": 0.0906344410876132, "MATH Lvl 5": 9.06344410876133, "GPQA Raw": 0.2810402684563758, "GPQA": 4.138702460850116, "MUSR Raw": 0.4097187499999999, "MUSR": 10.281510416666665, "MMLU-PRO Raw": 0.3218916223404255, "MMLU-PRO": 24.654624704491724, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-28T00:00:00", "Submission Date": "2024-07-04T00:00:00", "Generation": 0, "Base Model": "Columbia-NLP/LION-LLaMA-3-8b-dpo-v1.0"}, {"eval_name": "Columbia-NLP_LION-LLaMA-3-8b-odpo-v1.0_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Columbia-NLP/LION-LLaMA-3-8b-odpo-v1.0\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Columbia-NLP/LION-LLaMA-3-8b-odpo-v1.0</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Columbia-NLP__LION-LLaMA-3-8b-odpo-v1.0-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Columbia-NLP/LION-LLaMA-3-8b-odpo-v1.0", "Model sha": "e2cec0d68a67092951e9205dfe634a59f2f4a2dd", "Average \u2b06\ufe0f": 19.286742835199668, "Hub License": null, "Hub \u2764\ufe0f": 2, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3967993811974449, "IFEval": 39.6799381197445, "BBH Raw": 0.5023929881802022, "BBH": 30.457173008350704, "MATH Lvl 5 Raw": 0.0725075528700906, "MATH Lvl 5": 7.250755287009064, "GPQA Raw": 0.285234899328859, "GPQA": 4.697986577181204, "MUSR Raw": 0.40575, "MUSR": 9.718749999999998, "MMLU-PRO Raw": 0.3152426861702128, "MMLU-PRO": 23.91585401891253, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-28T00:00:00", "Submission Date": "2024-07-04T00:00:00", "Generation": 0, "Base Model": "Columbia-NLP/LION-LLaMA-3-8b-odpo-v1.0"}, {"eval_name": "Columbia-NLP_LION-LLaMA-3-8b-sft-v1.0_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Columbia-NLP/LION-LLaMA-3-8b-sft-v1.0\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Columbia-NLP/LION-LLaMA-3-8b-sft-v1.0</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Columbia-NLP__LION-LLaMA-3-8b-sft-v1.0-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Columbia-NLP/LION-LLaMA-3-8b-sft-v1.0", "Model sha": "822eddb2fd127178d9fb7bb9f4fca0e93ada2836", "Average \u2b06\ufe0f": 20.25792574381804, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3817116362362974, "IFEval": 38.17116362362975, "BBH Raw": 0.5087766443418147, "BBH": 30.88426036029, "MATH Lvl 5 Raw": 0.0845921450151057, "MATH Lvl 5": 8.459214501510575, "GPQA Raw": 0.2776845637583892, "GPQA": 3.691275167785232, "MUSR Raw": 0.4502708333333333, "MUSR": 15.483854166666664, "MMLU-PRO Raw": 0.323720079787234, "MMLU-PRO": 24.857786643026003, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-02T00:00:00", "Submission Date": "2024-07-04T00:00:00", "Generation": 0, "Base Model": "Columbia-NLP/LION-LLaMA-3-8b-sft-v1.0"}, {"eval_name": "CombinHorizon_YiSM-blossom5.1-34B-SLERP_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/CombinHorizon/YiSM-blossom5.1-34B-SLERP\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">CombinHorizon/YiSM-blossom5.1-34B-SLERP</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/CombinHorizon__YiSM-blossom5.1-34B-SLERP-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "CombinHorizon/YiSM-blossom5.1-34B-SLERP", "Model sha": "ebd8d6507623008567a0548cd0ff9e28cbd6a656", "Average \u2b06\ufe0f": 31.0904035184291, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 34, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5033112142448702, "IFEval": 50.33112142448702, "BBH Raw": 0.6207548093635428, "BBH": 46.39761279639615, "MATH Lvl 5 Raw": 0.1978851963746223, "MATH Lvl 5": 19.788519637462237, "GPQA Raw": 0.3557046979865771, "GPQA": 14.093959731543624, "MUSR Raw": 0.44134375, "MUSR": 14.367968750000005, "MMLU-PRO Raw": 0.4740691489361702, "MMLU-PRO": 41.56323877068557, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-27T00:00:00", "Submission Date": "2024-08-27T00:00:00", "Generation": 1, "Base Model": "CombinHorizon/YiSM-blossom5.1-34B-SLERP (Merge)"}, {"eval_name": "CoolSpring_Qwen2-0.5B-Abyme_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/CoolSpring/Qwen2-0.5B-Abyme\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">CoolSpring/Qwen2-0.5B-Abyme</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/CoolSpring__Qwen2-0.5B-Abyme-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "CoolSpring/Qwen2-0.5B-Abyme", "Model sha": "a48b7c04b854e5c60fe3464f96904bfc53c8640c", "Average \u2b06\ufe0f": 4.760820031680599, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.1915185042354286, "IFEval": 19.151850423542868, "BBH Raw": 0.2861834296481826, "BBH": 2.2764835705971893, "MATH Lvl 5 Raw": 0.0151057401812688, "MATH Lvl 5": 1.5105740181268883, "GPQA Raw": 0.2533557046979866, "GPQA": 0.4474272930648763, "MUSR Raw": 0.35421875, "MUSR": 1.47734375, "MMLU-PRO Raw": 0.1333111702127659, "MMLU-PRO": 3.701241134751772, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-18T00:00:00", "Submission Date": "2024-09-04T00:00:00", "Generation": 1, "Base Model": "Qwen/Qwen2-0.5B"}, {"eval_name": "CoolSpring_Qwen2-0.5B-Abyme-merge2_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/CoolSpring/Qwen2-0.5B-Abyme-merge2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">CoolSpring/Qwen2-0.5B-Abyme-merge2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/CoolSpring__Qwen2-0.5B-Abyme-merge2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "CoolSpring/Qwen2-0.5B-Abyme-merge2", "Model sha": "02c4c601453f7ecbfab5c95bf5afa889350026ba", "Average \u2b06\ufe0f": 6.068495826504678, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2021846478454944, "IFEval": 20.21846478454944, "BBH Raw": 0.2994272300913873, "BBH": 3.709041394335512, "MATH Lvl 5 Raw": 0.0181268882175226, "MATH Lvl 5": 1.812688821752266, "GPQA Raw": 0.2600671140939597, "GPQA": 1.342281879194629, "MUSR Raw": 0.3687291666666667, "MUSR": 3.891145833333335, "MMLU-PRO Raw": 0.1489361702127659, "MMLU-PRO": 5.437352245862883, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-27T00:00:00", "Submission Date": "2024-07-27T00:00:00", "Generation": 1, "Base Model": "CoolSpring/Qwen2-0.5B-Abyme-merge2 (Merge)"}, {"eval_name": "CoolSpring_Qwen2-0.5B-Abyme-merge3_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/CoolSpring/Qwen2-0.5B-Abyme-merge3\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">CoolSpring/Qwen2-0.5B-Abyme-merge3</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/CoolSpring__Qwen2-0.5B-Abyme-merge3-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "CoolSpring/Qwen2-0.5B-Abyme-merge3", "Model sha": "86fed893893cc2a6240f0ea09ce2eeda1a5178cc", "Average \u2b06\ufe0f": 6.643962447563062, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2386046800267734, "IFEval": 23.860468002677344, "BBH Raw": 0.3003140452593367, "BBH": 4.301149162861492, "MATH Lvl 5 Raw": 0.0211480362537764, "MATH Lvl 5": 2.114803625377644, "GPQA Raw": 0.2642617449664429, "GPQA": 1.9015659955257265, "MUSR Raw": 0.35009375, "MUSR": 2.1283854166666667, "MMLU-PRO Raw": 0.1500166223404255, "MMLU-PRO": 5.557402482269504, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-27T00:00:00", "Submission Date": "2024-07-27T00:00:00", "Generation": 1, "Base Model": "CoolSpring/Qwen2-0.5B-Abyme-merge3 (Merge)"}, {"eval_name": "Corianas_llama-3-reactor_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Corianas/llama-3-reactor\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Corianas/llama-3-reactor</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Corianas__llama-3-reactor-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Corianas/llama-3-reactor", "Model sha": "bef2eac42fd89baa0064badbc9c7958ad9ccbed3", "Average \u2b06\ufe0f": 13.945117259774769, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": -1, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2300119239174279, "IFEval": 23.0011923917428, "BBH Raw": 0.4457148560545015, "BBH": 21.88855981925079, "MATH Lvl 5 Raw": 0.0438066465256797, "MATH Lvl 5": 4.380664652567976, "GPQA Raw": 0.2978187919463087, "GPQA": 6.375838926174497, "MUSR Raw": 0.3977187499999999, "MUSR": 8.014843750000002, "MMLU-PRO Raw": 0.2800864361702128, "MMLU-PRO": 20.00960401891253, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-20T00:00:00", "Submission Date": "2024-07-23T00:00:00", "Generation": 0, "Base Model": "Corianas/llama-3-reactor"}, {"eval_name": "CortexLM_btlm-7b-base-v0.2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/CortexLM/btlm-7b-base-v0.2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">CortexLM/btlm-7b-base-v0.2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/CortexLM__btlm-7b-base-v0.2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "CortexLM/btlm-7b-base-v0.2", "Model sha": "eda8b4298365a26c8981316e09427c237b11217f", "Average \u2b06\ufe0f": 8.844726229775539, "Hub License": "mit", "Hub \u2764\ufe0f": 1, "#Params (B)": 6, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1483286568527063, "IFEval": 14.832865685270637, "BBH Raw": 0.4006411985841813, "BBH": 16.19327709708517, "MATH Lvl 5 Raw": 0.0105740181268882, "MATH Lvl 5": 1.0574018126888218, "GPQA Raw": 0.2533557046979866, "GPQA": 0.4474272930648763, "MUSR Raw": 0.3846041666666666, "MUSR": 5.542187500000001, "MMLU-PRO Raw": 0.2349567819148936, "MMLU-PRO": 14.995197990543732, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-13T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "CortexLM/btlm-7b-base-v0.2"}, {"eval_name": "Cran-May_T.E-8.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Cran-May/T.E-8.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Cran-May/T.E-8.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Cran-May__T.E-8.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Cran-May/T.E-8.1", "Model sha": "5f84709710dcce7cc05fa12473e8bb207fe25849", "Average \u2b06\ufe0f": 29.329928130753046, "Hub License": "cc-by-nc-sa-4.0", "Hub \u2764\ufe0f": 2, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7076922565459647, "IFEval": 70.76922565459647, "BBH Raw": 0.5581754708123893, "BBH": 37.02437662584371, "MATH Lvl 5 Raw": 0.0634441087613293, "MATH Lvl 5": 6.3444108761329305, "GPQA Raw": 0.3129194630872483, "GPQA": 8.389261744966444, "MUSR Raw": 0.4505208333333333, "MUSR": 15.31510416666667, "MMLU-PRO Raw": 0.4432347074468085, "MMLU-PRO": 38.13718971631205, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-27T00:00:00", "Submission Date": "2024-09-29T00:00:00", "Generation": 1, "Base Model": "Cran-May/T.E-8.1 (Merge)"}, {"eval_name": "DUAL-GPO_zephyr-7b-ipo-0k-15k-i1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Adapter", "Architecture": "?", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/DUAL-GPO/zephyr-7b-ipo-0k-15k-i1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">DUAL-GPO/zephyr-7b-ipo-0k-15k-i1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/DUAL-GPO__zephyr-7b-ipo-0k-15k-i1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "DUAL-GPO/zephyr-7b-ipo-0k-15k-i1", "Model sha": "564d269c67dfcc5c07a4fbc270a6a48da1929d30", "Average \u2b06\ufe0f": 15.41741895877682, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 14, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2756242325917454, "IFEval": 27.562423259174547, "BBH Raw": 0.4472712447565954, "BBH": 22.65864266009636, "MATH Lvl 5 Raw": 0.0256797583081571, "MATH Lvl 5": 2.56797583081571, "GPQA Raw": 0.2911073825503356, "GPQA": 5.480984340044745, "MUSR Raw": 0.4173437499999999, "MUSR": 10.567968750000002, "MMLU-PRO Raw": 0.3129986702127659, "MMLU-PRO": 23.66651891252955, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-20T00:00:00", "Submission Date": "2024-09-22T00:00:00", "Generation": 1, "Base Model": "DUAL-GPO/zephyr-7b-ipo-qlora-v0-merged"}, {"eval_name": "DZgas_GIGABATEMAN-7B_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/DZgas/GIGABATEMAN-7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">DZgas/GIGABATEMAN-7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/DZgas__GIGABATEMAN-7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "DZgas/GIGABATEMAN-7B", "Model sha": "edf2840350e7fd55895d9df560b489ac10ecb95e", "Average \u2b06\ufe0f": 20.34558780517841, "Hub License": null, "Hub \u2764\ufe0f": 5, "#Params (B)": 7, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4607463751734287, "IFEval": 46.07463751734288, "BBH Raw": 0.5032184342862756, "BBH": 29.827516654013998, "MATH Lvl 5 Raw": 0.0475830815709969, "MATH Lvl 5": 4.758308157099698, "GPQA Raw": 0.2894295302013422, "GPQA": 5.257270693512303, "MUSR Raw": 0.4328437499999999, "MUSR": 11.972135416666667, "MMLU-PRO Raw": 0.3176529255319149, "MMLU-PRO": 24.183658392434985, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-17T00:00:00", "Submission Date": "2024-09-15T00:00:00", "Generation": 1, "Base Model": "DZgas/GIGABATEMAN-7B (Merge)"}, {"eval_name": "Dampfinchen_Llama-3.1-8B-Ultra-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Dampfinchen/Llama-3.1-8B-Ultra-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Dampfinchen/Llama-3.1-8B-Ultra-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Dampfinchen__Llama-3.1-8B-Ultra-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Dampfinchen/Llama-3.1-8B-Ultra-Instruct", "Model sha": "46662d14130cfd34f7d90816540794f24a301f86", "Average \u2b06\ufe0f": 28.975994041023085, "Hub License": "llama3", "Hub \u2764\ufe0f": 6, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.8081091503876381, "IFEval": 80.81091503876381, "BBH Raw": 0.5257532452246574, "BBH": 32.49458680420566, "MATH Lvl 5 Raw": 0.1495468277945619, "MATH Lvl 5": 14.954682779456194, "GPQA Raw": 0.2919463087248322, "GPQA": 5.592841163310966, "MUSR Raw": 0.4003229166666666, "MUSR": 8.607031250000002, "MMLU-PRO Raw": 0.382563164893617, "MMLU-PRO": 31.395907210401887, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-26T00:00:00", "Submission Date": "2024-08-26T00:00:00", "Generation": 1, "Base Model": "Dampfinchen/Llama-3.1-8B-Ultra-Instruct (Merge)"}, {"eval_name": "Danielbrdz_Barcenas-14b-Phi-3-medium-ORPO_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Danielbrdz/Barcenas-14b-Phi-3-medium-ORPO\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Danielbrdz/Barcenas-14b-Phi-3-medium-ORPO</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Danielbrdz__Barcenas-14b-Phi-3-medium-ORPO-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Danielbrdz/Barcenas-14b-Phi-3-medium-ORPO", "Model sha": "b749dbcb19901b8fd0e9f38c923a24533569f895", "Average \u2b06\ufe0f": 31.42374466355467, "Hub License": "mit", "Hub \u2764\ufe0f": 5, "#Params (B)": 13, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4799055395240185, "IFEval": 47.990553952401854, "BBH Raw": 0.6536184886648629, "BBH": 51.029418403280296, "MATH Lvl 5 Raw": 0.1744712990936555, "MATH Lvl 5": 17.447129909365557, "GPQA Raw": 0.3263422818791946, "GPQA": 10.17897091722595, "MUSR Raw": 0.48075, "MUSR": 20.527083333333334, "MMLU-PRO Raw": 0.4723238031914893, "MMLU-PRO": 41.36931146572104, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-15T00:00:00", "Submission Date": "2024-08-13T00:00:00", "Generation": 0, "Base Model": "Danielbrdz/Barcenas-14b-Phi-3-medium-ORPO"}, {"eval_name": "Danielbrdz_Barcenas-Llama3-8b-ORPO_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Danielbrdz/Barcenas-Llama3-8b-ORPO\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Danielbrdz/Barcenas-Llama3-8b-ORPO</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Danielbrdz__Barcenas-Llama3-8b-ORPO-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Danielbrdz/Barcenas-Llama3-8b-ORPO", "Model sha": "66c848c4526d3db1ec41468c0f73ac4448c6abe9", "Average \u2b06\ufe0f": 26.380535768597014, "Hub License": "other", "Hub \u2764\ufe0f": 7, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.737242738156979, "IFEval": 73.7242738156979, "BBH Raw": 0.4986557855991124, "BBH": 28.600623499981847, "MATH Lvl 5 Raw": 0.0574018126888217, "MATH Lvl 5": 5.740181268882175, "GPQA Raw": 0.3070469798657718, "GPQA": 7.606263982102905, "MUSR Raw": 0.4189583333333333, "MUSR": 11.169791666666669, "MMLU-PRO Raw": 0.3829787234042553, "MMLU-PRO": 31.44208037825059, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-29T00:00:00", "Submission Date": "2024-06-29T00:00:00", "Generation": 0, "Base Model": "Danielbrdz/Barcenas-Llama3-8b-ORPO"}, {"eval_name": "Dans-DiscountModels_Dans-Instruct-CoreCurriculum-12b-ChatML_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Dans-DiscountModels/Dans-Instruct-CoreCurriculum-12b-ChatML\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Dans-DiscountModels/Dans-Instruct-CoreCurriculum-12b-ChatML</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Dans-DiscountModels__Dans-Instruct-CoreCurriculum-12b-ChatML-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Dans-DiscountModels/Dans-Instruct-CoreCurriculum-12b-ChatML", "Model sha": "56925fafe6a543e224db36864dd0927171542776", "Average \u2b06\ufe0f": 12.91345183517749, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2111020979888916, "IFEval": 21.11020979888917, "BBH Raw": 0.4791864789096407, "BBH": 26.046417064819565, "MATH Lvl 5 Raw": 0.0052870090634441, "MATH Lvl 5": 0.5287009063444109, "GPQA Raw": 0.2802013422818792, "GPQA": 4.026845637583895, "MUSR Raw": 0.3606354166666667, "MUSR": 5.712760416666669, "MMLU-PRO Raw": 0.2805019946808511, "MMLU-PRO": 20.05577718676123, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-04T00:00:00", "Submission Date": "2024-09-04T00:00:00", "Generation": 1, "Base Model": "mistralai/Mistral-Nemo-Base-2407"}, {"eval_name": "Dans-DiscountModels_Dans-Instruct-Mix-8b-ChatML_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Dans-DiscountModels/Dans-Instruct-Mix-8b-ChatML\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Dans-DiscountModels/Dans-Instruct-Mix-8b-ChatML</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Dans-DiscountModels__Dans-Instruct-Mix-8b-ChatML-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Dans-DiscountModels/Dans-Instruct-Mix-8b-ChatML", "Model sha": "029d84d4f4a618aa798490c046753b12801158e2", "Average \u2b06\ufe0f": 13.395475303290093, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.0825077461136451, "IFEval": 8.250774611364513, "BBH Raw": 0.4738171816307924, "BBH": 26.33639354405325, "MATH Lvl 5 Raw": 0.0475830815709969, "MATH Lvl 5": 4.758308157099698, "GPQA Raw": 0.2944630872483221, "GPQA": 5.92841163310962, "MUSR Raw": 0.3918229166666667, "MUSR": 9.677864583333337, "MMLU-PRO Raw": 0.3287898936170212, "MMLU-PRO": 25.42109929078014, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-09T00:00:00", "Submission Date": "2024-09-14T00:00:00", "Generation": 1, "Base Model": "Dans-DiscountModels/Meta-Llama-3.1-8B-ChatML"}, {"eval_name": "Dans-DiscountModels_Dans-Instruct-Mix-8b-ChatML-V0.1.0_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Dans-DiscountModels/Dans-Instruct-Mix-8b-ChatML-V0.1.0\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Dans-DiscountModels/Dans-Instruct-Mix-8b-ChatML-V0.1.0</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Dans-DiscountModels__Dans-Instruct-Mix-8b-ChatML-V0.1.0-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Dans-DiscountModels/Dans-Instruct-Mix-8b-ChatML-V0.1.0", "Model sha": "9367c1273b0025793531fcf3a2c15416539f5d81", "Average \u2b06\ufe0f": 12.83573254684527, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.0668204807688045, "IFEval": 6.682048076880455, "BBH Raw": 0.4774765621977728, "BBH": 26.737651950701505, "MATH Lvl 5 Raw": 0.052870090634441, "MATH Lvl 5": 5.287009063444108, "GPQA Raw": 0.2860738255033557, "GPQA": 4.809843400447425, "MUSR Raw": 0.3785833333333333, "MUSR": 8.122916666666667, "MMLU-PRO Raw": 0.328374335106383, "MMLU-PRO": 25.37492612293144, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-20T00:00:00", "Submission Date": "2024-09-20T00:00:00", "Generation": 1, "Base Model": "Dans-DiscountModels/Meta-Llama-3.1-8B-ChatML"}, {"eval_name": "Dans-DiscountModels_Dans-Instruct-Mix-8b-ChatML-V0.1.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Dans-DiscountModels/Dans-Instruct-Mix-8b-ChatML-V0.1.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Dans-DiscountModels/Dans-Instruct-Mix-8b-ChatML-V0.1.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Dans-DiscountModels__Dans-Instruct-Mix-8b-ChatML-V0.1.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Dans-DiscountModels/Dans-Instruct-Mix-8b-ChatML-V0.1.1", "Model sha": "a6188cd1807d0d72e55adc371ddd198d7e9aa7ae", "Average \u2b06\ufe0f": 13.173113371188242, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.0910506345385798, "IFEval": 9.105063453857984, "BBH Raw": 0.4748653313732898, "BBH": 26.412550636134668, "MATH Lvl 5 Raw": 0.0490936555891238, "MATH Lvl 5": 4.909365558912387, "GPQA Raw": 0.2911073825503356, "GPQA": 5.480984340044745, "MUSR Raw": 0.3824895833333333, "MUSR": 7.811197916666667, "MMLU-PRO Raw": 0.327875664893617, "MMLU-PRO": 25.319518321513, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-22T00:00:00", "Submission Date": "2024-09-23T00:00:00", "Generation": 1, "Base Model": "Dans-DiscountModels/Meta-Llama-3.1-8B-ChatML"}, {"eval_name": "Dans-DiscountModels_Dans-Instruct-Mix-8b-ChatML-V0.2.0_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Dans-DiscountModels/Dans-Instruct-Mix-8b-ChatML-V0.2.0\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Dans-DiscountModels/Dans-Instruct-Mix-8b-ChatML-V0.2.0</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Dans-DiscountModels__Dans-Instruct-Mix-8b-ChatML-V0.2.0-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Dans-DiscountModels/Dans-Instruct-Mix-8b-ChatML-V0.2.0", "Model sha": "15a9988381fdba15281f1bd6b04c34f3f96120cc", "Average \u2b06\ufe0f": 18.54056690827674, "Hub License": null, "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5064085515321569, "IFEval": 50.64085515321569, "BBH Raw": 0.4624263551503409, "BBH": 24.734770612245036, "MATH Lvl 5 Raw": 0.0407854984894259, "MATH Lvl 5": 4.078549848942599, "GPQA Raw": 0.2936241610738255, "GPQA": 5.8165548098434, "MUSR Raw": 0.3644479166666667, "MUSR": 3.755989583333333, "MMLU-PRO Raw": 0.2999501329787234, "MMLU-PRO": 22.21668144208038, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-30T00:00:00", "Submission Date": "2024-09-30T00:00:00", "Generation": 1, "Base Model": "Dans-DiscountModels/Meta-Llama-3.1-8B-ChatML"}, {"eval_name": "Darkknight535_OpenCrystal-12B-L3_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Darkknight535/OpenCrystal-12B-L3\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Darkknight535/OpenCrystal-12B-L3</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Darkknight535__OpenCrystal-12B-L3-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Darkknight535/OpenCrystal-12B-L3", "Model sha": "974d2d453afdde40f6a993601bbbbf9d97b43606", "Average \u2b06\ufe0f": 20.50924274767449, "Hub License": null, "Hub \u2764\ufe0f": 14, "#Params (B)": 11, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4070909630890482, "IFEval": 40.70909630890482, "BBH Raw": 0.5222598504945516, "BBH": 31.84449091545611, "MATH Lvl 5 Raw": 0.0793051359516616, "MATH Lvl 5": 7.930513595166164, "GPQA Raw": 0.3062080536912752, "GPQA": 7.494407158836691, "MUSR Raw": 0.36565625, "MUSR": 5.740364583333334, "MMLU-PRO Raw": 0.3640292553191489, "MMLU-PRO": 29.336583924349878, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-25T00:00:00", "Submission Date": "2024-08-26T00:00:00", "Generation": 0, "Base Model": "Darkknight535/OpenCrystal-12B-L3"}, {"eval_name": "DavidAU_L3-Dark-Planet-8B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/DavidAU/L3-Dark-Planet-8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">DavidAU/L3-Dark-Planet-8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/DavidAU__L3-Dark-Planet-8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "DavidAU/L3-Dark-Planet-8B", "Model sha": "462c9307ba4cfcb0c1edcceac5e06f4007bc803e", "Average \u2b06\ufe0f": 20.343302888078814, "Hub License": null, "Hub \u2764\ufe0f": 5, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4134108609600305, "IFEval": 41.34108609600305, "BBH Raw": 0.5084081453197787, "BBH": 29.78962694499553, "MATH Lvl 5 Raw": 0.0747734138972809, "MATH Lvl 5": 7.477341389728097, "GPQA Raw": 0.3003355704697986, "GPQA": 6.711409395973152, "MUSR Raw": 0.36159375, "MUSR": 6.332552083333334, "MMLU-PRO Raw": 0.3736702127659574, "MMLU-PRO": 30.40780141843972, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-05T00:00:00", "Submission Date": "2024-09-12T00:00:00", "Generation": 1, "Base Model": "DavidAU/L3-Dark-Planet-8B (Merge)"}, {"eval_name": "DavidAU_L3-Jamet-12.2B-MK.V-Blackroot-Instruct_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/DavidAU/L3-Jamet-12.2B-MK.V-Blackroot-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">DavidAU/L3-Jamet-12.2B-MK.V-Blackroot-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/DavidAU__L3-Jamet-12.2B-MK.V-Blackroot-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "DavidAU/L3-Jamet-12.2B-MK.V-Blackroot-Instruct", "Model sha": "db4ae3d7b608fd0e7490d2fcfa0436e56e21af33", "Average \u2b06\ufe0f": 17.857043217965458, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 12, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3961998608137519, "IFEval": 39.6199860813752, "BBH Raw": 0.4765717717789398, "BBH": 25.869793144697734, "MATH Lvl 5 Raw": 0.0407854984894259, "MATH Lvl 5": 4.078549848942599, "GPQA Raw": 0.2785234899328859, "GPQA": 3.803131991051453, "MUSR Raw": 0.40196875, "MUSR": 8.312760416666668, "MMLU-PRO Raw": 0.3291223404255319, "MMLU-PRO": 25.458037825059098, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-23T00:00:00", "Submission Date": "2024-09-04T00:00:00", "Generation": 1, "Base Model": "DavidAU/L3-Jamet-12.2B-MK.V-Blackroot-Instruct (Merge)"}, {"eval_name": "DavidAU_L3-Lumimaid-12.2B-v0.1-OAS-Instruct_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/DavidAU/L3-Lumimaid-12.2B-v0.1-OAS-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">DavidAU/L3-Lumimaid-12.2B-v0.1-OAS-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/DavidAU__L3-Lumimaid-12.2B-v0.1-OAS-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "DavidAU/L3-Lumimaid-12.2B-v0.1-OAS-Instruct", "Model sha": "65a9e957dc4211aa3d87fdf588767823af5cde3f", "Average \u2b06\ufe0f": 17.70567449730416, "Hub License": null, "Hub \u2764\ufe0f": 1, "#Params (B)": 12, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3924032677739509, "IFEval": 39.24032677739509, "BBH Raw": 0.4693020757969467, "BBH": 24.504815583181397, "MATH Lvl 5 Raw": 0.0385196374622356, "MATH Lvl 5": 3.8519637462235647, "GPQA Raw": 0.2768456375838926, "GPQA": 3.5794183445190177, "MUSR Raw": 0.4194270833333333, "MUSR": 11.26171875, "MMLU-PRO Raw": 0.3141622340425531, "MMLU-PRO": 23.795803782505907, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-24T00:00:00", "Submission Date": "2024-09-12T00:00:00", "Generation": 1, "Base Model": "DavidAU/L3-Lumimaid-12.2B-v0.1-OAS-Instruct (Merge)"}, {"eval_name": "DavidAU_L3-SMB-Instruct-12.2B-F32_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/DavidAU/L3-SMB-Instruct-12.2B-F32\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">DavidAU/L3-SMB-Instruct-12.2B-F32</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/DavidAU__L3-SMB-Instruct-12.2B-F32-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "DavidAU/L3-SMB-Instruct-12.2B-F32", "Model sha": "ac5e205a41b17a7b05b1b62f352aacc7e65b2f13", "Average \u2b06\ufe0f": 18.80093395589629, "Hub License": null, "Hub \u2764\ufe0f": 1, "#Params (B)": 12, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4303215468290802, "IFEval": 43.032154682908015, "BBH Raw": 0.4786412360346213, "BBH": 26.130957088441544, "MATH Lvl 5 Raw": 0.0407854984894259, "MATH Lvl 5": 4.078549848942599, "GPQA Raw": 0.2818791946308724, "GPQA": 4.250559284116329, "MUSR Raw": 0.4087291666666666, "MUSR": 9.624479166666667, "MMLU-PRO Raw": 0.3312001329787234, "MMLU-PRO": 25.6889036643026, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-25T00:00:00", "Submission Date": "2024-09-12T00:00:00", "Generation": 1, "Base Model": "DavidAU/L3-SMB-Instruct-12.2B-F32 (Merge)"}, {"eval_name": "DavidAU_L3-Stheno-Maid-Blackroot-Grand-HORROR-16B_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/DavidAU/L3-Stheno-Maid-Blackroot-Grand-HORROR-16B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">DavidAU/L3-Stheno-Maid-Blackroot-Grand-HORROR-16B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/DavidAU__L3-Stheno-Maid-Blackroot-Grand-HORROR-16B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "DavidAU/L3-Stheno-Maid-Blackroot-Grand-HORROR-16B", "Model sha": "7b626e50b6c35fcb064b8b039fcf30eae01c3fae", "Average \u2b06\ufe0f": 17.0967863641751, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 16, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3438930925499895, "IFEval": 34.38930925499896, "BBH Raw": 0.4736328900737677, "BBH": 26.692021341537863, "MATH Lvl 5 Raw": 0.0158610271903323, "MATH Lvl 5": 1.5861027190332326, "GPQA Raw": 0.2709731543624161, "GPQA": 2.796420581655479, "MUSR Raw": 0.4031145833333333, "MUSR": 8.555989583333334, "MMLU-PRO Raw": 0.3570478723404255, "MMLU-PRO": 28.56087470449172, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-23T00:00:00", "Submission Date": "2024-09-04T00:00:00", "Generation": 1, "Base Model": "DavidAU/L3-Stheno-Maid-Blackroot-Grand-HORROR-16B (Merge)"}, {"eval_name": "DavidAU_L3-Stheno-v3.2-12.2B-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/DavidAU/L3-Stheno-v3.2-12.2B-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">DavidAU/L3-Stheno-v3.2-12.2B-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/DavidAU__L3-Stheno-v3.2-12.2B-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "DavidAU/L3-Stheno-v3.2-12.2B-Instruct", "Model sha": "8271fc32a601a4fa5efbe58c41a0ef4181ad8836", "Average \u2b06\ufe0f": 18.727092168435487, "Hub License": null, "Hub \u2764\ufe0f": 1, "#Params (B)": 12, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4027945850343755, "IFEval": 40.279458503437546, "BBH Raw": 0.4845980190500647, "BBH": 27.36962320894452, "MATH Lvl 5 Raw": 0.0498489425981873, "MATH Lvl 5": 4.984894259818732, "GPQA Raw": 0.2751677852348993, "GPQA": 3.355704697986576, "MUSR Raw": 0.41025, "MUSR": 10.314583333333331, "MMLU-PRO Raw": 0.3345246010638298, "MMLU-PRO": 26.0582890070922, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-24T00:00:00", "Submission Date": "2024-09-12T00:00:00", "Generation": 1, "Base Model": "DavidAU/L3-Stheno-v3.2-12.2B-Instruct (Merge)"}, {"eval_name": "Deci_DeciLM-7B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "DeciLMForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Deci/DeciLM-7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Deci/DeciLM-7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Deci__DeciLM-7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Deci/DeciLM-7B", "Model sha": "c3c9f4226801dc0433f32aebffe0aac68ee2f051", "Average \u2b06\ufe0f": 14.947949239530876, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 224, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.281294742394624, "IFEval": 28.129474239462404, "BBH Raw": 0.4422856667426649, "BBH": 21.252729791067395, "MATH Lvl 5 Raw": 0.0241691842900302, "MATH Lvl 5": 2.416918429003021, "GPQA Raw": 0.2953020134228188, "GPQA": 6.040268456375841, "MUSR Raw": 0.4358541666666666, "MUSR": 13.0484375, "MMLU-PRO Raw": 0.2691988031914893, "MMLU-PRO": 18.799867021276597, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-12-10T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "Deci/DeciLM-7B"}, {"eval_name": "Deci_DeciLM-7B-instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "DeciLMForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Deci/DeciLM-7B-instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Deci/DeciLM-7B-instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Deci__DeciLM-7B-instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Deci/DeciLM-7B-instruct", "Model sha": "4adc7aa9efe61b47b0a98b2cc94527d9c45c3b4f", "Average \u2b06\ufe0f": 17.43232787053986, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 96, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4880239985460799, "IFEval": 48.802399854608, "BBH Raw": 0.4589748654047652, "BBH": 23.8871490441846, "MATH Lvl 5 Raw": 0.0279456193353474, "MATH Lvl 5": 2.794561933534743, "GPQA Raw": 0.2894295302013422, "GPQA": 5.257270693512303, "MUSR Raw": 0.3884166666666666, "MUSR": 5.985416666666667, "MMLU-PRO Raw": 0.2608045212765957, "MMLU-PRO": 17.86716903073286, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-12-10T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "Deci/DeciLM-7B-instruct"}, {"eval_name": "DeepAutoAI_Explore_Llama-3.1-8B-Inst_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/DeepAutoAI/Explore_Llama-3.1-8B-Inst\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">DeepAutoAI/Explore_Llama-3.1-8B-Inst</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/DeepAutoAI__Explore_Llama-3.1-8B-Inst-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "DeepAutoAI/Explore_Llama-3.1-8B-Inst", "Model sha": "9752180fafd8f584625eb649c0cba36b91bdc3ce", "Average \u2b06\ufe0f": 28.4987047216293, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7794828831943688, "IFEval": 77.94828831943687, "BBH Raw": 0.511742159482904, "BBH": 30.393262902042363, "MATH Lvl 5 Raw": 0.175226586102719, "MATH Lvl 5": 17.522658610271904, "GPQA Raw": 0.2835570469798658, "GPQA": 4.4742729306487705, "MUSR Raw": 0.3909583333333333, "MUSR": 9.63645833333333, "MMLU-PRO Raw": 0.379155585106383, "MMLU-PRO": 31.017287234042552, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-21T00:00:00", "Submission Date": "2024-10-09T00:00:00", "Generation": 1, "Base Model": "DeepAutoAI/Explore_Llama-3.1-8B-Inst (Merge)"}, {"eval_name": "DeepAutoAI_Explore_Llama-3.2-1B-Inst_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/DeepAutoAI/Explore_Llama-3.2-1B-Inst\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">DeepAutoAI/Explore_Llama-3.2-1B-Inst</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/DeepAutoAI__Explore_Llama-3.2-1B-Inst-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "DeepAutoAI/Explore_Llama-3.2-1B-Inst", "Model sha": "9fd790df246b8979c02173f7698819a7805fb04e", "Average \u2b06\ufe0f": 13.557497716654815, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 1, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5648856146136695, "IFEval": 56.48856146136695, "BBH Raw": 0.3504808563777001, "BBH": 8.292273657131942, "MATH Lvl 5 Raw": 0.0543806646525679, "MATH Lvl 5": 5.438066465256798, "GPQA Raw": 0.2558724832214765, "GPQA": 0.7829977628635317, "MUSR Raw": 0.31834375, "MUSR": 1.359635416666667, "MMLU-PRO Raw": 0.1808510638297872, "MMLU-PRO": 8.983451536643026, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-07T00:00:00", "Submission Date": "2024-10-09T00:00:00", "Generation": 1, "Base Model": "DeepAutoAI/Explore_Llama-3.2-1B-Inst (Merge)"}, {"eval_name": "DeepAutoAI_Explore_Llama-3.2-1B-Inst_v0_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/DeepAutoAI/Explore_Llama-3.2-1B-Inst_v0\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">DeepAutoAI/Explore_Llama-3.2-1B-Inst_v0</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/DeepAutoAI__Explore_Llama-3.2-1B-Inst_v0-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "DeepAutoAI/Explore_Llama-3.2-1B-Inst_v0", "Model sha": "9509dee6b01fff1a11dc26cf58d7eecbe3d9d9c4", "Average \u2b06\ufe0f": 13.069558379970369, "Hub License": null, "Hub \u2764\ufe0f": 1, "#Params (B)": 1, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5597148898256625, "IFEval": 55.97148898256626, "BBH Raw": 0.3365090320035271, "BBH": 7.042771972349901, "MATH Lvl 5 Raw": 0.0422960725075528, "MATH Lvl 5": 4.229607250755287, "GPQA Raw": 0.2634228187919463, "GPQA": 1.789709172259505, "MUSR Raw": 0.3103125, "MUSR": 0.4557291666666662, "MMLU-PRO Raw": 0.1803523936170212, "MMLU-PRO": 8.928043735224584, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-08T00:00:00", "Submission Date": "2024-10-08T00:00:00", "Generation": 0, "Base Model": "DeepAutoAI/Explore_Llama-3.2-1B-Inst_v0"}, {"eval_name": "DeepAutoAI_Explore_Llama-3.2-1B-Inst_v1_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/DeepAutoAI/Explore_Llama-3.2-1B-Inst_v1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">DeepAutoAI/Explore_Llama-3.2-1B-Inst_v1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/DeepAutoAI__Explore_Llama-3.2-1B-Inst_v1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "DeepAutoAI/Explore_Llama-3.2-1B-Inst_v1", "Model sha": "3f8b0fb6dcc1e9725ba52dd086241d5d9e413100", "Average \u2b06\ufe0f": 10.619318805675972, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 1, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4998891829235318, "IFEval": 49.98891829235318, "BBH Raw": 0.3141475230443668, "BBH": 4.257780193079653, "MATH Lvl 5 Raw": 0.0128398791540785, "MATH Lvl 5": 1.283987915407855, "GPQA Raw": 0.2449664429530201, "GPQA": 0.0, "MUSR Raw": 0.3780937499999999, "MUSR": 5.195052083333335, "MMLU-PRO Raw": 0.1269115691489361, "MMLU-PRO": 2.990174349881796, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-08T00:00:00", "Submission Date": "2024-10-08T00:00:00", "Generation": 1, "Base Model": "DeepAutoAI/Explore_Llama-3.2-1B-Inst_v1 (Merge)"}, {"eval_name": "DeepAutoAI_Explore_Llama-3.2-1B-Inst_v1.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/DeepAutoAI/Explore_Llama-3.2-1B-Inst_v1.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">DeepAutoAI/Explore_Llama-3.2-1B-Inst_v1.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/DeepAutoAI__Explore_Llama-3.2-1B-Inst_v1.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "DeepAutoAI/Explore_Llama-3.2-1B-Inst_v1.1", "Model sha": "158b977bca89e073871e2313740a7c75eb1291af", "Average \u2b06\ufe0f": 10.68924866941872, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 1, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4813295389566351, "IFEval": 48.13295389566351, "BBH Raw": 0.3128796183731584, "BBH": 5.18530518107402, "MATH Lvl 5 Raw": 0.0135951661631419, "MATH Lvl 5": 1.3595166163141994, "GPQA Raw": 0.2676174496644295, "GPQA": 2.348993288590602, "MUSR Raw": 0.3606979166666667, "MUSR": 4.053906250000002, "MMLU-PRO Raw": 0.1274933510638297, "MMLU-PRO": 3.0548167848699745, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-09T00:00:00", "Submission Date": "2024-10-09T00:00:00", "Generation": 0, "Base Model": "DeepAutoAI/Explore_Llama-3.2-1B-Inst_v1.1"}, {"eval_name": "DeepAutoAI_d2nwg_Llama-3.1-8B-Instruct-v0.0_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/DeepAutoAI/d2nwg_Llama-3.1-8B-Instruct-v0.0\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">DeepAutoAI/d2nwg_Llama-3.1-8B-Instruct-v0.0</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/DeepAutoAI__d2nwg_Llama-3.1-8B-Instruct-v0.0-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "DeepAutoAI/d2nwg_Llama-3.1-8B-Instruct-v0.0", "Model sha": "8bad8800d04a06f3f906728ee223cab2f50453a0", "Average \u2b06\ufe0f": 27.65215784092941, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7892746800711002, "IFEval": 78.92746800711004, "BBH Raw": 0.5080411642065981, "BBH": 30.51007603826353, "MATH Lvl 5 Raw": 0.0793051359516616, "MATH Lvl 5": 7.930513595166164, "GPQA Raw": 0.2919463087248322, "GPQA": 5.592841163310966, "MUSR Raw": 0.41346875, "MUSR": 10.983593749999995, "MMLU-PRO Raw": 0.3877160904255319, "MMLU-PRO": 31.96845449172577, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-10T00:00:00", "Submission Date": "2024-09-10T00:00:00", "Generation": 0, "Base Model": "DeepAutoAI/d2nwg_Llama-3.1-8B-Instruct-v0.0"}, {"eval_name": "DeepAutoAI_ldm_soup_Llama-3.1-8B-Inst_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/DeepAutoAI/ldm_soup_Llama-3.1-8B-Inst\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">DeepAutoAI/ldm_soup_Llama-3.1-8B-Inst</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/DeepAutoAI__ldm_soup_Llama-3.1-8B-Inst-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "DeepAutoAI/ldm_soup_Llama-3.1-8B-Inst", "Model sha": "0f04c5ad830f8ae0828191a4670fd4ba361b63d2", "Average \u2b06\ufe0f": 28.638010777342725, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.803263119633683, "IFEval": 80.32631196336831, "BBH Raw": 0.512116784464076, "BBH": 31.101628224178786, "MATH Lvl 5 Raw": 0.1155589123867069, "MATH Lvl 5": 11.555891238670696, "GPQA Raw": 0.2894295302013422, "GPQA": 5.257270693512303, "MUSR Raw": 0.4161354166666666, "MUSR": 11.51692708333333, "MMLU-PRO Raw": 0.3886303191489361, "MMLU-PRO": 32.070035460992905, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-16T00:00:00", "Submission Date": "2024-10-09T00:00:00", "Generation": 1, "Base Model": "DeepAutoAI/ldm_soup_Llama-3.1-8B-Inst (Merge)"}, {"eval_name": "DeepAutoAI_ldm_soup_Llama-3.1-8B-Instruct-v0.0_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/DeepAutoAI/ldm_soup_Llama-3.1-8B-Instruct-v0.0\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">DeepAutoAI/ldm_soup_Llama-3.1-8B-Instruct-v0.0</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/DeepAutoAI__ldm_soup_Llama-3.1-8B-Instruct-v0.0-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "DeepAutoAI/ldm_soup_Llama-3.1-8B-Instruct-v0.0", "Model sha": "210a97b4dadbda63cc9fe459e8415d4cd3bbaf99", "Average \u2b06\ufe0f": 28.275022779837723, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7889499860370484, "IFEval": 78.89499860370483, "BBH Raw": 0.5125175335277464, "BBH": 31.162649496607862, "MATH Lvl 5 Raw": 0.1042296072507553, "MATH Lvl 5": 10.42296072507553, "GPQA Raw": 0.2911073825503356, "GPQA": 5.480984340044745, "MUSR Raw": 0.4121354166666666, "MUSR": 11.51692708333333, "MMLU-PRO Raw": 0.3895445478723404, "MMLU-PRO": 32.171616430260045, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-14T00:00:00", "Submission Date": "2024-09-15T00:00:00", "Generation": 0, "Base Model": "DeepAutoAI/ldm_soup_Llama-3.1-8B-Instruct-v0.0"}, {"eval_name": "DeepAutoAI_ldm_soup_Llama-3.1-8B-Instruct-v0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/DeepAutoAI/ldm_soup_Llama-3.1-8B-Instruct-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">DeepAutoAI/ldm_soup_Llama-3.1-8B-Instruct-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/DeepAutoAI__ldm_soup_Llama-3.1-8B-Instruct-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "DeepAutoAI/ldm_soup_Llama-3.1-8B-Instruct-v0.1", "Model sha": "ecd140c95985b4292c896e25a94a7629d2924ad1", "Average \u2b06\ufe0f": 28.275022779837723, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7889499860370484, "IFEval": 78.89499860370483, "BBH Raw": 0.5125175335277464, "BBH": 31.162649496607862, "MATH Lvl 5 Raw": 0.1042296072507553, "MATH Lvl 5": 10.42296072507553, "GPQA Raw": 0.2911073825503356, "GPQA": 5.480984340044745, "MUSR Raw": 0.4121354166666666, "MUSR": 11.51692708333333, "MMLU-PRO Raw": 0.3895445478723404, "MMLU-PRO": 32.171616430260045, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-15T00:00:00", "Submission Date": "2024-09-16T00:00:00", "Generation": 0, "Base Model": "DeepAutoAI/ldm_soup_Llama-3.1-8B-Instruct-v0.1"}, {"eval_name": "DeepMount00_Lexora-Medium-7B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/DeepMount00/Lexora-Medium-7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">DeepMount00/Lexora-Medium-7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/DeepMount00__Lexora-Medium-7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "DeepMount00/Lexora-Medium-7B", "Model sha": "c53d166f4f2996a5b7f161529f1ea6548b54a2b2", "Average \u2b06\ufe0f": 24.427328943358773, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4103379034295669, "IFEval": 41.03379034295669, "BBH Raw": 0.5144844494250328, "BBH": 32.6953311808552, "MATH Lvl 5 Raw": 0.1374622356495468, "MATH Lvl 5": 13.746223564954684, "GPQA Raw": 0.3053691275167785, "GPQA": 7.38255033557047, "MUSR Raw": 0.4439479166666666, "MUSR": 14.76015625, "MMLU-PRO Raw": 0.4325132978723404, "MMLU-PRO": 36.9459219858156, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-24T00:00:00", "Submission Date": "2024-09-24T00:00:00", "Generation": 0, "Base Model": "DeepMount00/Lexora-Medium-7B"}, {"eval_name": "DeepMount00_Llama-3-8b-Ita_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/DeepMount00/Llama-3-8b-Ita\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">DeepMount00/Llama-3-8b-Ita</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/DeepMount00__Llama-3-8b-Ita-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "DeepMount00/Llama-3-8b-Ita", "Model sha": "d40847d2981b588690c1dc21d5157d3f4afb2978", "Average \u2b06\ufe0f": 26.582818423085385, "Hub License": "llama3", "Hub \u2764\ufe0f": 23, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7530297388706411, "IFEval": 75.3029738870641, "BBH Raw": 0.493576505761469, "BBH": 28.077745566893725, "MATH Lvl 5 Raw": 0.0536253776435045, "MATH Lvl 5": 5.362537764350453, "GPQA Raw": 0.3053691275167785, "GPQA": 7.38255033557047, "MUSR Raw": 0.4267708333333333, "MUSR": 11.6796875, "MMLU-PRO Raw": 0.3852227393617021, "MMLU-PRO": 31.691415484633573, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-01T00:00:00", "Submission Date": "2024-06-27T00:00:00", "Generation": 1, "Base Model": "meta-llama/Meta-Llama-3-8B"}, {"eval_name": "DeepMount00_Llama-3.1-8b-Ita_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/DeepMount00/Llama-3.1-8b-Ita\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">DeepMount00/Llama-3.1-8b-Ita</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/DeepMount00__Llama-3.1-8b-Ita-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "DeepMount00/Llama-3.1-8b-Ita", "Model sha": "5ede1e388b6b15bc06acd364a8f805fe9ed16db9", "Average \u2b06\ufe0f": 25.96361712155924, "Hub License": null, "Hub \u2764\ufe0f": 4, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.5364843060856306, "IFEval": 53.64843060856306, "BBH Raw": 0.5169995464792883, "BBH": 31.333639113507697, "MATH Lvl 5 Raw": 0.1525679758308157, "MATH Lvl 5": 15.256797583081571, "GPQA Raw": 0.3062080536912752, "GPQA": 7.494407158836691, "MUSR Raw": 0.44871875, "MUSR": 15.156510416666665, "MMLU-PRO Raw": 0.3960272606382978, "MMLU-PRO": 32.89191784869976, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-13T00:00:00", "Submission Date": "2024-08-23T00:00:00", "Generation": 2, "Base Model": "meta-llama/Meta-Llama-3.1-8B"}, {"eval_name": "Delta-Vector_Baldur-8B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Delta-Vector/Baldur-8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Delta-Vector/Baldur-8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Delta-Vector__Baldur-8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Delta-Vector/Baldur-8B", "Model sha": "97f5d321a8346551a5ed704997dd1e93c59883f3", "Average \u2b06\ufe0f": 23.902209033312896, "Hub License": "agpl-3.0", "Hub \u2764\ufe0f": 2, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4781823339849377, "IFEval": 47.818233398493774, "BBH Raw": 0.5305842954529679, "BBH": 32.54183409581636, "MATH Lvl 5 Raw": 0.1261329305135951, "MATH Lvl 5": 12.613293051359516, "GPQA Raw": 0.3020134228187919, "GPQA": 6.935123042505594, "MUSR Raw": 0.4371562499999999, "MUSR": 14.011197916666664, "MMLU-PRO Raw": 0.3654421542553192, "MMLU-PRO": 29.493572695035457, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-23T00:00:00", "Submission Date": "2024-10-06T00:00:00", "Generation": 1, "Base Model": "Delta-Vector/Baldur-8B (Merge)"}, {"eval_name": "Delta-Vector_Darkens-8B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Delta-Vector/Darkens-8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Delta-Vector/Darkens-8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Delta-Vector__Darkens-8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Delta-Vector/Darkens-8B", "Model sha": "e82be0389bfcecd1998dba1c3bb35b8d95d01bf2", "Average \u2b06\ufe0f": 18.798946119379348, "Hub License": "agpl-3.0", "Hub \u2764\ufe0f": 3, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2547662424588979, "IFEval": 25.476624245889795, "BBH Raw": 0.5250590567372793, "BBH": 32.88379503743108, "MATH Lvl 5 Raw": 0.0506042296072507, "MATH Lvl 5": 5.060422960725076, "GPQA Raw": 0.3246644295302013, "GPQA": 9.955257270693512, "MUSR Raw": 0.4105520833333333, "MUSR": 9.019010416666667, "MMLU-PRO Raw": 0.3735871010638298, "MMLU-PRO": 30.39856678486997, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-22T00:00:00", "Submission Date": "2024-10-06T00:00:00", "Generation": 1, "Base Model": "Delta-Vector/Darkens-8B (Merge)"}, {"eval_name": "Delta-Vector_Henbane-7b-attempt2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Delta-Vector/Henbane-7b-attempt2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Delta-Vector/Henbane-7b-attempt2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Delta-Vector__Henbane-7b-attempt2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Delta-Vector/Henbane-7b-attempt2", "Model sha": "448ef54e5af03e13f16f3db8ad8d1481479ac12e", "Average \u2b06\ufe0f": 23.474070825950168, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4157335868828043, "IFEval": 41.57335868828044, "BBH Raw": 0.5061177974093075, "BBH": 30.865849451121655, "MATH Lvl 5 Raw": 0.2069486404833836, "MATH Lvl 5": 20.694864048338367, "GPQA Raw": 0.2902684563758389, "GPQA": 5.369127516778524, "MUSR Raw": 0.39734375, "MUSR": 8.701302083333335, "MMLU-PRO Raw": 0.4027593085106383, "MMLU-PRO": 33.63992316784869, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-13T00:00:00", "Submission Date": "2024-10-11T00:00:00", "Generation": 1, "Base Model": "Qwen/Qwen2-7B"}, {"eval_name": "Delta-Vector_Odin-9B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Delta-Vector/Odin-9B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Delta-Vector/Odin-9B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Delta-Vector__Odin-9B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Delta-Vector/Odin-9B", "Model sha": "9ff20f5dd427e751ada834319bfdd9ea60b5e89c", "Average \u2b06\ufe0f": 24.64982165495847, "Hub License": "agpl-3.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 9, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3691970637907419, "IFEval": 36.91970637907419, "BBH Raw": 0.5440253444823155, "BBH": 34.83242280758616, "MATH Lvl 5 Raw": 0.1253776435045317, "MATH Lvl 5": 12.537764350453172, "GPQA Raw": 0.3414429530201342, "GPQA": 12.192393736017896, "MUSR Raw": 0.46478125, "MUSR": 17.56432291666666, "MMLU-PRO Raw": 0.4046708776595745, "MMLU-PRO": 33.85231973995272, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-27T00:00:00", "Submission Date": "2024-10-06T00:00:00", "Generation": 0, "Base Model": "Delta-Vector/Odin-9B"}, {"eval_name": "Delta-Vector_Tor-8B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Delta-Vector/Tor-8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Delta-Vector/Tor-8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Delta-Vector__Tor-8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Delta-Vector/Tor-8B", "Model sha": "d30a7a121c2ef5dc14004cfdf3fd13208dfbdb4f", "Average \u2b06\ufe0f": 18.331350407893748, "Hub License": "agpl-3.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2381547626963124, "IFEval": 23.815476269631244, "BBH Raw": 0.5209108776928992, "BBH": 31.73822449849867, "MATH Lvl 5 Raw": 0.0543806646525679, "MATH Lvl 5": 5.438066465256798, "GPQA Raw": 0.3238255033557047, "GPQA": 9.843400447427292, "MUSR Raw": 0.4092187499999999, "MUSR": 8.819010416666666, "MMLU-PRO Raw": 0.3730053191489361, "MMLU-PRO": 30.33392434988179, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-21T00:00:00", "Submission Date": "2024-10-06T00:00:00", "Generation": 1, "Base Model": "Delta-Vector/Tor-8B (Merge)"}, {"eval_name": "DreadPoor_Aspire-8B-model_stock_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/DreadPoor/Aspire-8B-model_stock\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">DreadPoor/Aspire-8B-model_stock</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/DreadPoor__Aspire-8B-model_stock-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "DreadPoor/Aspire-8B-model_stock", "Model sha": "5c23cb2aff877d0b7bdcfa4de43d1bc8a1852de0", "Average \u2b06\ufe0f": 28.283990653881688, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 2, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7140620221013578, "IFEval": 71.40620221013577, "BBH Raw": 0.5278251846388996, "BBH": 32.534270073092834, "MATH Lvl 5 Raw": 0.1299093655589124, "MATH Lvl 5": 12.990936555891238, "GPQA Raw": 0.3145973154362416, "GPQA": 8.612975391498878, "MUSR Raw": 0.4212499999999999, "MUSR": 13.456249999999995, "MMLU-PRO Raw": 0.3763297872340425, "MMLU-PRO": 30.703309692671397, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-16T00:00:00", "Submission Date": "2024-09-17T00:00:00", "Generation": 1, "Base Model": "DreadPoor/Aspire-8B-model_stock (Merge)"}, {"eval_name": "DreadPoor_Aurora_faustus-8B-LINEAR_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/DreadPoor/Aurora_faustus-8B-LINEAR\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">DreadPoor/Aurora_faustus-8B-LINEAR</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/DreadPoor__Aurora_faustus-8B-LINEAR-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "DreadPoor/Aurora_faustus-8B-LINEAR", "Model sha": "76acf1ac703eb827d2541d07a8d4a7cba4b731d4", "Average \u2b06\ufe0f": 29.305205249621, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7281003293483512, "IFEval": 72.81003293483514, "BBH Raw": 0.5515538279425277, "BBH": 36.26348248348271, "MATH Lvl 5 Raw": 0.1518126888217522, "MATH Lvl 5": 15.181268882175228, "GPQA Raw": 0.3070469798657718, "GPQA": 7.606263982102905, "MUSR Raw": 0.4145833333333333, "MUSR": 12.389583333333327, "MMLU-PRO Raw": 0.3842253989361702, "MMLU-PRO": 31.580599881796683, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-25T00:00:00", "Submission Date": "2024-09-26T00:00:00", "Generation": 1, "Base Model": "DreadPoor/Aurora_faustus-8B-LINEAR (Merge)"}, {"eval_name": "DreadPoor_Aurora_faustus-8B-LORABLATED_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/DreadPoor/Aurora_faustus-8B-LORABLATED\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">DreadPoor/Aurora_faustus-8B-LORABLATED</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/DreadPoor__Aurora_faustus-8B-LORABLATED-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "DreadPoor/Aurora_faustus-8B-LORABLATED", "Model sha": "97746081f7c681dcf7fad10c57de9a341aa10db1", "Average \u2b06\ufe0f": 28.799912693625576, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7527050448365891, "IFEval": 75.27050448365891, "BBH Raw": 0.539159616655651, "BBH": 34.19993531370101, "MATH Lvl 5 Raw": 0.1291540785498489, "MATH Lvl 5": 12.915407854984895, "GPQA Raw": 0.3020134228187919, "GPQA": 6.935123042505594, "MUSR Raw": 0.4238541666666666, "MUSR": 13.781770833333333, "MMLU-PRO Raw": 0.3672706117021276, "MMLU-PRO": 29.696734633569736, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-29T00:00:00", "Submission Date": "2024-09-29T00:00:00", "Generation": 1, "Base Model": "DreadPoor/Aurora_faustus-8B-LORABLATED (Merge)"}, {"eval_name": "DreadPoor_Aurora_faustus-8B-LORABLATED_ALT_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/DreadPoor/Aurora_faustus-8B-LORABLATED_ALT\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">DreadPoor/Aurora_faustus-8B-LORABLATED_ALT</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/DreadPoor__Aurora_faustus-8B-LORABLATED_ALT-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "DreadPoor/Aurora_faustus-8B-LORABLATED_ALT", "Model sha": "3ca36587d26bfd936aa1358adc1eabf377aa1e98", "Average \u2b06\ufe0f": 28.669802193133503, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7377923908562614, "IFEval": 73.77923908562614, "BBH Raw": 0.5387670721191214, "BBH": 34.21152011815682, "MATH Lvl 5 Raw": 0.1382175226586102, "MATH Lvl 5": 13.821752265861026, "GPQA Raw": 0.2986577181208054, "GPQA": 6.487695749440718, "MUSR Raw": 0.4225208333333333, "MUSR": 13.781770833333333, "MMLU-PRO Raw": 0.3694315159574468, "MMLU-PRO": 29.93683510638298, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-29T00:00:00", "Submission Date": "2024-09-29T00:00:00", "Generation": 1, "Base Model": "DreadPoor/Aurora_faustus-8B-LORABLATED_ALT (Merge)"}, {"eval_name": "DreadPoor_Eunoia_Vespera-8B-LINEAR_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/DreadPoor/Eunoia_Vespera-8B-LINEAR\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">DreadPoor/Eunoia_Vespera-8B-LINEAR</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/DreadPoor__Eunoia_Vespera-8B-LINEAR-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "DreadPoor/Eunoia_Vespera-8B-LINEAR", "Model sha": "c674956327af664735cf39b20c7a8276dfa579f9", "Average \u2b06\ufe0f": 28.70457003277254, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 2, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7235291249440374, "IFEval": 72.35291249440374, "BBH Raw": 0.5399310621081937, "BBH": 34.21610348917685, "MATH Lvl 5 Raw": 0.1389728096676737, "MATH Lvl 5": 13.897280966767372, "GPQA Raw": 0.3070469798657718, "GPQA": 7.606263982102905, "MUSR Raw": 0.4184895833333333, "MUSR": 12.611197916666663, "MMLU-PRO Raw": 0.3838929521276595, "MMLU-PRO": 31.543661347517727, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-22T00:00:00", "Submission Date": "2024-09-22T00:00:00", "Generation": 1, "Base Model": "DreadPoor/Eunoia_Vespera-8B-LINEAR (Merge)"}, {"eval_name": "DreadPoor_Heart_Stolen-8B-Model_Stock_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/DreadPoor/Heart_Stolen-8B-Model_Stock\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">DreadPoor/Heart_Stolen-8B-Model_Stock</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/DreadPoor__Heart_Stolen-8B-Model_Stock-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "DreadPoor/Heart_Stolen-8B-Model_Stock", "Model sha": "6d77987af7115c7455ddb072c48316815b018999", "Average \u2b06\ufe0f": 28.98303995348832, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 4, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7244533393617822, "IFEval": 72.44533393617823, "BBH Raw": 0.5395443745186658, "BBH": 34.44482164620488, "MATH Lvl 5 Raw": 0.1465256797583081, "MATH Lvl 5": 14.652567975830816, "GPQA Raw": 0.3171140939597315, "GPQA": 8.948545861297541, "MUSR Raw": 0.4162291666666666, "MUSR": 12.361979166666666, "MMLU-PRO Raw": 0.3794049202127659, "MMLU-PRO": 31.044991134751776, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-09T00:00:00", "Submission Date": "2024-09-10T00:00:00", "Generation": 1, "Base Model": "DreadPoor/Heart_Stolen-8B-Model_Stock (Merge)"}, {"eval_name": "DreadPoor_Heart_Stolen-ALT-8B-Model_Stock_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/DreadPoor/Heart_Stolen-ALT-8B-Model_Stock\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">DreadPoor/Heart_Stolen-ALT-8B-Model_Stock</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/DreadPoor__Heart_Stolen-ALT-8B-Model_Stock-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "DreadPoor/Heart_Stolen-ALT-8B-Model_Stock", "Model sha": "03d1d70cb7eb5a743468b97c9c580028df487564", "Average \u2b06\ufe0f": 27.52795903051036, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 2, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7183584001560305, "IFEval": 71.83584001560305, "BBH Raw": 0.526338467747489, "BBH": 32.354424456472486, "MATH Lvl 5 Raw": 0.1359516616314199, "MATH Lvl 5": 13.595166163141997, "GPQA Raw": 0.3011744966442953, "GPQA": 6.823266219239373, "MUSR Raw": 0.4054999999999999, "MUSR": 9.754166666666665, "MMLU-PRO Raw": 0.3772440159574468, "MMLU-PRO": 30.80489066193854, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-11T00:00:00", "Submission Date": "2024-09-11T00:00:00", "Generation": 1, "Base Model": "DreadPoor/Heart_Stolen-ALT-8B-Model_Stock (Merge)"}, {"eval_name": "DreadPoor_Irina-8B-model_stock_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/DreadPoor/Irina-8B-model_stock\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">DreadPoor/Irina-8B-model_stock</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/DreadPoor__Irina-8B-model_stock-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "DreadPoor/Irina-8B-model_stock", "Model sha": "b282e3ab449d71a31f48b8c13eb43a4435968728", "Average \u2b06\ufe0f": 25.16103489886336, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6799403360860294, "IFEval": 67.99403360860295, "BBH Raw": 0.5236638956084764, "BBH": 32.08833034979686, "MATH Lvl 5 Raw": 0.0906344410876132, "MATH Lvl 5": 9.06344410876133, "GPQA Raw": 0.2843959731543624, "GPQA": 4.586129753914992, "MUSR Raw": 0.4002916666666666, "MUSR": 8.636458333333332, "MMLU-PRO Raw": 0.3573803191489361, "MMLU-PRO": 28.59781323877068, "Maintainer's Highlight": false, "Upload To Hub Date": "", "Submission Date": "2024-08-30T00:00:00", "Generation": 0, "Base Model": "Removed"}, {"eval_name": "DreadPoor_ONeil-model_stock-8B_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/DreadPoor/ONeil-model_stock-8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">DreadPoor/ONeil-model_stock-8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/DreadPoor__ONeil-model_stock-8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "DreadPoor/ONeil-model_stock-8B", "Model sha": "d4b84956211fd57b85122fe0c6f88b2cb9a9c86a", "Average \u2b06\ufe0f": 26.78485096754873, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 2, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6785662043378236, "IFEval": 67.85662043378235, "BBH Raw": 0.5548337982400763, "BBH": 36.4126125295027, "MATH Lvl 5 Raw": 0.0921450151057401, "MATH Lvl 5": 9.214501510574015, "GPQA Raw": 0.3053691275167785, "GPQA": 7.38255033557047, "MUSR Raw": 0.4173437499999999, "MUSR": 10.967968749999995, "MMLU-PRO Raw": 0.3598736702127659, "MMLU-PRO": 28.874852245862886, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-06T00:00:00", "Submission Date": "2024-07-15T00:00:00", "Generation": 1, "Base Model": "DreadPoor/ONeil-model_stock-8B (Merge)"}, {"eval_name": "DreadPoor_Promissum_Mane-8B-LINEAR_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/DreadPoor/Promissum_Mane-8B-LINEAR\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">DreadPoor/Promissum_Mane-8B-LINEAR</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/DreadPoor__Promissum_Mane-8B-LINEAR-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "DreadPoor/Promissum_Mane-8B-LINEAR", "Model sha": "ff399e7004040e1807e8d08b4d0967206fc50afa", "Average \u2b06\ufe0f": 28.784946151997037, "Hub License": null, "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7150361042035134, "IFEval": 71.50361042035134, "BBH Raw": 0.5457684398146738, "BBH": 35.253190231117536, "MATH Lvl 5 Raw": 0.1367069486404833, "MATH Lvl 5": 13.670694864048338, "GPQA Raw": 0.3045302013422818, "GPQA": 7.270693512304249, "MUSR Raw": 0.4200416666666666, "MUSR": 13.338541666666666, "MMLU-PRO Raw": 0.3850565159574468, "MMLU-PRO": 31.672946217494097, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-30T00:00:00", "Submission Date": "2024-09-30T00:00:00", "Generation": 1, "Base Model": "DreadPoor/Promissum_Mane-8B-LINEAR (Merge)"}, {"eval_name": "DreadPoor_Promissum_Mane-8B-LINEAR-lorablated_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/DreadPoor/Promissum_Mane-8B-LINEAR-lorablated\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">DreadPoor/Promissum_Mane-8B-LINEAR-lorablated</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/DreadPoor__Promissum_Mane-8B-LINEAR-lorablated-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "DreadPoor/Promissum_Mane-8B-LINEAR-lorablated", "Model sha": "34c4a30b7462704810e35e033aa5ef33b075a97b", "Average \u2b06\ufe0f": 28.55897671372445, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7156356245872064, "IFEval": 71.56356245872064, "BBH Raw": 0.5435183631990302, "BBH": 34.60910725048443, "MATH Lvl 5 Raw": 0.1374622356495468, "MATH Lvl 5": 13.746223564954684, "GPQA Raw": 0.3036912751677852, "GPQA": 7.158836689038028, "MUSR Raw": 0.4197916666666666, "MUSR": 13.840624999999998, "MMLU-PRO Raw": 0.3739195478723404, "MMLU-PRO": 30.43550531914893, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-30T00:00:00", "Submission Date": "2024-09-30T00:00:00", "Generation": 1, "Base Model": "DreadPoor/Promissum_Mane-8B-LINEAR-lorablated (Merge)"}, {"eval_name": "DreadPoor_Sellen-8B-model_stock_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/DreadPoor/Sellen-8B-model_stock\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">DreadPoor/Sellen-8B-model_stock</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/DreadPoor__Sellen-8B-model_stock-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "DreadPoor/Sellen-8B-model_stock", "Model sha": "accde7145d81a428c782695ea61eebc608efd980", "Average \u2b06\ufe0f": 26.173645381640075, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7112893788481229, "IFEval": 71.1289378848123, "BBH Raw": 0.5231680557624704, "BBH": 31.3609793143707, "MATH Lvl 5 Raw": 0.120845921450151, "MATH Lvl 5": 12.084592145015106, "GPQA Raw": 0.2743288590604026, "GPQA": 3.243847874720355, "MUSR Raw": 0.3960416666666666, "MUSR": 10.671874999999996, "MMLU-PRO Raw": 0.3569647606382978, "MMLU-PRO": 28.551640070921984, "Maintainer's Highlight": false, "Upload To Hub Date": "", "Submission Date": "2024-08-27T00:00:00", "Generation": 0, "Base Model": "Removed"}, {"eval_name": "DreadPoor_Trinas_Nectar-8B-model_stock_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/DreadPoor/Trinas_Nectar-8B-model_stock\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">DreadPoor/Trinas_Nectar-8B-model_stock</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/DreadPoor__Trinas_Nectar-8B-model_stock-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "DreadPoor/Trinas_Nectar-8B-model_stock", "Model sha": "cb46b8431872557904d83fc5aa1b90dabeb74acc", "Average \u2b06\ufe0f": 27.270691825021363, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 2, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7259272064788096, "IFEval": 72.59272064788095, "BBH Raw": 0.5256123853406084, "BBH": 31.97509368554489, "MATH Lvl 5 Raw": 0.1374622356495468, "MATH Lvl 5": 13.746223564954684, "GPQA Raw": 0.2860738255033557, "GPQA": 4.809843400447425, "MUSR Raw": 0.4067708333333333, "MUSR": 11.413020833333327, "MMLU-PRO Raw": 0.3617852393617021, "MMLU-PRO": 29.08724881796691, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-16T00:00:00", "Submission Date": "2024-08-27T00:00:00", "Generation": 1, "Base Model": "DreadPoor/Trinas_Nectar-8B-model_stock (Merge)"}, {"eval_name": "DreadPoor_felix_dies-mistral-7B-model_stock_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/DreadPoor/felix_dies-mistral-7B-model_stock\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">DreadPoor/felix_dies-mistral-7B-model_stock</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/DreadPoor__felix_dies-mistral-7B-model_stock-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "DreadPoor/felix_dies-mistral-7B-model_stock", "Model sha": "bb317aa7565625327e18c5158aebd4710aa1d925", "Average \u2b06\ufe0f": 17.98853505038262, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3007786007792656, "IFEval": 30.07786007792657, "BBH Raw": 0.4900918073527422, "BBH": 28.890798050964488, "MATH Lvl 5 Raw": 0.0445619335347432, "MATH Lvl 5": 4.45619335347432, "GPQA Raw": 0.2919463087248322, "GPQA": 5.592841163310966, "MUSR Raw": 0.4518229166666667, "MUSR": 15.477864583333336, "MMLU-PRO Raw": 0.3109208776595745, "MMLU-PRO": 23.43565307328605, "Maintainer's Highlight": false, "Upload To Hub Date": "", "Submission Date": "2024-09-30T00:00:00", "Generation": 0, "Base Model": "Removed"}, {"eval_name": "EleutherAI_gpt-j-6b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "GPTJForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/EleutherAI/gpt-j-6b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">EleutherAI/gpt-j-6b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/EleutherAI__gpt-j-6b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "EleutherAI/gpt-j-6b", "Model sha": "47e169305d2e8376be1d31e765533382721b2cc1", "Average \u2b06\ufe0f": 6.545235535293089, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1424, "#Params (B)": 6, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2522185578708937, "IFEval": 25.221855787089368, "BBH Raw": 0.3191044431037278, "BBH": 4.912818068323685, "MATH Lvl 5 Raw": 0.0120845921450151, "MATH Lvl 5": 1.2084592145015105, "GPQA Raw": 0.2458053691275167, "GPQA": 0.0, "MUSR Raw": 0.36575, "MUSR": 5.252083333333334, "MMLU-PRO Raw": 0.1240857712765957, "MMLU-PRO": 2.6761968085106376, "Maintainer's Highlight": true, "Upload To Hub Date": "2022-03-02T00:00:00", "Submission Date": "2024-08-19T00:00:00", "Generation": 0, "Base Model": "EleutherAI/gpt-j-6b"}, {"eval_name": "EleutherAI_gpt-neo-1.3B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "GPTNeoForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/EleutherAI/gpt-neo-1.3B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">EleutherAI/gpt-neo-1.3B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/EleutherAI__gpt-neo-1.3B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "EleutherAI/gpt-neo-1.3B", "Model sha": "dbe59a7f4a88d01d1ba9798d78dbe3fe038792c8", "Average \u2b06\ufe0f": 5.328150264736912, "Hub License": "mit", "Hub \u2764\ufe0f": 259, "#Params (B)": 1, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2079050253327836, "IFEval": 20.790502533278367, "BBH Raw": 0.303923158693564, "BBH": 3.024569180930987, "MATH Lvl 5 Raw": 0.0067975830815709, "MATH Lvl 5": 0.6797583081570997, "GPQA Raw": 0.2558724832214765, "GPQA": 0.7829977628635317, "MUSR Raw": 0.38165625, "MUSR": 4.873697916666666, "MMLU-PRO Raw": 0.1163563829787234, "MMLU-PRO": 1.8173758865248215, "Maintainer's Highlight": true, "Upload To Hub Date": "2022-03-02T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "EleutherAI/gpt-neo-1.3B"}, {"eval_name": "EleutherAI_gpt-neo-125m_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "GPTNeoForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/EleutherAI/gpt-neo-125m\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">EleutherAI/gpt-neo-125m</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/EleutherAI__gpt-neo-125m-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "EleutherAI/gpt-neo-125m", "Model sha": "21def0189f5705e2521767faed922f1f15e7d7db", "Average \u2b06\ufe0f": 4.382145673978601, "Hub License": "mit", "Hub \u2764\ufe0f": 179, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.190544422133273, "IFEval": 19.054442213327302, "BBH Raw": 0.3115156885791523, "BBH": 3.436738951426704, "MATH Lvl 5 Raw": 0.0045317220543806, "MATH Lvl 5": 0.4531722054380665, "GPQA Raw": 0.2533557046979866, "GPQA": 0.4474272930648763, "MUSR Raw": 0.3593333333333333, "MUSR": 2.6166666666666654, "MMLU-PRO Raw": 0.1025598404255319, "MMLU-PRO": 0.2844267139479898, "Maintainer's Highlight": true, "Upload To Hub Date": "2022-03-02T00:00:00", "Submission Date": "2024-08-10T00:00:00", "Generation": 0, "Base Model": "EleutherAI/gpt-neo-125m"}, {"eval_name": "EleutherAI_gpt-neo-2.7B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "GPTNeoForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/EleutherAI/gpt-neo-2.7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">EleutherAI/gpt-neo-2.7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/EleutherAI__gpt-neo-2.7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "EleutherAI/gpt-neo-2.7B", "Model sha": "e24fa291132763e59f4a5422741b424fb5d59056", "Average \u2b06\ufe0f": 6.342930983263378, "Hub License": "mit", "Hub \u2764\ufe0f": 428, "#Params (B)": 2, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2589628851447493, "IFEval": 25.896288514474925, "BBH Raw": 0.3139516033315253, "BBH": 4.178602667081014, "MATH Lvl 5 Raw": 0.0052870090634441, "MATH Lvl 5": 0.5287009063444109, "GPQA Raw": 0.2659395973154362, "GPQA": 2.1252796420581683, "MUSR Raw": 0.3553645833333334, "MUSR": 3.5205729166666675, "MMLU-PRO Raw": 0.1162732712765957, "MMLU-PRO": 1.8081412529550824, "Maintainer's Highlight": true, "Upload To Hub Date": "2022-03-02T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "EleutherAI/gpt-neo-2.7B"}, {"eval_name": "EleutherAI_gpt-neox-20b_float16", "Precision": "float16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "GPTNeoXForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/EleutherAI/gpt-neox-20b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">EleutherAI/gpt-neox-20b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/EleutherAI__gpt-neox-20b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "EleutherAI/gpt-neox-20b", "Model sha": "c292233c833e336628618a88a648727eb3dff0a7", "Average \u2b06\ufe0f": 5.990640984297092, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 530, "#Params (B)": 20, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2586880587951081, "IFEval": 25.86880587951081, "BBH Raw": 0.3165038032087756, "BBH": 4.929114201526899, "MATH Lvl 5 Raw": 0.0060422960725075, "MATH Lvl 5": 0.6042296072507553, "GPQA Raw": 0.2432885906040268, "GPQA": 0.0, "MUSR Raw": 0.3646666666666666, "MUSR": 2.816666666666666, "MMLU-PRO Raw": 0.1155252659574468, "MMLU-PRO": 1.725029550827422, "Maintainer's Highlight": true, "Upload To Hub Date": "2022-04-07T00:00:00", "Submission Date": "2024-06-09T00:00:00", "Generation": 0, "Base Model": "EleutherAI/gpt-neox-20b"}, {"eval_name": "EleutherAI_pythia-12b_float16", "Precision": "float16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "GPTNeoXForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/EleutherAI/pythia-12b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">EleutherAI/pythia-12b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/EleutherAI__pythia-12b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "EleutherAI/pythia-12b", "Model sha": "35c9d7f32fbb108fb8b5bdd574eb03369d1eed49", "Average \u2b06\ufe0f": 5.9339603247654615, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 131, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2471475684517081, "IFEval": 24.71475684517081, "BBH Raw": 0.3179653957935337, "BBH": 4.987531038290507, "MATH Lvl 5 Raw": 0.0090634441087613, "MATH Lvl 5": 0.906344410876133, "GPQA Raw": 0.2466442953020134, "GPQA": 0.0, "MUSR Raw": 0.3646979166666667, "MUSR": 3.787239583333335, "MMLU-PRO Raw": 0.1108710106382978, "MMLU-PRO": 1.2078900709219855, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-02-28T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "EleutherAI/pythia-12b"}, {"eval_name": "EleutherAI_pythia-160m_float16", "Precision": "float16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "GPTNeoXForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/EleutherAI/pythia-160m\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">EleutherAI/pythia-160m</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/EleutherAI__pythia-160m-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "EleutherAI/pythia-160m", "Model sha": "50f5173d932e8e61f858120bcb800b97af589f46", "Average \u2b06\ufe0f": 5.6171015655565055, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 26, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1815516163778773, "IFEval": 18.15516163778773, "BBH Raw": 0.2970437484241321, "BBH": 2.198832279508135, "MATH Lvl 5 Raw": 0.0022658610271903, "MATH Lvl 5": 0.2265861027190332, "GPQA Raw": 0.2583892617449664, "GPQA": 1.1185682326621946, "MUSR Raw": 0.4179375, "MUSR": 10.675520833333332, "MMLU-PRO Raw": 0.1119514627659574, "MMLU-PRO": 1.3279403073286051, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-02-08T00:00:00", "Submission Date": "2024-06-09T00:00:00", "Generation": 0, "Base Model": "EleutherAI/pythia-160m"}, {"eval_name": "EleutherAI_pythia-2.8b_float16", "Precision": "float16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "GPTNeoXForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/EleutherAI/pythia-2.8b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">EleutherAI/pythia-2.8b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/EleutherAI__pythia-2.8b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "EleutherAI/pythia-2.8b", "Model sha": "2a259cdd96a4beb1cdf467512e3904197345f6a9", "Average \u2b06\ufe0f": 5.441653230243495, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 29, "#Params (B)": 2, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2173222604910526, "IFEval": 21.73222604910526, "BBH Raw": 0.3224085936276087, "BBH": 5.077786161905462, "MATH Lvl 5 Raw": 0.0067975830815709, "MATH Lvl 5": 0.6797583081570997, "GPQA Raw": 0.25, "GPQA": 0.0, "MUSR Raw": 0.3485729166666667, "MUSR": 3.63828125, "MMLU-PRO Raw": 0.1136968085106382, "MMLU-PRO": 1.521867612293143, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-02-13T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "EleutherAI/pythia-2.8b"}, {"eval_name": "EleutherAI_pythia-410m_float16", "Precision": "float16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "GPTNeoXForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/EleutherAI/pythia-410m\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">EleutherAI/pythia-410m</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/EleutherAI__pythia-410m-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "EleutherAI/pythia-410m", "Model sha": "9879c9b5f8bea9051dcb0e68dff21493d67e9d4f", "Average \u2b06\ufe0f": 5.113779260124896, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 21, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.219545251045005, "IFEval": 21.954525104500505, "BBH Raw": 0.302813387064426, "BBH": 2.7154281203357478, "MATH Lvl 5 Raw": 0.0030211480362537, "MATH Lvl 5": 0.3021148036253776, "GPQA Raw": 0.259228187919463, "GPQA": 1.230425055928408, "MUSR Raw": 0.3578125, "MUSR": 3.0598958333333326, "MMLU-PRO Raw": 0.112782579787234, "MMLU-PRO": 1.4202866430260035, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-02-13T00:00:00", "Submission Date": "2024-06-09T00:00:00", "Generation": 0, "Base Model": "EleutherAI/pythia-410m"}, {"eval_name": "EleutherAI_pythia-6.9b_float16", "Precision": "float16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "GPTNeoXForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/EleutherAI/pythia-6.9b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">EleutherAI/pythia-6.9b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/EleutherAI__pythia-6.9b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "EleutherAI/pythia-6.9b", "Model sha": "f271943e880e60c0c715fd10e4dc74ec4e31eb44", "Average \u2b06\ufe0f": 5.853253723382477, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 43, "#Params (B)": 6, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2281136273975274, "IFEval": 22.811362739752745, "BBH Raw": 0.3232287869322383, "BBH": 5.88163197981621, "MATH Lvl 5 Raw": 0.0075528700906344, "MATH Lvl 5": 0.7552870090634441, "GPQA Raw": 0.2516778523489933, "GPQA": 0.2237136465324418, "MUSR Raw": 0.3590520833333333, "MUSR": 3.81484375, "MMLU-PRO Raw": 0.1146941489361702, "MMLU-PRO": 1.632683215130022, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-02-14T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "EleutherAI/pythia-6.9b"}, {"eval_name": "Enno-Ai_EnnoAi-Pro-French-Llama-3-8B-v0.4_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Enno-Ai/EnnoAi-Pro-French-Llama-3-8B-v0.4\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Enno-Ai/EnnoAi-Pro-French-Llama-3-8B-v0.4</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Enno-Ai__EnnoAi-Pro-French-Llama-3-8B-v0.4-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Enno-Ai/EnnoAi-Pro-French-Llama-3-8B-v0.4", "Model sha": "328722ae96e3a112ec900dbe77d410788a526c5c", "Average \u2b06\ufe0f": 15.180944731273977, "Hub License": "creativeml-openrail-m", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4188807918545016, "IFEval": 41.88807918545016, "BBH Raw": 0.4074954889367559, "BBH": 16.875928374989595, "MATH Lvl 5 Raw": 0.0060422960725075, "MATH Lvl 5": 0.6042296072507553, "GPQA Raw": 0.2709731543624161, "GPQA": 2.796420581655479, "MUSR Raw": 0.417, "MUSR": 10.758333333333336, "MMLU-PRO Raw": 0.2634640957446808, "MMLU-PRO": 18.162677304964536, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-27T00:00:00", "Submission Date": "2024-06-30T00:00:00", "Generation": 0, "Base Model": "Enno-Ai/EnnoAi-Pro-French-Llama-3-8B-v0.4"}, {"eval_name": "Enno-Ai_EnnoAi-Pro-Llama-3-8B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Enno-Ai/EnnoAi-Pro-Llama-3-8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Enno-Ai/EnnoAi-Pro-Llama-3-8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Enno-Ai__EnnoAi-Pro-Llama-3-8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Enno-Ai/EnnoAi-Pro-Llama-3-8B", "Model sha": "6a5d745bdd304753244fe601e2a958d37d13cd71", "Average \u2b06\ufe0f": 12.17466675780287, "Hub License": "creativeml-openrail-m", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3195377154838051, "IFEval": 31.953771548380523, "BBH Raw": 0.4151575806137866, "BBH": 17.507545086854382, "MATH Lvl 5 Raw": 0.0015105740181268, "MATH Lvl 5": 0.1510574018126888, "GPQA Raw": 0.261744966442953, "GPQA": 1.5659955257270708, "MUSR Raw": 0.4070520833333333, "MUSR": 9.081510416666667, "MMLU-PRO Raw": 0.2150930851063829, "MMLU-PRO": 12.788120567375886, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-01T00:00:00", "Submission Date": "2024-07-08T00:00:00", "Generation": 0, "Base Model": "Enno-Ai/EnnoAi-Pro-Llama-3-8B"}, {"eval_name": "Enno-Ai_EnnoAi-Pro-Llama-3-8B-v0.3_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Enno-Ai/EnnoAi-Pro-Llama-3-8B-v0.3\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Enno-Ai/EnnoAi-Pro-Llama-3-8B-v0.3</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Enno-Ai__EnnoAi-Pro-Llama-3-8B-v0.3-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Enno-Ai/EnnoAi-Pro-Llama-3-8B-v0.3", "Model sha": "cf29b8b484a909132e3a1f85ce891d28347c0d13", "Average \u2b06\ufe0f": 17.498881657596346, "Hub License": "creativeml-openrail-m", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5082569803676467, "IFEval": 50.82569803676467, "BBH Raw": 0.4100577461090639, "BBH": 16.668385554519382, "MATH Lvl 5 Raw": 0.0105740181268882, "MATH Lvl 5": 1.0574018126888218, "GPQA Raw": 0.2651006711409396, "GPQA": 2.0134228187919474, "MUSR Raw": 0.4235729166666666, "MUSR": 12.313281249999996, "MMLU-PRO Raw": 0.2990359042553192, "MMLU-PRO": 22.11510047281324, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-26T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "Enno-Ai/EnnoAi-Pro-Llama-3-8B-v0.3"}, {"eval_name": "Enno-Ai_EnnoAi-Pro-Llama-3.1-8B-v0.9_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Enno-Ai/EnnoAi-Pro-Llama-3.1-8B-v0.9\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Enno-Ai/EnnoAi-Pro-Llama-3.1-8B-v0.9</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Enno-Ai__EnnoAi-Pro-Llama-3.1-8B-v0.9-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Enno-Ai/EnnoAi-Pro-Llama-3.1-8B-v0.9", "Model sha": "c740871122fd471a1a225cf2b4368e333752d74c", "Average \u2b06\ufe0f": 14.945694080269645, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4689147018799009, "IFEval": 46.891470187990095, "BBH Raw": 0.4160272083619012, "BBH": 17.49829637438283, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2659395973154362, "GPQA": 2.1252796420581683, "MUSR Raw": 0.3831770833333333, "MUSR": 5.43046875, "MMLU-PRO Raw": 0.2595578457446808, "MMLU-PRO": 17.728649527186757, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-22T00:00:00", "Submission Date": "2024-09-06T00:00:00", "Generation": 0, "Base Model": "Enno-Ai/EnnoAi-Pro-Llama-3.1-8B-v0.9"}, {"eval_name": "EnnoAi_EnnoAi-Pro-Llama-3.1-8B-v1.0_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/EnnoAi/EnnoAi-Pro-Llama-3.1-8B-v1.0\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">EnnoAi/EnnoAi-Pro-Llama-3.1-8B-v1.0</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/EnnoAi__EnnoAi-Pro-Llama-3.1-8B-v1.0-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "EnnoAi/EnnoAi-Pro-Llama-3.1-8B-v1.0", "Model sha": "c740871122fd471a1a225cf2b4368e333752d74c", "Average \u2b06\ufe0f": 14.97108966029361, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4704384366813389, "IFEval": 47.04384366813389, "BBH Raw": 0.4160272083619012, "BBH": 17.49829637438283, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2659395973154362, "GPQA": 2.1252796420581683, "MUSR Raw": 0.3831770833333333, "MUSR": 5.43046875, "MMLU-PRO Raw": 0.2595578457446808, "MMLU-PRO": 17.728649527186757, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-22T00:00:00", "Submission Date": "2024-09-06T00:00:00", "Generation": 0, "Base Model": "EnnoAi/EnnoAi-Pro-Llama-3.1-8B-v1.0"}, {"eval_name": "Epiculous_Azure_Dusk-v0.2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Epiculous/Azure_Dusk-v0.2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Epiculous/Azure_Dusk-v0.2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Epiculous__Azure_Dusk-v0.2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Epiculous/Azure_Dusk-v0.2", "Model sha": "ebddf1b2efbe7f9cae066d263b0991ded89c88e8", "Average \u2b06\ufe0f": 14.025650985925456, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 7, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.346715603487635, "IFEval": 34.67156034876351, "BBH Raw": 0.4119721873553597, "BBH": 17.396414392379338, "MATH Lvl 5 Raw": 0.0166163141993957, "MATH Lvl 5": 1.6616314199395772, "GPQA Raw": 0.2609060402684564, "GPQA": 1.45413870246085, "MUSR Raw": 0.3834583333333333, "MUSR": 6.365625000000002, "MMLU-PRO Raw": 0.3034408244680851, "MMLU-PRO": 22.604536052009458, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-09T00:00:00", "Submission Date": "2024-09-14T00:00:00", "Generation": 0, "Base Model": "Epiculous/Azure_Dusk-v0.2"}, {"eval_name": "Epiculous_Crimson_Dawn-v0.2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Epiculous/Crimson_Dawn-v0.2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Epiculous/Crimson_Dawn-v0.2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Epiculous__Crimson_Dawn-v0.2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Epiculous/Crimson_Dawn-v0.2", "Model sha": "4cceb1e25026afef241ad5325097e88eccd8f37a", "Average \u2b06\ufe0f": 14.821600296632884, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 8, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3103454389907667, "IFEval": 31.034543899076677, "BBH Raw": 0.4482379648964543, "BBH": 21.68824851395527, "MATH Lvl 5 Raw": 0.0271903323262839, "MATH Lvl 5": 2.719033232628399, "GPQA Raw": 0.276006711409396, "GPQA": 3.467561521252797, "MUSR Raw": 0.4151770833333333, "MUSR": 10.897135416666666, "MMLU-PRO Raw": 0.2721077127659574, "MMLU-PRO": 19.123079196217496, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-02T00:00:00", "Submission Date": "2024-09-05T00:00:00", "Generation": 0, "Base Model": "Epiculous/Crimson_Dawn-v0.2"}, {"eval_name": "Epiculous_Violet_Twilight-v0.2_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Epiculous/Violet_Twilight-v0.2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Epiculous/Violet_Twilight-v0.2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Epiculous__Violet_Twilight-v0.2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Epiculous/Violet_Twilight-v0.2", "Model sha": "30c8bad3c1f565150afbf2fc90cacf4f45d096f6", "Average \u2b06\ufe0f": 18.527597253790933, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 8, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4531775688506496, "IFEval": 45.317756885064966, "BBH Raw": 0.4614552476845888, "BBH": 23.94053725590186, "MATH Lvl 5 Raw": 0.0271903323262839, "MATH Lvl 5": 2.719033232628399, "GPQA Raw": 0.2659395973154362, "GPQA": 2.1252796420581683, "MUSR Raw": 0.4299375, "MUSR": 13.608854166666664, "MMLU-PRO Raw": 0.3110871010638298, "MMLU-PRO": 23.45412234042553, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-12T00:00:00", "Submission Date": "2024-09-16T00:00:00", "Generation": 0, "Base Model": "Epiculous/Violet_Twilight-v0.2"}, {"eval_name": "EpistemeAI_Alpaca-Llama3.1-8B_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/EpistemeAI/Alpaca-Llama3.1-8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">EpistemeAI/Alpaca-Llama3.1-8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/EpistemeAI__Alpaca-Llama3.1-8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "EpistemeAI/Alpaca-Llama3.1-8B", "Model sha": "3152dfa17322dff7c6af6dbf3daceaf5db51e230", "Average \u2b06\ufe0f": 13.83398895060816, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1598691471961063, "IFEval": 15.986914719610631, "BBH Raw": 0.4755260853974287, "BBH": 25.93522655511771, "MATH Lvl 5 Raw": 0.0415407854984894, "MATH Lvl 5": 4.154078549848943, "GPQA Raw": 0.2902684563758389, "GPQA": 5.369127516778524, "MUSR Raw": 0.3402604166666667, "MUSR": 6.599218750000001, "MMLU-PRO Raw": 0.3246343085106383, "MMLU-PRO": 24.959367612293143, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-11T00:00:00", "Submission Date": "2024-08-13T00:00:00", "Generation": 2, "Base Model": "meta-llama/Meta-Llama-3.1-8B"}, {"eval_name": "EpistemeAI_Athena-gemma-2-2b-it_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/EpistemeAI/Athena-gemma-2-2b-it\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">EpistemeAI/Athena-gemma-2-2b-it</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/EpistemeAI__Athena-gemma-2-2b-it-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "EpistemeAI/Athena-gemma-2-2b-it", "Model sha": "661c1dc6a1a096222e33416e099bd02b7b970405", "Average \u2b06\ufe0f": 14.26915315913036, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 2, "#Params (B)": 2, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3134172883504657, "IFEval": 31.341728835046567, "BBH Raw": 0.42642293591146, "BBH": 19.417817674461517, "MATH Lvl 5 Raw": 0.0324773413897281, "MATH Lvl 5": 3.2477341389728096, "GPQA Raw": 0.2684563758389262, "GPQA": 2.460850111856823, "MUSR Raw": 0.4350520833333333, "MUSR": 13.348177083333333, "MMLU-PRO Raw": 0.2421875, "MMLU-PRO": 15.79861111111111, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-29T00:00:00", "Submission Date": "2024-09-06T00:00:00", "Generation": 2, "Base Model": "unsloth/gemma-2-9b-it-bnb-4bit"}, {"eval_name": "EpistemeAI_Athena-gemma-2-2b-it-Philos_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/EpistemeAI/Athena-gemma-2-2b-it-Philos\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">EpistemeAI/Athena-gemma-2-2b-it-Philos</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/EpistemeAI__Athena-gemma-2-2b-it-Philos-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "EpistemeAI/Athena-gemma-2-2b-it-Philos", "Model sha": "dea2b35d496bd32ed3c88d42ff3022654153f2e1", "Average \u2b06\ufe0f": 15.097481043601915, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 2, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4620950189940469, "IFEval": 46.20950189940469, "BBH Raw": 0.3794776879058674, "BBH": 13.212088152695856, "MATH Lvl 5 Raw": 0.0030211480362537, "MATH Lvl 5": 0.3021148036253776, "GPQA Raw": 0.2810402684563758, "GPQA": 4.138702460850116, "MUSR Raw": 0.4313645833333333, "MUSR": 12.85390625, "MMLU-PRO Raw": 0.2248171542553191, "MMLU-PRO": 13.86857269503546, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-05T00:00:00", "Submission Date": "2024-09-05T00:00:00", "Generation": 1, "Base Model": "unsloth/gemma-2-2b-it-bnb-4bit"}, {"eval_name": "EpistemeAI_Athene-codegemma-2-7b-it-alpaca-v1.3_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "GemmaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/EpistemeAI/Athene-codegemma-2-7b-it-alpaca-v1.3\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">EpistemeAI/Athene-codegemma-2-7b-it-alpaca-v1.3</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/EpistemeAI__Athene-codegemma-2-7b-it-alpaca-v1.3-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "EpistemeAI/Athene-codegemma-2-7b-it-alpaca-v1.3", "Model sha": "9c26e1242a11178b53937bc0e9a744ef6141e05a", "Average \u2b06\ufe0f": 17.21331665389153, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4029940557720182, "IFEval": 40.299405577201824, "BBH Raw": 0.4331916189482215, "BBH": 20.87379456667128, "MATH Lvl 5 Raw": 0.0558912386706948, "MATH Lvl 5": 5.589123867069486, "GPQA Raw": 0.2802013422818792, "GPQA": 4.026845637583895, "MUSR Raw": 0.4503020833333333, "MUSR": 14.854427083333334, "MMLU-PRO Raw": 0.2587267287234042, "MMLU-PRO": 17.636303191489358, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-06T00:00:00", "Submission Date": "2024-09-06T00:00:00", "Generation": 2, "Base Model": "Removed"}, {"eval_name": "EpistemeAI_FineLlama3.1-8B-Instruct_4bit", "Precision": "4bit", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Adapter", "Architecture": "?", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/EpistemeAI/FineLlama3.1-8B-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">EpistemeAI/FineLlama3.1-8B-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/EpistemeAI__FineLlama3.1-8B-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "EpistemeAI/FineLlama3.1-8B-Instruct", "Model sha": "a8b0fc584b10e0110e04f9d21c7f10d24391c1d5", "Average \u2b06\ufe0f": 11.050434229320144, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 14, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.0800099292100515, "IFEval": 8.000992921005155, "BBH Raw": 0.4557363538416332, "BBH": 23.506618815003453, "MATH Lvl 5 Raw": 0.0234138972809667, "MATH Lvl 5": 2.3413897280966767, "GPQA Raw": 0.2802013422818792, "GPQA": 4.026845637583895, "MUSR Raw": 0.3481666666666667, "MUSR": 4.954166666666666, "MMLU-PRO Raw": 0.3112533244680851, "MMLU-PRO": 23.47259160756501, "Maintainer's Highlight": false, "Upload To Hub Date": "", "Submission Date": "2024-08-10T00:00:00", "Generation": 0, "Base Model": "Removed"}, {"eval_name": "EpistemeAI_Fireball-12B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/EpistemeAI/Fireball-12B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">EpistemeAI/Fireball-12B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/EpistemeAI__Fireball-12B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "EpistemeAI/Fireball-12B", "Model sha": "e2ed12c3244f2502321fb20e76dfc72ad7817d6e", "Average \u2b06\ufe0f": 15.44641453563428, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1833501775289565, "IFEval": 18.33501775289565, "BBH Raw": 0.5110893652548262, "BBH": 30.666711502632054, "MATH Lvl 5 Raw": 0.0354984894259818, "MATH Lvl 5": 3.5498489425981874, "GPQA Raw": 0.261744966442953, "GPQA": 1.5659955257270708, "MUSR Raw": 0.4236354166666666, "MUSR": 12.521093749999997, "MMLU-PRO Raw": 0.3343583776595745, "MMLU-PRO": 26.03981973995272, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-20T00:00:00", "Submission Date": "2024-08-21T00:00:00", "Generation": 2, "Base Model": "Removed"}, {"eval_name": "EpistemeAI_Fireball-12B-v1.13a-philosophers_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/EpistemeAI/Fireball-12B-v1.13a-philosophers\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">EpistemeAI/Fireball-12B-v1.13a-philosophers</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/EpistemeAI__Fireball-12B-v1.13a-philosophers-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "EpistemeAI/Fireball-12B-v1.13a-philosophers", "Model sha": "7fa824d4a40abca3f8c75d432ea151dc0d1d67d6", "Average \u2b06\ufe0f": 14.340159682699374, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 2, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.0875532476052429, "IFEval": 8.755324760524298, "BBH Raw": 0.5102697700597862, "BBH": 30.33623264030357, "MATH Lvl 5 Raw": 0.0385196374622356, "MATH Lvl 5": 3.8519637462235647, "GPQA Raw": 0.3011744966442953, "GPQA": 6.823266219239373, "MUSR Raw": 0.4080729166666666, "MUSR": 9.975781249999995, "MMLU-PRO Raw": 0.3366855053191489, "MMLU-PRO": 26.29838947990544, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-28T00:00:00", "Submission Date": "2024-09-03T00:00:00", "Generation": 1, "Base Model": "Removed"}, {"eval_name": "EpistemeAI_Fireball-Alpaca-Llama-3.1-8B-Philos-DPO-200_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/EpistemeAI/Fireball-Alpaca-Llama-3.1-8B-Philos-DPO-200\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">EpistemeAI/Fireball-Alpaca-Llama-3.1-8B-Philos-DPO-200</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/EpistemeAI__Fireball-Alpaca-Llama-3.1-8B-Philos-DPO-200-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "EpistemeAI/Fireball-Alpaca-Llama-3.1-8B-Philos-DPO-200", "Model sha": "27d67626304954db71f21fec9e7fc516421274ec", "Average \u2b06\ufe0f": 20.878152146275053, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4577243934981405, "IFEval": 45.77243934981405, "BBH Raw": 0.4838398624677178, "BBH": 26.377774027551386, "MATH Lvl 5 Raw": 0.1080060422960725, "MATH Lvl 5": 10.80060422960725, "GPQA Raw": 0.3003355704697986, "GPQA": 6.711409395973152, "MUSR Raw": 0.3944583333333333, "MUSR": 6.907291666666666, "MMLU-PRO Raw": 0.3582945478723404, "MMLU-PRO": 28.69939420803782, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-16T00:00:00", "Submission Date": "2024-09-16T00:00:00", "Generation": 3, "Base Model": "unsloth/Meta-Llama-3.1-8B"}, {"eval_name": "EpistemeAI_Fireball-Alpaca-Llama3.1.07-8B-Philos-Math-KTO-beta_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/EpistemeAI/Fireball-Alpaca-Llama3.1.07-8B-Philos-Math-KTO-beta\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">EpistemeAI/Fireball-Alpaca-Llama3.1.07-8B-Philos-Math-KTO-beta</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/EpistemeAI__Fireball-Alpaca-Llama3.1.07-8B-Philos-Math-KTO-beta-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "EpistemeAI/Fireball-Alpaca-Llama3.1.07-8B-Philos-Math-KTO-beta", "Model sha": "2851384717556dd6ac14c00ed87aac1f267eb263", "Average \u2b06\ufe0f": 24.90234874285021, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7274010735958367, "IFEval": 72.74010735958367, "BBH Raw": 0.4864890213966847, "BBH": 26.897964171299805, "MATH Lvl 5 Raw": 0.1321752265861027, "MATH Lvl 5": 13.217522658610273, "GPQA Raw": 0.2802013422818792, "GPQA": 4.026845637583895, "MUSR Raw": 0.3619375, "MUSR": 4.275520833333334, "MMLU-PRO Raw": 0.3543051861702128, "MMLU-PRO": 28.25613179669031, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-12T00:00:00", "Submission Date": "2024-09-14T00:00:00", "Generation": 4, "Base Model": "unsloth/Meta-Llama-3.1-8B"}, {"eval_name": "EpistemeAI_Fireball-Alpaca-Llama3.1.08-8B-Philos-C-R2_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/EpistemeAI/Fireball-Alpaca-Llama3.1.08-8B-Philos-C-R2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">EpistemeAI/Fireball-Alpaca-Llama3.1.08-8B-Philos-C-R2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/EpistemeAI__Fireball-Alpaca-Llama3.1.08-8B-Philos-C-R2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "EpistemeAI/Fireball-Alpaca-Llama3.1.08-8B-Philos-C-R2", "Model sha": "b19336101aa5f4807d1574f4c11eebc1c1a1c34e", "Average \u2b06\ufe0f": 22.323890524521705, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4673156114664645, "IFEval": 46.731561146646456, "BBH Raw": 0.4932027479020209, "BBH": 28.24700927539328, "MATH Lvl 5 Raw": 0.1102719033232628, "MATH Lvl 5": 11.027190332326285, "GPQA Raw": 0.2860738255033557, "GPQA": 4.809843400447425, "MUSR Raw": 0.4623645833333333, "MUSR": 16.995572916666667, "MMLU-PRO Raw": 0.3351894946808511, "MMLU-PRO": 26.13216607565012, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-14T00:00:00", "Submission Date": "2024-09-14T00:00:00", "Generation": 2, "Base Model": "unsloth/Meta-Llama-3.1-8B"}, {"eval_name": "EpistemeAI_Fireball-Meta-Llama-3.1-8B-Instruct-Agent-0.003-128K_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/EpistemeAI/Fireball-Meta-Llama-3.1-8B-Instruct-Agent-0.003-128K\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">EpistemeAI/Fireball-Meta-Llama-3.1-8B-Instruct-Agent-0.003-128K</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/EpistemeAI__Fireball-Meta-Llama-3.1-8B-Instruct-Agent-0.003-128K-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "EpistemeAI/Fireball-Meta-Llama-3.1-8B-Instruct-Agent-0.003-128K", "Model sha": "b4a88fb5fb27fc5d8a503303cdb7aaeff373fd92", "Average \u2b06\ufe0f": 20.476110504709, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 2, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4457339858242796, "IFEval": 44.57339858242796, "BBH Raw": 0.4897319921686054, "BBH": 28.02516078188715, "MATH Lvl 5 Raw": 0.1117824773413897, "MATH Lvl 5": 11.178247734138973, "GPQA Raw": 0.2944630872483221, "GPQA": 5.92841163310962, "MUSR Raw": 0.3762291666666666, "MUSR": 4.895312499999999, "MMLU-PRO Raw": 0.3543051861702128, "MMLU-PRO": 28.25613179669031, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-26T00:00:00", "Submission Date": "2024-10-05T00:00:00", "Generation": 1, "Base Model": "Removed"}, {"eval_name": "EpistemeAI_Fireball-Meta-Llama-3.1-8B-Instruct-Agent-0.003-128K-code_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/EpistemeAI/Fireball-Meta-Llama-3.1-8B-Instruct-Agent-0.003-128K-code\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">EpistemeAI/Fireball-Meta-Llama-3.1-8B-Instruct-Agent-0.003-128K-code</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/EpistemeAI__Fireball-Meta-Llama-3.1-8B-Instruct-Agent-0.003-128K-code-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "EpistemeAI/Fireball-Meta-Llama-3.1-8B-Instruct-Agent-0.003-128K-code", "Model sha": "8e8f1569a8a01ed3d6588f2669c730d4993355b5", "Average \u2b06\ufe0f": 23.720715972216976, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.5975334335119704, "IFEval": 59.753343351197046, "BBH Raw": 0.4904191122627008, "BBH": 28.17188778217276, "MATH Lvl 5 Raw": 0.120845921450151, "MATH Lvl 5": 12.084592145015106, "GPQA Raw": 0.3020134228187919, "GPQA": 6.935123042505594, "MUSR Raw": 0.40103125, "MUSR": 8.462239583333334, "MMLU-PRO Raw": 0.3422539893617021, "MMLU-PRO": 26.917109929078016, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-04T00:00:00", "Submission Date": "2024-10-05T00:00:00", "Generation": 2, "Base Model": "Removed"}, {"eval_name": "EpistemeAI_Fireball-Meta-Llama-3.1-8B-Instruct-Agent-0.004-128K-code-COT_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/EpistemeAI/Fireball-Meta-Llama-3.1-8B-Instruct-Agent-0.004-128K-code-COT\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">EpistemeAI/Fireball-Meta-Llama-3.1-8B-Instruct-Agent-0.004-128K-code-COT</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/EpistemeAI__Fireball-Meta-Llama-3.1-8B-Instruct-Agent-0.004-128K-code-COT-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "EpistemeAI/Fireball-Meta-Llama-3.1-8B-Instruct-Agent-0.004-128K-code-COT", "Model sha": "bb90c19dc7c4a509e7bd73f4620dca818b58be25", "Average \u2b06\ufe0f": 20.61825318563923, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4578241288669619, "IFEval": 45.78241288669619, "BBH Raw": 0.4760520079608936, "BBH": 25.82086537586569, "MATH Lvl 5 Raw": 0.1238670694864048, "MATH Lvl 5": 12.386706948640484, "GPQA Raw": 0.2936241610738255, "GPQA": 5.8165548098434, "MUSR Raw": 0.3881354166666667, "MUSR": 6.450260416666667, "MMLU-PRO Raw": 0.3470744680851064, "MMLU-PRO": 27.45271867612293, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-11T00:00:00", "Submission Date": "2024-10-11T00:00:00", "Generation": 3, "Base Model": "Removed"}, {"eval_name": "EpistemeAI_Fireball-Meta-Llama-3.1-8B-Instruct-Math_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/EpistemeAI/Fireball-Meta-Llama-3.1-8B-Instruct-Math\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">EpistemeAI/Fireball-Meta-Llama-3.1-8B-Instruct-Math</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/EpistemeAI__Fireball-Meta-Llama-3.1-8B-Instruct-Math-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "EpistemeAI/Fireball-Meta-Llama-3.1-8B-Instruct-Math", "Model sha": "677c97b4f92bfc330d4fae628e9a1df1ef606dcc", "Average \u2b06\ufe0f": 20.394283471400204, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4622955979024543, "IFEval": 46.22955979024543, "BBH Raw": 0.4982950432079305, "BBH": 28.95934409387967, "MATH Lvl 5 Raw": 0.0981873111782477, "MATH Lvl 5": 9.818731117824774, "GPQA Raw": 0.2911073825503356, "GPQA": 5.480984340044745, "MUSR Raw": 0.3640729166666667, "MUSR": 5.97578125, "MMLU-PRO Raw": 0.3331117021276595, "MMLU-PRO": 25.901300236406616, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-23T00:00:00", "Submission Date": "2024-09-23T00:00:00", "Generation": 2, "Base Model": "unsloth/Meta-Llama-3.1-8B"}, {"eval_name": "EpistemeAI_Fireball-Meta-Llama-3.2-8B-Instruct-agent-003-128k-code-DPO_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/EpistemeAI/Fireball-Meta-Llama-3.2-8B-Instruct-agent-003-128k-code-DPO\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">EpistemeAI/Fireball-Meta-Llama-3.2-8B-Instruct-agent-003-128k-code-DPO</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/EpistemeAI__Fireball-Meta-Llama-3.2-8B-Instruct-agent-003-128k-code-DPO-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "EpistemeAI/Fireball-Meta-Llama-3.2-8B-Instruct-agent-003-128k-code-DPO", "Model sha": "b3c0fce7daa359cd8ed5be6595dd1a76ca2cfea2", "Average \u2b06\ufe0f": 21.016622845213828, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4610965571350682, "IFEval": 46.109655713506825, "BBH Raw": 0.4801014153797021, "BBH": 26.31787775764873, "MATH Lvl 5 Raw": 0.1087613293051359, "MATH Lvl 5": 10.876132930513595, "GPQA Raw": 0.3003355704697986, "GPQA": 6.711409395973152, "MUSR Raw": 0.3998229166666667, "MUSR": 8.077864583333334, "MMLU-PRO Raw": 0.3520611702127659, "MMLU-PRO": 28.00679669030733, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-08T00:00:00", "Submission Date": "2024-10-09T00:00:00", "Generation": 3, "Base Model": "Removed"}, {"eval_name": "EpistemeAI_Fireball-Mistral-Nemo-Base-2407-v1-DPO2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/EpistemeAI/Fireball-Mistral-Nemo-Base-2407-v1-DPO2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">EpistemeAI/Fireball-Mistral-Nemo-Base-2407-v1-DPO2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/EpistemeAI__Fireball-Mistral-Nemo-Base-2407-v1-DPO2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "EpistemeAI/Fireball-Mistral-Nemo-Base-2407-v1-DPO2", "Model sha": "2cf732fbffefdf37341b946edd7995f14d3f9487", "Average \u2b06\ufe0f": 15.2512234825841, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1860729530977805, "IFEval": 18.607295309778056, "BBH Raw": 0.4967768759035089, "BBH": 28.56782489270228, "MATH Lvl 5 Raw": 0.0309667673716012, "MATH Lvl 5": 3.096676737160121, "GPQA Raw": 0.2919463087248322, "GPQA": 5.592841163310966, "MUSR Raw": 0.4040104166666667, "MUSR": 9.501302083333336, "MMLU-PRO Raw": 0.3352726063829787, "MMLU-PRO": 26.14140070921986, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-19T00:00:00", "Submission Date": "2024-08-19T00:00:00", "Generation": 1, "Base Model": "Removed"}, {"eval_name": "EpistemeAI_Llama-3.2-3B-Agent007-Coder_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/EpistemeAI/Llama-3.2-3B-Agent007-Coder\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">EpistemeAI/Llama-3.2-3B-Agent007-Coder</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/EpistemeAI__Llama-3.2-3B-Agent007-Coder-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "EpistemeAI/Llama-3.2-3B-Agent007-Coder", "Model sha": "7ff4e77796b6d308e96d0150e1a01081c0b82e01", "Average \u2b06\ufe0f": 18.700563823005737, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.5399562050913798, "IFEval": 53.99562050913798, "BBH Raw": 0.4303758760727905, "BBH": 19.02580948500905, "MATH Lvl 5 Raw": 0.0981873111782477, "MATH Lvl 5": 9.818731117824774, "GPQA Raw": 0.2575503355704698, "GPQA": 1.0067114093959737, "MUSR Raw": 0.3668020833333333, "MUSR": 7.783593750000001, "MMLU-PRO Raw": 0.28515625, "MMLU-PRO": 20.572916666666664, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-08T00:00:00", "Submission Date": "2024-10-08T00:00:00", "Generation": 2, "Base Model": "meta-llama/Llama-3.2-3B-Instruct"}, {"eval_name": "EpistemeAI_Mistral-Nemo-Instruct-12B-Philosophy-Math_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/EpistemeAI/Mistral-Nemo-Instruct-12B-Philosophy-Math\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">EpistemeAI/Mistral-Nemo-Instruct-12B-Philosophy-Math</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/EpistemeAI__Mistral-Nemo-Instruct-12B-Philosophy-Math-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "EpistemeAI/Mistral-Nemo-Instruct-12B-Philosophy-Math", "Model sha": "1ac4205f8da109326b4a5cf173e5491a20087d76", "Average \u2b06\ufe0f": 16.427763140196443, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.0694679007256302, "IFEval": 6.946790072563022, "BBH Raw": 0.5364928342081372, "BBH": 33.835810999564586, "MATH Lvl 5 Raw": 0.0853474320241691, "MATH Lvl 5": 8.534743202416918, "GPQA Raw": 0.3313758389261745, "GPQA": 10.850111856823268, "MUSR Raw": 0.42921875, "MUSR": 12.885677083333327, "MMLU-PRO Raw": 0.3296210106382978, "MMLU-PRO": 25.513445626477537, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-15T00:00:00", "Submission Date": "2024-09-26T00:00:00", "Generation": 1, "Base Model": "unsloth/Mistral-Nemo-Instruct-2407-bnb-4bit"}, {"eval_name": "EpistemeAI2_Athene-codegemma-2-7b-it-alpaca-v1.2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "GemmaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/EpistemeAI2/Athene-codegemma-2-7b-it-alpaca-v1.2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">EpistemeAI2/Athene-codegemma-2-7b-it-alpaca-v1.2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/EpistemeAI2__Athene-codegemma-2-7b-it-alpaca-v1.2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "EpistemeAI2/Athene-codegemma-2-7b-it-alpaca-v1.2", "Model sha": "21b31062334a316b50680e8c3a141a72e4c30b61", "Average \u2b06\ufe0f": 15.579921563255526, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4351177098986245, "IFEval": 43.511770989862455, "BBH Raw": 0.4175415446097842, "BBH": 18.971369774912947, "MATH Lvl 5 Raw": 0.0339879154078549, "MATH Lvl 5": 3.3987915407854987, "GPQA Raw": 0.2709731543624161, "GPQA": 2.796420581655479, "MUSR Raw": 0.41696875, "MUSR": 10.387760416666667, "MMLU-PRO Raw": 0.229720744680851, "MMLU-PRO": 14.413416075650115, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-26T00:00:00", "Submission Date": "2024-08-26T00:00:00", "Generation": 2, "Base Model": "Removed"}, {"eval_name": "EpistemeAI2_Fireball-12B-v1.2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/EpistemeAI2/Fireball-12B-v1.2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">EpistemeAI2/Fireball-12B-v1.2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/EpistemeAI2__Fireball-12B-v1.2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "EpistemeAI2/Fireball-12B-v1.2", "Model sha": "57af42edf8232189ee99e9a21e33a0c306e3f561", "Average \u2b06\ufe0f": 15.061817298840808, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1355392580575096, "IFEval": 13.553925805750964, "BBH Raw": 0.5018583230653281, "BBH": 29.776014226579218, "MATH Lvl 5 Raw": 0.0332326283987915, "MATH Lvl 5": 3.3232628398791544, "GPQA Raw": 0.2986577181208054, "GPQA": 6.487695749440718, "MUSR Raw": 0.4173125, "MUSR": 11.264062499999996, "MMLU-PRO Raw": 0.3336934840425531, "MMLU-PRO": 25.965942671394792, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-27T00:00:00", "Submission Date": "2024-08-28T00:00:00", "Generation": 1, "Base Model": "Removed"}, {"eval_name": "EpistemeAI2_Fireball-Alpaca-Llama3.1-8B-Philos_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/EpistemeAI2/Fireball-Alpaca-Llama3.1-8B-Philos\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">EpistemeAI2/Fireball-Alpaca-Llama3.1-8B-Philos</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/EpistemeAI2__Fireball-Alpaca-Llama3.1-8B-Philos-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "EpistemeAI2/Fireball-Alpaca-Llama3.1-8B-Philos", "Model sha": "3dcca4cf9bdd9003c8dc91f5c78cefef1d4ae0d7", "Average \u2b06\ufe0f": 22.388028059979813, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.498640274471735, "IFEval": 49.8640274471735, "BBH Raw": 0.4977581192690881, "BBH": 29.259226071264724, "MATH Lvl 5 Raw": 0.1087613293051359, "MATH Lvl 5": 10.876132930513595, "GPQA Raw": 0.2927852348993288, "GPQA": 5.7046979865771785, "MUSR Raw": 0.4276666666666666, "MUSR": 11.891666666666667, "MMLU-PRO Raw": 0.3405917553191489, "MMLU-PRO": 26.73241725768321, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-29T00:00:00", "Submission Date": "2024-08-29T00:00:00", "Generation": 2, "Base Model": "unsloth/Meta-Llama-3.1-8B"}, {"eval_name": "EpistemeAI2_Fireball-Alpaca-Llama3.1.01-8B-Philos_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/EpistemeAI2/Fireball-Alpaca-Llama3.1.01-8B-Philos\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">EpistemeAI2/Fireball-Alpaca-Llama3.1.01-8B-Philos</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/EpistemeAI2__Fireball-Alpaca-Llama3.1.01-8B-Philos-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "EpistemeAI2/Fireball-Alpaca-Llama3.1.01-8B-Philos", "Model sha": "f97293ed5cec7fb9482b16600259967c6c923e4b", "Average \u2b06\ufe0f": 21.3909103333252, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4211791380204523, "IFEval": 42.11791380204524, "BBH Raw": 0.4956109231272791, "BBH": 28.628475325906475, "MATH Lvl 5 Raw": 0.1253776435045317, "MATH Lvl 5": 12.537764350453172, "GPQA Raw": 0.2885906040268456, "GPQA": 5.145413870246088, "MUSR Raw": 0.4370624999999999, "MUSR": 13.432812500000002, "MMLU-PRO Raw": 0.3383477393617021, "MMLU-PRO": 26.483082151300238, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-03T00:00:00", "Submission Date": "2024-09-03T00:00:00", "Generation": 2, "Base Model": "unsloth/Meta-Llama-3.1-8B"}, {"eval_name": "EpistemeAI2_Fireball-Alpaca-Llama3.1.03-8B-Philos_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/EpistemeAI2/Fireball-Alpaca-Llama3.1.03-8B-Philos\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">EpistemeAI2/Fireball-Alpaca-Llama3.1.03-8B-Philos</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/EpistemeAI2__Fireball-Alpaca-Llama3.1.03-8B-Philos-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "EpistemeAI2/Fireball-Alpaca-Llama3.1.03-8B-Philos", "Model sha": "6e60f783f80f7d126b8e4f2b417e14dea63d2c4f", "Average \u2b06\ufe0f": 20.098339722469724, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3880814017916905, "IFEval": 38.80814017916904, "BBH Raw": 0.4950869933936326, "BBH": 27.99254879661235, "MATH Lvl 5 Raw": 0.1178247734138972, "MATH Lvl 5": 11.782477341389727, "GPQA Raw": 0.2785234899328859, "GPQA": 3.803131991051453, "MUSR Raw": 0.4280104166666666, "MUSR": 12.034635416666667, "MMLU-PRO Raw": 0.3355219414893617, "MMLU-PRO": 26.16910460992908, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-04T00:00:00", "Submission Date": "2024-09-04T00:00:00", "Generation": 2, "Base Model": "unsloth/Meta-Llama-3.1-8B"}, {"eval_name": "EpistemeAI2_Fireball-Alpaca-Llama3.1.04-8B-Philos_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/EpistemeAI2/Fireball-Alpaca-Llama3.1.04-8B-Philos\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">EpistemeAI2/Fireball-Alpaca-Llama3.1.04-8B-Philos</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/EpistemeAI2__Fireball-Alpaca-Llama3.1.04-8B-Philos-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "EpistemeAI2/Fireball-Alpaca-Llama3.1.04-8B-Philos", "Model sha": "efd0c251373e1a2fa2bc8cead502c03ff6dc7c8b", "Average \u2b06\ufe0f": 20.80499081051805, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4084396069096663, "IFEval": 40.84396069096664, "BBH Raw": 0.4930009712421776, "BBH": 27.963797525362725, "MATH Lvl 5 Raw": 0.1027190332326284, "MATH Lvl 5": 10.27190332326284, "GPQA Raw": 0.2902684563758389, "GPQA": 5.369127516778524, "MUSR Raw": 0.43721875, "MUSR": 13.685677083333337, "MMLU-PRO Raw": 0.3402593085106383, "MMLU-PRO": 26.695478723404253, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-05T00:00:00", "Submission Date": "2024-09-05T00:00:00", "Generation": 2, "Base Model": "unsloth/Meta-Llama-3.1-8B"}, {"eval_name": "EpistemeAI2_Fireball-Alpaca-Llama3.1.06-8B-Philos-dpo_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/EpistemeAI2/Fireball-Alpaca-Llama3.1.06-8B-Philos-dpo\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">EpistemeAI2/Fireball-Alpaca-Llama3.1.06-8B-Philos-dpo</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/EpistemeAI2__Fireball-Alpaca-Llama3.1.06-8B-Philos-dpo-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "EpistemeAI2/Fireball-Alpaca-Llama3.1.06-8B-Philos-dpo", "Model sha": "3e76f190b505b515479cc25e92f8229c2b05159f", "Average \u2b06\ufe0f": 21.641045650180043, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4865756193566404, "IFEval": 48.65756193566404, "BBH Raw": 0.4880773053900922, "BBH": 27.207176615070413, "MATH Lvl 5 Raw": 0.1170694864048338, "MATH Lvl 5": 11.706948640483382, "GPQA Raw": 0.2978187919463087, "GPQA": 6.375838926174497, "MUSR Raw": 0.3931875, "MUSR": 6.848437499999999, "MMLU-PRO Raw": 0.3614527925531915, "MMLU-PRO": 29.050310283687946, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-09T00:00:00", "Submission Date": "2024-09-09T00:00:00", "Generation": 4, "Base Model": "unsloth/Meta-Llama-3.1-8B"}, {"eval_name": "EpistemeAI2_Fireball-Alpaca-Llama3.1.07-8B-Philos-Math_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/EpistemeAI2/Fireball-Alpaca-Llama3.1.07-8B-Philos-Math\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">EpistemeAI2/Fireball-Alpaca-Llama3.1.07-8B-Philos-Math</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/EpistemeAI2__Fireball-Alpaca-Llama3.1.07-8B-Philos-Math-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "EpistemeAI2/Fireball-Alpaca-Llama3.1.07-8B-Philos-Math", "Model sha": "0b2842bddfa6c308f67eb5a20daf04536a4e6d1a", "Average \u2b06\ufe0f": 21.719107698634502, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.5079079065767719, "IFEval": 50.79079065767719, "BBH Raw": 0.4847020640542447, "BBH": 26.901201452028392, "MATH Lvl 5 Raw": 0.1049848942598187, "MATH Lvl 5": 10.498489425981871, "GPQA Raw": 0.2961409395973154, "GPQA": 6.152125279642054, "MUSR Raw": 0.4063020833333333, "MUSR": 7.854427083333334, "MMLU-PRO Raw": 0.3530585106382978, "MMLU-PRO": 28.117612293144205, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-10T00:00:00", "Submission Date": "2024-09-10T00:00:00", "Generation": 3, "Base Model": "unsloth/Meta-Llama-3.1-8B"}, {"eval_name": "EpistemeAI2_Fireball-Alpaca-Llama3.1.08-8B-C-R1-KTO-Reflection_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/EpistemeAI2/Fireball-Alpaca-Llama3.1.08-8B-C-R1-KTO-Reflection\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">EpistemeAI2/Fireball-Alpaca-Llama3.1.08-8B-C-R1-KTO-Reflection</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/EpistemeAI2__Fireball-Alpaca-Llama3.1.08-8B-C-R1-KTO-Reflection-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "EpistemeAI2/Fireball-Alpaca-Llama3.1.08-8B-C-R1-KTO-Reflection", "Model sha": "dc900138b4406353b7e84251bc8649d70c16f13f", "Average \u2b06\ufe0f": 20.70580318254501, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3952257787115963, "IFEval": 39.52257787115964, "BBH Raw": 0.4955305233431472, "BBH": 27.571611204577167, "MATH Lvl 5 Raw": 0.1132930513595166, "MATH Lvl 5": 11.329305135951662, "GPQA Raw": 0.299496644295302, "GPQA": 6.599552572706939, "MUSR Raw": 0.4048125, "MUSR": 10.4015625, "MMLU-PRO Raw": 0.3592918882978723, "MMLU-PRO": 28.8102098108747, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-16T00:00:00", "Submission Date": "2024-09-16T00:00:00", "Generation": 5, "Base Model": "unsloth/Meta-Llama-3.1-8B"}, {"eval_name": "EpistemeAI2_Fireball-Alpaca-Llama3.1.08-8B-Philos-C-R1_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/EpistemeAI2/Fireball-Alpaca-Llama3.1.08-8B-Philos-C-R1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">EpistemeAI2/Fireball-Alpaca-Llama3.1.08-8B-Philos-C-R1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/EpistemeAI2__Fireball-Alpaca-Llama3.1.08-8B-Philos-C-R1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "EpistemeAI2/Fireball-Alpaca-Llama3.1.08-8B-Philos-C-R1", "Model sha": "c57c786426123635baf6c8b4d30638d2053f4565", "Average \u2b06\ufe0f": 22.259425909127472, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.5316382753316755, "IFEval": 53.16382753316755, "BBH Raw": 0.4827931104634334, "BBH": 26.76368521382555, "MATH Lvl 5 Raw": 0.1087613293051359, "MATH Lvl 5": 10.876132930513595, "GPQA Raw": 0.296979865771812, "GPQA": 6.263982102908276, "MUSR Raw": 0.4103020833333333, "MUSR": 8.454427083333332, "MMLU-PRO Raw": 0.3523105053191489, "MMLU-PRO": 28.034500591016545, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-13T00:00:00", "Submission Date": "2024-09-13T00:00:00", "Generation": 3, "Base Model": "unsloth/Meta-Llama-3.1-8B"}, {"eval_name": "EpistemeAI2_Fireball-Llama-3.1-8B-Philos-Reflection_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/EpistemeAI2/Fireball-Llama-3.1-8B-Philos-Reflection\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">EpistemeAI2/Fireball-Llama-3.1-8B-Philos-Reflection</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/EpistemeAI2__Fireball-Llama-3.1-8B-Philos-Reflection-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "EpistemeAI2/Fireball-Llama-3.1-8B-Philos-Reflection", "Model sha": "4b0b75d9235886e8a947c45b94f87c5a65a81467", "Average \u2b06\ufe0f": 20.238251619304048, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3596047376516532, "IFEval": 35.96047376516532, "BBH Raw": 0.4897693552241443, "BBH": 27.76979570236311, "MATH Lvl 5 Raw": 0.1200906344410876, "MATH Lvl 5": 12.009063444108762, "GPQA Raw": 0.3078859060402684, "GPQA": 7.718120805369126, "MUSR Raw": 0.3957291666666667, "MUSR": 9.632812500000002, "MMLU-PRO Raw": 0.3550531914893617, "MMLU-PRO": 28.33924349881796, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-17T00:00:00", "Submission Date": "2024-09-17T00:00:00", "Generation": 4, "Base Model": "unsloth/Meta-Llama-3.1-8B"}, {"eval_name": "EpistemeAI2_Fireball-MathMistral-Nemo-Base-2407-v2dpo_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/EpistemeAI2/Fireball-MathMistral-Nemo-Base-2407-v2dpo\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">EpistemeAI2/Fireball-MathMistral-Nemo-Base-2407-v2dpo</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/EpistemeAI2__Fireball-MathMistral-Nemo-Base-2407-v2dpo-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "EpistemeAI2/Fireball-MathMistral-Nemo-Base-2407-v2dpo", "Model sha": "6b7d851c66359f39d16da6fbcf810b816dc6e4bc", "Average \u2b06\ufe0f": 11.2944540454497, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 11, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3097204306794859, "IFEval": 30.9720430679486, "BBH Raw": 0.432763732856821, "BBH": 21.145528378150857, "MATH Lvl 5 Raw": 0.0324773413897281, "MATH Lvl 5": 3.2477341389728096, "GPQA Raw": 0.2634228187919463, "GPQA": 1.789709172259505, "MUSR Raw": 0.4029583333333333, "MUSR": 8.96979166666667, "MMLU-PRO Raw": 0.1147772606382978, "MMLU-PRO": 1.6419178486997636, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-21T00:00:00", "Submission Date": "2024-08-24T00:00:00", "Generation": 2, "Base Model": "unsloth/Mistral-Nemo-Base-2407-bnb-4bit"}, {"eval_name": "EpistemeAI2_Fireball-Meta-Llama-3.1-8B-Instruct-Agent-0.005-128K-code-COT_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/EpistemeAI2/Fireball-Meta-Llama-3.1-8B-Instruct-Agent-0.005-128K-code-COT\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">EpistemeAI2/Fireball-Meta-Llama-3.1-8B-Instruct-Agent-0.005-128K-code-COT</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/EpistemeAI2__Fireball-Meta-Llama-3.1-8B-Instruct-Agent-0.005-128K-code-COT-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "EpistemeAI2/Fireball-Meta-Llama-3.1-8B-Instruct-Agent-0.005-128K-code-COT", "Model sha": "cf8b99d4aa00c18fdaebfb24fa3c674ee6defa1a", "Average \u2b06\ufe0f": 20.83634896282936, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4633195476890207, "IFEval": 46.33195476890207, "BBH Raw": 0.4790834283312441, "BBH": 26.400991557555106, "MATH Lvl 5 Raw": 0.1049848942598187, "MATH Lvl 5": 10.498489425981871, "GPQA Raw": 0.3120805369127516, "GPQA": 8.277404921700223, "MUSR Raw": 0.3774375, "MUSR": 5.013020833333332, "MMLU-PRO Raw": 0.3564660904255319, "MMLU-PRO": 28.496232269503547, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-11T00:00:00", "Submission Date": "2024-10-11T00:00:00", "Generation": 3, "Base Model": "Removed"}, {"eval_name": "EpistemeAI2_Fireball-Phi-3-medium-4k-inst-Philos_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/EpistemeAI2/Fireball-Phi-3-medium-4k-inst-Philos\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">EpistemeAI2/Fireball-Phi-3-medium-4k-inst-Philos</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/EpistemeAI2__Fireball-Phi-3-medium-4k-inst-Philos-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "EpistemeAI2/Fireball-Phi-3-medium-4k-inst-Philos", "Model sha": "147715051102034fac98091e2a0cae6cade15ae0", "Average \u2b06\ufe0f": 28.99660862188793, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 13, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5312880933700359, "IFEval": 53.1288093370036, "BBH Raw": 0.6177842639287514, "BBH": 46.20887281141656, "MATH Lvl 5 Raw": 0.1299093655589124, "MATH Lvl 5": 12.990936555891238, "GPQA Raw": 0.3322147651006711, "GPQA": 10.96196868008949, "MUSR Raw": 0.41390625, "MUSR": 10.704947916666669, "MMLU-PRO Raw": 0.4598570478723404, "MMLU-PRO": 39.984116430260045, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-19T00:00:00", "Submission Date": "2024-09-20T00:00:00", "Generation": 1, "Base Model": "unsloth/phi-3-medium-4k-instruct-bnb-4bit"}, {"eval_name": "Eric111_CatunaMayo_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Eric111/CatunaMayo\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Eric111/CatunaMayo</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Eric111__CatunaMayo-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Eric111/CatunaMayo", "Model sha": "23337893381293975cbcc35f75b634954fbcefaf", "Average \u2b06\ufe0f": 21.14809764222952, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4074156571231, "IFEval": 40.741565712310006, "BBH Raw": 0.5243635518600797, "BBH": 33.299425909067885, "MATH Lvl 5 Raw": 0.0770392749244713, "MATH Lvl 5": 7.7039274924471295, "GPQA Raw": 0.2919463087248322, "GPQA": 5.592841163310966, "MUSR Raw": 0.4539895833333333, "MUSR": 15.348697916666667, "MMLU-PRO Raw": 0.3178191489361702, "MMLU-PRO": 24.202127659574465, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-02-15T00:00:00", "Submission Date": "2024-07-03T00:00:00", "Generation": 0, "Base Model": "Eric111/CatunaMayo"}, {"eval_name": "Eric111_CatunaMayo-DPO_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Eric111/CatunaMayo-DPO\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Eric111/CatunaMayo-DPO</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Eric111__CatunaMayo-DPO-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Eric111/CatunaMayo-DPO", "Model sha": "6bdbe06c10d57d152dd8a79a71edd8e30135b689", "Average \u2b06\ufe0f": 21.154415682573266, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4214539643700936, "IFEval": 42.14539643700936, "BBH Raw": 0.5223991323844243, "BBH": 33.08995159999345, "MATH Lvl 5 Raw": 0.073262839879154, "MATH Lvl 5": 7.326283987915408, "GPQA Raw": 0.2919463087248322, "GPQA": 5.592841163310966, "MUSR Raw": 0.44503125, "MUSR": 14.662239583333337, "MMLU-PRO Raw": 0.3169880319148936, "MMLU-PRO": 24.109781323877066, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-02-21T00:00:00", "Submission Date": "2024-06-27T00:00:00", "Generation": 0, "Base Model": "Eric111/CatunaMayo-DPO"}, {"eval_name": "Etherll_Herplete-LLM-Llama-3.1-8b_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Etherll/Herplete-LLM-Llama-3.1-8b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Etherll/Herplete-LLM-Llama-3.1-8b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Etherll__Herplete-LLM-Llama-3.1-8b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Etherll/Herplete-LLM-Llama-3.1-8b", "Model sha": "b3829cf437216f099c031a9ab5e4c8ec974766dd", "Average \u2b06\ufe0f": 19.58870802333299, "Hub License": null, "Hub \u2764\ufe0f": 5, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4671914963408201, "IFEval": 46.71914963408201, "BBH Raw": 0.5013428726325629, "BBH": 28.952590926070883, "MATH Lvl 5 Raw": 0.0279456193353474, "MATH Lvl 5": 2.794561933534743, "GPQA Raw": 0.2860738255033557, "GPQA": 4.809843400447425, "MUSR Raw": 0.3859999999999999, "MUSR": 6.683333333333335, "MMLU-PRO Raw": 0.3481549202127659, "MMLU-PRO": 27.57276891252955, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-24T00:00:00", "Submission Date": "2024-08-29T00:00:00", "Generation": 1, "Base Model": "Etherll/Herplete-LLM-Llama-3.1-8b (Merge)"}, {"eval_name": "Etherll_Replete-LLM-V3-Llama-3.1-8b_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Etherll/Replete-LLM-V3-Llama-3.1-8b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Etherll/Replete-LLM-V3-Llama-3.1-8b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Etherll__Replete-LLM-V3-Llama-3.1-8b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Etherll/Replete-LLM-V3-Llama-3.1-8b", "Model sha": "e79849d72f70ef74677ed81a8885403973b2470c", "Average \u2b06\ufe0f": 17.927882200113448, "Hub License": null, "Hub \u2764\ufe0f": 5, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5262924595628488, "IFEval": 52.62924595628488, "BBH Raw": 0.4543377420594779, "BBH": 22.902455222412783, "MATH Lvl 5 Raw": 0.0007552870090634, "MATH Lvl 5": 0.0755287009063444, "GPQA Raw": 0.2684563758389262, "GPQA": 2.460850111856823, "MUSR Raw": 0.3516458333333334, "MUSR": 2.0557291666666675, "MMLU-PRO Raw": 0.3469913563829787, "MMLU-PRO": 27.44348404255319, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-24T00:00:00", "Submission Date": "2024-08-26T00:00:00", "Generation": 1, "Base Model": "Etherll/Replete-LLM-V3-Llama-3.1-8b (Merge)"}, {"eval_name": "Eurdem_Defne-llama3.1-8B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Eurdem/Defne-llama3.1-8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Eurdem/Defne-llama3.1-8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Eurdem__Defne-llama3.1-8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Eurdem/Defne-llama3.1-8B", "Model sha": "7832ba3066636bf4dab3e7d658c0b3ded12491ae", "Average \u2b06\ufe0f": 24.805902490587115, "Hub License": "llama3.1", "Hub \u2764\ufe0f": 2, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.5036115285220991, "IFEval": 50.36115285220991, "BBH Raw": 0.5320979090308238, "BBH": 32.822381370434904, "MATH Lvl 5 Raw": 0.141238670694864, "MATH Lvl 5": 14.123867069486405, "GPQA Raw": 0.2961409395973154, "GPQA": 6.152125279642054, "MUSR Raw": 0.43309375, "MUSR": 13.53671875, "MMLU-PRO Raw": 0.3865525265957447, "MMLU-PRO": 31.839169621749413, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-29T00:00:00", "Submission Date": "2024-08-14T00:00:00", "Generation": 0, "Base Model": "Eurdem/Defne-llama3.1-8B"}, {"eval_name": "FallenMerick_Chewy-Lemon-Cookie-11B_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/FallenMerick/Chewy-Lemon-Cookie-11B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">FallenMerick/Chewy-Lemon-Cookie-11B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/FallenMerick__Chewy-Lemon-Cookie-11B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "FallenMerick/Chewy-Lemon-Cookie-11B", "Model sha": "0f5d0d6d218b3ef034f58eba32d6fe7ac4c237ae", "Average \u2b06\ufe0f": 21.905256368788628, "Hub License": "cc-by-4.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 10, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4875242135312083, "IFEval": 48.75242135312082, "BBH Raw": 0.5251122307375103, "BBH": 33.01430008846961, "MATH Lvl 5 Raw": 0.04607250755287, "MATH Lvl 5": 4.607250755287009, "GPQA Raw": 0.2793624161073825, "GPQA": 3.9149888143176734, "MUSR Raw": 0.4545520833333333, "MUSR": 15.952343750000002, "MMLU-PRO Raw": 0.3267121010638298, "MMLU-PRO": 25.19023345153664, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-06T00:00:00", "Submission Date": "2024-06-27T00:00:00", "Generation": 1, "Base Model": "FallenMerick/Chewy-Lemon-Cookie-11B (Merge)"}, {"eval_name": "Felladrin_Llama-160M-Chat-v1_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Felladrin/Llama-160M-Chat-v1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Felladrin/Llama-160M-Chat-v1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Felladrin__Llama-160M-Chat-v1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Felladrin/Llama-160M-Chat-v1", "Model sha": "e7f50665676821867ee7dfad32d0ca9fb68fc6bc", "Average \u2b06\ufe0f": 4.10106118080753, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 15, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.1575464212733325, "IFEval": 15.754642127333252, "BBH Raw": 0.3036081114634836, "BBH": 3.166755569392556, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2575503355704698, "GPQA": 1.0067114093959737, "MUSR Raw": 0.366125, "MUSR": 3.165625, "MMLU-PRO Raw": 0.1136136968085106, "MMLU-PRO": 1.512632978723403, "Maintainer's Highlight": false, "Upload To Hub Date": "2023-12-20T00:00:00", "Submission Date": "2024-07-23T00:00:00", "Generation": 1, "Base Model": "JackFram/llama-160m"}, {"eval_name": "Felladrin_Minueza-32M-UltraChat_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Felladrin/Minueza-32M-UltraChat\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Felladrin/Minueza-32M-UltraChat</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Felladrin__Minueza-32M-UltraChat-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Felladrin/Minueza-32M-UltraChat", "Model sha": "28506b99c5902d2215eb378ec91d4226a7396c49", "Average \u2b06\ufe0f": 3.8487272872743534, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 4, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.1375627778738192, "IFEval": 13.756277787381924, "BBH Raw": 0.2941478734048925, "BBH": 2.4372895622895623, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2558724832214765, "GPQA": 0.7829977628635317, "MUSR Raw": 0.3741874999999999, "MUSR": 4.640104166666668, "MMLU-PRO Raw": 0.11328125, "MMLU-PRO": 1.4756944444444438, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-02-27T00:00:00", "Submission Date": "2024-07-23T00:00:00", "Generation": 1, "Base Model": "Felladrin/Minueza-32M-Base"}, {"eval_name": "FuJhen_ft-openhermes-25-mistral-7b-irca-dpo-pairs_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Adapter", "Architecture": "?", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/FuJhen/ft-openhermes-25-mistral-7b-irca-dpo-pairs\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">FuJhen/ft-openhermes-25-mistral-7b-irca-dpo-pairs</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/FuJhen__ft-openhermes-25-mistral-7b-irca-dpo-pairs-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "FuJhen/ft-openhermes-25-mistral-7b-irca-dpo-pairs", "Model sha": "24c0bea14d53e6f67f1fbe2eca5bfe7cae389b33", "Average \u2b06\ufe0f": 19.615524943255757, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 14, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5420041046645123, "IFEval": 54.20041046645124, "BBH Raw": 0.4773032389554811, "BBH": 26.59686097043189, "MATH Lvl 5 Raw": 0.0015105740181268, "MATH Lvl 5": 0.1510574018126888, "GPQA Raw": 0.2785234899328859, "GPQA": 3.803131991051453, "MUSR Raw": 0.417375, "MUSR": 11.20520833333333, "MMLU-PRO Raw": 0.2956283244680851, "MMLU-PRO": 21.736480496453904, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-12T00:00:00", "Submission Date": "2024-09-12T00:00:00", "Generation": 1, "Base Model": "FuJhen/ft-openhermes-25-mistral-7b-irca-dpo-pairs (Merge)"}, {"eval_name": "FuJhen_mistral-instruct-7B-DPO_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Adapter", "Architecture": "?", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/FuJhen/mistral-instruct-7B-DPO\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">FuJhen/mistral-instruct-7B-DPO</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/FuJhen__mistral-instruct-7B-DPO-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "FuJhen/mistral-instruct-7B-DPO", "Model sha": "e0bc86c23ce5aae1db576c8cca6f06f1f73af2db", "Average \u2b06\ufe0f": 18.966590198042024, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 14, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4968417133206558, "IFEval": 49.68417133206558, "BBH Raw": 0.4623905056138621, "BBH": 24.92582719493644, "MATH Lvl 5 Raw": 0.0347432024169184, "MATH Lvl 5": 3.474320241691843, "GPQA Raw": 0.2776845637583892, "GPQA": 3.691275167785232, "MUSR Raw": 0.4015625, "MUSR": 9.428645833333327, "MMLU-PRO Raw": 0.3033577127659574, "MMLU-PRO": 22.59530141843972, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-12T00:00:00", "Submission Date": "2024-09-12T00:00:00", "Generation": 1, "Base Model": "FuJhen/mistral-instruct-7B-DPO (Merge)"}, {"eval_name": "FuJhen_mistral_7b_v0.1_structedData_e2e_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Adapter", "Architecture": "?", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/FuJhen/mistral_7b_v0.1_structedData_e2e\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">FuJhen/mistral_7b_v0.1_structedData_e2e</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/FuJhen__mistral_7b_v0.1_structedData_e2e-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "FuJhen/mistral_7b_v0.1_structedData_e2e", "Model sha": "7231864981174d9bee8c7687c24c8344414eae6b", "Average \u2b06\ufe0f": 10.871546697990665, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1726840339188907, "IFEval": 17.268403391889077, "BBH Raw": 0.4113914854984489, "BBH": 18.06242392393546, "MATH Lvl 5 Raw": 0.0022658610271903, "MATH Lvl 5": 0.2265861027190332, "GPQA Raw": 0.2793624161073825, "GPQA": 3.9149888143176734, "MUSR Raw": 0.3722916666666667, "MUSR": 5.636458333333335, "MMLU-PRO Raw": 0.2810837765957447, "MMLU-PRO": 20.12041962174941, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-13T00:00:00", "Submission Date": "2024-09-13T00:00:00", "Generation": 1, "Base Model": "FuJhen/mistral_7b_v0.1_structedData_e2e (Merge)"}, {"eval_name": "FuJhen_mistral_7b_v0.1_structedData_viggo_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Adapter", "Architecture": "?", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/FuJhen/mistral_7b_v0.1_structedData_viggo\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">FuJhen/mistral_7b_v0.1_structedData_viggo</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/FuJhen__mistral_7b_v0.1_structedData_viggo-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "FuJhen/mistral_7b_v0.1_structedData_viggo", "Model sha": "7231864981174d9bee8c7687c24c8344414eae6b", "Average \u2b06\ufe0f": 12.30211322578691, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 14, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1783290557941816, "IFEval": 17.832905579418167, "BBH Raw": 0.4523863454598681, "BBH": 23.960171694414896, "MATH Lvl 5 Raw": 0.0203927492447129, "MATH Lvl 5": 2.0392749244712998, "GPQA Raw": 0.2835570469798658, "GPQA": 4.4742729306487705, "MUSR Raw": 0.3738125, "MUSR": 3.9265625000000015, "MMLU-PRO Raw": 0.2942154255319149, "MMLU-PRO": 21.57949172576832, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-13T00:00:00", "Submission Date": "2024-09-13T00:00:00", "Generation": 1, "Base Model": "FuJhen/mistral_7b_v0.1_structedData_viggo (Merge)"}, {"eval_name": "GalrionSoftworks_MN-LooseCannon-12B-v1_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/GalrionSoftworks/MN-LooseCannon-12B-v1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">GalrionSoftworks/MN-LooseCannon-12B-v1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/GalrionSoftworks__MN-LooseCannon-12B-v1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "GalrionSoftworks/MN-LooseCannon-12B-v1", "Model sha": null, "Average \u2b06\ufe0f": 21.78454809931311, "Hub License": null, "Hub \u2764\ufe0f": 6, "#Params (B)": 12, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5417791459992819, "IFEval": 54.177914599928194, "BBH Raw": 0.5128183808679557, "BBH": 29.97606209295129, "MATH Lvl 5 Raw": 0.0649546827794562, "MATH Lvl 5": 6.495468277945619, "GPQA Raw": 0.285234899328859, "GPQA": 4.697986577181204, "MUSR Raw": 0.41384375, "MUSR": 10.963802083333327, "MMLU-PRO Raw": 0.3195644946808511, "MMLU-PRO": 24.396054964539008, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-09T00:00:00", "Submission Date": "2024-09-05T00:00:00", "Generation": 1, "Base Model": "GalrionSoftworks/MN-LooseCannon-12B-v1 (Merge)"}, {"eval_name": "GalrionSoftworks_MagnusIntellectus-12B-v1_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/GalrionSoftworks/MagnusIntellectus-12B-v1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">GalrionSoftworks/MagnusIntellectus-12B-v1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/GalrionSoftworks__MagnusIntellectus-12B-v1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "GalrionSoftworks/MagnusIntellectus-12B-v1", "Model sha": "fc83cb3eec2f8328448c5fe3cb830fc77983a6b9", "Average \u2b06\ufe0f": 21.546709429306777, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 4, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4421368635221213, "IFEval": 44.21368635221213, "BBH Raw": 0.5323010476246133, "BBH": 33.26225439614359, "MATH Lvl 5 Raw": 0.0513595166163142, "MATH Lvl 5": 5.13595166163142, "GPQA Raw": 0.2843959731543624, "GPQA": 4.586129753914992, "MUSR Raw": 0.4428020833333333, "MUSR": 15.183593749999996, "MMLU-PRO Raw": 0.3420877659574468, "MMLU-PRO": 26.898640661938533, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-13T00:00:00", "Submission Date": "2024-09-05T00:00:00", "Generation": 1, "Base Model": "GalrionSoftworks/MagnusIntellectus-12B-v1 (Merge)"}, {"eval_name": "Goekdeniz-Guelmez_Josiefied-Qwen2.5-1.5B-Instruct-abliterated-v1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Goekdeniz-Guelmez/Josiefied-Qwen2.5-1.5B-Instruct-abliterated-v1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Goekdeniz-Guelmez/Josiefied-Qwen2.5-1.5B-Instruct-abliterated-v1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Goekdeniz-Guelmez__Josiefied-Qwen2.5-1.5B-Instruct-abliterated-v1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Goekdeniz-Guelmez/Josiefied-Qwen2.5-1.5B-Instruct-abliterated-v1", "Model sha": "eca7edeba61e894597e9940348e8d90817c1ad79", "Average \u2b06\ufe0f": 15.25638117767924, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 2, "#Params (B)": 1, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4768580699211425, "IFEval": 47.68580699211426, "BBH Raw": 0.418600731531926, "BBH": 18.30601328940368, "MATH Lvl 5 Raw": 0.0173716012084592, "MATH Lvl 5": 1.7371601208459215, "GPQA Raw": 0.2432885906040268, "GPQA": 0.0, "MUSR Raw": 0.3674895833333333, "MUSR": 4.002864583333333, "MMLU-PRO Raw": 0.2782579787234042, "MMLU-PRO": 19.806442080378247, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-20T00:00:00", "Submission Date": "2024-09-28T00:00:00", "Generation": 1, "Base Model": "Qwen/Qwen2.5-1.5B"}, {"eval_name": "Goekdeniz-Guelmez_Josiefied-Qwen2.5-1.5B-Instruct-abliterated-v2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Goekdeniz-Guelmez/Josiefied-Qwen2.5-1.5B-Instruct-abliterated-v2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Goekdeniz-Guelmez/Josiefied-Qwen2.5-1.5B-Instruct-abliterated-v2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Goekdeniz-Guelmez__Josiefied-Qwen2.5-1.5B-Instruct-abliterated-v2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Goekdeniz-Guelmez/Josiefied-Qwen2.5-1.5B-Instruct-abliterated-v2", "Model sha": "ff4a6eff69adb015dfcfbff7a2d2dc43b34afe89", "Average \u2b06\ufe0f": 13.615591113522926, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 1, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.421553699738915, "IFEval": 42.155369973891496, "BBH Raw": 0.4041892170443674, "BBH": 16.499503211302823, "MATH Lvl 5 Raw": 0.0098187311178247, "MATH Lvl 5": 0.9818731117824772, "GPQA Raw": 0.2399328859060402, "GPQA": 0.0, "MUSR Raw": 0.3768541666666666, "MUSR": 4.706770833333335, "MMLU-PRO Raw": 0.2561502659574468, "MMLU-PRO": 17.350029550827426, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-28T00:00:00", "Submission Date": "2024-09-28T00:00:00", "Generation": 2, "Base Model": "Qwen/Qwen2.5-1.5B"}, {"eval_name": "Goekdeniz-Guelmez_Josiefied-Qwen2.5-1.5B-Instruct-abliterated-v3_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Goekdeniz-Guelmez/Josiefied-Qwen2.5-1.5B-Instruct-abliterated-v3\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Goekdeniz-Guelmez/Josiefied-Qwen2.5-1.5B-Instruct-abliterated-v3</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Goekdeniz-Guelmez__Josiefied-Qwen2.5-1.5B-Instruct-abliterated-v3-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Goekdeniz-Guelmez/Josiefied-Qwen2.5-1.5B-Instruct-abliterated-v3", "Model sha": "03ffa6f7a6ada9d63d838707c597297f048d409b", "Average \u2b06\ufe0f": 13.51574808602399, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 1, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4252505574098946, "IFEval": 42.52505574098946, "BBH Raw": 0.4053446177133173, "BBH": 16.439711885397813, "MATH Lvl 5 Raw": 0.0060422960725075, "MATH Lvl 5": 0.6042296072507553, "GPQA Raw": 0.2432885906040268, "GPQA": 0.0, "MUSR Raw": 0.3701874999999999, "MUSR": 4.240104166666668, "MMLU-PRO Raw": 0.2555684840425531, "MMLU-PRO": 17.28538711583924, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-28T00:00:00", "Submission Date": "2024-09-28T00:00:00", "Generation": 3, "Base Model": "Qwen/Qwen2.5-1.5B"}, {"eval_name": "Goekdeniz-Guelmez_Josiefied-Qwen2.5-7B-Instruct-abliterated-v2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Goekdeniz-Guelmez/Josiefied-Qwen2.5-7B-Instruct-abliterated-v2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Goekdeniz-Guelmez/Josiefied-Qwen2.5-7B-Instruct-abliterated-v2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Goekdeniz-Guelmez__Josiefied-Qwen2.5-7B-Instruct-abliterated-v2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Goekdeniz-Guelmez/Josiefied-Qwen2.5-7B-Instruct-abliterated-v2", "Model sha": "ecf4024048ea1be2f0840a50080fb79b88aacde9", "Average \u2b06\ufe0f": 27.76376328826473, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 4, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7813811797142693, "IFEval": 78.13811797142694, "BBH Raw": 0.5309672164610734, "BBH": 33.33398601463088, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2986577181208054, "GPQA": 6.487695749440718, "MUSR Raw": 0.4353958333333333, "MUSR": 13.957812500000005, "MMLU-PRO Raw": 0.4119847074468085, "MMLU-PRO": 34.66496749408983, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-20T00:00:00", "Submission Date": "2024-10-08T00:00:00", "Generation": 1, "Base Model": "Qwen/Qwen2.5-7B"}, {"eval_name": "Goekdeniz-Guelmez_j.o.s.i.e.v4o-1.5b-dpo-stage1-v1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Goekdeniz-Guelmez/j.o.s.i.e.v4o-1.5b-dpo-stage1-v1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Goekdeniz-Guelmez/j.o.s.i.e.v4o-1.5b-dpo-stage1-v1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Goekdeniz-Guelmez__j.o.s.i.e.v4o-1.5b-dpo-stage1-v1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Goekdeniz-Guelmez/j.o.s.i.e.v4o-1.5b-dpo-stage1-v1", "Model sha": "d5ddad290d83b1ba8a7612a6c1cfad6fb4346fe4", "Average \u2b06\ufe0f": 13.491944982083778, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 1, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4188309241700909, "IFEval": 41.883092417009095, "BBH Raw": 0.4124210163363482, "BBH": 17.748016873381815, "MATH Lvl 5 Raw": 0.0249244712990936, "MATH Lvl 5": 2.492447129909366, "GPQA Raw": 0.2508389261744966, "GPQA": 0.1118568232662209, "MUSR Raw": 0.3528541666666667, "MUSR": 1.4401041666666683, "MMLU-PRO Raw": 0.2554853723404255, "MMLU-PRO": 17.2761524822695, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-07T00:00:00", "Submission Date": "2024-10-08T00:00:00", "Generation": 2, "Base Model": "Qwen/Qwen2.5-1.5B"}, {"eval_name": "GritLM_GritLM-7B-KTO_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/GritLM/GritLM-7B-KTO\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">GritLM/GritLM-7B-KTO</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/GritLM__GritLM-7B-KTO-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "GritLM/GritLM-7B-KTO", "Model sha": "b5c48669508c1de18c698460c187f64e90e7df44", "Average \u2b06\ufe0f": 19.14777809369423, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 4, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5310132670203948, "IFEval": 53.10132670203948, "BBH Raw": 0.485293719684692, "BBH": 27.904317623033844, "MATH Lvl 5 Raw": 0.0219033232628398, "MATH Lvl 5": 2.190332326283988, "GPQA Raw": 0.2978187919463087, "GPQA": 6.375838926174497, "MUSR Raw": 0.3710208333333333, "MUSR": 6.644270833333335, "MMLU-PRO Raw": 0.2680352393617021, "MMLU-PRO": 18.67058215130024, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-16T00:00:00", "Submission Date": "2024-08-04T00:00:00", "Generation": 0, "Base Model": "GritLM/GritLM-7B-KTO"}, {"eval_name": "GritLM_GritLM-8x7B-KTO_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/GritLM/GritLM-8x7B-KTO\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">GritLM/GritLM-8x7B-KTO</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/GritLM__GritLM-8x7B-KTO-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "GritLM/GritLM-8x7B-KTO", "Model sha": "938913477064fcc498757c5136d9899bb6e713ed", "Average \u2b06\ufe0f": 25.62448698448212, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 3, "#Params (B)": 46, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5714049832222946, "IFEval": 57.14049832222946, "BBH Raw": 0.5820304362331497, "BBH": 40.8261615594601, "MATH Lvl 5 Raw": 0.0853474320241691, "MATH Lvl 5": 8.534743202416918, "GPQA Raw": 0.2961409395973154, "GPQA": 6.152125279642054, "MUSR Raw": 0.42165625, "MUSR": 11.673697916666669, "MMLU-PRO Raw": 0.3647772606382978, "MMLU-PRO": 29.419695626477544, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-17T00:00:00", "Submission Date": "2024-08-04T00:00:00", "Generation": 0, "Base Model": "GritLM/GritLM-8x7B-KTO"}, {"eval_name": "Gryphe_Pantheon-RP-1.0-8b-Llama-3_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Gryphe/Pantheon-RP-1.0-8b-Llama-3\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Gryphe/Pantheon-RP-1.0-8b-Llama-3</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Gryphe__Pantheon-RP-1.0-8b-Llama-3-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Gryphe/Pantheon-RP-1.0-8b-Llama-3", "Model sha": "70a6df202c9df9abdc6928bec5a5ab47f2667aee", "Average \u2b06\ufe0f": 16.6843006512946, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 46, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3932521265796974, "IFEval": 39.32521265796974, "BBH Raw": 0.4539075127777334, "BBH": 23.631914688111305, "MATH Lvl 5 Raw": 0.0521148036253776, "MATH Lvl 5": 5.211480362537765, "GPQA Raw": 0.276006711409396, "GPQA": 3.467561521252797, "MUSR Raw": 0.3832395833333333, "MUSR": 5.504947916666667, "MMLU-PRO Raw": 0.3066821808510638, "MMLU-PRO": 22.96468676122932, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-08T00:00:00", "Submission Date": "2024-06-27T00:00:00", "Generation": 1, "Base Model": "meta-llama/Meta-Llama-3-8B"}, {"eval_name": "Gryphe_Pantheon-RP-1.5-12b-Nemo_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Gryphe/Pantheon-RP-1.5-12b-Nemo\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Gryphe/Pantheon-RP-1.5-12b-Nemo</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Gryphe__Pantheon-RP-1.5-12b-Nemo-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Gryphe/Pantheon-RP-1.5-12b-Nemo", "Model sha": "00107381f05f69666772d88a1b11affe77c94a47", "Average \u2b06\ufe0f": 21.23562982267361, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 27, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4763084172218602, "IFEval": 47.63084172218603, "BBH Raw": 0.519582216884963, "BBH": 31.750144021634004, "MATH Lvl 5 Raw": 0.0438066465256797, "MATH Lvl 5": 4.380664652567976, "GPQA Raw": 0.2726510067114094, "GPQA": 3.0201342281879207, "MUSR Raw": 0.44203125, "MUSR": 15.053906250000004, "MMLU-PRO Raw": 0.3302027925531915, "MMLU-PRO": 25.57808806146572, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-25T00:00:00", "Submission Date": "2024-08-04T00:00:00", "Generation": 1, "Base Model": "mistralai/Mistral-Nemo-Base-2407"}, {"eval_name": "Gryphe_Pantheon-RP-1.6-12b-Nemo_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Gryphe/Pantheon-RP-1.6-12b-Nemo\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Gryphe/Pantheon-RP-1.6-12b-Nemo</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Gryphe__Pantheon-RP-1.6-12b-Nemo-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Gryphe/Pantheon-RP-1.6-12b-Nemo", "Model sha": "60cf38ae0367baf314e3cce748d9a199adfea557", "Average \u2b06\ufe0f": 20.314836892204767, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 11, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4480567117470533, "IFEval": 44.80567117470534, "BBH Raw": 0.5204007434392454, "BBH": 31.68734382617837, "MATH Lvl 5 Raw": 0.0309667673716012, "MATH Lvl 5": 3.096676737160121, "GPQA Raw": 0.2776845637583892, "GPQA": 3.691275167785232, "MUSR Raw": 0.4287604166666667, "MUSR": 12.92838541666667, "MMLU-PRO Raw": 0.3311170212765957, "MMLU-PRO": 25.67966903073286, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-18T00:00:00", "Submission Date": "2024-08-31T00:00:00", "Generation": 1, "Base Model": "mistralai/Mistral-Nemo-Base-2407"}, {"eval_name": "Gryphe_Pantheon-RP-1.6-12b-Nemo-KTO_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Gryphe/Pantheon-RP-1.6-12b-Nemo-KTO\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Gryphe/Pantheon-RP-1.6-12b-Nemo-KTO</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Gryphe__Pantheon-RP-1.6-12b-Nemo-KTO-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Gryphe/Pantheon-RP-1.6-12b-Nemo-KTO", "Model sha": "6cb6d8d9a7352d71f539ab5053987e058c090443", "Average \u2b06\ufe0f": 21.31942430595572, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 4, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4636187537954849, "IFEval": 46.36187537954849, "BBH Raw": 0.5276980814125921, "BBH": 33.032200369425645, "MATH Lvl 5 Raw": 0.0385196374622356, "MATH Lvl 5": 3.8519637462235647, "GPQA Raw": 0.2953020134228188, "GPQA": 6.040268456375841, "MUSR Raw": 0.4247916666666667, "MUSR": 12.165625, "MMLU-PRO Raw": 0.3381815159574468, "MMLU-PRO": 26.46461288416076, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-28T00:00:00", "Submission Date": "2024-08-31T00:00:00", "Generation": 1, "Base Model": "mistralai/Mistral-Nemo-Base-2407"}, {"eval_name": "HiroseKoichi_Llama-Salad-4x8B-V3_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/HiroseKoichi/Llama-Salad-4x8B-V3\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">HiroseKoichi/Llama-Salad-4x8B-V3</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/HiroseKoichi__Llama-Salad-4x8B-V3-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "HiroseKoichi/Llama-Salad-4x8B-V3", "Model sha": "a343915429779efbd1478f01ba1f7fd9d8d226c0", "Average \u2b06\ufe0f": 24.74646808875121, "Hub License": "llama3", "Hub \u2764\ufe0f": 5, "#Params (B)": 24, "Available on the hub": true, "Not_Merged": false, "MoE": false, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6653523761397536, "IFEval": 66.53523761397537, "BBH Raw": 0.5244649789001753, "BBH": 31.92884881074505, "MATH Lvl 5 Raw": 0.0853474320241691, "MATH Lvl 5": 8.534743202416918, "GPQA Raw": 0.3028523489932886, "GPQA": 7.046979865771815, "MUSR Raw": 0.37403125, "MUSR": 6.453906249999996, "MMLU-PRO Raw": 0.351811835106383, "MMLU-PRO": 27.979092789598106, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-17T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "HiroseKoichi/Llama-Salad-4x8B-V3"}, {"eval_name": "HuggingFaceH4_zephyr-7b-alpha_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/HuggingFaceH4/zephyr-7b-alpha\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">HuggingFaceH4/zephyr-7b-alpha</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/HuggingFaceH4__zephyr-7b-alpha-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "HuggingFaceH4/zephyr-7b-alpha", "Model sha": "2ce2d025864af849b3e5029e2ec9d568eeda892d", "Average \u2b06\ufe0f": 18.534099869931413, "Hub License": "mit", "Hub \u2764\ufe0f": 1096, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5191480826429429, "IFEval": 51.91480826429429, "BBH Raw": 0.4587863505904412, "BBH": 23.955291427068445, "MATH Lvl 5 Raw": 0.0151057401812688, "MATH Lvl 5": 1.5105740181268883, "GPQA Raw": 0.2978187919463087, "GPQA": 6.375838926174497, "MUSR Raw": 0.3949583333333333, "MUSR": 7.503125000000001, "MMLU-PRO Raw": 0.2795046542553192, "MMLU-PRO": 19.94496158392435, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-10-09T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 1, "Base Model": "mistralai/Mistral-7B-v0.1"}, {"eval_name": "HuggingFaceH4_zephyr-7b-beta_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/HuggingFaceH4/zephyr-7b-beta\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">HuggingFaceH4/zephyr-7b-beta</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/HuggingFaceH4__zephyr-7b-beta-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "HuggingFaceH4/zephyr-7b-beta", "Model sha": "b70e0c9a2d9e14bd1e812d3c398e5f313e93b473", "Average \u2b06\ufe0f": 17.71670852646412, "Hub License": "mit", "Hub \u2764\ufe0f": 1587, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4950431521695767, "IFEval": 49.50431521695767, "BBH Raw": 0.431582191918003, "BBH": 21.487542182806735, "MATH Lvl 5 Raw": 0.0241691842900302, "MATH Lvl 5": 2.416918429003021, "GPQA Raw": 0.2902684563758389, "GPQA": 5.369127516778524, "MUSR Raw": 0.3925416666666666, "MUSR": 7.7343749999999964, "MMLU-PRO Raw": 0.2780917553191489, "MMLU-PRO": 19.78797281323877, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-10-26T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 1, "Base Model": "mistralai/Mistral-7B-v0.1"}, {"eval_name": "HuggingFaceH4_zephyr-7b-gemma-v0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "GemmaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/HuggingFaceH4/zephyr-7b-gemma-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">HuggingFaceH4/zephyr-7b-gemma-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/HuggingFaceH4__zephyr-7b-gemma-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "HuggingFaceH4/zephyr-7b-gemma-v0.1", "Model sha": "03b3427d0ed07d2e0f86c0a7e53d82d4beef9540", "Average \u2b06\ufe0f": 15.778281005897105, "Hub License": "other", "Hub \u2764\ufe0f": 122, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3363741539116212, "IFEval": 33.637415391162115, "BBH Raw": 0.4623735014679749, "BBH": 23.751162749201274, "MATH Lvl 5 Raw": 0.066465256797583, "MATH Lvl 5": 6.646525679758309, "GPQA Raw": 0.2944630872483221, "GPQA": 5.92841163310962, "MUSR Raw": 0.3739687499999999, "MUSR": 4.179427083333334, "MMLU-PRO Raw": 0.2847406914893617, "MMLU-PRO": 20.526743498817968, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-03-01T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 2, "Base Model": "google/gemma-7b"}, {"eval_name": "HuggingFaceH4_zephyr-orpo-141b-A35b-v0.1_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/HuggingFaceH4/zephyr-orpo-141b-A35b-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">HuggingFaceH4/zephyr-orpo-141b-A35b-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/HuggingFaceH4__zephyr-orpo-141b-A35b-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "HuggingFaceH4/zephyr-orpo-141b-A35b-v0.1", "Model sha": "a3be084543d278e61b64cd600f28157afc79ffd3", "Average \u2b06\ufe0f": 33.77349611377467, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 260, "#Params (B)": 140, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6510891102275296, "IFEval": 65.10891102275296, "BBH Raw": 0.6290439728524093, "BBH": 47.5037962865412, "MATH Lvl 5 Raw": 0.1835347432024169, "MATH Lvl 5": 18.35347432024169, "GPQA Raw": 0.3783557046979866, "GPQA": 17.114093959731544, "MUSR Raw": 0.4465208333333333, "MUSR": 14.715104166666668, "MMLU-PRO Raw": 0.4586103723404255, "MMLU-PRO": 39.84559692671394, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-04-10T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 1, "Base Model": "mistral-community/Mixtral-8x22B-v0.1"}, {"eval_name": "HuggingFaceTB_SmolLM-1.7B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/HuggingFaceTB/SmolLM-1.7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">HuggingFaceTB/SmolLM-1.7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/HuggingFaceTB__SmolLM-1.7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "HuggingFaceTB/SmolLM-1.7B", "Model sha": "673a07602ca1191e5bc2ddda428e2f608a0a14c0", "Average \u2b06\ufe0f": 5.425398534456355, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 152, "#Params (B)": 1, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2361567308075905, "IFEval": 23.61567308075905, "BBH Raw": 0.3180516538964782, "BBH": 4.4111278515492005, "MATH Lvl 5 Raw": 0.0075528700906344, "MATH Lvl 5": 0.7552870090634441, "GPQA Raw": 0.2416107382550335, "GPQA": 0.0, "MUSR Raw": 0.34209375, "MUSR": 2.1283854166666667, "MMLU-PRO Raw": 0.1147772606382978, "MMLU-PRO": 1.6419178486997636, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-14T00:00:00", "Submission Date": "2024-07-18T00:00:00", "Generation": 0, "Base Model": "HuggingFaceTB/SmolLM-1.7B"}, {"eval_name": "HuggingFaceTB_SmolLM-1.7B-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/HuggingFaceTB/SmolLM-1.7B-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">HuggingFaceTB/SmolLM-1.7B-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/HuggingFaceTB__SmolLM-1.7B-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "HuggingFaceTB/SmolLM-1.7B-Instruct", "Model sha": "0ad161e59935a9a691dfde2818df8b98786f30a7", "Average \u2b06\ufe0f": 5.138221532759036, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 97, "#Params (B)": 1, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2347825990593846, "IFEval": 23.478259905938465, "BBH Raw": 0.2885111436321769, "BBH": 2.0803742908537424, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2600671140939597, "GPQA": 1.342281879194629, "MUSR Raw": 0.3486666666666667, "MUSR": 2.0833333333333326, "MMLU-PRO Raw": 0.1166057180851063, "MMLU-PRO": 1.8450797872340408, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-15T00:00:00", "Submission Date": "2024-07-18T00:00:00", "Generation": 1, "Base Model": "HuggingFaceTB/SmolLM-1.7B"}, {"eval_name": "HuggingFaceTB_SmolLM-135M_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/HuggingFaceTB/SmolLM-135M\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">HuggingFaceTB/SmolLM-135M</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/HuggingFaceTB__SmolLM-135M-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "HuggingFaceTB/SmolLM-135M", "Model sha": "eec6e461571fba3e197a57c298f60b75422eae02", "Average \u2b06\ufe0f": 6.838196840775357, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 163, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2124762297370975, "IFEval": 21.24762297370976, "BBH Raw": 0.3046054260062988, "BBH": 3.2853998220852616, "MATH Lvl 5 Raw": 0.0067975830815709, "MATH Lvl 5": 0.6797583081570997, "GPQA Raw": 0.2583892617449664, "GPQA": 1.1185682326621946, "MUSR Raw": 0.4366041666666667, "MUSR": 13.3421875, "MMLU-PRO Raw": 0.1122007978723404, "MMLU-PRO": 1.3556442080378246, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-14T00:00:00", "Submission Date": "2024-07-18T00:00:00", "Generation": 0, "Base Model": "HuggingFaceTB/SmolLM-135M"}, {"eval_name": "HuggingFaceTB_SmolLM-135M-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/HuggingFaceTB/SmolLM-135M-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">HuggingFaceTB/SmolLM-135M-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/HuggingFaceTB__SmolLM-135M-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "HuggingFaceTB/SmolLM-135M-Instruct", "Model sha": "8ca7af58e27777cae460ad8ca3ab9db15f5c160d", "Average \u2b06\ufe0f": 3.5641708324788968, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 90, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.1214012154416946, "IFEval": 12.14012154416947, "BBH Raw": 0.3015081678997875, "BBH": 2.69295800470458, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.259228187919463, "GPQA": 1.230425055928408, "MUSR Raw": 0.3634583333333332, "MUSR": 3.365625, "MMLU-PRO Raw": 0.1176030585106382, "MMLU-PRO": 1.9558953900709208, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-15T00:00:00", "Submission Date": "2024-10-12T00:00:00", "Generation": 1, "Base Model": "HuggingFaceTB/SmolLM-135M"}, {"eval_name": "HuggingFaceTB_SmolLM-360M_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/HuggingFaceTB/SmolLM-360M\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">HuggingFaceTB/SmolLM-360M</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/HuggingFaceTB__SmolLM-360M-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "HuggingFaceTB/SmolLM-360M", "Model sha": "318cc630b73730bfd712e5873063156ffb8936b5", "Average \u2b06\ufe0f": 6.147595806027067, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 55, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2133505764704318, "IFEval": 21.33505764704318, "BBH Raw": 0.3064516033315252, "BBH": 3.284915303246592, "MATH Lvl 5 Raw": 0.0045317220543806, "MATH Lvl 5": 0.4531722054380665, "GPQA Raw": 0.2676174496644295, "GPQA": 2.348993288590602, "MUSR Raw": 0.40178125, "MUSR": 8.089322916666665, "MMLU-PRO Raw": 0.1123670212765957, "MMLU-PRO": 1.374113475177304, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-14T00:00:00", "Submission Date": "2024-07-18T00:00:00", "Generation": 0, "Base Model": "HuggingFaceTB/SmolLM-360M"}, {"eval_name": "HuggingFaceTB_SmolLM-360M-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/HuggingFaceTB/SmolLM-360M-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">HuggingFaceTB/SmolLM-360M-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/HuggingFaceTB__SmolLM-360M-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "HuggingFaceTB/SmolLM-360M-Instruct", "Model sha": "8e951de8c220295ea4f85d078c4e320df7137535", "Average \u2b06\ufe0f": 4.70678415207999, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 71, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.1951654942219976, "IFEval": 19.51654942219977, "BBH Raw": 0.2885111436321769, "BBH": 2.0803742908537424, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2642617449664429, "GPQA": 1.9015659955257265, "MUSR Raw": 0.3471770833333333, "MUSR": 2.897135416666666, "MMLU-PRO Raw": 0.1166057180851063, "MMLU-PRO": 1.8450797872340408, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-15T00:00:00", "Submission Date": "2024-08-20T00:00:00", "Generation": 1, "Base Model": "HuggingFaceTB/SmolLM-360M"}, {"eval_name": "HumanLLMs_Humanish-LLama3-8B-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/HumanLLMs/Humanish-LLama3-8B-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">HumanLLMs/Humanish-LLama3-8B-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/HumanLLMs__Humanish-LLama3-8B-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "HumanLLMs/Humanish-LLama3-8B-Instruct", "Model sha": "42f73ada2b7fb16f18a75404d72b7911bf1e65ce", "Average \u2b06\ufe0f": 22.37608894415371, "Hub License": "llama3", "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6497903340913221, "IFEval": 64.97903340913221, "BBH Raw": 0.4967709662789654, "BBH": 28.012476599572, "MATH Lvl 5 Raw": 0.0845921450151057, "MATH Lvl 5": 8.459214501510575, "GPQA Raw": 0.2558724832214765, "GPQA": 0.7829977628635317, "MUSR Raw": 0.3581562499999999, "MUSR": 2.0028645833333325, "MMLU-PRO Raw": 0.3701795212765957, "MMLU-PRO": 30.019946808510632, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-04T00:00:00", "Submission Date": "2024-10-05T00:00:00", "Generation": 1, "Base Model": "meta-llama/Meta-Llama-3-8B-Instruct"}, {"eval_name": "HumanLLMs_Humanish-Mistral-Nemo-Instruct-2407_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/HumanLLMs/Humanish-Mistral-Nemo-Instruct-2407\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">HumanLLMs/Humanish-Mistral-Nemo-Instruct-2407</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/HumanLLMs__Humanish-Mistral-Nemo-Instruct-2407-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "HumanLLMs/Humanish-Mistral-Nemo-Instruct-2407", "Model sha": "45b80bdce8d447ef494af06751904afcc607eb37", "Average \u2b06\ufe0f": 22.88101850355426, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 2, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5451269298793867, "IFEval": 54.51269298793867, "BBH Raw": 0.5261780772532613, "BBH": 32.70961342122556, "MATH Lvl 5 Raw": 0.0762839879154078, "MATH Lvl 5": 7.628398791540786, "GPQA Raw": 0.287751677852349, "GPQA": 5.033557046979867, "MUSR Raw": 0.3967604166666666, "MUSR": 9.395052083333336, "MMLU-PRO Raw": 0.3520611702127659, "MMLU-PRO": 28.00679669030733, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-06T00:00:00", "Submission Date": "2024-10-06T00:00:00", "Generation": 2, "Base Model": "mistralai/Mistral-Nemo-Base-2407"}, {"eval_name": "HumanLLMs_Humanish-Qwen2.5-7B-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/HumanLLMs/Humanish-Qwen2.5-7B-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">HumanLLMs/Humanish-Qwen2.5-7B-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/HumanLLMs__Humanish-Qwen2.5-7B-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "HumanLLMs/Humanish-Qwen2.5-7B-Instruct", "Model sha": "7d2c71d926832d6e257ad2776011494dbac2d151", "Average \u2b06\ufe0f": 26.665374096819846, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 2, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7284250233824031, "IFEval": 72.84250233824031, "BBH Raw": 0.5363681457807072, "BBH": 34.47899758661866, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2986577181208054, "GPQA": 6.487695749440718, "MUSR Raw": 0.3980625, "MUSR": 8.424479166666668, "MMLU-PRO Raw": 0.4398271276595745, "MMLU-PRO": 37.75856973995272, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-05T00:00:00", "Submission Date": "2024-10-05T00:00:00", "Generation": 2, "Base Model": "Qwen/Qwen2.5-7B"}, {"eval_name": "IDEA-CCNL_Ziya-LLaMA-13B-v1_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/IDEA-CCNL/Ziya-LLaMA-13B-v1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">IDEA-CCNL/Ziya-LLaMA-13B-v1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/IDEA-CCNL__Ziya-LLaMA-13B-v1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "IDEA-CCNL/Ziya-LLaMA-13B-v1", "Model sha": "64d931f346e1a49ea3bbca07a83137075bab1c66", "Average \u2b06\ufe0f": 3.9064248386004095, "Hub License": "gpl-3.0", "Hub \u2764\ufe0f": 272, "#Params (B)": 13, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1696864320004255, "IFEval": 16.968643200042553, "BBH Raw": 0.2877029244540947, "BBH": 1.4636170460989155, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2491610738255033, "GPQA": 0.0, "MUSR Raw": 0.3750520833333333, "MUSR": 3.881510416666668, "MMLU-PRO Raw": 0.1101230053191489, "MMLU-PRO": 1.124778368794326, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-05-16T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "IDEA-CCNL/Ziya-LLaMA-13B-v1"}, {"eval_name": "Infinirc_Infinirc-Llama3-8B-2G-Release-v1.0_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Infinirc/Infinirc-Llama3-8B-2G-Release-v1.0\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Infinirc/Infinirc-Llama3-8B-2G-Release-v1.0</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Infinirc__Infinirc-Llama3-8B-2G-Release-v1.0-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Infinirc/Infinirc-Llama3-8B-2G-Release-v1.0", "Model sha": "9c542d9ec3f86e145ae445c200c6ebe9066e8cd6", "Average \u2b06\ufe0f": 13.0619567214822, "Hub License": "llama3", "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2024339862675478, "IFEval": 20.24339862675479, "BBH Raw": 0.4350743566823793, "BBH": 20.83116494676627, "MATH Lvl 5 Raw": 0.0105740181268882, "MATH Lvl 5": 1.0574018126888218, "GPQA Raw": 0.299496644295302, "GPQA": 6.599552572706939, "MUSR Raw": 0.4609375, "MUSR": 16.750520833333336, "MMLU-PRO Raw": 0.2160073138297872, "MMLU-PRO": 12.889701536643026, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-26T00:00:00", "Submission Date": "2024-09-29T00:00:00", "Generation": 0, "Base Model": "Infinirc/Infinirc-Llama3-8B-2G-Release-v1.0"}, {"eval_name": "Intel_neural-chat-7b-v3_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Intel/neural-chat-7b-v3\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Intel/neural-chat-7b-v3</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Intel__neural-chat-7b-v3-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Intel/neural-chat-7b-v3", "Model sha": "fc679274dfcd28a8b6087634f71af7ed2a0659c4", "Average \u2b06\ufe0f": 17.943646116016044, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 65, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2777973554612871, "IFEval": 27.779735546128716, "BBH Raw": 0.5048316221363103, "BBH": 30.205692320538088, "MATH Lvl 5 Raw": 0.0219033232628398, "MATH Lvl 5": 2.190332326283988, "GPQA Raw": 0.2919463087248322, "GPQA": 5.592841163310966, "MUSR Raw": 0.5054895833333334, "MUSR": 23.01953125, "MMLU-PRO Raw": 0.2698636968085106, "MMLU-PRO": 18.873744089834517, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-10-25T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 1, "Base Model": "mistralai/Mistral-7B-v0.1"}, {"eval_name": "Intel_neural-chat-7b-v3-1_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Intel/neural-chat-7b-v3-1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Intel/neural-chat-7b-v3-1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Intel__neural-chat-7b-v3-1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Intel/neural-chat-7b-v3-1", "Model sha": "c0d379a49c1c0579529d5e6f2e936ddb759552a8", "Average \u2b06\ufe0f": 21.00498617686432, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 542, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4686897432146704, "IFEval": 46.86897432146704, "BBH Raw": 0.5051565464054848, "BBH": 29.7397523676162, "MATH Lvl 5 Raw": 0.0317220543806646, "MATH Lvl 5": 3.1722054380664653, "GPQA Raw": 0.2902684563758389, "GPQA": 5.369127516778524, "MUSR Raw": 0.4978958333333333, "MUSR": 22.236979166666657, "MMLU-PRO Raw": 0.2677859042553192, "MMLU-PRO": 18.642878250591018, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-11-14T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 1, "Base Model": "mistralai/Mistral-7B-v0.1"}, {"eval_name": "Intel_neural-chat-7b-v3-2_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Intel/neural-chat-7b-v3-2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Intel/neural-chat-7b-v3-2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Intel__neural-chat-7b-v3-2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Intel/neural-chat-7b-v3-2", "Model sha": "0d8f77647810d21d935ea90c66d6339b85e65a75", "Average \u2b06\ufe0f": 21.43364681812902, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 56, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4988397452093778, "IFEval": 49.88397452093778, "BBH Raw": 0.5032226831964403, "BBH": 30.237457969159426, "MATH Lvl 5 Raw": 0.0453172205438066, "MATH Lvl 5": 4.531722054380665, "GPQA Raw": 0.2902684563758389, "GPQA": 5.369127516778524, "MUSR Raw": 0.4895208333333333, "MUSR": 20.05677083333333, "MMLU-PRO Raw": 0.2667054521276595, "MMLU-PRO": 18.522828014184395, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-11-21T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "Intel/neural-chat-7b-v3-2"}, {"eval_name": "Intel_neural-chat-7b-v3-3_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Intel/neural-chat-7b-v3-3\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Intel/neural-chat-7b-v3-3</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Intel__neural-chat-7b-v3-3-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Intel/neural-chat-7b-v3-3", "Model sha": "bdd31cf498d13782cc7497cba5896996ce429f91", "Average \u2b06\ufe0f": 19.99112025734428, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 75, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4762585495374495, "IFEval": 47.62585495374495, "BBH Raw": 0.4876618052428969, "BBH": 27.753850886523697, "MATH Lvl 5 Raw": 0.0067975830815709, "MATH Lvl 5": 0.6797583081570997, "GPQA Raw": 0.2894295302013422, "GPQA": 5.257270693512303, "MUSR Raw": 0.4859583333333333, "MUSR": 20.578125, "MMLU-PRO Raw": 0.2624667553191489, "MMLU-PRO": 18.05186170212766, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-12-09T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 2, "Base Model": "mistralai/Mistral-7B-v0.1"}, {"eval_name": "Isaak-Carter_JOSIEv4o-8b-stage1-v4_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Isaak-Carter/JOSIEv4o-8b-stage1-v4\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Isaak-Carter/JOSIEv4o-8b-stage1-v4</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Isaak-Carter__JOSIEv4o-8b-stage1-v4-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Isaak-Carter/JOSIEv4o-8b-stage1-v4", "Model sha": "a8380a7be51b547761824e524b3d95ac73203122", "Average \u2b06\ufe0f": 15.567377233131843, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2552660274737696, "IFEval": 25.526602747376963, "BBH Raw": 0.4724973116620121, "BBH": 25.7872756997585, "MATH Lvl 5 Raw": 0.0468277945619335, "MATH Lvl 5": 4.682779456193353, "GPQA Raw": 0.2919463087248322, "GPQA": 5.592841163310966, "MUSR Raw": 0.3654375, "MUSR": 6.0796875, "MMLU-PRO Raw": 0.3316156914893617, "MMLU-PRO": 25.7350768321513, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-03T00:00:00", "Submission Date": "2024-08-03T00:00:00", "Generation": 0, "Base Model": "Isaak-Carter/JOSIEv4o-8b-stage1-v4"}, {"eval_name": "Isaak-Carter_JOSIEv4o-8b-stage1-v4_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Isaak-Carter/JOSIEv4o-8b-stage1-v4\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Isaak-Carter/JOSIEv4o-8b-stage1-v4</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Isaak-Carter__JOSIEv4o-8b-stage1-v4-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Isaak-Carter/JOSIEv4o-8b-stage1-v4", "Model sha": "a8380a7be51b547761824e524b3d95ac73203122", "Average \u2b06\ufe0f": 15.305979197679385, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2476972211509905, "IFEval": 24.76972211509905, "BBH Raw": 0.4758066295235124, "BBH": 25.91957835941345, "MATH Lvl 5 Raw": 0.0385196374622356, "MATH Lvl 5": 3.8519637462235647, "GPQA Raw": 0.2911073825503356, "GPQA": 5.480984340044745, "MUSR Raw": 0.3641041666666667, "MUSR": 6.346354166666667, "MMLU-PRO Raw": 0.3292054521276595, "MMLU-PRO": 25.46727245862884, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-03T00:00:00", "Submission Date": "2024-08-03T00:00:00", "Generation": 0, "Base Model": "Isaak-Carter/JOSIEv4o-8b-stage1-v4"}, {"eval_name": "Isaak-Carter_Josiefied-Qwen2.5-7B-Instruct-abliterated_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Isaak-Carter/Josiefied-Qwen2.5-7B-Instruct-abliterated\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Isaak-Carter/Josiefied-Qwen2.5-7B-Instruct-abliterated</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Isaak-Carter__Josiefied-Qwen2.5-7B-Instruct-abliterated-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Isaak-Carter/Josiefied-Qwen2.5-7B-Instruct-abliterated", "Model sha": "879168f9ce9fac315a19dd4f4c7df5253bb660f2", "Average \u2b06\ufe0f": 26.85729545990909, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7317473193349202, "IFEval": 73.17473193349201, "BBH Raw": 0.5396376284460921, "BBH": 34.904315688323074, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.3028523489932886, "GPQA": 7.046979865771815, "MUSR Raw": 0.4086666666666667, "MUSR": 9.616666666666667, "MMLU-PRO Raw": 0.4276097074468085, "MMLU-PRO": 36.401078605200944, "Maintainer's Highlight": false, "Upload To Hub Date": "", "Submission Date": "2024-09-21T00:00:00", "Generation": 0, "Base Model": "Removed"}, {"eval_name": "Isaak-Carter_Josiefied-Qwen2.5-7B-Instruct-abliterated-v2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Isaak-Carter/Josiefied-Qwen2.5-7B-Instruct-abliterated-v2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Isaak-Carter/Josiefied-Qwen2.5-7B-Instruct-abliterated-v2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Isaak-Carter__Josiefied-Qwen2.5-7B-Instruct-abliterated-v2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Isaak-Carter/Josiefied-Qwen2.5-7B-Instruct-abliterated-v2", "Model sha": "5d07f58562422feb9f25c9c048e40356d2cf7e4b", "Average \u2b06\ufe0f": 27.81795957129169, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 4, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7841039552830933, "IFEval": 78.41039552830932, "BBH Raw": 0.5310923599182072, "BBH": 33.2945398202129, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2986577181208054, "GPQA": 6.487695749440718, "MUSR Raw": 0.4353958333333333, "MUSR": 13.957812500000005, "MMLU-PRO Raw": 0.4128158244680851, "MMLU-PRO": 34.75731382978724, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-20T00:00:00", "Submission Date": "2024-09-21T00:00:00", "Generation": 1, "Base Model": "Qwen/Qwen2.5-7B"}, {"eval_name": "Jacoby746_Inf-Silent-Kunoichi-v0.1-2x7B_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Jacoby746/Inf-Silent-Kunoichi-v0.1-2x7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Jacoby746/Inf-Silent-Kunoichi-v0.1-2x7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Jacoby746__Inf-Silent-Kunoichi-v0.1-2x7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Jacoby746/Inf-Silent-Kunoichi-v0.1-2x7B", "Model sha": "9ab68beb6fe16cab2ab708b9af4417c89751d297", "Average \u2b06\ufe0f": 20.00994764974528, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3879816664228691, "IFEval": 38.79816664228691, "BBH Raw": 0.518546209727402, "BBH": 32.38700420411291, "MATH Lvl 5 Raw": 0.0604229607250755, "MATH Lvl 5": 6.042296072507553, "GPQA Raw": 0.2894295302013422, "GPQA": 5.257270693512303, "MUSR Raw": 0.4280416666666666, "MUSR": 12.338541666666671, "MMLU-PRO Raw": 0.3271276595744681, "MMLU-PRO": 25.236406619385345, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-19T00:00:00", "Submission Date": "2024-09-20T00:00:00", "Generation": 1, "Base Model": "Jacoby746/Inf-Silent-Kunoichi-v0.1-2x7B (Merge)"}, {"eval_name": "Jacoby746_Inf-Silent-Kunoichi-v0.2-2x7B_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Jacoby746/Inf-Silent-Kunoichi-v0.2-2x7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Jacoby746/Inf-Silent-Kunoichi-v0.2-2x7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Jacoby746__Inf-Silent-Kunoichi-v0.2-2x7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Jacoby746/Inf-Silent-Kunoichi-v0.2-2x7B", "Model sha": "711263c24f812676eb382a31a5f0fed9bd8c16e4", "Average \u2b06\ufe0f": 19.917523364619857, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3636019095998617, "IFEval": 36.36019095998617, "BBH Raw": 0.5209417299963208, "BBH": 32.259183510828905, "MATH Lvl 5 Raw": 0.0566465256797583, "MATH Lvl 5": 5.664652567975831, "GPQA Raw": 0.3003355704697986, "GPQA": 6.711409395973152, "MUSR Raw": 0.4319791666666666, "MUSR": 13.264062499999996, "MMLU-PRO Raw": 0.3272107712765957, "MMLU-PRO": 25.24564125295508, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-19T00:00:00", "Submission Date": "2024-09-21T00:00:00", "Generation": 1, "Base Model": "Jacoby746/Inf-Silent-Kunoichi-v0.2-2x7B (Merge)"}, {"eval_name": "Jacoby746_Proto-Athena-4x7B_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Jacoby746/Proto-Athena-4x7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Jacoby746/Proto-Athena-4x7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Jacoby746__Proto-Athena-4x7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Jacoby746/Proto-Athena-4x7B", "Model sha": "450fcba7a630fb61a662f71936d37979226fced8", "Average \u2b06\ufe0f": 19.64969645530488, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 24, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3702963691893066, "IFEval": 37.02963691893066, "BBH Raw": 0.5106547638742905, "BBH": 30.870822876627887, "MATH Lvl 5 Raw": 0.0574018126888217, "MATH Lvl 5": 5.740181268882175, "GPQA Raw": 0.2944630872483221, "GPQA": 5.92841163310962, "MUSR Raw": 0.4347708333333333, "MUSR": 13.813020833333328, "MMLU-PRO Raw": 0.3206449468085106, "MMLU-PRO": 24.516105200945624, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-21T00:00:00", "Submission Date": "2024-09-21T00:00:00", "Generation": 1, "Base Model": "Jacoby746/Proto-Athena-4x7B (Merge)"}, {"eval_name": "Jacoby746_Proto-Athena-v0.2-4x7B_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Jacoby746/Proto-Athena-v0.2-4x7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Jacoby746/Proto-Athena-v0.2-4x7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Jacoby746__Proto-Athena-v0.2-4x7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Jacoby746/Proto-Athena-v0.2-4x7B", "Model sha": "01feeded217ea83a8794e7968c8850859b5f0b14", "Average \u2b06\ufe0f": 19.143897625710437, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 24, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.375242135312083, "IFEval": 37.524213531208304, "BBH Raw": 0.5067731005424964, "BBH": 30.34084433030367, "MATH Lvl 5 Raw": 0.0513595166163142, "MATH Lvl 5": 5.13595166163142, "GPQA Raw": 0.2986577181208054, "GPQA": 6.487695749440718, "MUSR Raw": 0.42128125, "MUSR": 10.960156250000002, "MMLU-PRO Raw": 0.3197307180851064, "MMLU-PRO": 24.414524231678485, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-21T00:00:00", "Submission Date": "2024-09-21T00:00:00", "Generation": 1, "Base Model": "Jacoby746/Proto-Athena-v0.2-4x7B (Merge)"}, {"eval_name": "Jacoby746_Proto-Harpy-Blazing-Light-v0.1-2x7B_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Jacoby746/Proto-Harpy-Blazing-Light-v0.1-2x7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Jacoby746/Proto-Harpy-Blazing-Light-v0.1-2x7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Jacoby746__Proto-Harpy-Blazing-Light-v0.1-2x7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Jacoby746/Proto-Harpy-Blazing-Light-v0.1-2x7B", "Model sha": "bbb5d7c7a0c9e999e057ffa71eaa93d59d95b36b", "Average \u2b06\ufe0f": 22.292391864753952, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 12, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4904719477652628, "IFEval": 49.04719477652628, "BBH Raw": 0.5186849053052595, "BBH": 32.63252990159268, "MATH Lvl 5 Raw": 0.0634441087613293, "MATH Lvl 5": 6.3444108761329305, "GPQA Raw": 0.2953020134228188, "GPQA": 6.040268456375841, "MUSR Raw": 0.4449687499999999, "MUSR": 14.12109375, "MMLU-PRO Raw": 0.3301196808510638, "MMLU-PRO": 25.56885342789598, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-22T00:00:00", "Submission Date": "2024-09-30T00:00:00", "Generation": 1, "Base Model": "Jacoby746/Proto-Harpy-Blazing-Light-v0.1-2x7B (Merge)"}, {"eval_name": "Jacoby746_Proto-Harpy-Spark-v0.1-7B_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Jacoby746/Proto-Harpy-Spark-v0.1-7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Jacoby746/Proto-Harpy-Spark-v0.1-7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Jacoby746__Proto-Harpy-Spark-v0.1-7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Jacoby746/Proto-Harpy-Spark-v0.1-7B", "Model sha": "984cca02cd930b2e1b7b2a7d53471d32d9821cdd", "Average \u2b06\ufe0f": 19.78705931661709, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4332692810631346, "IFEval": 43.32692810631347, "BBH Raw": 0.4735771808296548, "BBH": 26.913110159424864, "MATH Lvl 5 Raw": 0.0581570996978852, "MATH Lvl 5": 5.81570996978852, "GPQA Raw": 0.3053691275167785, "GPQA": 7.38255033557047, "MUSR Raw": 0.4316666666666666, "MUSR": 12.29166666666667, "MMLU-PRO Raw": 0.3069315159574468, "MMLU-PRO": 22.992390661938536, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-22T00:00:00", "Submission Date": "2024-09-30T00:00:00", "Generation": 1, "Base Model": "Jacoby746/Proto-Harpy-Spark-v0.1-7B (Merge)"}, {"eval_name": "Jimmy19991222_Llama-3-Instruct-8B-SimPO-v0.2_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Jimmy19991222/Llama-3-Instruct-8B-SimPO-v0.2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Jimmy19991222/Llama-3-Instruct-8B-SimPO-v0.2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Jimmy19991222__Llama-3-Instruct-8B-SimPO-v0.2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Jimmy19991222/Llama-3-Instruct-8B-SimPO-v0.2", "Model sha": "53a517ceaef324efc3626be44140b4f18a010591", "Average \u2b06\ufe0f": 24.229595975570845, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6540368444615842, "IFEval": 65.40368444615842, "BBH Raw": 0.498371102582105, "BBH": 29.1238227637126, "MATH Lvl 5 Raw": 0.0400302114803625, "MATH Lvl 5": 4.003021148036254, "GPQA Raw": 0.3145973154362416, "GPQA": 8.612975391498878, "MUSR Raw": 0.40125, "MUSR": 8.389583333333334, "MMLU-PRO Raw": 0.3686003989361702, "MMLU-PRO": 29.84448877068557, "Maintainer's Highlight": false, "Upload To Hub Date": "", "Submission Date": "2024-09-06T00:00:00", "Generation": 0, "Base Model": "Removed"}, {"eval_name": "Jimmy19991222_llama-3-8b-instruct-gapo-v2-bert-f1-beta10-gamma0.3-lr1.0e-6-1minus-rerun_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Jimmy19991222/llama-3-8b-instruct-gapo-v2-bert-f1-beta10-gamma0.3-lr1.0e-6-1minus-rerun\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Jimmy19991222/llama-3-8b-instruct-gapo-v2-bert-f1-beta10-gamma0.3-lr1.0e-6-1minus-rerun</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Jimmy19991222__llama-3-8b-instruct-gapo-v2-bert-f1-beta10-gamma0.3-lr1.0e-6-1minus-rerun-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Jimmy19991222/llama-3-8b-instruct-gapo-v2-bert-f1-beta10-gamma0.3-lr1.0e-6-1minus-rerun", "Model sha": "00c02a823b4ff1a6cfcded6085ba9630df633998", "Average \u2b06\ufe0f": 23.74217557790853, "Hub License": "llama3", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6717221416951467, "IFEval": 67.17221416951466, "BBH Raw": 0.4879796567289935, "BBH": 27.755228582197063, "MATH Lvl 5 Raw": 0.0362537764350453, "MATH Lvl 5": 3.625377643504532, "GPQA Raw": 0.2944630872483221, "GPQA": 5.92841163310962, "MUSR Raw": 0.4040729166666667, "MUSR": 8.709114583333337, "MMLU-PRO Raw": 0.3633643617021276, "MMLU-PRO": 29.26270685579196, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-17T00:00:00", "Submission Date": "2024-09-18T00:00:00", "Generation": 1, "Base Model": "meta-llama/Meta-Llama-3-8B-Instruct"}, {"eval_name": "Jimmy19991222_llama-3-8b-instruct-gapo-v2-bert_f1-beta10-gamma0.3-lr1.0e-6-scale-log_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Jimmy19991222/llama-3-8b-instruct-gapo-v2-bert_f1-beta10-gamma0.3-lr1.0e-6-scale-log\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Jimmy19991222/llama-3-8b-instruct-gapo-v2-bert_f1-beta10-gamma0.3-lr1.0e-6-scale-log</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Jimmy19991222__llama-3-8b-instruct-gapo-v2-bert_f1-beta10-gamma0.3-lr1.0e-6-scale-log-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Jimmy19991222/llama-3-8b-instruct-gapo-v2-bert_f1-beta10-gamma0.3-lr1.0e-6-scale-log", "Model sha": "99d9e31df5b7e88b1da78b1bd335cac3215dfd6e", "Average \u2b06\ufe0f": 23.680741238465657, "Hub License": "llama3", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6555605792630221, "IFEval": 65.55605792630222, "BBH Raw": 0.4934584036729416, "BBH": 28.613596677525617, "MATH Lvl 5 Raw": 0.0294561933534743, "MATH Lvl 5": 2.9456193353474323, "GPQA Raw": 0.3045302013422818, "GPQA": 7.270693512304249, "MUSR Raw": 0.4000104166666667, "MUSR": 8.167968750000002, "MMLU-PRO Raw": 0.3657746010638298, "MMLU-PRO": 29.53051122931442, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-22T00:00:00", "Submission Date": "2024-09-22T00:00:00", "Generation": 1, "Base Model": "meta-llama/Meta-Llama-3-8B-Instruct"}, {"eval_name": "Jimmy19991222_llama-3-8b-instruct-gapo-v2-bert_p-beta10-gamma0.3-lr1.0e-6-scale-log_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Jimmy19991222/llama-3-8b-instruct-gapo-v2-bert_p-beta10-gamma0.3-lr1.0e-6-scale-log\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Jimmy19991222/llama-3-8b-instruct-gapo-v2-bert_p-beta10-gamma0.3-lr1.0e-6-scale-log</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Jimmy19991222__llama-3-8b-instruct-gapo-v2-bert_p-beta10-gamma0.3-lr1.0e-6-scale-log-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Jimmy19991222/llama-3-8b-instruct-gapo-v2-bert_p-beta10-gamma0.3-lr1.0e-6-scale-log", "Model sha": "49a029ea2605d768e89b638ad78a59fd62d192ab", "Average \u2b06\ufe0f": 22.69727395161694, "Hub License": "llama3", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6315055164740666, "IFEval": 63.150551647406665, "BBH Raw": 0.4916414793938901, "BBH": 27.666183558964235, "MATH Lvl 5 Raw": 0.0445619335347432, "MATH Lvl 5": 4.45619335347432, "GPQA Raw": 0.2860738255033557, "GPQA": 4.809843400447425, "MUSR Raw": 0.3935, "MUSR": 7.087500000000001, "MMLU-PRO Raw": 0.3611203457446808, "MMLU-PRO": 29.01337174940898, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-22T00:00:00", "Submission Date": "2024-09-22T00:00:00", "Generation": 1, "Base Model": "meta-llama/Meta-Llama-3-8B-Instruct"}, {"eval_name": "Jimmy19991222_llama-3-8b-instruct-gapo-v2-bleu-beta0.1-no-length-scale-gamma0.4_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Jimmy19991222/llama-3-8b-instruct-gapo-v2-bleu-beta0.1-no-length-scale-gamma0.4\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Jimmy19991222/llama-3-8b-instruct-gapo-v2-bleu-beta0.1-no-length-scale-gamma0.4</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Jimmy19991222__llama-3-8b-instruct-gapo-v2-bleu-beta0.1-no-length-scale-gamma0.4-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Jimmy19991222/llama-3-8b-instruct-gapo-v2-bleu-beta0.1-no-length-scale-gamma0.4", "Model sha": "de8bb28ad7a9d1158f318a4461dc47ad03e6e560", "Average \u2b06\ufe0f": 22.81472367204724, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6284580468711907, "IFEval": 62.84580468711906, "BBH Raw": 0.4986088445592742, "BBH": 29.3297318748178, "MATH Lvl 5 Raw": 0.0166163141993957, "MATH Lvl 5": 1.6616314199395772, "GPQA Raw": 0.2927852348993288, "GPQA": 5.7046979865771785, "MUSR Raw": 0.401375, "MUSR": 9.071875000000002, "MMLU-PRO Raw": 0.3544714095744681, "MMLU-PRO": 28.27460106382979, "Maintainer's Highlight": false, "Upload To Hub Date": "", "Submission Date": "2024-09-06T00:00:00", "Generation": 0, "Base Model": "Removed"}, {"eval_name": "Jimmy19991222_llama-3-8b-instruct-gapo-v2-rouge2-beta10-1minus-gamma0.3-rerun_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Jimmy19991222/llama-3-8b-instruct-gapo-v2-rouge2-beta10-1minus-gamma0.3-rerun\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Jimmy19991222/llama-3-8b-instruct-gapo-v2-rouge2-beta10-1minus-gamma0.3-rerun</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Jimmy19991222__llama-3-8b-instruct-gapo-v2-rouge2-beta10-1minus-gamma0.3-rerun-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Jimmy19991222/llama-3-8b-instruct-gapo-v2-rouge2-beta10-1minus-gamma0.3-rerun", "Model sha": "e9692d8dbe30273839763757aa9ef07a5fcf0c59", "Average \u2b06\ufe0f": 24.033144978837928, "Hub License": "llama3", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6677504576745258, "IFEval": 66.77504576745258, "BBH Raw": 0.4940463886115545, "BBH": 28.390676236054286, "MATH Lvl 5 Raw": 0.0400302114803625, "MATH Lvl 5": 4.003021148036254, "GPQA Raw": 0.3062080536912752, "GPQA": 7.494407158836691, "MUSR Raw": 0.3987083333333334, "MUSR": 8.005208333333334, "MMLU-PRO Raw": 0.3657746010638298, "MMLU-PRO": 29.53051122931442, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-14T00:00:00", "Submission Date": "2024-09-15T00:00:00", "Generation": 1, "Base Model": "meta-llama/Meta-Llama-3-8B-Instruct"}, {"eval_name": "Jimmy19991222_llama-3-8b-instruct-gapo-v2-rouge2-beta10-gamma0.3-lr1.0e-6-scale-log_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Jimmy19991222/llama-3-8b-instruct-gapo-v2-rouge2-beta10-gamma0.3-lr1.0e-6-scale-log\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Jimmy19991222/llama-3-8b-instruct-gapo-v2-rouge2-beta10-gamma0.3-lr1.0e-6-scale-log</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Jimmy19991222__llama-3-8b-instruct-gapo-v2-rouge2-beta10-gamma0.3-lr1.0e-6-scale-log-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Jimmy19991222/llama-3-8b-instruct-gapo-v2-rouge2-beta10-gamma0.3-lr1.0e-6-scale-log", "Model sha": "9ff0ce408abb8dbcf7efb9b6533338f2c344a355", "Average \u2b06\ufe0f": 23.80803032063199, "Hub License": "llama3", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6605063453857986, "IFEval": 66.05063453857986, "BBH Raw": 0.4916007558129804, "BBH": 28.07503551511944, "MATH Lvl 5 Raw": 0.0415407854984894, "MATH Lvl 5": 4.154078549848943, "GPQA Raw": 0.3036912751677852, "GPQA": 7.158836689038028, "MUSR Raw": 0.4000416666666667, "MUSR": 7.805208333333336, "MMLU-PRO Raw": 0.3664394946808511, "MMLU-PRO": 29.604388297872337, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-22T00:00:00", "Submission Date": "2024-09-22T00:00:00", "Generation": 1, "Base Model": "meta-llama/Meta-Llama-3-8B-Instruct"}, {"eval_name": "Jimmy19991222_llama-3-8b-instruct-gapo-v2-rougeL-beta10-gamma0.3-lr1.0e-6-scale-log_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Jimmy19991222/llama-3-8b-instruct-gapo-v2-rougeL-beta10-gamma0.3-lr1.0e-6-scale-log\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Jimmy19991222/llama-3-8b-instruct-gapo-v2-rougeL-beta10-gamma0.3-lr1.0e-6-scale-log</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Jimmy19991222__llama-3-8b-instruct-gapo-v2-rougeL-beta10-gamma0.3-lr1.0e-6-scale-log-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Jimmy19991222/llama-3-8b-instruct-gapo-v2-rougeL-beta10-gamma0.3-lr1.0e-6-scale-log", "Model sha": "ec67f95c4d1813a34bbde52d0ad14824fd7111a0", "Average \u2b06\ufe0f": 23.679328554876804, "Hub License": "llama3", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.649190813707629, "IFEval": 64.91908137076291, "BBH Raw": 0.4952489348573605, "BBH": 28.56256683836558, "MATH Lvl 5 Raw": 0.0415407854984894, "MATH Lvl 5": 4.154078549848943, "GPQA Raw": 0.3020134228187919, "GPQA": 6.935123042505594, "MUSR Raw": 0.3961354166666667, "MUSR": 7.383593750000003, "MMLU-PRO Raw": 0.37109375, "MMLU-PRO": 30.12152777777778, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-22T00:00:00", "Submission Date": "2024-09-22T00:00:00", "Generation": 1, "Base Model": "meta-llama/Meta-Llama-3-8B-Instruct"}, {"eval_name": "Joseph717171_Llama-3.1-SuperNova-8B-Lite_TIES_with_Base_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Joseph717171/Llama-3.1-SuperNova-8B-Lite_TIES_with_Base\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Joseph717171/Llama-3.1-SuperNova-8B-Lite_TIES_with_Base</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Joseph717171__Llama-3.1-SuperNova-8B-Lite_TIES_with_Base-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Joseph717171/Llama-3.1-SuperNova-8B-Lite_TIES_with_Base", "Model sha": "f1e2cad4dca10f948fd2ee9588f80df0b40d7232", "Average \u2b06\ufe0f": 29.77926772695886, "Hub License": "llama3.1", "Hub \u2764\ufe0f": 5, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.8096328851890761, "IFEval": 80.9632885189076, "BBH Raw": 0.5147423127141911, "BBH": 31.46581339489899, "MATH Lvl 5 Raw": 0.1555891238670695, "MATH Lvl 5": 15.55891238670695, "GPQA Raw": 0.3095637583892617, "GPQA": 7.941834451901568, "MUSR Raw": 0.4109895833333333, "MUSR": 10.74036458333333, "MMLU-PRO Raw": 0.3880485372340425, "MMLU-PRO": 32.00539302600473, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-02T00:00:00", "Submission Date": "2024-10-03T00:00:00", "Generation": 0, "Base Model": "Joseph717171/Llama-3.1-SuperNova-8B-Lite_TIES_with_Base"}, {"eval_name": "Josephgflowers_Cinder-Phi-2-V1-F16-gguf_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "PhiForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Josephgflowers/Cinder-Phi-2-V1-F16-gguf\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Josephgflowers/Cinder-Phi-2-V1-F16-gguf</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Josephgflowers__Cinder-Phi-2-V1-F16-gguf-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Josephgflowers/Cinder-Phi-2-V1-F16-gguf", "Model sha": "85629ec9b18efee31d07630664e7a3815121badf", "Average \u2b06\ufe0f": 10.855702876978864, "Hub License": "mit", "Hub \u2764\ufe0f": 4, "#Params (B)": 2, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2356569457927188, "IFEval": 23.565694579271884, "BBH Raw": 0.4396616219689493, "BBH": 22.45340222827221, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2818791946308724, "GPQA": 4.250559284116329, "MUSR Raw": 0.3434583333333333, "MUSR": 1.965625, "MMLU-PRO Raw": 0.2160904255319149, "MMLU-PRO": 12.898936170212766, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-02-25T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "Josephgflowers/Cinder-Phi-2-V1-F16-gguf"}, {"eval_name": "Josephgflowers_TinyLlama-Cinder-Agent-v1_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Josephgflowers/TinyLlama-Cinder-Agent-v1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Josephgflowers/TinyLlama-Cinder-Agent-v1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Josephgflowers__TinyLlama-Cinder-Agent-v1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Josephgflowers/TinyLlama-Cinder-Agent-v1", "Model sha": "a9cd8b48bfe30f29bb1f819213da9a4c41eee67f", "Average \u2b06\ufe0f": 5.816564399847588, "Hub License": "mit", "Hub \u2764\ufe0f": 0, "#Params (B)": 1, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2669561208704016, "IFEval": 26.695612087040164, "BBH Raw": 0.3116036735177651, "BBH": 3.804167155031377, "MATH Lvl 5 Raw": 0.0037764350453172, "MATH Lvl 5": 0.3776435045317221, "GPQA Raw": 0.2441275167785234, "GPQA": 0.0, "MUSR Raw": 0.3394583333333333, "MUSR": 2.232291666666667, "MMLU-PRO Raw": 0.1161070478723404, "MMLU-PRO": 1.7896719858156025, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-21T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 4, "Base Model": "Josephgflowers/TinyLlama-3T-Cinder-v1.2"}, {"eval_name": "Josephgflowers_TinyLlama-v1.1-Cinders-World_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Josephgflowers/TinyLlama-v1.1-Cinders-World\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Josephgflowers/TinyLlama-v1.1-Cinders-World</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Josephgflowers__TinyLlama-v1.1-Cinders-World-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Josephgflowers/TinyLlama-v1.1-Cinders-World", "Model sha": "11a2c305f787a7908dd87c4e5a7d0f1e314a1f05", "Average \u2b06\ufe0f": 5.116537372140582, "Hub License": "mit", "Hub \u2764\ufe0f": 0, "#Params (B)": 1, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2469226097864776, "IFEval": 24.692260978647766, "BBH Raw": 0.2997965317600307, "BBH": 3.107714473502144, "MATH Lvl 5 Raw": 0.0007552870090634, "MATH Lvl 5": 0.0755287009063444, "GPQA Raw": 0.2441275167785234, "GPQA": 0.0, "MUSR Raw": 0.3356145833333333, "MUSR": 0.6184895833333329, "MMLU-PRO Raw": 0.1198470744680851, "MMLU-PRO": 2.2052304964539005, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-12T00:00:00", "Submission Date": "2024-10-13T00:00:00", "Generation": 0, "Base Model": "Josephgflowers/TinyLlama-v1.1-Cinders-World"}, {"eval_name": "Josephgflowers_TinyLlama_v1.1_math_code-world-test-1_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Josephgflowers/TinyLlama_v1.1_math_code-world-test-1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Josephgflowers/TinyLlama_v1.1_math_code-world-test-1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Josephgflowers__TinyLlama_v1.1_math_code-world-test-1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Josephgflowers/TinyLlama_v1.1_math_code-world-test-1", "Model sha": "6f7c2aaf0b8723bc6a1dc23a4a1ff0ec24dc11ec", "Average \u2b06\ufe0f": 1.8265776396195836, "Hub License": "mit", "Hub \u2764\ufe0f": 0, "#Params (B)": 1, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.0078436326724202, "IFEval": 0.784363267242029, "BBH Raw": 0.3146349750892843, "BBH": 4.164017098724634, "MATH Lvl 5 Raw": 0.0090634441087613, "MATH Lvl 5": 0.906344410876133, "GPQA Raw": 0.2340604026845637, "GPQA": 0.0, "MUSR Raw": 0.34990625, "MUSR": 3.63828125, "MMLU-PRO Raw": 0.1131981382978723, "MMLU-PRO": 1.466459810874704, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-23T00:00:00", "Submission Date": "2024-09-09T00:00:00", "Generation": 0, "Base Model": "Josephgflowers/TinyLlama_v1.1_math_code-world-test-1"}, {"eval_name": "KSU-HW-SEC_Llama3-70b-SVA-FT-1415_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/KSU-HW-SEC/Llama3-70b-SVA-FT-1415\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">KSU-HW-SEC/Llama3-70b-SVA-FT-1415</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/KSU-HW-SEC__Llama3-70b-SVA-FT-1415-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "KSU-HW-SEC/Llama3-70b-SVA-FT-1415", "Model sha": "1c09728455567898116d2d9cfb6cbbbbd4ee730c", "Average \u2b06\ufe0f": 35.80452980279753, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 70, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.6179913739987677, "IFEval": 61.79913739987677, "BBH Raw": 0.6650146340680478, "BBH": 51.328741195678994, "MATH Lvl 5 Raw": 0.2009063444108761, "MATH Lvl 5": 20.09063444108761, "GPQA Raw": 0.375, "GPQA": 16.666666666666664, "MUSR Raw": 0.4565416666666667, "MUSR": 17.801041666666663, "MMLU-PRO Raw": 0.5242686170212766, "MMLU-PRO": 47.140957446808514, "Maintainer's Highlight": false, "Upload To Hub Date": "", "Submission Date": "2024-09-08T00:00:00", "Generation": 0, "Base Model": "Removed"}, {"eval_name": "KSU-HW-SEC_Llama3-70b-SVA-FT-500_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/KSU-HW-SEC/Llama3-70b-SVA-FT-500\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">KSU-HW-SEC/Llama3-70b-SVA-FT-500</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/KSU-HW-SEC__Llama3-70b-SVA-FT-500-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "KSU-HW-SEC/Llama3-70b-SVA-FT-500", "Model sha": "856a23f28aeada23d1135c86a37e05524307e8ed", "Average \u2b06\ufe0f": 35.61383283174935, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 70, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.6105223030448099, "IFEval": 61.052230304481, "BBH Raw": 0.6692236023098005, "BBH": 51.8870262488106, "MATH Lvl 5 Raw": 0.1933534743202417, "MATH Lvl 5": 19.335347432024168, "GPQA Raw": 0.3808724832214765, "GPQA": 17.4496644295302, "MUSR Raw": 0.4511458333333333, "MUSR": 16.993229166666666, "MMLU-PRO Raw": 0.522689494680851, "MMLU-PRO": 46.96549940898345, "Maintainer's Highlight": false, "Upload To Hub Date": "", "Submission Date": "2024-09-08T00:00:00", "Generation": 0, "Base Model": "Removed"}, {"eval_name": "KSU-HW-SEC_Llama3-70b-SVA-FT-final_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/KSU-HW-SEC/Llama3-70b-SVA-FT-final\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">KSU-HW-SEC/Llama3-70b-SVA-FT-final</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/KSU-HW-SEC__Llama3-70b-SVA-FT-final-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "KSU-HW-SEC/Llama3-70b-SVA-FT-final", "Model sha": "391bbd94173b34975d1aa2c7356977a630253b75", "Average \u2b06\ufe0f": 35.779134222773564, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 70, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.6164676391973297, "IFEval": 61.64676391973297, "BBH Raw": 0.6650146340680478, "BBH": 51.328741195678994, "MATH Lvl 5 Raw": 0.2009063444108761, "MATH Lvl 5": 20.09063444108761, "GPQA Raw": 0.375, "GPQA": 16.666666666666664, "MUSR Raw": 0.4565416666666667, "MUSR": 17.801041666666663, "MMLU-PRO Raw": 0.5242686170212766, "MMLU-PRO": 47.140957446808514, "Maintainer's Highlight": false, "Upload To Hub Date": "", "Submission Date": "2024-09-08T00:00:00", "Generation": 0, "Base Model": "Removed"}, {"eval_name": "KSU-HW-SEC_Llama3.1-70b-SVA-FT-1000step_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/KSU-HW-SEC/Llama3.1-70b-SVA-FT-1000step\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">KSU-HW-SEC/Llama3.1-70b-SVA-FT-1000step</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/KSU-HW-SEC__Llama3.1-70b-SVA-FT-1000step-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "KSU-HW-SEC/Llama3.1-70b-SVA-FT-1000step", "Model sha": "b195fea0d8f350ff29243d4e88654b1baa5af79e", "Average \u2b06\ufe0f": 40.33485081581015, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 70, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.7238039512936785, "IFEval": 72.38039512936786, "BBH Raw": 0.6903120365165111, "BBH": 55.48536459580824, "MATH Lvl 5 Raw": 0.29607250755287, "MATH Lvl 5": 29.607250755287005, "GPQA Raw": 0.3959731543624161, "GPQA": 19.463087248322143, "MUSR Raw": 0.4591770833333333, "MUSR": 17.830468749999998, "MMLU-PRO Raw": 0.5251828457446809, "MMLU-PRO": 47.24253841607565, "Maintainer's Highlight": false, "Upload To Hub Date": "", "Submission Date": "2024-09-08T00:00:00", "Generation": 0, "Base Model": "Removed"}, {"eval_name": "KingNish_Qwen2.5-0.5b-Test-ft_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/KingNish/Qwen2.5-0.5b-Test-ft\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">KingNish/Qwen2.5-0.5b-Test-ft</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/KingNish__Qwen2.5-0.5b-Test-ft-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "KingNish/Qwen2.5-0.5b-Test-ft", "Model sha": "f905bb1d37c7853fb5c7157d8d3ad0f062b65c0f", "Average \u2b06\ufe0f": 7.462595860645532, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 4, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2670813441668107, "IFEval": 26.708134416681077, "BBH Raw": 0.3231533857529747, "BBH": 6.058845092070314, "MATH Lvl 5 Raw": 0.0113293051359516, "MATH Lvl 5": 1.1329305135951662, "GPQA Raw": 0.2634228187919463, "GPQA": 1.789709172259505, "MUSR Raw": 0.342125, "MUSR": 1.432291666666666, "MMLU-PRO Raw": 0.1688829787234042, "MMLU-PRO": 7.65366430260047, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-26T00:00:00", "Submission Date": "2024-09-29T00:00:00", "Generation": 1, "Base Model": "KingNish/Qwen2.5-0.5b-Test-ft (Merge)"}, {"eval_name": "Kquant03_CognitiveFusion2-4x7B-BF16_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Kquant03/CognitiveFusion2-4x7B-BF16\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Kquant03/CognitiveFusion2-4x7B-BF16</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Kquant03__CognitiveFusion2-4x7B-BF16-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Kquant03/CognitiveFusion2-4x7B-BF16", "Model sha": "db45b86c462bb93db7ba4f2c3fe3517582c859a1", "Average \u2b06\ufe0f": 15.51576181600297, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 3, "#Params (B)": 24, "Available on the hub": true, "Not_Merged": false, "MoE": false, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3566570034175986, "IFEval": 35.665700341759866, "BBH Raw": 0.4107828611148378, "BBH": 17.689002759870313, "MATH Lvl 5 Raw": 0.0506042296072507, "MATH Lvl 5": 5.060422960725076, "GPQA Raw": 0.2860738255033557, "GPQA": 4.809843400447425, "MUSR Raw": 0.4145520833333333, "MUSR": 9.95234375, "MMLU-PRO Raw": 0.2792553191489361, "MMLU-PRO": 19.917257683215126, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-06T00:00:00", "Submission Date": "2024-07-31T00:00:00", "Generation": 0, "Base Model": "Kquant03/CognitiveFusion2-4x7B-BF16"}, {"eval_name": "Kukedlc_NeuralExperiment-7b-MagicCoder-v7.5_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Kukedlc/NeuralExperiment-7b-MagicCoder-v7.5\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Kukedlc/NeuralExperiment-7b-MagicCoder-v7.5</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Kukedlc__NeuralExperiment-7b-MagicCoder-v7.5-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Kukedlc/NeuralExperiment-7b-MagicCoder-v7.5", "Model sha": "43ea8d27d652dc15e4d27f665c5d636a5937780b", "Average \u2b06\ufe0f": 17.917887808264958, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 6, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4552509563513699, "IFEval": 45.52509563513699, "BBH Raw": 0.3988446544778517, "BBH": 16.386034485864904, "MATH Lvl 5 Raw": 0.0611782477341389, "MATH Lvl 5": 6.117824773413897, "GPQA Raw": 0.2961409395973154, "GPQA": 6.152125279642054, "MUSR Raw": 0.4281979166666667, "MUSR": 13.058072916666664, "MMLU-PRO Raw": 0.2824135638297872, "MMLU-PRO": 20.268173758865245, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-03-07T00:00:00", "Submission Date": "2024-07-30T00:00:00", "Generation": 0, "Base Model": "Kukedlc/NeuralExperiment-7b-MagicCoder-v7.5"}, {"eval_name": "Kukedlc_NeuralLLaMa-3-8b-DT-v0.1_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Kukedlc/NeuralLLaMa-3-8b-DT-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Kukedlc/NeuralLLaMa-3-8b-DT-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Kukedlc__NeuralLLaMa-3-8b-DT-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Kukedlc/NeuralLLaMa-3-8b-DT-v0.1", "Model sha": "1fe849c1e7e4793c2fdd869fcfb51e0d1910674f", "Average \u2b06\ufe0f": 21.121129349724736, "Hub License": "other", "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4371412297149342, "IFEval": 43.71412297149342, "BBH Raw": 0.4986771544360115, "BBH": 28.008307823364888, "MATH Lvl 5 Raw": 0.0725075528700906, "MATH Lvl 5": 7.250755287009064, "GPQA Raw": 0.3028523489932886, "GPQA": 7.046979865771815, "MUSR Raw": 0.4071145833333333, "MUSR": 9.68932291666667, "MMLU-PRO Raw": 0.379155585106383, "MMLU-PRO": 31.017287234042552, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-11T00:00:00", "Submission Date": "2024-09-17T00:00:00", "Generation": 1, "Base Model": "Kukedlc/NeuralLLaMa-3-8b-DT-v0.1 (Merge)"}, {"eval_name": "Kukedlc_NeuralLLaMa-3-8b-ORPO-v0.3_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Kukedlc/NeuralLLaMa-3-8b-ORPO-v0.3\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Kukedlc/NeuralLLaMa-3-8b-ORPO-v0.3</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Kukedlc__NeuralLLaMa-3-8b-ORPO-v0.3-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Kukedlc/NeuralLLaMa-3-8b-ORPO-v0.3", "Model sha": "aa176c0db7791a1c09039135791145b0704a5f46", "Average \u2b06\ufe0f": 17.522155521370127, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5275912356990563, "IFEval": 52.759123569905626, "BBH Raw": 0.4557141539616392, "BBH": 22.39171190823084, "MATH Lvl 5 Raw": 0.0347432024169184, "MATH Lvl 5": 3.474320241691843, "GPQA Raw": 0.2390939597315436, "GPQA": 0.0, "MUSR Raw": 0.37003125, "MUSR": 3.65390625, "MMLU-PRO Raw": 0.3056848404255319, "MMLU-PRO": 22.853871158392437, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-14T00:00:00", "Submission Date": "2024-07-28T00:00:00", "Generation": 1, "Base Model": "Kukedlc/NeuralLLaMa-3-8b-ORPO-v0.3 (Merge)"}, {"eval_name": "Kukedlc_NeuralSynthesis-7B-v0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Kukedlc/NeuralSynthesis-7B-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Kukedlc/NeuralSynthesis-7B-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Kukedlc__NeuralSynthesis-7B-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Kukedlc/NeuralSynthesis-7B-v0.1", "Model sha": "547a5dc8963e127a9638256bb80eb3a36da1cc5d", "Average \u2b06\ufe0f": 19.90238373005356, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 3, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4184563624516283, "IFEval": 41.84563624516284, "BBH Raw": 0.5144745481048844, "BBH": 31.83439540006779, "MATH Lvl 5 Raw": 0.0566465256797583, "MATH Lvl 5": 5.664652567975831, "GPQA Raw": 0.2810402684563758, "GPQA": 4.138702460850116, "MUSR Raw": 0.43328125, "MUSR": 13.160156250000004, "MMLU-PRO Raw": 0.304936835106383, "MMLU-PRO": 22.770759456264773, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-06T00:00:00", "Submission Date": "2024-06-29T00:00:00", "Generation": 0, "Base Model": "Kukedlc/NeuralSynthesis-7B-v0.1"}, {"eval_name": "Kukedlc_NeuralSynthesis-7B-v0.3_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Kukedlc/NeuralSynthesis-7B-v0.3\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Kukedlc/NeuralSynthesis-7B-v0.3</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Kukedlc__NeuralSynthesis-7B-v0.3-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Kukedlc/NeuralSynthesis-7B-v0.3", "Model sha": "090fab29146f8e55066bce2f5f5859ab2d6027f4", "Average \u2b06\ufe0f": 19.994567773449344, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4078400865259733, "IFEval": 40.78400865259733, "BBH Raw": 0.5138078814382175, "BBH": 31.811748341244265, "MATH Lvl 5 Raw": 0.0717522658610271, "MATH Lvl 5": 7.175226586102719, "GPQA Raw": 0.2802013422818792, "GPQA": 4.026845637583895, "MUSR Raw": 0.4345833333333333, "MUSR": 13.389583333333327, "MMLU-PRO Raw": 0.3050199468085106, "MMLU-PRO": 22.779994089834517, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-07T00:00:00", "Submission Date": "2024-07-31T00:00:00", "Generation": 0, "Base Model": "Kukedlc/NeuralSynthesis-7B-v0.3"}, {"eval_name": "Kukedlc_NeuralSynthesis-7b-v0.4-slerp_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Kukedlc/NeuralSynthesis-7b-v0.4-slerp\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Kukedlc/NeuralSynthesis-7b-v0.4-slerp</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Kukedlc__NeuralSynthesis-7b-v0.4-slerp-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Kukedlc/NeuralSynthesis-7b-v0.4-slerp", "Model sha": "bb3bd36fce162f472668dbd91960cd1525b45f30", "Average \u2b06\ufe0f": 19.45498395105225, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3947259936967247, "IFEval": 39.47259936967247, "BBH Raw": 0.5142932549151301, "BBH": 31.99718681136041, "MATH Lvl 5 Raw": 0.0581570996978852, "MATH Lvl 5": 5.81570996978852, "GPQA Raw": 0.2776845637583892, "GPQA": 3.691275167785232, "MUSR Raw": 0.4332499999999999, "MUSR": 13.056250000000004, "MMLU-PRO Raw": 0.3042719414893617, "MMLU-PRO": 22.696882387706854, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-12T00:00:00", "Submission Date": "2024-07-31T00:00:00", "Generation": 1, "Base Model": "Kukedlc/NeuralSynthesis-7b-v0.4-slerp (Merge)"}, {"eval_name": "Kumar955_Hemanth-llm_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Kumar955/Hemanth-llm\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Kumar955/Hemanth-llm</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Kumar955__Hemanth-llm-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Kumar955/Hemanth-llm", "Model sha": "871325cc04f57cd953c161a0ace49c47af8eca4c", "Average \u2b06\ufe0f": 22.042313502585937, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.5045102550122564, "IFEval": 50.45102550122565, "BBH Raw": 0.522494907014536, "BBH": 33.044262388969805, "MATH Lvl 5 Raw": 0.0641993957703927, "MATH Lvl 5": 6.419939577039275, "GPQA Raw": 0.2827181208053691, "GPQA": 4.36241610738255, "MUSR Raw": 0.4485625, "MUSR": 14.503645833333335, "MMLU-PRO Raw": 0.3112533244680851, "MMLU-PRO": 23.47259160756501, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-24T00:00:00", "Submission Date": "2024-09-24T00:00:00", "Generation": 1, "Base Model": "Kumar955/Hemanth-llm (Merge)"}, {"eval_name": "LGAI-EXAONE_EXAONE-3.0-7.8B-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "ExaoneForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/LGAI-EXAONE__EXAONE-3.0-7.8B-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct", "Model sha": "7f15baedd46858153d817445aff032f4d6cf4939", "Average \u2b06\ufe0f": 21.403463325745587, "Hub License": "other", "Hub \u2764\ufe0f": 360, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7192826145737754, "IFEval": 71.92826145737754, "BBH Raw": 0.4174432647784512, "BBH": 17.97733539518049, "MATH Lvl 5 Raw": 0.0445619335347432, "MATH Lvl 5": 4.45619335347432, "GPQA Raw": 0.2659395973154362, "GPQA": 2.1252796420581683, "MUSR Raw": 0.366125, "MUSR": 3.298958333333333, "MMLU-PRO Raw": 0.3577127659574468, "MMLU-PRO": 28.63475177304965, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-31T00:00:00", "Submission Date": "2024-08-18T00:00:00", "Generation": 0, "Base Model": "LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct"}, {"eval_name": "LLM360_K2_float16", "Precision": "float16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/LLM360/K2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">LLM360/K2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/LLM360__K2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "LLM360/K2", "Model sha": "49d159b6f2b64d562e745f0ff06e65b9a4c28ead", "Average \u2b06\ufe0f": 14.53046023857977, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 78, "#Params (B)": 65, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2252157608478836, "IFEval": 22.52157608478836, "BBH Raw": 0.4971835676523677, "BBH": 28.220402834201128, "MATH Lvl 5 Raw": 0.0203927492447129, "MATH Lvl 5": 2.0392749244712998, "GPQA Raw": 0.2768456375838926, "GPQA": 3.5794183445190177, "MUSR Raw": 0.3979999999999999, "MUSR": 8.550000000000004, "MMLU-PRO Raw": 0.3004488031914893, "MMLU-PRO": 22.27208924349881, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-04-17T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "LLM360/K2"}, {"eval_name": "LLM360_K2-Chat_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/LLM360/K2-Chat\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">LLM360/K2-Chat</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/LLM360__K2-Chat-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "LLM360/K2-Chat", "Model sha": "5454f2d28031c9127e4227c873ca2f154e02e4c7", "Average \u2b06\ufe0f": 22.92692360397488, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 33, "#Params (B)": 65, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5151763986223221, "IFEval": 51.51763986223221, "BBH Raw": 0.5358099630242067, "BBH": 33.79382923599304, "MATH Lvl 5 Raw": 0.0158610271903323, "MATH Lvl 5": 1.5861027190332326, "GPQA Raw": 0.3062080536912752, "GPQA": 7.494407158836691, "MUSR Raw": 0.457, "MUSR": 16.824999999999996, "MMLU-PRO Raw": 0.3371010638297872, "MMLU-PRO": 26.34456264775413, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-05-22T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "LLM360/K2-Chat"}, {"eval_name": "Lambent_qwen2.5-reinstruct-alternate-lumen-14B_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Lambent/qwen2.5-reinstruct-alternate-lumen-14B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Lambent/qwen2.5-reinstruct-alternate-lumen-14B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Lambent__qwen2.5-reinstruct-alternate-lumen-14B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Lambent/qwen2.5-reinstruct-alternate-lumen-14B", "Model sha": "dac3be334098338fb6c02636349e8ed53f18c4a4", "Average \u2b06\ufe0f": 33.66477745902409, "Hub License": null, "Hub \u2764\ufe0f": 3, "#Params (B)": 14, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4793813747523238, "IFEval": 47.93813747523238, "BBH Raw": 0.6458988582965893, "BBH": 48.989609006737815, "MATH Lvl 5 Raw": 0.1978851963746223, "MATH Lvl 5": 19.788519637462237, "GPQA Raw": 0.3766778523489933, "GPQA": 16.890380313199106, "MUSR Raw": 0.477, "MUSR": 19.625, "MMLU-PRO Raw": 0.538813164893617, "MMLU-PRO": 48.757018321512994, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-23T00:00:00", "Submission Date": "2024-09-28T00:00:00", "Generation": 1, "Base Model": "Lambent/qwen2.5-reinstruct-alternate-lumen-14B (Merge)"}, {"eval_name": "LenguajeNaturalAI_leniachat-gemma-2b-v0_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "GemmaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/LenguajeNaturalAI/leniachat-gemma-2b-v0\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">LenguajeNaturalAI/leniachat-gemma-2b-v0</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/LenguajeNaturalAI__leniachat-gemma-2b-v0-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "LenguajeNaturalAI/leniachat-gemma-2b-v0", "Model sha": "e5691dcc682a10dc9ef4bdbb3dc896fcf271018e", "Average \u2b06\ufe0f": 5.598771713093911, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 12, "#Params (B)": 2, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2149740466406911, "IFEval": 21.49740466406912, "BBH Raw": 0.3074021189541203, "BBH": 4.138296963728068, "MATH Lvl 5 Raw": 0.0030211480362537, "MATH Lvl 5": 0.3021148036253776, "GPQA Raw": 0.2659395973154362, "GPQA": 2.1252796420581683, "MUSR Raw": 0.36590625, "MUSR": 3.63828125, "MMLU-PRO Raw": 0.1170212765957446, "MMLU-PRO": 1.891252955082742, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-09T00:00:00", "Submission Date": "2024-09-01T00:00:00", "Generation": 1, "Base Model": "google/gemma-2b"}, {"eval_name": "LenguajeNaturalAI_leniachat-qwen2-1.5B-v0_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/LenguajeNaturalAI/leniachat-qwen2-1.5B-v0\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">LenguajeNaturalAI/leniachat-qwen2-1.5B-v0</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/LenguajeNaturalAI__leniachat-qwen2-1.5B-v0-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "LenguajeNaturalAI/leniachat-qwen2-1.5B-v0", "Model sha": "031a2efebb3cc1150e46f42ba0bea9fa7b855436", "Average \u2b06\ufe0f": 8.543038998265203, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 19, "#Params (B)": 1, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2221184235605969, "IFEval": 22.211842356059694, "BBH Raw": 0.3683559019561201, "BBH": 12.771666354808303, "MATH Lvl 5 Raw": 0.0105740181268882, "MATH Lvl 5": 1.0574018126888218, "GPQA Raw": 0.261744966442953, "GPQA": 1.5659955257270708, "MUSR Raw": 0.3749895833333334, "MUSR": 3.873697916666666, "MMLU-PRO Raw": 0.1879986702127659, "MMLU-PRO": 9.77763002364066, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-16T00:00:00", "Submission Date": "2024-09-30T00:00:00", "Generation": 1, "Base Model": "Qwen/Qwen2-1.5B"}, {"eval_name": "LeroyDyer_LCARS_AI_001_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/LeroyDyer/LCARS_AI_001\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">LeroyDyer/LCARS_AI_001</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/LeroyDyer__LCARS_AI_001-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "LeroyDyer/LCARS_AI_001", "Model sha": "3452e84fbfd92c62085fdce3834eff5c9cd87d4f", "Average \u2b06\ufe0f": 14.404029505784408, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3109449593744597, "IFEval": 31.094495937445977, "BBH Raw": 0.4257887582559014, "BBH": 19.460966800253622, "MATH Lvl 5 Raw": 0.0219033232628398, "MATH Lvl 5": 2.190332326283988, "GPQA Raw": 0.2634228187919463, "GPQA": 1.789709172259505, "MUSR Raw": 0.4383645833333333, "MUSR": 13.328906250000005, "MMLU-PRO Raw": 0.2670378989361702, "MMLU-PRO": 18.559766548463354, "Maintainer's Highlight": false, "Upload To Hub Date": "", "Submission Date": "2024-08-06T00:00:00", "Generation": 0, "Base Model": "Removed"}, {"eval_name": "LeroyDyer_LCARS_AI_1x4_003_SuperAI_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/LeroyDyer/LCARS_AI_1x4_003_SuperAI\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">LeroyDyer/LCARS_AI_1x4_003_SuperAI</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/LeroyDyer__LCARS_AI_1x4_003_SuperAI-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "LeroyDyer/LCARS_AI_1x4_003_SuperAI", "Model sha": "917c84d241bfff8b8648d9d865ae4b5bead68c6b", "Average \u2b06\ufe0f": 19.367171647500957, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 2, "#Params (B)": 24, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4111125147940797, "IFEval": 41.11125147940797, "BBH Raw": 0.4919850357370479, "BBH": 28.423430655930204, "MATH Lvl 5 Raw": 0.0483383685800604, "MATH Lvl 5": 4.833836858006042, "GPQA Raw": 0.2827181208053691, "GPQA": 4.36241610738255, "MUSR Raw": 0.4506145833333333, "MUSR": 15.560156250000004, "MMLU-PRO Raw": 0.2972074468085106, "MMLU-PRO": 21.91193853427896, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-03T00:00:00", "Submission Date": "2024-08-07T00:00:00", "Generation": 1, "Base Model": "LeroyDyer/LCARS_AI_1x4_003_SuperAI (Merge)"}, {"eval_name": "LeroyDyer_LCARS_AI_StarTrek_Computer_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/LeroyDyer/LCARS_AI_StarTrek_Computer\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">LeroyDyer/LCARS_AI_StarTrek_Computer</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/LeroyDyer__LCARS_AI_StarTrek_Computer-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "LeroyDyer/LCARS_AI_StarTrek_Computer", "Model sha": "9d4af4ab13df574ad0d40ed71de7d43c17f59a94", "Average \u2b06\ufe0f": 14.513188638433974, "Hub License": "mit", "Hub \u2764\ufe0f": 2, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3582560938310349, "IFEval": 35.8256093831035, "BBH Raw": 0.4446191188748297, "BBH": 21.78100309570489, "MATH Lvl 5 Raw": 0.0347432024169184, "MATH Lvl 5": 3.474320241691843, "GPQA Raw": 0.2676174496644295, "GPQA": 2.348993288590602, "MUSR Raw": 0.3950208333333333, "MUSR": 7.444270833333334, "MMLU-PRO Raw": 0.245844414893617, "MMLU-PRO": 16.204934988179666, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-11T00:00:00", "Submission Date": "2024-08-07T00:00:00", "Generation": 0, "Base Model": "LeroyDyer/LCARS_AI_StarTrek_Computer"}, {"eval_name": "LeroyDyer_LCARS_TOP_SCORE_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/LeroyDyer/LCARS_TOP_SCORE\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">LeroyDyer/LCARS_TOP_SCORE</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/LeroyDyer__LCARS_TOP_SCORE-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "LeroyDyer/LCARS_TOP_SCORE", "Model sha": "ada3e3ac6ae162503da5158e72851053f4c7dac8", "Average \u2b06\ufe0f": 20.25906482012466, "Hub License": "openrail", "Hub \u2764\ufe0f": 2, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4370658741029357, "IFEval": 43.70658741029358, "BBH Raw": 0.5127371051825098, "BBH": 31.69912679947687, "MATH Lvl 5 Raw": 0.0634441087613293, "MATH Lvl 5": 6.3444108761329305, "GPQA Raw": 0.2860738255033557, "GPQA": 4.809843400447425, "MUSR Raw": 0.42928125, "MUSR": 12.426822916666673, "MMLU-PRO Raw": 0.3031083776595745, "MMLU-PRO": 22.567597517730498, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-03-30T00:00:00", "Submission Date": "2024-08-08T00:00:00", "Generation": 1, "Base Model": "LeroyDyer/LCARS_TOP_SCORE (Merge)"}, {"eval_name": "LeroyDyer_Mixtral_AI_SwahiliTron_7b_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/LeroyDyer/Mixtral_AI_SwahiliTron_7b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">LeroyDyer/Mixtral_AI_SwahiliTron_7b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/LeroyDyer__Mixtral_AI_SwahiliTron_7b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "LeroyDyer/Mixtral_AI_SwahiliTron_7b", "Model sha": "fd997ccdee03788e7e79944d26d9c641dc4fcd4c", "Average \u2b06\ufe0f": 4.2705450975952735, "Hub License": "mit", "Hub \u2764\ufe0f": 3, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": false, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.1533996462718919, "IFEval": 15.339964627189191, "BBH Raw": 0.3055092453201354, "BBH": 3.211683047233007, "MATH Lvl 5 Raw": 0.0083081570996978, "MATH Lvl 5": 0.8308157099697886, "GPQA Raw": 0.2651006711409396, "GPQA": 2.0134228187919474, "MUSR Raw": 0.34203125, "MUSR": 1.920572916666666, "MMLU-PRO Raw": 0.1207613031914893, "MMLU-PRO": 2.30681146572104, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-10T00:00:00", "Submission Date": "2024-07-12T00:00:00", "Generation": 0, "Base Model": "LeroyDyer/Mixtral_AI_SwahiliTron_7b"}, {"eval_name": "LeroyDyer_SpydazWeb_AI_CyberTron_Ultra_7b_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/LeroyDyer/SpydazWeb_AI_CyberTron_Ultra_7b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">LeroyDyer/SpydazWeb_AI_CyberTron_Ultra_7b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/LeroyDyer__SpydazWeb_AI_CyberTron_Ultra_7b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "LeroyDyer/SpydazWeb_AI_CyberTron_Ultra_7b", "Model sha": "50c69e539578ab5384eb018a60cc1268637becae", "Average \u2b06\ufe0f": 13.4659706964448, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 4, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1555727691414336, "IFEval": 15.557276914143362, "BBH Raw": 0.4810773610856182, "BBH": 27.74553183153259, "MATH Lvl 5 Raw": 0.0075528700906344, "MATH Lvl 5": 0.7552870090634441, "GPQA Raw": 0.2927852348993288, "GPQA": 5.7046979865771785, "MUSR Raw": 0.4136249999999999, "MUSR": 10.303125000000003, "MMLU-PRO Raw": 0.2865691489361702, "MMLU-PRO": 20.72990543735224, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-14T00:00:00", "Submission Date": "2024-07-12T00:00:00", "Generation": 1, "Base Model": "LeroyDyer/Mixtral_AI_CyberTron_Ultra"}, {"eval_name": "LeroyDyer__Spydaz_Web_AI_12_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/LeroyDyer/_Spydaz_Web_AI_12\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">LeroyDyer/_Spydaz_Web_AI_12</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/LeroyDyer___Spydaz_Web_AI_12-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "LeroyDyer/_Spydaz_Web_AI_12", "Model sha": "675cf7fbfa36974b2eb5aef53afdf56a65ecfcfd", "Average \u2b06\ufe0f": 6.451512878120261, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2764985793250797, "IFEval": 27.64985793250797, "BBH Raw": 0.3163396029210794, "BBH": 4.495993524198578, "MATH Lvl 5 Raw": 0.0037764350453172, "MATH Lvl 5": 0.3776435045317221, "GPQA Raw": 0.2684563758389262, "GPQA": 2.460850111856823, "MUSR Raw": 0.3581562499999999, "MUSR": 2.2028645833333327, "MMLU-PRO Raw": 0.1136968085106382, "MMLU-PRO": 1.521867612293143, "Maintainer's Highlight": false, "Upload To Hub Date": "", "Submission Date": "2024-09-19T00:00:00", "Generation": 0, "Base Model": "Removed"}, {"eval_name": "LeroyDyer__Spydaz_Web_AI_14_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/LeroyDyer/_Spydaz_Web_AI_14\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">LeroyDyer/_Spydaz_Web_AI_14</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/LeroyDyer___Spydaz_Web_AI_14-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "LeroyDyer/_Spydaz_Web_AI_14", "Model sha": "53e73726a0a780db48303f4befbf7574e5c04984", "Average \u2b06\ufe0f": 4.20213088745114, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.1811770546594148, "IFEval": 18.11770546594148, "BBH Raw": 0.2988848127354542, "BBH": 2.162400468558809, "MATH Lvl 5 Raw": 0.0015105740181268, "MATH Lvl 5": 0.1510574018126888, "GPQA Raw": 0.2659395973154362, "GPQA": 2.1252796420581683, "MUSR Raw": 0.3395208333333333, "MUSR": 1.1067708333333328, "MMLU-PRO Raw": 0.1139461436170212, "MMLU-PRO": 1.549571513002364, "Maintainer's Highlight": false, "Upload To Hub Date": "", "Submission Date": "2024-09-23T00:00:00", "Generation": 0, "Base Model": "Removed"}, {"eval_name": "LeroyDyer__Spydaz_Web_AI_BIBLE_002_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/LeroyDyer/_Spydaz_Web_AI_BIBLE_002\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">LeroyDyer/_Spydaz_Web_AI_BIBLE_002</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/LeroyDyer___Spydaz_Web_AI_BIBLE_002-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "LeroyDyer/_Spydaz_Web_AI_BIBLE_002", "Model sha": "f47113e6352f4df8c50e9e571fc85cd7a154a07f", "Average \u2b06\ufe0f": 6.760196792392537, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 2, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2194953833605943, "IFEval": 21.949538336059437, "BBH Raw": 0.3289070186514165, "BBH": 6.349580156104774, "MATH Lvl 5 Raw": 0.0113293051359516, "MATH Lvl 5": 1.1329305135951662, "GPQA Raw": 0.2843959731543624, "GPQA": 4.586129753914992, "MUSR Raw": 0.3406979166666666, "MUSR": 2.45390625, "MMLU-PRO Raw": 0.1368018617021276, "MMLU-PRO": 4.089095744680851, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-10T00:00:00", "Submission Date": "2024-09-14T00:00:00", "Generation": 0, "Base Model": "LeroyDyer/_Spydaz_Web_AI_BIBLE_002"}, {"eval_name": "LeroyDyer__Spydaz_Web_AI_ChatML_002_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/LeroyDyer/_Spydaz_Web_AI_ChatML_002\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">LeroyDyer/_Spydaz_Web_AI_ChatML_002</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/LeroyDyer___Spydaz_Web_AI_ChatML_002-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "LeroyDyer/_Spydaz_Web_AI_ChatML_002", "Model sha": "9475af8113cf4027839974283b702d6be502f7fa", "Average \u2b06\ufe0f": 5.526903574467614, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.241227720226776, "IFEval": 24.12277202267761, "BBH Raw": 0.3106383598957094, "BBH": 4.191974214495695, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2575503355704698, "GPQA": 1.0067114093959737, "MUSR Raw": 0.3623125, "MUSR": 2.7890625000000004, "MMLU-PRO Raw": 0.1094581117021276, "MMLU-PRO": 1.0509013002364058, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-01T00:00:00", "Submission Date": "2024-09-01T00:00:00", "Generation": 0, "Base Model": "LeroyDyer/_Spydaz_Web_AI_ChatML_002"}, {"eval_name": "LeroyDyer__Spydaz_Web_AI_ChatQA_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/LeroyDyer/_Spydaz_Web_AI_ChatQA\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">LeroyDyer/_Spydaz_Web_AI_ChatQA</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/LeroyDyer___Spydaz_Web_AI_ChatQA-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "LeroyDyer/_Spydaz_Web_AI_ChatQA", "Model sha": "9f86dd12d4c75e0290aa3084a44cf111bc975144", "Average \u2b06\ufe0f": 4.951487996576415, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1414591062824417, "IFEval": 14.14591062824417, "BBH Raw": 0.323594938374135, "BBH": 5.599561733978841, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2659395973154362, "GPQA": 2.1252796420581683, "MUSR Raw": 0.3447291666666667, "MUSR": 2.5578125000000003, "MMLU-PRO Raw": 0.1475232712765957, "MMLU-PRO": 5.280363475177306, "Maintainer's Highlight": false, "Upload To Hub Date": "", "Submission Date": "2024-08-06T00:00:00", "Generation": 0, "Base Model": "Removed"}, {"eval_name": "LeroyDyer__Spydaz_Web_AI_ChatQA_003_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/LeroyDyer/_Spydaz_Web_AI_ChatQA_003\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">LeroyDyer/_Spydaz_Web_AI_ChatQA_003</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/LeroyDyer___Spydaz_Web_AI_ChatQA_003-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "LeroyDyer/_Spydaz_Web_AI_ChatQA_003", "Model sha": null, "Average \u2b06\ufe0f": 6.13167884357284, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2209193827932108, "IFEval": 22.09193827932109, "BBH Raw": 0.3171811407815537, "BBH": 4.293436202390652, "MATH Lvl 5 Raw": 0.0030211480362537, "MATH Lvl 5": 0.3021148036253776, "GPQA Raw": 0.2709731543624161, "GPQA": 2.796420581655479, "MUSR Raw": 0.38184375, "MUSR": 5.830468750000001, "MMLU-PRO Raw": 0.11328125, "MMLU-PRO": 1.4756944444444438, "Maintainer's Highlight": false, "Upload To Hub Date": "", "Submission Date": "2024-09-14T00:00:00", "Generation": 0, "Base Model": "Removed"}, {"eval_name": "LilRg_10PRYMMAL-3B-slerp_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "Phi3ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/LilRg/10PRYMMAL-3B-slerp\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">LilRg/10PRYMMAL-3B-slerp</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/LilRg__10PRYMMAL-3B-slerp-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "LilRg/10PRYMMAL-3B-slerp", "Model sha": "3e0a12c2ec82e18136fc1cf1609c66154cff8a6e", "Average \u2b06\ufe0f": 20.231903810833604, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1945903535951276, "IFEval": 19.45903535951276, "BBH Raw": 0.5320377091634505, "BBH": 34.877917500461, "MATH Lvl 5 Raw": 0.0981873111782477, "MATH Lvl 5": 9.818731117824774, "GPQA Raw": 0.3213087248322148, "GPQA": 9.50782997762864, "MUSR Raw": 0.45290625, "MUSR": 15.71328125, "MMLU-PRO Raw": 0.3881316489361702, "MMLU-PRO": 32.014627659574465, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-23T00:00:00", "Submission Date": "2024-09-24T00:00:00", "Generation": 1, "Base Model": "LilRg/10PRYMMAL-3B-slerp (Merge)"}, {"eval_name": "LilRg_ECE-1B-merge-PRYMMAL_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/LilRg/ECE-1B-merge-PRYMMAL\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">LilRg/ECE-1B-merge-PRYMMAL</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/LilRg__ECE-1B-merge-PRYMMAL-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "LilRg/ECE-1B-merge-PRYMMAL", "Model sha": "009c75039786c38e2a6168cf93c9a46a4d111fb9", "Average \u2b06\ufe0f": 14.145185276004682, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 1, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2712281191682513, "IFEval": 27.122811916825132, "BBH Raw": 0.4234560017690874, "BBH": 19.141465000010825, "MATH Lvl 5 Raw": 0.080060422960725, "MATH Lvl 5": 8.006042296072508, "GPQA Raw": 0.2810402684563758, "GPQA": 4.138702460850116, "MUSR Raw": 0.3801041666666667, "MUSR": 5.279687499999999, "MMLU-PRO Raw": 0.2906416223404255, "MMLU-PRO": 21.1824024822695, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-07T00:00:00", "Submission Date": "2024-10-07T00:00:00", "Generation": 1, "Base Model": "LilRg/ECE-1B-merge-PRYMMAL (Merge)"}, {"eval_name": "LilRg_ECE_Finetunning_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Adapter", "Architecture": "?", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/LilRg/ECE_Finetunning\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">LilRg/ECE_Finetunning</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/LilRg__ECE_Finetunning-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "LilRg/ECE_Finetunning", "Model sha": "8d10549bcf802355f2d6203a33ed27e81b15b9e5", "Average \u2b06\ufe0f": 11.83597485774352, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 16, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.0445384912033404, "IFEval": 4.453849120334047, "BBH Raw": 0.4732159679073051, "BBH": 26.530834895216355, "MATH Lvl 5 Raw": 0.0362537764350453, "MATH Lvl 5": 3.625377643504532, "GPQA Raw": 0.2827181208053691, "GPQA": 4.36241610738255, "MUSR Raw": 0.3839479166666666, "MUSR": 7.693489583333334, "MMLU-PRO Raw": 0.3191489361702128, "MMLU-PRO": 24.34988179669031, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-28T00:00:00", "Submission Date": "2024-09-28T00:00:00", "Generation": 3, "Base Model": "meta-llama/Meta-Llama-3.1-8B"}, {"eval_name": "LilRg_PRYMMAL-6B-slerp_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/LilRg/PRYMMAL-6B-slerp\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">LilRg/PRYMMAL-6B-slerp</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/LilRg__PRYMMAL-6B-slerp-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "LilRg/PRYMMAL-6B-slerp", "Model sha": "1ce0f5fdaae6a7866eda77df18378e9b5621af65", "Average \u2b06\ufe0f": 3.23270592407536, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1153306559927658, "IFEval": 11.533065599276586, "BBH Raw": 0.2867621569203611, "BBH": 2.2124311744899985, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2458053691275167, "GPQA": 0.0, "MUSR Raw": 0.36975, "MUSR": 4.452083333333333, "MMLU-PRO Raw": 0.1107878989361702, "MMLU-PRO": 1.198655437352245, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-24T00:00:00", "Submission Date": "2024-09-24T00:00:00", "Generation": 1, "Base Model": "LilRg/PRYMMAL-6B-slerp (Merge)"}, {"eval_name": "LilRg_PRYMMAL-slerp-Merge_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "Phi3ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/LilRg/PRYMMAL-slerp-Merge\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">LilRg/PRYMMAL-slerp-Merge</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/LilRg__PRYMMAL-slerp-Merge-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "LilRg/PRYMMAL-slerp-Merge", "Model sha": "e5597549ceb5afe56428097cb297326537d07c3e", "Average \u2b06\ufe0f": 22.194019414630507, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.304400102838247, "IFEval": 30.440010283824694, "BBH Raw": 0.5364156271768925, "BBH": 35.553775523419816, "MATH Lvl 5 Raw": 0.0876132930513595, "MATH Lvl 5": 8.761329305135952, "GPQA Raw": 0.3204697986577181, "GPQA": 9.395973154362418, "MUSR Raw": 0.4634791666666666, "MUSR": 17.2015625, "MMLU-PRO Raw": 0.3863031914893617, "MMLU-PRO": 31.811465721040182, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-24T00:00:00", "Submission Date": "2024-09-24T00:00:00", "Generation": 1, "Base Model": "LilRg/PRYMMAL-slerp-Merge (Merge)"}, {"eval_name": "LimYeri_CodeMind-Llama3-8B-unsloth_v2-merged_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/LimYeri/CodeMind-Llama3-8B-unsloth_v2-merged\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">LimYeri/CodeMind-Llama3-8B-unsloth_v2-merged</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/LimYeri__CodeMind-Llama3-8B-unsloth_v2-merged-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "LimYeri/CodeMind-Llama3-8B-unsloth_v2-merged", "Model sha": "d4ec745f8279e3ac6d41709153c21cc077e66385", "Average \u2b06\ufe0f": 22.321849917425524, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6946280314011268, "IFEval": 69.46280314011267, "BBH Raw": 0.4860092088299632, "BBH": 26.655629407381003, "MATH Lvl 5 Raw": 0.0574018126888217, "MATH Lvl 5": 5.740181268882175, "GPQA Raw": 0.2651006711409396, "GPQA": 2.0134228187919474, "MUSR Raw": 0.3316145833333333, "MUSR": 2.218489583333334, "MMLU-PRO Raw": 0.3505651595744681, "MMLU-PRO": 27.840573286052013, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-04T00:00:00", "Submission Date": "2024-08-28T00:00:00", "Generation": 1, "Base Model": "unsloth/llama-3-8b-Instruct-bnb-4bit"}, {"eval_name": "LimYeri_CodeMind-Llama3-8B-unsloth_v3-merged_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/LimYeri/CodeMind-Llama3-8B-unsloth_v3-merged\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">LimYeri/CodeMind-Llama3-8B-unsloth_v3-merged</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/LimYeri__CodeMind-Llama3-8B-unsloth_v3-merged-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "LimYeri/CodeMind-Llama3-8B-unsloth_v3-merged", "Model sha": "548a221b00d8056fe7090f5e6e0af58ee7c62563", "Average \u2b06\ufe0f": 21.719892019810317, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6762933460994606, "IFEval": 67.62933460994606, "BBH Raw": 0.4908161460506797, "BBH": 27.02521610839599, "MATH Lvl 5 Raw": 0.0566465256797583, "MATH Lvl 5": 5.664652567975831, "GPQA Raw": 0.2583892617449664, "GPQA": 1.1185682326621946, "MUSR Raw": 0.3356145833333333, "MUSR": 1.1518229166666667, "MMLU-PRO Raw": 0.3495678191489361, "MMLU-PRO": 27.729757683215126, "Maintainer's Highlight": false, "Upload To Hub Date": "", "Submission Date": "2024-08-28T00:00:00", "Generation": 0, "Base Model": "Removed"}, {"eval_name": "LimYeri_CodeMind-Llama3-8B-unsloth_v4-one-DPO-merged_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/LimYeri/CodeMind-Llama3-8B-unsloth_v4-one-DPO-merged\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">LimYeri/CodeMind-Llama3-8B-unsloth_v4-one-DPO-merged</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/LimYeri__CodeMind-Llama3-8B-unsloth_v4-one-DPO-merged-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "LimYeri/CodeMind-Llama3-8B-unsloth_v4-one-DPO-merged", "Model sha": "e21e4932c56cebd3f9816bf083c1792cdccbe7a7", "Average \u2b06\ufe0f": 21.66113725975599, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6492406813920397, "IFEval": 64.92406813920398, "BBH Raw": 0.4852658232224004, "BBH": 26.37017668673992, "MATH Lvl 5 Raw": 0.0649546827794562, "MATH Lvl 5": 6.495468277945619, "GPQA Raw": 0.2684563758389262, "GPQA": 2.460850111856823, "MUSR Raw": 0.3607916666666667, "MUSR": 3.565625000000001, "MMLU-PRO Raw": 0.3353557180851064, "MMLU-PRO": 26.150635342789595, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-07T00:00:00", "Submission Date": "2024-08-28T00:00:00", "Generation": 1, "Base Model": "unsloth/llama-3-8b-Instruct-bnb-4bit"}, {"eval_name": "LimYeri_CodeMind-Llama3-8B-unsloth_v4-one-merged_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/LimYeri/CodeMind-Llama3-8B-unsloth_v4-one-merged\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">LimYeri/CodeMind-Llama3-8B-unsloth_v4-one-merged</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/LimYeri__CodeMind-Llama3-8B-unsloth_v4-one-merged-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "LimYeri/CodeMind-Llama3-8B-unsloth_v4-one-merged", "Model sha": "9c8939ccdc10beee56462eadbc16e28359a6d4c4", "Average \u2b06\ufe0f": 17.537717668875114, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3210869382128308, "IFEval": 32.10869382128308, "BBH Raw": 0.4738758608456885, "BBH": 24.57473532012109, "MATH Lvl 5 Raw": 0.0506042296072507, "MATH Lvl 5": 5.060422960725076, "GPQA Raw": 0.3095637583892617, "GPQA": 7.941834451901568, "MUSR Raw": 0.4069270833333333, "MUSR": 9.399218750000005, "MMLU-PRO Raw": 0.3352726063829787, "MMLU-PRO": 26.14140070921986, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-06T00:00:00", "Submission Date": "2024-08-28T00:00:00", "Generation": 1, "Base Model": "unsloth/llama-3-8b-Instruct-bnb-4bit"}, {"eval_name": "LimYeri_CodeMind-Llama3.1-8B-unsloth-merged_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/LimYeri/CodeMind-Llama3.1-8B-unsloth-merged\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">LimYeri/CodeMind-Llama3.1-8B-unsloth-merged</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/LimYeri__CodeMind-Llama3.1-8B-unsloth-merged-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "LimYeri/CodeMind-Llama3.1-8B-unsloth-merged", "Model sha": "911ffe6614d23bfc9cb7ece0cd3afd861a65d7f0", "Average \u2b06\ufe0f": 22.166638011916135, "Hub License": "mit", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6490157227268093, "IFEval": 64.90157227268094, "BBH Raw": 0.4694777854416285, "BBH": 24.185738827978955, "MATH Lvl 5 Raw": 0.0996978851963746, "MATH Lvl 5": 9.969788519637463, "GPQA Raw": 0.2642617449664429, "GPQA": 1.9015659955257265, "MUSR Raw": 0.3752395833333333, "MUSR": 6.038281250000002, "MMLU-PRO Raw": 0.3340259308510638, "MMLU-PRO": 26.002881205673763, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-31T00:00:00", "Submission Date": "2024-08-31T00:00:00", "Generation": 2, "Base Model": "unsloth/Meta-Llama-3.1-8B"}, {"eval_name": "Locutusque_Hercules-6.0-Llama-3.1-8B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Locutusque/Hercules-6.0-Llama-3.1-8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Locutusque/Hercules-6.0-Llama-3.1-8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Locutusque__Hercules-6.0-Llama-3.1-8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Locutusque/Hercules-6.0-Llama-3.1-8B", "Model sha": "f35a95aeabf9f82bbd64bfc6fd0d857df750ee83", "Average \u2b06\ufe0f": 23.282136013215556, "Hub License": "llama3.1", "Hub \u2764\ufe0f": 8, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6630041622893922, "IFEval": 66.30041622893921, "BBH Raw": 0.4813303790011953, "BBH": 26.63965184405082, "MATH Lvl 5 Raw": 0.1336858006042296, "MATH Lvl 5": 13.36858006042296, "GPQA Raw": 0.2642617449664429, "GPQA": 1.9015659955257265, "MUSR Raw": 0.362125, "MUSR": 2.432291666666666, "MMLU-PRO Raw": 0.3614527925531915, "MMLU-PRO": 29.050310283687946, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-25T00:00:00", "Submission Date": "2024-09-26T00:00:00", "Generation": 0, "Base Model": "Locutusque/Hercules-6.0-Llama-3.1-8B"}, {"eval_name": "Locutusque_Hercules-6.1-Llama-3.1-8B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Locutusque/Hercules-6.1-Llama-3.1-8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Locutusque/Hercules-6.1-Llama-3.1-8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Locutusque__Hercules-6.1-Llama-3.1-8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Locutusque/Hercules-6.1-Llama-3.1-8B", "Model sha": "f4abf4385111b4acbea8bee2c6636ef84b2dac43", "Average \u2b06\ufe0f": 22.39595752437374, "Hub License": "llama3.1", "Hub \u2764\ufe0f": 6, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6006806384836678, "IFEval": 60.068063848366776, "BBH Raw": 0.4656242376503401, "BBH": 24.151873375413786, "MATH Lvl 5 Raw": 0.1563444108761329, "MATH Lvl 5": 15.634441087613292, "GPQA Raw": 0.2609060402684564, "GPQA": 1.45413870246085, "MUSR Raw": 0.3553333333333333, "MUSR": 3.4166666666666674, "MMLU-PRO Raw": 0.3668550531914893, "MMLU-PRO": 29.650561465721044, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-30T00:00:00", "Submission Date": "2024-10-01T00:00:00", "Generation": 0, "Base Model": "Locutusque/Hercules-6.1-Llama-3.1-8B"}, {"eval_name": "Locutusque_Llama-3-NeuralHercules-5.0-8B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Locutusque/Llama-3-NeuralHercules-5.0-8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Locutusque/Llama-3-NeuralHercules-5.0-8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Locutusque__Llama-3-NeuralHercules-5.0-8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Locutusque/Llama-3-NeuralHercules-5.0-8B", "Model sha": "2bbb675e592a1772f2389fe2d58a5b610d479d94", "Average \u2b06\ufe0f": 15.929182857756098, "Hub License": "llama3", "Hub \u2764\ufe0f": 2, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4489310584803876, "IFEval": 44.89310584803876, "BBH Raw": 0.3940474241916672, "BBH": 16.34207153663529, "MATH Lvl 5 Raw": 0.0362537764350453, "MATH Lvl 5": 3.625377643504532, "GPQA Raw": 0.2684563758389262, "GPQA": 2.460850111856823, "MUSR Raw": 0.3880729166666667, "MUSR": 6.7757812500000005, "MMLU-PRO Raw": 0.2933011968085106, "MMLU-PRO": 21.47791075650118, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-28T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "Locutusque/Llama-3-NeuralHercules-5.0-8B"}, {"eval_name": "Locutusque_Llama-3-Yggdrasil-2.0-8B_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Locutusque/Llama-3-Yggdrasil-2.0-8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Locutusque/Llama-3-Yggdrasil-2.0-8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Locutusque__Llama-3-Yggdrasil-2.0-8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Locutusque/Llama-3-Yggdrasil-2.0-8B", "Model sha": "ec2329946ccc81a7c1ae36210728f717bc4f01d8", "Average \u2b06\ufe0f": 20.22102327485013, "Hub License": null, "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5370583385417359, "IFEval": 53.70583385417359, "BBH Raw": 0.4772455142466685, "BBH": 26.922800957191782, "MATH Lvl 5 Raw": 0.0687311178247734, "MATH Lvl 5": 6.873111782477341, "GPQA Raw": 0.2625838926174497, "GPQA": 1.6778523489932915, "MUSR Raw": 0.39765625, "MUSR": 8.073697916666669, "MMLU-PRO Raw": 0.316655585106383, "MMLU-PRO": 24.072842789598106, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-05T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "Locutusque/Llama-3-Yggdrasil-2.0-8B (Merge)"}, {"eval_name": "Locutusque_TinyMistral-248M-v2.5_float16", "Precision": "float16", "Type": "\ud83d\udfe9 continuously pretrained", "T": "\ud83d\udfe9", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Locutusque/TinyMistral-248M-v2.5\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Locutusque/TinyMistral-248M-v2.5</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Locutusque__TinyMistral-248M-v2.5-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Locutusque/TinyMistral-248M-v2.5", "Model sha": "214e48aabc01235e25c67477898756f1bebef215", "Average \u2b06\ufe0f": 3.871793949822724, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 26, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.1336409615376091, "IFEval": 13.36409615376091, "BBH Raw": 0.3038576112326078, "BBH": 3.181881126755549, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2508389261744966, "GPQA": 0.1118568232662209, "MUSR Raw": 0.3781562499999999, "MUSR": 5.069531250000002, "MMLU-PRO Raw": 0.1135305851063829, "MMLU-PRO": 1.5033983451536632, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-01-24T00:00:00", "Submission Date": "2024-09-17T00:00:00", "Generation": 0, "Base Model": "Locutusque/TinyMistral-248M-v2.5"}, {"eval_name": "Luni_StarDust-12b-v1_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Luni/StarDust-12b-v1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Luni/StarDust-12b-v1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Luni__StarDust-12b-v1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Luni/StarDust-12b-v1", "Model sha": "91976b0c71dce1310f4a6139552e10a6149bdc31", "Average \u2b06\ufe0f": 23.171040984419324, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 12, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5459259210007226, "IFEval": 54.59259210007225, "BBH Raw": 0.5366139363101082, "BBH": 34.44627563758498, "MATH Lvl 5 Raw": 0.059667673716012, "MATH Lvl 5": 5.966767371601208, "GPQA Raw": 0.276006711409396, "GPQA": 3.467561521252797, "MUSR Raw": 0.4324479166666666, "MUSR": 13.755989583333331, "MMLU-PRO Raw": 0.3411735372340425, "MMLU-PRO": 26.797059692671397, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-29T00:00:00", "Submission Date": "2024-09-03T00:00:00", "Generation": 1, "Base Model": "Luni/StarDust-12b-v1 (Merge)"}, {"eval_name": "Luni_StarDust-12b-v2_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Luni/StarDust-12b-v2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Luni/StarDust-12b-v2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Luni__StarDust-12b-v2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Luni/StarDust-12b-v2", "Model sha": "75bffd7b86f37c2cebc4fdf83fbc3ab33d6c6e05", "Average \u2b06\ufe0f": 24.0640190349219, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 29, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5628620947973599, "IFEval": 56.28620947973599, "BBH Raw": 0.5419479534912178, "BBH": 34.95288411454464, "MATH Lvl 5 Raw": 0.059667673716012, "MATH Lvl 5": 5.966767371601208, "GPQA Raw": 0.2936241610738255, "GPQA": 5.8165548098434, "MUSR Raw": 0.4338125, "MUSR": 14.259895833333331, "MMLU-PRO Raw": 0.3439162234042553, "MMLU-PRO": 27.10180260047281, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-01T00:00:00", "Submission Date": "2024-09-03T00:00:00", "Generation": 1, "Base Model": "Luni/StarDust-12b-v2 (Merge)"}, {"eval_name": "Lyte_Llama-3.1-8B-Instruct-Reasoner-1o1_v0.3_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Lyte/Llama-3.1-8B-Instruct-Reasoner-1o1_v0.3\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Lyte/Llama-3.1-8B-Instruct-Reasoner-1o1_v0.3</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Lyte__Llama-3.1-8B-Instruct-Reasoner-1o1_v0.3-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Lyte/Llama-3.1-8B-Instruct-Reasoner-1o1_v0.3", "Model sha": "35ab483f04afa763f36f978408f4f82e0379ee25", "Average \u2b06\ufe0f": 25.04852659909162, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 6, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7098155117310957, "IFEval": 70.98155117310957, "BBH Raw": 0.4949521619329585, "BBH": 27.83521213410715, "MATH Lvl 5 Raw": 0.148036253776435, "MATH Lvl 5": 14.803625377643504, "GPQA Raw": 0.2701342281879195, "GPQA": 2.684563758389265, "MUSR Raw": 0.346125, "MUSR": 4.898958333333336, "MMLU-PRO Raw": 0.3617852393617021, "MMLU-PRO": 29.08724881796691, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-17T00:00:00", "Submission Date": "2024-09-17T00:00:00", "Generation": 2, "Base Model": "unsloth/Meta-Llama-3.1-8B"}, {"eval_name": "Lyte_Llama-3.2-1B-Instruct-COT-RL-Expriement1-EP04_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Lyte/Llama-3.2-1B-Instruct-COT-RL-Expriement1-EP04\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Lyte/Llama-3.2-1B-Instruct-COT-RL-Expriement1-EP04</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Lyte__Llama-3.2-1B-Instruct-COT-RL-Expriement1-EP04-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Lyte/Llama-3.2-1B-Instruct-COT-RL-Expriement1-EP04", "Model sha": "59d93307c6f2cb7a29c593cbc7393122d502d1b1", "Average \u2b06\ufe0f": 14.420721668377588, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 1, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5773503193748144, "IFEval": 57.73503193748144, "BBH Raw": 0.3515036874279285, "BBH": 8.894408584162113, "MATH Lvl 5 Raw": 0.066465256797583, "MATH Lvl 5": 6.646525679758309, "GPQA Raw": 0.2600671140939597, "GPQA": 1.342281879194629, "MUSR Raw": 0.3235520833333333, "MUSR": 2.5440104166666675, "MMLU-PRO Raw": 0.1842586436170212, "MMLU-PRO": 9.362071513002364, "Maintainer's Highlight": false, "Upload To Hub Date": "", "Submission Date": "2024-09-26T00:00:00", "Generation": 0, "Base Model": "Removed"}, {"eval_name": "MLP-KTLim_llama-3-Korean-Bllossom-8B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/MLP-KTLim/llama-3-Korean-Bllossom-8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">MLP-KTLim/llama-3-Korean-Bllossom-8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/MLP-KTLim__llama-3-Korean-Bllossom-8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "MLP-KTLim/llama-3-Korean-Bllossom-8B", "Model sha": "8a738f9f622ffc2b0a4a6b81dabbca80406248bf", "Average \u2b06\ufe0f": 20.09480154252228, "Hub License": "llama3", "Hub \u2764\ufe0f": 264, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5112800702136997, "IFEval": 51.12800702136997, "BBH Raw": 0.4900455647018766, "BBH": 26.927527973055067, "MATH Lvl 5 Raw": 0.0838368580060422, "MATH Lvl 5": 8.38368580060423, "GPQA Raw": 0.2625838926174497, "GPQA": 1.6778523489932915, "MUSR Raw": 0.3674583333333334, "MUSR": 3.632291666666669, "MMLU-PRO Raw": 0.359375, "MMLU-PRO": 28.819444444444446, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-25T00:00:00", "Submission Date": "2024-07-09T00:00:00", "Generation": 1, "Base Model": "MLP-KTLim/llama-3-Korean-Bllossom-8B (Merge)"}, {"eval_name": "MTSAIR_MultiVerse_70B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/MTSAIR/MultiVerse_70B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">MTSAIR/MultiVerse_70B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/MTSAIR__MultiVerse_70B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "MTSAIR/MultiVerse_70B", "Model sha": "063430cdc4d972a0884e3e3e3d45ea4afbdf71a2", "Average \u2b06\ufe0f": 31.728251738484943, "Hub License": "other", "Hub \u2764\ufe0f": 38, "#Params (B)": 72, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.5249183278146429, "IFEval": 52.49183278146429, "BBH Raw": 0.6183134284931178, "BBH": 46.135898982415, "MATH Lvl 5 Raw": 0.161631419939577, "MATH Lvl 5": 16.1631419939577, "GPQA Raw": 0.3540268456375839, "GPQA": 13.870246085011187, "MUSR Raw": 0.4739895833333333, "MUSR": 18.815364583333327, "MMLU-PRO Raw": 0.4860372340425531, "MMLU-PRO": 42.89302600472813, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-03-25T00:00:00", "Submission Date": "2024-06-29T00:00:00", "Generation": 0, "Base Model": "MTSAIR/MultiVerse_70B"}, {"eval_name": "Magpie-Align_Llama-3-8B-Magpie-Align-SFT-v0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Magpie-Align/Llama-3-8B-Magpie-Align-SFT-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Magpie-Align/Llama-3-8B-Magpie-Align-SFT-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Magpie-Align__Llama-3-8B-Magpie-Align-SFT-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Magpie-Align/Llama-3-8B-Magpie-Align-SFT-v0.1", "Model sha": "1ed587f54f70334f495efb9c027acb03e96fe24f", "Average \u2b06\ufe0f": 15.828206418730916, "Hub License": "llama3", "Hub \u2764\ufe0f": 4, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4361416596851908, "IFEval": 43.61416596851908, "BBH Raw": 0.4615102744527366, "BBH": 23.990124398411343, "MATH Lvl 5 Raw": 0.0498489425981873, "MATH Lvl 5": 4.984894259818732, "GPQA Raw": 0.2625838926174497, "GPQA": 1.6778523489932915, "MUSR Raw": 0.3277395833333333, "MUSR": 0.0, "MMLU-PRO Raw": 0.2863198138297872, "MMLU-PRO": 20.702201536643024, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-06T00:00:00", "Submission Date": "2024-09-17T00:00:00", "Generation": 1, "Base Model": "meta-llama/Meta-Llama-3-8B"}, {"eval_name": "Magpie-Align_Llama-3-8B-Magpie-Align-SFT-v0.3_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Magpie-Align/Llama-3-8B-Magpie-Align-SFT-v0.3\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Magpie-Align/Llama-3-8B-Magpie-Align-SFT-v0.3</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Magpie-Align__Llama-3-8B-Magpie-Align-SFT-v0.3-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Magpie-Align/Llama-3-8B-Magpie-Align-SFT-v0.3", "Model sha": "d2578eb754d1c20efe604749296580f680950917", "Average \u2b06\ufe0f": 17.376991734811295, "Hub License": "llama3", "Hub \u2764\ufe0f": 2, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5063586838477463, "IFEval": 50.63586838477463, "BBH Raw": 0.4571580899672054, "BBH": 23.698815892387582, "MATH Lvl 5 Raw": 0.0626888217522658, "MATH Lvl 5": 6.268882175226587, "GPQA Raw": 0.2659395973154362, "GPQA": 2.1252796420581683, "MUSR Raw": 0.342375, "MUSR": 0.3968749999999998, "MMLU-PRO Raw": 0.2902260638297872, "MMLU-PRO": 21.1362293144208, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-13T00:00:00", "Submission Date": "2024-08-06T00:00:00", "Generation": 1, "Base Model": "meta-llama/Meta-Llama-3-8B"}, {"eval_name": "Magpie-Align_Llama-3-8B-Magpie-Align-v0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Magpie-Align/Llama-3-8B-Magpie-Align-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Magpie-Align/Llama-3-8B-Magpie-Align-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Magpie-Align__Llama-3-8B-Magpie-Align-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Magpie-Align/Llama-3-8B-Magpie-Align-v0.1", "Model sha": "a83ddac146fb2da1dd1bfa4069e336074d1439a8", "Average \u2b06\ufe0f": 16.473094269110153, "Hub License": "llama3", "Hub \u2764\ufe0f": 10, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4118117705465941, "IFEval": 41.181177054659415, "BBH Raw": 0.4811441560714845, "BBH": 26.69176089392447, "MATH Lvl 5 Raw": 0.0339879154078549, "MATH Lvl 5": 3.3987915407854987, "GPQA Raw": 0.2751677852348993, "GPQA": 3.355704697986576, "MUSR Raw": 0.3046979166666667, "MUSR": 1.920572916666666, "MMLU-PRO Raw": 0.3006150265957447, "MMLU-PRO": 22.2905585106383, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-29T00:00:00", "Submission Date": "2024-07-03T00:00:00", "Generation": 2, "Base Model": "meta-llama/Meta-Llama-3-8B"}, {"eval_name": "Magpie-Align_Llama-3-8B-Magpie-Align-v0.1_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Magpie-Align/Llama-3-8B-Magpie-Align-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Magpie-Align/Llama-3-8B-Magpie-Align-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Magpie-Align__Llama-3-8B-Magpie-Align-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Magpie-Align/Llama-3-8B-Magpie-Align-v0.1", "Model sha": "a83ddac146fb2da1dd1bfa4069e336074d1439a8", "Average \u2b06\ufe0f": 16.257418523378423, "Hub License": "llama3", "Hub \u2764\ufe0f": 10, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4027192294223771, "IFEval": 40.27192294223771, "BBH Raw": 0.4789408101970551, "BBH": 26.289712088654472, "MATH Lvl 5 Raw": 0.0324773413897281, "MATH Lvl 5": 3.2477341389728096, "GPQA Raw": 0.2768456375838926, "GPQA": 3.5794183445190177, "MUSR Raw": 0.3086979166666666, "MUSR": 1.920572916666666, "MMLU-PRO Raw": 0.3001163563829787, "MMLU-PRO": 22.23515070921986, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-29T00:00:00", "Submission Date": "2024-07-03T00:00:00", "Generation": 2, "Base Model": "meta-llama/Meta-Llama-3-8B"}, {"eval_name": "Magpie-Align_Llama-3-8B-Magpie-Align-v0.3_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Magpie-Align/Llama-3-8B-Magpie-Align-v0.3\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Magpie-Align/Llama-3-8B-Magpie-Align-v0.3</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Magpie-Align__Llama-3-8B-Magpie-Align-v0.3-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Magpie-Align/Llama-3-8B-Magpie-Align-v0.3", "Model sha": "7e420ddd6ff48bf213dcab2a9ddb7845b80dd1aa", "Average \u2b06\ufe0f": 16.886382003677163, "Hub License": "llama3", "Hub \u2764\ufe0f": 3, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4497056698449004, "IFEval": 44.97056698449004, "BBH Raw": 0.456960506522001, "BBH": 24.311446807587014, "MATH Lvl 5 Raw": 0.0256797583081571, "MATH Lvl 5": 2.56797583081571, "GPQA Raw": 0.2651006711409396, "GPQA": 2.0134228187919474, "MUSR Raw": 0.3406041666666666, "MUSR": 3.7421875, "MMLU-PRO Raw": 0.3134142287234042, "MMLU-PRO": 23.712692080378247, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-15T00:00:00", "Submission Date": "2024-08-06T00:00:00", "Generation": 2, "Base Model": "meta-llama/Meta-Llama-3-8B"}, {"eval_name": "Magpie-Align_Llama-3.1-8B-Magpie-Align-SFT-v0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Magpie-Align/Llama-3.1-8B-Magpie-Align-SFT-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Magpie-Align/Llama-3.1-8B-Magpie-Align-SFT-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Magpie-Align__Llama-3.1-8B-Magpie-Align-SFT-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Magpie-Align/Llama-3.1-8B-Magpie-Align-SFT-v0.1", "Model sha": "b191916912f0e76b2bdc93c46c0af590cc87e7ae", "Average \u2b06\ufe0f": 17.799565610240027, "Hub License": "llama3.1", "Hub \u2764\ufe0f": 2, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4782067137417607, "IFEval": 47.82067137417607, "BBH Raw": 0.4764157817799906, "BBH": 26.13667696363235, "MATH Lvl 5 Raw": 0.0793051359516616, "MATH Lvl 5": 7.930513595166164, "GPQA Raw": 0.2609060402684564, "GPQA": 1.45413870246085, "MUSR Raw": 0.3397395833333334, "MUSR": 1.8666666666666685, "MMLU-PRO Raw": 0.2942985372340425, "MMLU-PRO": 21.588726359338057, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-23T00:00:00", "Submission Date": "2024-09-17T00:00:00", "Generation": 1, "Base Model": "meta-llama/Meta-Llama-3.1-8B"}, {"eval_name": "Magpie-Align_Llama-3.1-8B-Magpie-Align-v0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Magpie-Align/Llama-3.1-8B-Magpie-Align-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Magpie-Align/Llama-3.1-8B-Magpie-Align-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Magpie-Align__Llama-3.1-8B-Magpie-Align-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Magpie-Align/Llama-3.1-8B-Magpie-Align-v0.1", "Model sha": "dd34258a5f2bf7630b5a8e5662b050c60a088927", "Average \u2b06\ufe0f": 16.439100559586322, "Hub License": "llama3.1", "Hub \u2764\ufe0f": 2, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4457838535086903, "IFEval": 44.57838535086903, "BBH Raw": 0.4622396316468014, "BBH": 24.04053735093787, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2634228187919463, "GPQA": 1.789709172259505, "MUSR Raw": 0.3140624999999999, "MUSR": 3.091145833333334, "MMLU-PRO Raw": 0.3262134308510638, "MMLU-PRO": 25.1348256501182, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-24T00:00:00", "Submission Date": "2024-09-17T00:00:00", "Generation": 2, "Base Model": "meta-llama/Meta-Llama-3.1-8B"}, {"eval_name": "Magpie-Align_MagpieLM-8B-Chat-v0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Magpie-Align/MagpieLM-8B-Chat-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Magpie-Align/MagpieLM-8B-Chat-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Magpie-Align__MagpieLM-8B-Chat-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Magpie-Align/MagpieLM-8B-Chat-v0.1", "Model sha": "0b30eabc82a01fb42f44ba62c2dc81e1bd09cc04", "Average \u2b06\ufe0f": 14.006706850729245, "Hub License": "llama3.1", "Hub \u2764\ufe0f": 18, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3700714105240761, "IFEval": 37.00714105240761, "BBH Raw": 0.4172338260055306, "BBH": 18.25580502860485, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.261744966442953, "GPQA": 1.5659955257270708, "MUSR Raw": 0.3500625, "MUSR": 2.824479166666667, "MMLU-PRO Raw": 0.3194813829787234, "MMLU-PRO": 24.386820330969268, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-15T00:00:00", "Submission Date": "2024-09-19T00:00:00", "Generation": 2, "Base Model": "meta-llama/Meta-Llama-3.1-8B"}, {"eval_name": "Magpie-Align_MagpieLM-8B-SFT-v0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Magpie-Align/MagpieLM-8B-SFT-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Magpie-Align/MagpieLM-8B-SFT-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Magpie-Align__MagpieLM-8B-SFT-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Magpie-Align/MagpieLM-8B-SFT-v0.1", "Model sha": "b91f605a511707cb3b7f0893a8ed80c77b32d5a8", "Average \u2b06\ufe0f": 16.902761323393705, "Hub License": "llama3.1", "Hub \u2764\ufe0f": 3, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4720619068515982, "IFEval": 47.20619068515982, "BBH Raw": 0.4552850159555335, "BBH": 23.61231335017796, "MATH Lvl 5 Raw": 0.0226586102719033, "MATH Lvl 5": 2.2658610271903323, "GPQA Raw": 0.2676174496644295, "GPQA": 2.348993288590602, "MUSR Raw": 0.3648854166666667, "MUSR": 3.877343750000002, "MMLU-PRO Raw": 0.2989527925531915, "MMLU-PRO": 22.1058658392435, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-15T00:00:00", "Submission Date": "2024-09-19T00:00:00", "Generation": 1, "Base Model": "meta-llama/Meta-Llama-3.1-8B"}, {"eval_name": "MarinaraSpaghetti_NemoReRemix-12B_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/MarinaraSpaghetti/NemoReRemix-12B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">MarinaraSpaghetti/NemoReRemix-12B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/MarinaraSpaghetti__NemoReRemix-12B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "MarinaraSpaghetti/NemoReRemix-12B", "Model sha": "9ebc7c2d4577b663fb050d86ed91fb676eb2e1f2", "Average \u2b06\ufe0f": 21.593996739464632, "Hub License": null, "Hub \u2764\ufe0f": 25, "#Params (B)": 12, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3342508987264901, "IFEval": 33.42508987264902, "BBH Raw": 0.5536511805668158, "BBH": 36.12470152357596, "MATH Lvl 5 Raw": 0.0641993957703927, "MATH Lvl 5": 6.419939577039275, "GPQA Raw": 0.3179530201342282, "GPQA": 9.060402684563762, "MUSR Raw": 0.4501458333333333, "MUSR": 15.668229166666665, "MMLU-PRO Raw": 0.3597905585106383, "MMLU-PRO": 28.865617612293136, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-14T00:00:00", "Submission Date": "2024-09-17T00:00:00", "Generation": 1, "Base Model": "MarinaraSpaghetti/NemoReRemix-12B (Merge)"}, {"eval_name": "MarinaraSpaghetti_Nemomix-v4.0-12B_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/MarinaraSpaghetti/Nemomix-v4.0-12B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">MarinaraSpaghetti/Nemomix-v4.0-12B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/MarinaraSpaghetti__Nemomix-v4.0-12B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "MarinaraSpaghetti/Nemomix-v4.0-12B", "Model sha": "69fbd8449ce3e916fc257e982a78189308123074", "Average \u2b06\ufe0f": 24.203626184847035, "Hub License": null, "Hub \u2764\ufe0f": 20, "#Params (B)": 12, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5574664113441224, "IFEval": 55.74664113441224, "BBH Raw": 0.5274986611124783, "BBH": 32.879942700903165, "MATH Lvl 5 Raw": 0.0921450151057401, "MATH Lvl 5": 9.214501510574015, "GPQA Raw": 0.2919463087248322, "GPQA": 5.592841163310966, "MUSR Raw": 0.4244479166666666, "MUSR": 12.75598958333333, "MMLU-PRO Raw": 0.3612865691489361, "MMLU-PRO": 29.03184101654845, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-30T00:00:00", "Submission Date": "2024-08-02T00:00:00", "Generation": 1, "Base Model": "MarinaraSpaghetti/Nemomix-v4.0-12B (Merge)"}, {"eval_name": "Marsouuu_MiniMathExpert-2_61B-ECE-PRYMMAL-Martial_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Marsouuu/MiniMathExpert-2_61B-ECE-PRYMMAL-Martial\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Marsouuu/MiniMathExpert-2_61B-ECE-PRYMMAL-Martial</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Marsouuu__MiniMathExpert-2_61B-ECE-PRYMMAL-Martial-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Marsouuu/MiniMathExpert-2_61B-ECE-PRYMMAL-Martial", "Model sha": "df21939a22e7233ebb7d62dfaf1c854facc5c772", "Average \u2b06\ufe0f": 12.356150837552184, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 2, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2548415980708963, "IFEval": 25.484159807089632, "BBH Raw": 0.3952730330493959, "BBH": 15.297499289020854, "MATH Lvl 5 Raw": 0.0657099697885196, "MATH Lvl 5": 6.570996978851963, "GPQA Raw": 0.2751677852348993, "GPQA": 3.355704697986576, "MUSR Raw": 0.4083229166666666, "MUSR": 9.273697916666668, "MMLU-PRO Raw": 0.2273936170212765, "MMLU-PRO": 14.154846335697396, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-06T00:00:00", "Submission Date": "2024-10-06T00:00:00", "Generation": 1, "Base Model": "Marsouuu/MiniMathExpert-2_61B-ECE-PRYMMAL-Martial (Merge)"}, {"eval_name": "Marsouuu_MiniQwenMathExpert-ECE-PRYMMAL-Martial_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Marsouuu/MiniQwenMathExpert-ECE-PRYMMAL-Martial\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Marsouuu/MiniQwenMathExpert-ECE-PRYMMAL-Martial</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Marsouuu__MiniQwenMathExpert-ECE-PRYMMAL-Martial-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Marsouuu/MiniQwenMathExpert-ECE-PRYMMAL-Martial", "Model sha": "0787682e65f7763ef978c4cf2e32803be8b49298", "Average \u2b06\ufe0f": 14.666581290794134, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 1, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2794961812435449, "IFEval": 27.949618124354487, "BBH Raw": 0.4230134304410893, "BBH": 19.019948525917457, "MATH Lvl 5 Raw": 0.0891238670694864, "MATH Lvl 5": 8.91238670694864, "GPQA Raw": 0.2818791946308724, "GPQA": 4.250559284116329, "MUSR Raw": 0.3867395833333333, "MUSR": 6.509114583333333, "MMLU-PRO Raw": 0.2922207446808511, "MMLU-PRO": 21.35786052009456, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-07T00:00:00", "Submission Date": "2024-10-07T00:00:00", "Generation": 1, "Base Model": "Marsouuu/MiniQwenMathExpert-ECE-PRYMMAL-Martial (Merge)"}, {"eval_name": "Marsouuu_MistralBase-4x7B-MoE-ECE-PRYMMAL-Martial_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Marsouuu/MistralBase-4x7B-MoE-ECE-PRYMMAL-Martial\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Marsouuu/MistralBase-4x7B-MoE-ECE-PRYMMAL-Martial</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Marsouuu__MistralBase-4x7B-MoE-ECE-PRYMMAL-Martial-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Marsouuu/MistralBase-4x7B-MoE-ECE-PRYMMAL-Martial", "Model sha": "9cb9e74d2a65abd6458dffac103ad99c3b8f5154", "Average \u2b06\ufe0f": 6.572937761865147, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 24, "Available on the hub": true, "Not_Merged": false, "MoE": false, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1697362996848362, "IFEval": 16.973629968483625, "BBH Raw": 0.3464368053320647, "BBH": 8.870227428732667, "MATH Lvl 5 Raw": 0.0030211480362537, "MATH Lvl 5": 0.3021148036253776, "GPQA Raw": 0.259228187919463, "GPQA": 1.230425055928408, "MUSR Raw": 0.3990833333333333, "MUSR": 7.852083333333335, "MMLU-PRO Raw": 0.1378823138297872, "MMLU-PRO": 4.209145981087471, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-03T00:00:00", "Submission Date": "2024-10-03T00:00:00", "Generation": 1, "Base Model": "Marsouuu/MistralBase-4x7B-MoE-ECE-PRYMMAL-Martial (Merge)"}, {"eval_name": "MaziyarPanahi_Calme-4x7B-MoE-v0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/MaziyarPanahi/Calme-4x7B-MoE-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">MaziyarPanahi/Calme-4x7B-MoE-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/MaziyarPanahi__Calme-4x7B-MoE-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "MaziyarPanahi/Calme-4x7B-MoE-v0.1", "Model sha": "e2fab90eef37977002947684043f139a1660f519", "Average \u2b06\ufe0f": 19.92319839398422, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 2, "#Params (B)": 24, "Available on the hub": true, "Not_Merged": true, "MoE": false, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4315205875964663, "IFEval": 43.15205875964662, "BBH Raw": 0.5102819889174134, "BBH": 31.26187805626151, "MATH Lvl 5 Raw": 0.0740181268882175, "MATH Lvl 5": 7.401812688821751, "GPQA Raw": 0.2818791946308724, "GPQA": 4.250559284116329, "MUSR Raw": 0.4198854166666666, "MUSR": 10.619010416666669, "MMLU-PRO Raw": 0.3056848404255319, "MMLU-PRO": 22.853871158392437, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-03-17T00:00:00", "Submission Date": "2024-08-05T00:00:00", "Generation": 0, "Base Model": "MaziyarPanahi/Calme-4x7B-MoE-v0.1"}, {"eval_name": "MaziyarPanahi_Calme-4x7B-MoE-v0.2_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/MaziyarPanahi/Calme-4x7B-MoE-v0.2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">MaziyarPanahi/Calme-4x7B-MoE-v0.2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/MaziyarPanahi__Calme-4x7B-MoE-v0.2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "MaziyarPanahi/Calme-4x7B-MoE-v0.2", "Model sha": "ffef41baf94b3f88b30cf0aeb3fd72d9e4187161", "Average \u2b06\ufe0f": 20.063067894713587, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 2, "#Params (B)": 24, "Available on the hub": true, "Not_Merged": true, "MoE": false, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.429447200095746, "IFEval": 42.9447200095746, "BBH Raw": 0.5110766802558263, "BBH": 31.396819621762447, "MATH Lvl 5 Raw": 0.0672205438066465, "MATH Lvl 5": 6.722054380664652, "GPQA Raw": 0.2793624161073825, "GPQA": 3.9149888143176734, "MUSR Raw": 0.4317604166666666, "MUSR": 12.536718750000004, "MMLU-PRO Raw": 0.3057679521276595, "MMLU-PRO": 22.86310579196217, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-03-17T00:00:00", "Submission Date": "2024-08-05T00:00:00", "Generation": 0, "Base Model": "MaziyarPanahi/Calme-4x7B-MoE-v0.2"}, {"eval_name": "MaziyarPanahi_Llama-3-70B-Instruct-v0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/MaziyarPanahi/Llama-3-70B-Instruct-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">MaziyarPanahi/Llama-3-70B-Instruct-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/MaziyarPanahi__Llama-3-70B-Instruct-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "MaziyarPanahi/Llama-3-70B-Instruct-v0.1", "Model sha": "6db1cb4256525fc5429734ddc0eb941d08d0be30", "Average \u2b06\ufe0f": 25.817800647863557, "Hub License": "llama3", "Hub \u2764\ufe0f": 1, "#Params (B)": 70, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4714380067110821, "IFEval": 47.14380067110822, "BBH Raw": 0.5366257615951637, "BBH": 32.71291726367119, "MATH Lvl 5 Raw": 0.1495468277945619, "MATH Lvl 5": 14.954682779456194, "GPQA Raw": 0.2843959731543624, "GPQA": 4.586129753914992, "MUSR Raw": 0.4433020833333334, "MUSR": 15.312760416666672, "MMLU-PRO Raw": 0.4617686170212766, "MMLU-PRO": 40.196513002364064, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-14T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 2, "Base Model": "meta-llama/Meta-Llama-3-70B"}, {"eval_name": "MaziyarPanahi_Llama-3-8B-Instruct-v0.10_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/MaziyarPanahi/Llama-3-8B-Instruct-v0.10\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">MaziyarPanahi/Llama-3-8B-Instruct-v0.10</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/MaziyarPanahi__Llama-3-8B-Instruct-v0.10-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "MaziyarPanahi/Llama-3-8B-Instruct-v0.10", "Model sha": "4411eb9f6f5e4c462a6bdbc64c26dcc123100b66", "Average \u2b06\ufe0f": 26.65893410313845, "Hub License": "other", "Hub \u2764\ufe0f": 6, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7667433520835827, "IFEval": 76.67433520835827, "BBH Raw": 0.4924311866686311, "BBH": 27.924674302120888, "MATH Lvl 5 Raw": 0.0490936555891238, "MATH Lvl 5": 4.909365558912387, "GPQA Raw": 0.3087248322147651, "GPQA": 7.829977628635347, "MUSR Raw": 0.4214374999999999, "MUSR": 10.813020833333333, "MMLU-PRO Raw": 0.386220079787234, "MMLU-PRO": 31.80223108747045, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-04T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 4, "Base Model": "meta-llama/Meta-Llama-3-8B-Instruct"}, {"eval_name": "MaziyarPanahi_Llama-3-8B-Instruct-v0.8_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/MaziyarPanahi/Llama-3-8B-Instruct-v0.8\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">MaziyarPanahi/Llama-3-8B-Instruct-v0.8</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/MaziyarPanahi__Llama-3-8B-Instruct-v0.8-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "MaziyarPanahi/Llama-3-8B-Instruct-v0.8", "Model sha": "94d222b8447b600b9836da4036df9490b59fe966", "Average \u2b06\ufe0f": 26.788179439182212, "Hub License": "other", "Hub \u2764\ufe0f": 8, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7527549125209998, "IFEval": 75.27549125209998, "BBH Raw": 0.4962783681594988, "BBH": 28.270418759783485, "MATH Lvl 5 Raw": 0.0717522658610271, "MATH Lvl 5": 7.175226586102719, "GPQA Raw": 0.3053691275167785, "GPQA": 7.38255033557047, "MUSR Raw": 0.4201979166666666, "MUSR": 10.924739583333334, "MMLU-PRO Raw": 0.3853058510638298, "MMLU-PRO": 31.700650118203303, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-01T00:00:00", "Submission Date": "2024-07-11T00:00:00", "Generation": 2, "Base Model": "meta-llama/Meta-Llama-3-8B-Instruct"}, {"eval_name": "MaziyarPanahi_Llama-3-8B-Instruct-v0.9_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/MaziyarPanahi/Llama-3-8B-Instruct-v0.9\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">MaziyarPanahi/Llama-3-8B-Instruct-v0.9</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/MaziyarPanahi__Llama-3-8B-Instruct-v0.9-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "MaziyarPanahi/Llama-3-8B-Instruct-v0.9", "Model sha": "ddf91fdc0a3ab5e5d76864f1c4cf44e5adacd565", "Average \u2b06\ufe0f": 26.69852757439215, "Hub License": "other", "Hub \u2764\ufe0f": 6, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.763046494412603, "IFEval": 76.3046494412603, "BBH Raw": 0.4936132794870085, "BBH": 27.903013285410186, "MATH Lvl 5 Raw": 0.0679758308157099, "MATH Lvl 5": 6.797583081570997, "GPQA Raw": 0.3078859060402684, "GPQA": 7.718120805369126, "MUSR Raw": 0.4148020833333333, "MUSR": 9.850260416666666, "MMLU-PRO Raw": 0.3845578457446808, "MMLU-PRO": 31.61753841607564, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-30T00:00:00", "Submission Date": "2024-08-06T00:00:00", "Generation": 3, "Base Model": "meta-llama/Meta-Llama-3-8B-Instruct"}, {"eval_name": "MaziyarPanahi_Qwen1.5-MoE-A2.7B-Wikihow_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2MoeForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/MaziyarPanahi/Qwen1.5-MoE-A2.7B-Wikihow\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">MaziyarPanahi/Qwen1.5-MoE-A2.7B-Wikihow</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/MaziyarPanahi__Qwen1.5-MoE-A2.7B-Wikihow-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "MaziyarPanahi/Qwen1.5-MoE-A2.7B-Wikihow", "Model sha": "191cf0630b7b50fe1fc9be198e1f203935df1428", "Average \u2b06\ufe0f": 11.43167829557359, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 2, "#Params (B)": 14, "Available on the hub": true, "Not_Merged": true, "MoE": false, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2954327850104389, "IFEval": 29.5432785010439, "BBH Raw": 0.3920071454890602, "BBH": 15.47343942401254, "MATH Lvl 5 Raw": 0.0287009063444108, "MATH Lvl 5": 2.8700906344410875, "GPQA Raw": 0.2751677852348993, "GPQA": 3.355704697986576, "MUSR Raw": 0.35021875, "MUSR": 2.010677083333334, "MMLU-PRO Raw": 0.238031914893617, "MMLU-PRO": 15.336879432624112, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-03-30T00:00:00", "Submission Date": "2024-09-12T00:00:00", "Generation": 1, "Base Model": "Qwen/Qwen1.5-MoE-A2.7B"}, {"eval_name": "MaziyarPanahi_Qwen2-7B-Instruct-v0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/MaziyarPanahi/Qwen2-7B-Instruct-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">MaziyarPanahi/Qwen2-7B-Instruct-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/MaziyarPanahi__Qwen2-7B-Instruct-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "MaziyarPanahi/Qwen2-7B-Instruct-v0.1", "Model sha": "5123ecd76cefd4ef3b6009542b13e060d03e5232", "Average \u2b06\ufe0f": 22.69198227196428, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3352249808286457, "IFEval": 33.52249808286457, "BBH Raw": 0.5123061019250074, "BBH": 31.92360727430821, "MATH Lvl 5 Raw": 0.2039274924471299, "MATH Lvl 5": 20.39274924471299, "GPQA Raw": 0.285234899328859, "GPQA": 4.697986577181204, "MUSR Raw": 0.4434791666666666, "MUSR": 13.868229166666667, "MMLU-PRO Raw": 0.3857214095744681, "MMLU-PRO": 31.746823286052013, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-27T00:00:00", "Submission Date": "2024-07-07T00:00:00", "Generation": 1, "Base Model": "Qwen/Qwen2-7B"}, {"eval_name": "MaziyarPanahi_Qwen2-7B-Instruct-v0.8_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/MaziyarPanahi/Qwen2-7B-Instruct-v0.8\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">MaziyarPanahi/Qwen2-7B-Instruct-v0.8</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/MaziyarPanahi__Qwen2-7B-Instruct-v0.8-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "MaziyarPanahi/Qwen2-7B-Instruct-v0.8", "Model sha": "a6f9d0e11efcba18c905554ab43b877ead187a77", "Average \u2b06\ufe0f": 19.218258434197452, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 5, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2774726614272352, "IFEval": 27.74726614272353, "BBH Raw": 0.4637108491317945, "BBH": 25.532524528361478, "MATH Lvl 5 Raw": 0.1563444108761329, "MATH Lvl 5": 15.634441087613292, "GPQA Raw": 0.2936241610738255, "GPQA": 5.8165548098434, "MUSR Raw": 0.4293125, "MUSR": 12.0640625, "MMLU-PRO Raw": 0.3566323138297872, "MMLU-PRO": 28.514701536643027, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-27T00:00:00", "Submission Date": "2024-07-07T00:00:00", "Generation": 1, "Base Model": "Qwen/Qwen2-7B"}, {"eval_name": "MaziyarPanahi_calme-2.1-phi3-4b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Phi3ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/MaziyarPanahi/calme-2.1-phi3-4b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">MaziyarPanahi/calme-2.1-phi3-4b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/MaziyarPanahi__calme-2.1-phi3-4b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "MaziyarPanahi/calme-2.1-phi3-4b", "Model sha": "6764c79badacba5fa3584d2d2593d762caa1d17d", "Average \u2b06\ufe0f": 24.512555585212223, "Hub License": "mit", "Hub \u2764\ufe0f": 1, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.552520645221346, "IFEval": 55.2520645221346, "BBH Raw": 0.5595320442699866, "BBH": 38.1242795228128, "MATH Lvl 5 Raw": 0.0430513595166163, "MATH Lvl 5": 4.305135951661631, "GPQA Raw": 0.3296979865771812, "GPQA": 10.626398210290828, "MUSR Raw": 0.4015312499999999, "MUSR": 8.258072916666668, "MMLU-PRO Raw": 0.3745844414893617, "MMLU-PRO": 30.50938238770685, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-09T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "microsoft/Phi-3-mini-4k-instruct"}, {"eval_name": "MaziyarPanahi_calme-2.1-phi3.5-4b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Phi3ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/MaziyarPanahi/calme-2.1-phi3.5-4b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">MaziyarPanahi/calme-2.1-phi3.5-4b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/MaziyarPanahi__calme-2.1-phi3.5-4b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "MaziyarPanahi/calme-2.1-phi3.5-4b", "Model sha": "583b7f382a8ed35f6f7c09f2950f0f2346945a83", "Average \u2b06\ufe0f": 27.005917215022084, "Hub License": "mit", "Hub \u2764\ufe0f": 3, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5659095644002359, "IFEval": 56.59095644002358, "BBH Raw": 0.5483695590203843, "BBH": 36.11009692957303, "MATH Lvl 5 Raw": 0.1442598187311178, "MATH Lvl 5": 14.425981873111782, "GPQA Raw": 0.3439597315436241, "GPQA": 12.527964205816552, "MUSR Raw": 0.3994583333333333, "MUSR": 9.765624999999998, "MMLU-PRO Raw": 0.3935339095744681, "MMLU-PRO": 32.61487884160757, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-23T00:00:00", "Submission Date": "2024-08-23T00:00:00", "Generation": 1, "Base Model": "microsoft/Phi-3.5-mini-instruct"}, {"eval_name": "MaziyarPanahi_calme-2.1-qwen2-72b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/MaziyarPanahi/calme-2.1-qwen2-72b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">MaziyarPanahi/calme-2.1-qwen2-72b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/MaziyarPanahi__calme-2.1-qwen2-72b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "MaziyarPanahi/calme-2.1-qwen2-72b", "Model sha": "0369c39770f45f2464587918f2dbdb8449ea3a0d", "Average \u2b06\ufe0f": 43.60589252695375, "Hub License": "other", "Hub \u2764\ufe0f": 27, "#Params (B)": 72, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.8162774770941104, "IFEval": 81.62774770941103, "BBH Raw": 0.6965560971922596, "BBH": 57.3258823447103, "MATH Lvl 5 Raw": 0.3602719033232628, "MATH Lvl 5": 36.027190332326285, "GPQA Raw": 0.3808724832214765, "GPQA": 17.4496644295302, "MUSR Raw": 0.47321875, "MUSR": 20.15234375, "MMLU-PRO Raw": 0.5414727393617021, "MMLU-PRO": 49.05252659574468, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-08T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 2, "Base Model": "Qwen/Qwen2-72B"}, {"eval_name": "MaziyarPanahi_calme-2.1-qwen2-7b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/MaziyarPanahi/calme-2.1-qwen2-7b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">MaziyarPanahi/calme-2.1-qwen2-7b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/MaziyarPanahi__calme-2.1-qwen2-7b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "MaziyarPanahi/calme-2.1-qwen2-7b", "Model sha": "5aac57e2290f7c49af88a9cb9883ce25b58882a1", "Average \u2b06\ufe0f": 23.20200075601005, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3816119008674761, "IFEval": 38.16119008674761, "BBH Raw": 0.5045925887362795, "BBH": 31.00709744702013, "MATH Lvl 5 Raw": 0.2107250755287009, "MATH Lvl 5": 21.07250755287009, "GPQA Raw": 0.2894295302013422, "GPQA": 5.257270693512303, "MUSR Raw": 0.4436979166666666, "MUSR": 13.795572916666666, "MMLU-PRO Raw": 0.3692652925531915, "MMLU-PRO": 29.918365839243503, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-27T00:00:00", "Submission Date": "2024-09-18T00:00:00", "Generation": 1, "Base Model": "Qwen/Qwen2-7B"}, {"eval_name": "MaziyarPanahi_calme-2.1-qwen2.5-72b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/MaziyarPanahi/calme-2.1-qwen2.5-72b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">MaziyarPanahi/calme-2.1-qwen2.5-72b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/MaziyarPanahi__calme-2.1-qwen2.5-72b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "MaziyarPanahi/calme-2.1-qwen2.5-72b", "Model sha": "eb6c92dec932070ea872f39469ca5b9daf2d34e6", "Average \u2b06\ufe0f": 38.377870062099255, "Hub License": "other", "Hub \u2764\ufe0f": 1, "#Params (B)": 72, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.8662360315075112, "IFEval": 86.62360315075111, "BBH Raw": 0.7261624327092416, "BBH": 61.65570318314716, "MATH Lvl 5 Raw": 0.0226586102719033, "MATH Lvl 5": 2.2658610271903323, "GPQA Raw": 0.3632550335570469, "GPQA": 15.100671140939594, "MUSR Raw": 0.42984375, "MUSR": 13.297135416666665, "MMLU-PRO Raw": 0.5619182180851063, "MMLU-PRO": 51.3242464539007, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-19T00:00:00", "Submission Date": "2024-09-26T00:00:00", "Generation": 1, "Base Model": "Qwen/Qwen2.5-72B"}, {"eval_name": "MaziyarPanahi_calme-2.1-rys-78b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/MaziyarPanahi/calme-2.1-rys-78b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">MaziyarPanahi/calme-2.1-rys-78b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/MaziyarPanahi__calme-2.1-rys-78b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "MaziyarPanahi/calme-2.1-rys-78b", "Model sha": "e746f5ddc0c9b31a2382d985a4ec87fa910847c7", "Average \u2b06\ufe0f": 44.14047383019146, "Hub License": "mit", "Hub \u2764\ufe0f": 3, "#Params (B)": 77, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.8135547015252862, "IFEval": 81.35547015252862, "BBH Raw": 0.7097861139530462, "BBH": 59.4700307859535, "MATH Lvl 5 Raw": 0.3640483383685801, "MATH Lvl 5": 36.40483383685801, "GPQA Raw": 0.3942953020134228, "GPQA": 19.239373601789712, "MUSR Raw": 0.4693125, "MUSR": 18.99739583333333, "MMLU-PRO Raw": 0.5443816489361702, "MMLU-PRO": 49.37573877068559, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-06T00:00:00", "Submission Date": "2024-08-08T00:00:00", "Generation": 1, "Base Model": "dnhkng/RYS-XLarge"}, {"eval_name": "MaziyarPanahi_calme-2.2-llama3-70b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/MaziyarPanahi/calme-2.2-llama3-70b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">MaziyarPanahi/calme-2.2-llama3-70b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/MaziyarPanahi__calme-2.2-llama3-70b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "MaziyarPanahi/calme-2.2-llama3-70b", "Model sha": "95366b974baedee4d95c1e841bc3d15e94753804", "Average \u2b06\ufe0f": 37.97641817189397, "Hub License": "llama3", "Hub \u2764\ufe0f": 17, "#Params (B)": 70, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.8208486814984242, "IFEval": 82.0848681498424, "BBH Raw": 0.6435431762417703, "BBH": 48.57170594999846, "MATH Lvl 5 Raw": 0.229607250755287, "MATH Lvl 5": 22.9607250755287, "GPQA Raw": 0.3414429530201342, "GPQA": 12.192393736017896, "MUSR Raw": 0.4445729166666667, "MUSR": 15.30494791666667, "MMLU-PRO Raw": 0.5206948138297872, "MMLU-PRO": 46.74386820330969, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-27T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 2, "Base Model": "meta-llama/Meta-Llama-3-70B"}, {"eval_name": "MaziyarPanahi_calme-2.2-llama3.1-70b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/MaziyarPanahi/calme-2.2-llama3.1-70b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">MaziyarPanahi/calme-2.2-llama3.1-70b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/MaziyarPanahi__calme-2.2-llama3.1-70b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "MaziyarPanahi/calme-2.2-llama3.1-70b", "Model sha": "c81ac05ed2c2344e9fd366cfff197da406ef5234", "Average \u2b06\ufe0f": 36.387542564119, "Hub License": null, "Hub \u2764\ufe0f": 2, "#Params (B)": 70, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.8592667455684251, "IFEval": 85.92667455684251, "BBH Raw": 0.6792920009427085, "BBH": 54.20646208605566, "MATH Lvl 5 Raw": 0.0211480362537764, "MATH Lvl 5": 2.114803625377644, "GPQA Raw": 0.3246644295302013, "GPQA": 9.955257270693512, "MUSR Raw": 0.45415625, "MUSR": 17.06953125, "MMLU-PRO Raw": 0.5414727393617021, "MMLU-PRO": 49.05252659574468, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-09T00:00:00", "Submission Date": "2024-09-09T00:00:00", "Generation": 2, "Base Model": "meta-llama/Meta-Llama-3.1-70B"}, {"eval_name": "MaziyarPanahi_calme-2.2-phi3-4b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Phi3ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/MaziyarPanahi/calme-2.2-phi3-4b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">MaziyarPanahi/calme-2.2-phi3-4b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/MaziyarPanahi__calme-2.2-phi3-4b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "MaziyarPanahi/calme-2.2-phi3-4b", "Model sha": "c0a366a4c01d7e724ceba7e2f2c19251983423fe", "Average \u2b06\ufe0f": 23.205953725977537, "Hub License": "mit", "Hub \u2764\ufe0f": 2, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5069083365470286, "IFEval": 50.69083365470286, "BBH Raw": 0.5529604896487258, "BBH": 37.733734155011526, "MATH Lvl 5 Raw": 0.0234138972809667, "MATH Lvl 5": 2.3413897280966767, "GPQA Raw": 0.3213087248322148, "GPQA": 9.50782997762864, "MUSR Raw": 0.3975625, "MUSR": 7.695312500000001, "MMLU-PRO Raw": 0.3813996010638298, "MMLU-PRO": 31.26662234042553, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-10T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "microsoft/Phi-3-mini-4k-instruct"}, {"eval_name": "MaziyarPanahi_calme-2.2-qwen2-72b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/MaziyarPanahi/calme-2.2-qwen2-72b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">MaziyarPanahi/calme-2.2-qwen2-72b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/MaziyarPanahi__calme-2.2-qwen2-72b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "MaziyarPanahi/calme-2.2-qwen2-72b", "Model sha": "529e9bd80a76d943409bc92bb246aa7ca63dd9e6", "Average \u2b06\ufe0f": 43.39774933567276, "Hub License": "other", "Hub \u2764\ufe0f": 5, "#Params (B)": 72, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.8008151704145002, "IFEval": 80.08151704145003, "BBH Raw": 0.6939595229335245, "BBH": 56.79594225047665, "MATH Lvl 5 Raw": 0.411631419939577, "MATH Lvl 5": 41.1631419939577, "GPQA Raw": 0.3741610738255033, "GPQA": 16.554809843400445, "MUSR Raw": 0.4508020833333333, "MUSR": 16.516927083333332, "MMLU-PRO Raw": 0.543467420212766, "MMLU-PRO": 49.27415780141844, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-09T00:00:00", "Submission Date": "2024-08-06T00:00:00", "Generation": 1, "Base Model": "Qwen/Qwen2-72B"}, {"eval_name": "MaziyarPanahi_calme-2.2-qwen2-7b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/MaziyarPanahi/calme-2.2-qwen2-7b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">MaziyarPanahi/calme-2.2-qwen2-7b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/MaziyarPanahi__calme-2.2-qwen2-7b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "MaziyarPanahi/calme-2.2-qwen2-7b", "Model sha": "bbb1d119f75c5b2eaa8978286808bd59cae04997", "Average \u2b06\ufe0f": 23.23085216838605, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3597299609480622, "IFEval": 35.97299609480623, "BBH Raw": 0.5214913750127922, "BBH": 33.10936559556884, "MATH Lvl 5 Raw": 0.1933534743202417, "MATH Lvl 5": 19.335347432024168, "GPQA Raw": 0.2911073825503356, "GPQA": 5.480984340044745, "MUSR Raw": 0.4358229166666666, "MUSR": 13.277864583333338, "MMLU-PRO Raw": 0.3898769946808511, "MMLU-PRO": 32.208554964539005, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-27T00:00:00", "Submission Date": "2024-09-18T00:00:00", "Generation": 1, "Base Model": "Qwen/Qwen2-7B"}, {"eval_name": "MaziyarPanahi_calme-2.2-qwen2.5-72b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/MaziyarPanahi/calme-2.2-qwen2.5-72b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">MaziyarPanahi/calme-2.2-qwen2.5-72b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/MaziyarPanahi__calme-2.2-qwen2.5-72b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "MaziyarPanahi/calme-2.2-qwen2.5-72b", "Model sha": "c6c7fdf70d8bf81364108975eb8ba78eecac83d4", "Average \u2b06\ufe0f": 38.0100752445117, "Hub License": "other", "Hub \u2764\ufe0f": 3, "#Params (B)": 72, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.8476763875406145, "IFEval": 84.76763875406145, "BBH Raw": 0.7276399007138082, "BBH": 61.80360419146786, "MATH Lvl 5 Raw": 0.0362537764350453, "MATH Lvl 5": 3.625377643504532, "GPQA Raw": 0.3590604026845637, "GPQA": 14.5413870246085, "MUSR Raw": 0.4206666666666667, "MUSR": 12.016666666666673, "MMLU-PRO Raw": 0.561751994680851, "MMLU-PRO": 51.305777186761226, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-19T00:00:00", "Submission Date": "2024-09-26T00:00:00", "Generation": 1, "Base Model": "Qwen/Qwen2.5-72B"}, {"eval_name": "MaziyarPanahi_calme-2.2-rys-78b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/MaziyarPanahi/calme-2.2-rys-78b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">MaziyarPanahi/calme-2.2-rys-78b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/MaziyarPanahi__calme-2.2-rys-78b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "MaziyarPanahi/calme-2.2-rys-78b", "Model sha": "8d0dde25c9042705f65559446944a19259c3fc8e", "Average \u2b06\ufe0f": 43.92057408159756, "Hub License": "mit", "Hub \u2764\ufe0f": 3, "#Params (B)": 77, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7986420475449585, "IFEval": 79.86420475449586, "BBH Raw": 0.7081014602379213, "BBH": 59.268645675184494, "MATH Lvl 5 Raw": 0.3791540785498489, "MATH Lvl 5": 37.91540785498489, "GPQA Raw": 0.4068791946308724, "GPQA": 20.917225950783, "MUSR Raw": 0.4535625, "MUSR": 16.82864583333333, "MMLU-PRO Raw": 0.538563829787234, "MMLU-PRO": 48.72931442080378, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-06T00:00:00", "Submission Date": "2024-08-08T00:00:00", "Generation": 1, "Base Model": "dnhkng/RYS-XLarge"}, {"eval_name": "MaziyarPanahi_calme-2.3-llama3-70b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/MaziyarPanahi/calme-2.3-llama3-70b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">MaziyarPanahi/calme-2.3-llama3-70b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/MaziyarPanahi__calme-2.3-llama3-70b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "MaziyarPanahi/calme-2.3-llama3-70b", "Model sha": "bd17453eaae0e36d1e1e17da13fdd155fce91a29", "Average \u2b06\ufe0f": 36.84044616302646, "Hub License": "llama3", "Hub \u2764\ufe0f": 3, "#Params (B)": 70, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.8010401290797307, "IFEval": 80.10401290797307, "BBH Raw": 0.6399173489368603, "BBH": 48.0085850617923, "MATH Lvl 5 Raw": 0.2190332326283988, "MATH Lvl 5": 21.90332326283988, "GPQA Raw": 0.3380872483221476, "GPQA": 11.74496644295302, "MUSR Raw": 0.426125, "MUSR": 12.565625000000002, "MMLU-PRO Raw": 0.5204454787234043, "MMLU-PRO": 46.71616430260048, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-27T00:00:00", "Submission Date": "2024-08-30T00:00:00", "Generation": 2, "Base Model": "meta-llama/Meta-Llama-3-70B"}, {"eval_name": "MaziyarPanahi_calme-2.3-llama3.1-70b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/MaziyarPanahi/calme-2.3-llama3.1-70b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">MaziyarPanahi/calme-2.3-llama3.1-70b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/MaziyarPanahi__calme-2.3-llama3.1-70b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "MaziyarPanahi/calme-2.3-llama3.1-70b", "Model sha": "a39c79250721b75beefa1b1763895eafd010f6f6", "Average \u2b06\ufe0f": 40.30439437414668, "Hub License": null, "Hub \u2764\ufe0f": 3, "#Params (B)": 70, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.8604657863358112, "IFEval": 86.04657863358113, "BBH Raw": 0.6871653740091753, "BBH": 55.58549511699308, "MATH Lvl 5 Raw": 0.2145015105740181, "MATH Lvl 5": 21.45015105740181, "GPQA Raw": 0.3439597315436241, "GPQA": 12.527964205816552, "MUSR Raw": 0.4568229166666666, "MUSR": 17.736197916666658, "MMLU-PRO Raw": 0.5363198138297872, "MMLU-PRO": 48.4799793144208, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-10T00:00:00", "Submission Date": "2024-09-18T00:00:00", "Generation": 2, "Base Model": "meta-llama/Meta-Llama-3.1-70B"}, {"eval_name": "MaziyarPanahi_calme-2.3-phi3-4b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Phi3ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/MaziyarPanahi/calme-2.3-phi3-4b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">MaziyarPanahi/calme-2.3-phi3-4b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/MaziyarPanahi__calme-2.3-phi3-4b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "MaziyarPanahi/calme-2.3-phi3-4b", "Model sha": "e1f70c3724c728aadd1c7c1bb279487494f7059e", "Average \u2b06\ufe0f": 23.01786654679916, "Hub License": "mit", "Hub \u2764\ufe0f": 9, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4926450706348045, "IFEval": 49.26450706348045, "BBH Raw": 0.5537867816134527, "BBH": 37.65889241962552, "MATH Lvl 5 Raw": 0.0294561933534743, "MATH Lvl 5": 2.9456193353474323, "GPQA Raw": 0.3179530201342282, "GPQA": 9.060402684563762, "MUSR Raw": 0.3988333333333333, "MUSR": 7.754166666666667, "MMLU-PRO Raw": 0.3828125, "MMLU-PRO": 31.42361111111111, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-10T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "microsoft/Phi-3-mini-4k-instruct"}, {"eval_name": "MaziyarPanahi_calme-2.3-qwen2-72b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/MaziyarPanahi/calme-2.3-qwen2-72b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">MaziyarPanahi/calme-2.3-qwen2-72b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/MaziyarPanahi__calme-2.3-qwen2-72b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "MaziyarPanahi/calme-2.3-qwen2-72b", "Model sha": "12ff2e800f968e867a580c072905cf4671da066f", "Average \u2b06\ufe0f": 30.168504636926237, "Hub License": "other", "Hub \u2764\ufe0f": 2, "#Params (B)": 72, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3849840645044039, "IFEval": 38.49840645044039, "BBH Raw": 0.6576306700720502, "BBH": 51.22830430718469, "MATH Lvl 5 Raw": 0.1472809667673716, "MATH Lvl 5": 14.72809667673716, "GPQA Raw": 0.3716442953020134, "GPQA": 16.21923937360179, "MUSR Raw": 0.4112395833333333, "MUSR": 11.23828125, "MMLU-PRO Raw": 0.5418882978723404, "MMLU-PRO": 49.09869976359338, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-06T00:00:00", "Submission Date": "2024-09-15T00:00:00", "Generation": 1, "Base Model": "Qwen/Qwen2-72B"}, {"eval_name": "MaziyarPanahi_calme-2.3-qwen2-7b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/MaziyarPanahi/calme-2.3-qwen2-7b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">MaziyarPanahi/calme-2.3-qwen2-7b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/MaziyarPanahi__calme-2.3-qwen2-7b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "MaziyarPanahi/calme-2.3-qwen2-7b", "Model sha": "ca39e60052a600a709e03fefceabd9620e0b66d7", "Average \u2b06\ufe0f": 22.74182185027272, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3824862476008103, "IFEval": 38.24862476008103, "BBH Raw": 0.5064049035932394, "BBH": 30.95608211537095, "MATH Lvl 5 Raw": 0.1865558912386707, "MATH Lvl 5": 18.65558912386707, "GPQA Raw": 0.296979865771812, "GPQA": 6.263982102908276, "MUSR Raw": 0.4422395833333333, "MUSR": 13.313281249999998, "MMLU-PRO Raw": 0.3611203457446808, "MMLU-PRO": 29.01337174940898, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-27T00:00:00", "Submission Date": "2024-09-18T00:00:00", "Generation": 1, "Base Model": "Qwen/Qwen2-7B"}, {"eval_name": "MaziyarPanahi_calme-2.3-rys-78b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/MaziyarPanahi/calme-2.3-rys-78b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">MaziyarPanahi/calme-2.3-rys-78b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/MaziyarPanahi__calme-2.3-rys-78b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "MaziyarPanahi/calme-2.3-rys-78b", "Model sha": "a8a4e55c2f7054d25c2f0ab3a3b3d806eb915180", "Average \u2b06\ufe0f": 44.01608480560864, "Hub License": "mit", "Hub \u2764\ufe0f": 4, "#Params (B)": 77, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.8065854155862002, "IFEval": 80.65854155862002, "BBH Raw": 0.7107763314317289, "BBH": 59.57454695904105, "MATH Lvl 5 Raw": 0.3655589123867069, "MATH Lvl 5": 36.5558912386707, "GPQA Raw": 0.4043624161073825, "GPQA": 20.581655480984335, "MUSR Raw": 0.4549270833333333, "MUSR": 16.999218749999997, "MMLU-PRO Raw": 0.5475398936170213, "MMLU-PRO": 49.7266548463357, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-06T00:00:00", "Submission Date": "2024-09-03T00:00:00", "Generation": 1, "Base Model": "dnhkng/RYS-XLarge"}, {"eval_name": "MaziyarPanahi_calme-2.4-llama3-70b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/MaziyarPanahi/calme-2.4-llama3-70b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">MaziyarPanahi/calme-2.4-llama3-70b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/MaziyarPanahi__calme-2.4-llama3-70b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "MaziyarPanahi/calme-2.4-llama3-70b", "Model sha": "cb03e4d810b82d86e7cb01ab146bade09a5d06d1", "Average \u2b06\ufe0f": 32.184110445139304, "Hub License": "llama3", "Hub \u2764\ufe0f": 14, "#Params (B)": 70, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5027371817887649, "IFEval": 50.27371817887649, "BBH Raw": 0.6418191966839487, "BBH": 48.39776612820646, "MATH Lvl 5 Raw": 0.2265861027190332, "MATH Lvl 5": 22.658610271903324, "GPQA Raw": 0.3397651006711409, "GPQA": 11.968680089485462, "MUSR Raw": 0.4287916666666667, "MUSR": 13.098958333333336, "MMLU-PRO Raw": 0.5203623670212766, "MMLU-PRO": 46.706929669030735, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-28T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 2, "Base Model": "meta-llama/Meta-Llama-3-70B"}, {"eval_name": "MaziyarPanahi_calme-2.4-qwen2-7b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/MaziyarPanahi/calme-2.4-qwen2-7b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">MaziyarPanahi/calme-2.4-qwen2-7b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/MaziyarPanahi__calme-2.4-qwen2-7b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "MaziyarPanahi/calme-2.4-qwen2-7b", "Model sha": "d683c3ef1feb13e92227f5fd92fe5bc4b55ea4a2", "Average \u2b06\ufe0f": 22.524149732844705, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3299545206718174, "IFEval": 32.995452067181745, "BBH Raw": 0.5101416326251771, "BBH": 31.8182656422348, "MATH Lvl 5 Raw": 0.1835347432024169, "MATH Lvl 5": 18.35347432024169, "GPQA Raw": 0.2835570469798658, "GPQA": 4.4742729306487705, "MUSR Raw": 0.44528125, "MUSR": 14.426822916666667, "MMLU-PRO Raw": 0.3976894946808511, "MMLU-PRO": 33.076610520094555, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-27T00:00:00", "Submission Date": "2024-09-18T00:00:00", "Generation": 1, "Base Model": "Qwen/Qwen2-7B"}, {"eval_name": "MaziyarPanahi_calme-2.4-rys-78b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/MaziyarPanahi/calme-2.4-rys-78b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">MaziyarPanahi/calme-2.4-rys-78b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/MaziyarPanahi__calme-2.4-rys-78b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "MaziyarPanahi/calme-2.4-rys-78b", "Model sha": "0a35e51ffa9efa644c11816a2d56434804177acb", "Average \u2b06\ufe0f": 50.26152251751407, "Hub License": "mit", "Hub \u2764\ufe0f": 32, "#Params (B)": 77, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.8010899967641414, "IFEval": 80.10899967641413, "BBH Raw": 0.7279510956242796, "BBH": 62.15654929467119, "MATH Lvl 5 Raw": 0.3768882175226586, "MATH Lvl 5": 37.68882175226586, "GPQA Raw": 0.4026845637583892, "GPQA": 20.3579418344519, "MUSR Raw": 0.5770624999999999, "MUSR": 34.56614583333333, "MMLU-PRO Raw": 0.7002160904255319, "MMLU-PRO": 66.690676713948, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-07T00:00:00", "Submission Date": "2024-09-03T00:00:00", "Generation": 2, "Base Model": "dnhkng/RYS-XLarge"}, {"eval_name": "MaziyarPanahi_calme-2.5-qwen2-7b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/MaziyarPanahi/calme-2.5-qwen2-7b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">MaziyarPanahi/calme-2.5-qwen2-7b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/MaziyarPanahi__calme-2.5-qwen2-7b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "MaziyarPanahi/calme-2.5-qwen2-7b", "Model sha": "20fb1afc22c0722cb2c57185fff59befeba0fbec", "Average \u2b06\ufe0f": 22.344835764608693, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3144922139922073, "IFEval": 31.449221399220733, "BBH Raw": 0.4886561146965678, "BBH": 28.28099517875505, "MATH Lvl 5 Raw": 0.2069486404833836, "MATH Lvl 5": 20.694864048338367, "GPQA Raw": 0.3104026845637584, "GPQA": 8.05369127516779, "MUSR Raw": 0.45646875, "MUSR": 15.791927083333334, "MMLU-PRO Raw": 0.3681848404255319, "MMLU-PRO": 29.79831560283688, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-27T00:00:00", "Submission Date": "2024-09-29T00:00:00", "Generation": 1, "Base Model": "Qwen/Qwen2-7B"}, {"eval_name": "MaziyarPanahi_calme-2.6-qwen2-7b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/MaziyarPanahi/calme-2.6-qwen2-7b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">MaziyarPanahi/calme-2.6-qwen2-7b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/MaziyarPanahi__calme-2.6-qwen2-7b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "MaziyarPanahi/calme-2.6-qwen2-7b", "Model sha": "ebfaae016a50f8922098a2a262ec3ca704504cae", "Average \u2b06\ufe0f": 21.0812734526526, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3442676542684522, "IFEval": 34.426765426845215, "BBH Raw": 0.4930243946403894, "BBH": 29.30841923308876, "MATH Lvl 5 Raw": 0.1125377643504531, "MATH Lvl 5": 11.253776435045316, "GPQA Raw": 0.2843959731543625, "GPQA": 4.586129753914999, "MUSR Raw": 0.4586145833333333, "MUSR": 16.560156250000002, "MMLU-PRO Raw": 0.3731715425531915, "MMLU-PRO": 30.352393617021285, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-27T00:00:00", "Submission Date": "2024-09-29T00:00:00", "Generation": 1, "Base Model": "Qwen/Qwen2-7B"}, {"eval_name": "MaziyarPanahi_calme-2.7-qwen2-7b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/MaziyarPanahi/calme-2.7-qwen2-7b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">MaziyarPanahi/calme-2.7-qwen2-7b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/MaziyarPanahi__calme-2.7-qwen2-7b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "MaziyarPanahi/calme-2.7-qwen2-7b", "Model sha": "edc11a1baccedc04a5a4576ee4910fd8922ad47f", "Average \u2b06\ufe0f": 22.065740464307083, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3592301759331906, "IFEval": 35.92301759331906, "BBH Raw": 0.4883170901309997, "BBH": 28.912244614673995, "MATH Lvl 5 Raw": 0.120845921450151, "MATH Lvl 5": 12.084592145015106, "GPQA Raw": 0.2911073825503356, "GPQA": 5.480984340044745, "MUSR Raw": 0.4824270833333333, "MUSR": 19.93671875, "MMLU-PRO Raw": 0.3705119680851064, "MMLU-PRO": 30.056885342789595, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-27T00:00:00", "Submission Date": "2024-09-18T00:00:00", "Generation": 1, "Base Model": "Qwen/Qwen2-7B"}, {"eval_name": "Mxode_NanoLM-0.3B-Instruct-v1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Mxode/NanoLM-0.3B-Instruct-v1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Mxode/NanoLM-0.3B-Instruct-v1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Mxode__NanoLM-0.3B-Instruct-v1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Mxode/NanoLM-0.3B-Instruct-v1", "Model sha": "638cda2c122e96c7992227b56b29967d9c8fd57e", "Average \u2b06\ufe0f": 5.498565044787242, "Hub License": "gpl-3.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.1536744726215331, "IFEval": 15.36744726215331, "BBH Raw": 0.3028246216476712, "BBH": 3.104609898338746, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2718120805369127, "GPQA": 2.9082774049217, "MUSR Raw": 0.4155208333333333, "MUSR": 10.440104166666668, "MMLU-PRO Raw": 0.1105385638297872, "MMLU-PRO": 1.1709515366430252, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-03T00:00:00", "Submission Date": "2024-09-05T00:00:00", "Generation": 0, "Base Model": "Mxode/NanoLM-0.3B-Instruct-v1"}, {"eval_name": "Mxode_NanoLM-0.3B-Instruct-v1.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Mxode/NanoLM-0.3B-Instruct-v1.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Mxode/NanoLM-0.3B-Instruct-v1.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Mxode__NanoLM-0.3B-Instruct-v1.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Mxode/NanoLM-0.3B-Instruct-v1.1", "Model sha": "7338464708c691667b193e7bb8f6b5bb3f9df27d", "Average \u2b06\ufe0f": 5.861005557078461, "Hub License": "gpl-3.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.1782791881097709, "IFEval": 17.827918810977096, "BBH Raw": 0.3014403673764691, "BBH": 3.0952799822018195, "MATH Lvl 5 Raw": 0.0067975830815709, "MATH Lvl 5": 0.6797583081570997, "GPQA Raw": 0.25, "GPQA": 0.0, "MUSR Raw": 0.4273333333333333, "MUSR": 12.216666666666669, "MMLU-PRO Raw": 0.1121176861702127, "MMLU-PRO": 1.3464095744680846, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-05T00:00:00", "Submission Date": "2024-09-05T00:00:00", "Generation": 0, "Base Model": "Mxode/NanoLM-0.3B-Instruct-v1.1"}, {"eval_name": "Mxode_NanoLM-0.3B-Instruct-v2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Mxode/NanoLM-0.3B-Instruct-v2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Mxode/NanoLM-0.3B-Instruct-v2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Mxode__NanoLM-0.3B-Instruct-v2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Mxode/NanoLM-0.3B-Instruct-v2", "Model sha": "40027e2a1a404144975cfc0dd7d354057b98854b", "Average \u2b06\ufe0f": 4.900377500631554, "Hub License": "gpl-3.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.1667885654507817, "IFEval": 16.67885654507817, "BBH Raw": 0.2921103945685064, "BBH": 2.2094810446663797, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2609060402684564, "GPQA": 1.45413870246085, "MUSR Raw": 0.3954583333333333, "MUSR": 7.565625, "MMLU-PRO Raw": 0.1134474734042553, "MMLU-PRO": 1.4941637115839237, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-07T00:00:00", "Submission Date": "2024-09-08T00:00:00", "Generation": 0, "Base Model": "Mxode/NanoLM-0.3B-Instruct-v2"}, {"eval_name": "Mxode_NanoLM-1B-Instruct-v1.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Mxode/NanoLM-1B-Instruct-v1.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Mxode/NanoLM-1B-Instruct-v1.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Mxode__NanoLM-1B-Instruct-v1.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Mxode/NanoLM-1B-Instruct-v1.1", "Model sha": "cad6274afcfcf33927dc6c116d63013dcc1dfc48", "Average \u2b06\ufe0f": 6.630842074042275, "Hub License": "gpl-3.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 1, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2395288944445183, "IFEval": 23.952889444451834, "BBH Raw": 0.3183501205959037, "BBH": 6.106919191919192, "MATH Lvl 5 Raw": 0.0287009063444108, "MATH Lvl 5": 2.8700906344410875, "GPQA Raw": 0.2634228187919463, "GPQA": 1.789709172259505, "MUSR Raw": 0.3432708333333333, "MUSR": 2.675520833333333, "MMLU-PRO Raw": 0.1215093085106382, "MMLU-PRO": 2.3899231678486985, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-07T00:00:00", "Submission Date": "2024-09-08T00:00:00", "Generation": 0, "Base Model": "Mxode/NanoLM-1B-Instruct-v1.1"}, {"eval_name": "Mxode_NanoLM-1B-Instruct-v2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Mxode/NanoLM-1B-Instruct-v2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Mxode/NanoLM-1B-Instruct-v2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Mxode__NanoLM-1B-Instruct-v2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Mxode/NanoLM-1B-Instruct-v2", "Model sha": "ebd8c374447985dbd4e247ffe6c5ebb5b4910418", "Average \u2b06\ufe0f": 7.001947325260577, "Hub License": "gpl-3.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 1, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2629844368497808, "IFEval": 26.29844368497808, "BBH Raw": 0.3123145400715591, "BBH": 4.910622895622894, "MATH Lvl 5 Raw": 0.0203927492447129, "MATH Lvl 5": 2.0392749244712998, "GPQA Raw": 0.2634228187919463, "GPQA": 1.789709172259505, "MUSR Raw": 0.3552083333333333, "MUSR": 4.3343750000000005, "MMLU-PRO Raw": 0.1237533244680851, "MMLU-PRO": 2.639258274231678, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-07T00:00:00", "Submission Date": "2024-09-09T00:00:00", "Generation": 0, "Base Model": "Mxode/NanoLM-1B-Instruct-v2"}, {"eval_name": "NAPS-ai_naps-llama-3_1-8b-instruct-v0.3_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/NAPS-ai/naps-llama-3_1-8b-instruct-v0.3\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">NAPS-ai/naps-llama-3_1-8b-instruct-v0.3</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/NAPS-ai__naps-llama-3_1-8b-instruct-v0.3-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "NAPS-ai/naps-llama-3_1-8b-instruct-v0.3", "Model sha": "3dcd36be024e02de712d537f8786d868659127bb", "Average \u2b06\ufe0f": 22.648931679771465, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.5390818583580456, "IFEval": 53.90818583580456, "BBH Raw": 0.4900525115527062, "BBH": 26.27454019814682, "MATH Lvl 5 Raw": 0.1525679758308157, "MATH Lvl 5": 15.256797583081571, "GPQA Raw": 0.299496644295302, "GPQA": 6.599552572706939, "MUSR Raw": 0.3787083333333333, "MUSR": 7.205208333333334, "MMLU-PRO Raw": 0.33984375, "MMLU-PRO": 26.649305555555557, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-02T00:00:00", "Submission Date": "2024-09-30T00:00:00", "Generation": 0, "Base Model": "NAPS-ai/naps-llama-3_1-8b-instruct-v0.3"}, {"eval_name": "NAPS-ai_naps-llama-3_1-8b-instruct-v0.4_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/NAPS-ai/naps-llama-3_1-8b-instruct-v0.4\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">NAPS-ai/naps-llama-3_1-8b-instruct-v0.4</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/NAPS-ai__naps-llama-3_1-8b-instruct-v0.4-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "NAPS-ai/naps-llama-3_1-8b-instruct-v0.4", "Model sha": "152229e8de5270aea7b9d7689503fb2577f8911a", "Average \u2b06\ufe0f": 27.312264799580262, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7344202272193336, "IFEval": 73.44202272193337, "BBH Raw": 0.4861833360906734, "BBH": 27.832818693945708, "MATH Lvl 5 Raw": 0.1722054380664652, "MATH Lvl 5": 17.220543806646525, "GPQA Raw": 0.2793624161073825, "GPQA": 3.9149888143176734, "MUSR Raw": 0.4421145833333333, "MUSR": 13.964322916666667, "MMLU-PRO Raw": 0.3474900265957447, "MMLU-PRO": 27.498891843971627, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-12T00:00:00", "Submission Date": "2024-09-30T00:00:00", "Generation": 1, "Base Model": "NAPS-ai/naps-llama-3_1-8b-instruct-v0.4 (Merge)"}, {"eval_name": "NAPS-ai_naps-llama-3_1-instruct-v0.5.0_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/NAPS-ai/naps-llama-3_1-instruct-v0.5.0\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">NAPS-ai/naps-llama-3_1-instruct-v0.5.0</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/NAPS-ai__naps-llama-3_1-instruct-v0.5.0-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "NAPS-ai/naps-llama-3_1-instruct-v0.5.0", "Model sha": "bf6d3578346e80c586ec1a4a9883079523b48c11", "Average \u2b06\ufe0f": 15.82458922712433, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5020124381086628, "IFEval": 50.20124381086628, "BBH Raw": 0.4147584365689691, "BBH": 18.110133310152776, "MATH Lvl 5 Raw": 0.0256797583081571, "MATH Lvl 5": 2.56797583081571, "GPQA Raw": 0.2684563758389262, "GPQA": 2.460850111856823, "MUSR Raw": 0.3712708333333332, "MUSR": 3.675520833333333, "MMLU-PRO Raw": 0.2613863031914893, "MMLU-PRO": 17.93181146572104, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-12T00:00:00", "Submission Date": "2024-09-30T00:00:00", "Generation": 0, "Base Model": "NAPS-ai/naps-llama-3_1-instruct-v0.5.0"}, {"eval_name": "NLPark_AnFeng_v3.1-Avocet_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/NLPark/AnFeng_v3.1-Avocet\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">NLPark/AnFeng_v3.1-Avocet</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/NLPark__AnFeng_v3.1-Avocet-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "NLPark/AnFeng_v3.1-Avocet", "Model sha": "5170739731033323e6e66a0f68d34790042a3b2a", "Average \u2b06\ufe0f": 28.05107719474438, "Hub License": "cc-by-nc-nd-4.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 34, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.5096311121158525, "IFEval": 50.96311121158526, "BBH Raw": 0.582852329074409, "BBH": 40.309033651453255, "MATH Lvl 5 Raw": 0.1389728096676737, "MATH Lvl 5": 13.897280966767372, "GPQA Raw": 0.3246644295302013, "GPQA": 9.955257270693512, "MUSR Raw": 0.4475729166666666, "MUSR": 14.979947916666662, "MMLU-PRO Raw": 0.4438164893617021, "MMLU-PRO": 38.20183215130024, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-03T00:00:00", "Submission Date": "2024-08-07T00:00:00", "Generation": 0, "Base Model": "NLPark/AnFeng_v3.1-Avocet"}, {"eval_name": "NLPark_B-and-W_Flycatcher-3AD1E_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/NLPark/B-and-W_Flycatcher-3AD1E\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">NLPark/B-and-W_Flycatcher-3AD1E</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/NLPark__B-and-W_Flycatcher-3AD1E-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "NLPark/B-and-W_Flycatcher-3AD1E", "Model sha": "21044e39f6854f5a6df84c5074d449b7eb96b522", "Average \u2b06\ufe0f": 29.120404453120823, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 14, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4908465094837254, "IFEval": 49.08465094837254, "BBH Raw": 0.6065117528534355, "BBH": 43.74245801092346, "MATH Lvl 5 Raw": 0.1570996978851963, "MATH Lvl 5": 15.709969788519636, "GPQA Raw": 0.3305369127516778, "GPQA": 10.738255033557047, "MUSR Raw": 0.4422708333333333, "MUSR": 13.883854166666673, "MMLU-PRO Raw": 0.4740691489361702, "MMLU-PRO": 41.56323877068557, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-28T00:00:00", "Submission Date": "2024-09-28T00:00:00", "Generation": 0, "Base Model": "NLPark/B-and-W_Flycatcher-3AD1E"}, {"eval_name": "NTQAI_Nxcode-CQ-7B-orpo_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/NTQAI/Nxcode-CQ-7B-orpo\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">NTQAI/Nxcode-CQ-7B-orpo</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/NTQAI__Nxcode-CQ-7B-orpo-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "NTQAI/Nxcode-CQ-7B-orpo", "Model sha": "74f3b3c06de36b261af9ef857279d6e33f893336", "Average \u2b06\ufe0f": 12.298250998539771, "Hub License": "other", "Hub \u2764\ufe0f": 97, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4007211975336551, "IFEval": 40.07211975336551, "BBH Raw": 0.4143023249178217, "BBH": 17.58000487008142, "MATH Lvl 5 Raw": 0.0173716012084592, "MATH Lvl 5": 1.7371601208459215, "GPQA Raw": 0.2541946308724832, "GPQA": 0.5592841163310973, "MUSR Raw": 0.39396875, "MUSR": 7.04609375, "MMLU-PRO Raw": 0.1611535904255319, "MMLU-PRO": 6.794843380614658, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-24T00:00:00", "Submission Date": "2024-08-10T00:00:00", "Generation": 0, "Base Model": "NTQAI/Nxcode-CQ-7B-orpo"}, {"eval_name": "NYTK_PULI-GPTrio_float16", "Precision": "float16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "GPTNeoXForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/NYTK/PULI-GPTrio\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">NYTK/PULI-GPTrio</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/NYTK__PULI-GPTrio-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "NYTK/PULI-GPTrio", "Model sha": "16a56dd22d184e4b7b49d90461fa8d4810639463", "Average \u2b06\ufe0f": 5.758199210150148, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 10, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2179716485591563, "IFEval": 21.79716485591564, "BBH Raw": 0.3060029090623754, "BBH": 3.015221141570497, "MATH Lvl 5 Raw": 0.0075528700906344, "MATH Lvl 5": 0.7552870090634441, "GPQA Raw": 0.2659395973154362, "GPQA": 2.1252796420581683, "MUSR Raw": 0.3818749999999999, "MUSR": 5.3343750000000005, "MMLU-PRO Raw": 0.1136968085106382, "MMLU-PRO": 1.521867612293143, "Maintainer's Highlight": false, "Upload To Hub Date": "2023-06-08T00:00:00", "Submission Date": "2024-08-24T00:00:00", "Generation": 0, "Base Model": "NYTK/PULI-GPTrio"}, {"eval_name": "NYTK_PULI-LlumiX-32K_float16", "Precision": "float16", "Type": "\ud83d\udfe9 continuously pretrained", "T": "\ud83d\udfe9", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/NYTK/PULI-LlumiX-32K\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">NYTK/PULI-LlumiX-32K</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/NYTK__PULI-LlumiX-32K-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "NYTK/PULI-LlumiX-32K", "Model sha": "a589894397a36b61c578d0dd4778ee6e5fe471ff", "Average \u2b06\ufe0f": 6.4058163053555175, "Hub License": "llama2", "Hub \u2764\ufe0f": 9, "#Params (B)": 6, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1699612583500667, "IFEval": 16.99612583500667, "BBH Raw": 0.3189358224294937, "BBH": 5.107047129907727, "MATH Lvl 5 Raw": 0.0060422960725075, "MATH Lvl 5": 0.6042296072507553, "GPQA Raw": 0.2533557046979866, "GPQA": 0.4474272930648763, "MUSR Raw": 0.3964166666666666, "MUSR": 7.718750000000001, "MMLU-PRO Raw": 0.1680518617021276, "MMLU-PRO": 7.561317966903072, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-03-12T00:00:00", "Submission Date": "2024-08-24T00:00:00", "Generation": 0, "Base Model": "NYTK/PULI-LlumiX-32K"}, {"eval_name": "Naveenpoliasetty_llama3-8B-V2_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Naveenpoliasetty/llama3-8B-V2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Naveenpoliasetty/llama3-8B-V2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Naveenpoliasetty__llama3-8B-V2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Naveenpoliasetty/llama3-8B-V2", "Model sha": "e0458381d02bc411b9e576796d185f23dcc11f71", "Average \u2b06\ufe0f": 20.694805569454903, "Hub License": null, "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4122616878770551, "IFEval": 41.226168787705504, "BBH Raw": 0.5188657580065063, "BBH": 30.873209425039573, "MATH Lvl 5 Raw": 0.0709969788519637, "MATH Lvl 5": 7.099697885196375, "GPQA Raw": 0.2902684563758389, "GPQA": 5.369127516778524, "MUSR Raw": 0.4081354166666666, "MUSR": 9.183593750000002, "MMLU-PRO Raw": 0.3737533244680851, "MMLU-PRO": 30.41703605200945, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-18T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "Naveenpoliasetty/llama3-8B-V2 (Merge)"}, {"eval_name": "Nekochu_Llama-3.1-8B-German-ORPO_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Nekochu/Llama-3.1-8B-German-ORPO\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Nekochu/Llama-3.1-8B-German-ORPO</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Nekochu__Llama-3.1-8B-German-ORPO-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Nekochu/Llama-3.1-8B-German-ORPO", "Model sha": "463ea77e46fb6d69c86f23df21b0ab0a0b9e77cd", "Average \u2b06\ufe0f": 21.302894109086605, "Hub License": "llama3.1", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4610710692074806, "IFEval": 46.10710692074806, "BBH Raw": 0.4982577044334462, "BBH": 29.419254274936463, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.3162751677852349, "GPQA": 8.83668903803132, "MUSR Raw": 0.46475, "MUSR": 16.860416666666666, "MMLU-PRO Raw": 0.339345079787234, "MMLU-PRO": 26.593897754137117, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-13T00:00:00", "Submission Date": "2024-09-24T00:00:00", "Generation": 2, "Base Model": "meta-llama/Meta-Llama-3.1-8B"}, {"eval_name": "Nekochu_Llama-3.1-8B-french-DPO_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Nekochu/Llama-3.1-8B-french-DPO\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Nekochu/Llama-3.1-8B-french-DPO</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Nekochu__Llama-3.1-8B-french-DPO-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Nekochu/Llama-3.1-8B-french-DPO", "Model sha": "b0c66dd2a2814a6bfb05313ffec856fd4c6c7bd7", "Average \u2b06\ufe0f": 20.757183551091423, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4656422736117944, "IFEval": 46.56422736117945, "BBH Raw": 0.5110888403999433, "BBH": 30.03259699633449, "MATH Lvl 5 Raw": 0.0407854984894259, "MATH Lvl 5": 4.078549848942599, "GPQA Raw": 0.2911073825503356, "GPQA": 5.480984340044745, "MUSR Raw": 0.4215625, "MUSR": 11.561979166666667, "MMLU-PRO Raw": 0.3414228723404255, "MMLU-PRO": 26.824763593380613, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-12T00:00:00", "Submission Date": "2024-10-12T00:00:00", "Generation": 1, "Base Model": "NousResearch/Meta-Llama-3.1-8B-Instruct"}, {"eval_name": "Nekochu_Luminia-13B-v3_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Nekochu/Luminia-13B-v3\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Nekochu/Luminia-13B-v3</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Nekochu__Luminia-13B-v3-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Nekochu/Luminia-13B-v3", "Model sha": "602563f3af32b3c6be067ad522e6f3eaff4f8627", "Average \u2b06\ufe0f": 11.546959822842666, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 4, "#Params (B)": 13, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.252318293239715, "IFEval": 25.231829323971507, "BBH Raw": 0.4112151551092962, "BBH": 17.690523920374847, "MATH Lvl 5 Raw": 0.0128398791540785, "MATH Lvl 5": 1.283987915407855, "GPQA Raw": 0.2701342281879195, "GPQA": 2.684563758389265, "MUSR Raw": 0.3983333333333334, "MUSR": 8.891666666666667, "MMLU-PRO Raw": 0.2214926861702127, "MMLU-PRO": 13.499187352245862, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-03-18T00:00:00", "Submission Date": "2024-09-25T00:00:00", "Generation": 1, "Base Model": "meta-llama/Llama-2-13b-chat-hf"}, {"eval_name": "Nekochu_Luminia-8B-RP_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Nekochu/Luminia-8B-RP\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Nekochu/Luminia-8B-RP</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Nekochu__Luminia-8B-RP-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Nekochu/Luminia-8B-RP", "Model sha": "619be17206729d86b898b9d1b3369a7135c1a9b9", "Average \u2b06\ufe0f": 24.30338987672522, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.5574165436597118, "IFEval": 55.74165436597117, "BBH Raw": 0.5218151030627874, "BBH": 31.802699112572423, "MATH Lvl 5 Raw": 0.1170694864048338, "MATH Lvl 5": 11.706948640483382, "GPQA Raw": 0.296979865771812, "GPQA": 6.263982102908276, "MUSR Raw": 0.3997604166666666, "MUSR": 11.070052083333328, "MMLU-PRO Raw": 0.3631150265957447, "MMLU-PRO": 29.235002955082745, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-13T00:00:00", "Submission Date": "2024-09-24T00:00:00", "Generation": 2, "Base Model": "meta-llama/Meta-Llama-3.1-8B"}, {"eval_name": "NeverSleep_Lumimaid-v0.2-12B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/NeverSleep/Lumimaid-v0.2-12B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">NeverSleep/Lumimaid-v0.2-12B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/NeverSleep__Lumimaid-v0.2-12B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "NeverSleep/Lumimaid-v0.2-12B", "Model sha": "b04f4e8f9a0c64fbb271d1135b208c90c3aa0ad0", "Average \u2b06\ufe0f": 17.76967093202197, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 76, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1099349725395284, "IFEval": 10.993497253952846, "BBH Raw": 0.5395610525850818, "BBH": 34.40988943485442, "MATH Lvl 5 Raw": 0.0339879154078549, "MATH Lvl 5": 3.3987915407854987, "GPQA Raw": 0.3145973154362416, "GPQA": 8.612975391498878, "MUSR Raw": 0.4821145833333333, "MUSR": 21.297656250000003, "MMLU-PRO Raw": 0.3511469414893617, "MMLU-PRO": 27.905215721040182, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-25T00:00:00", "Submission Date": "2024-07-31T00:00:00", "Generation": 0, "Base Model": "NeverSleep/Lumimaid-v0.2-12B"}, {"eval_name": "NeverSleep_Lumimaid-v0.2-8B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/NeverSleep/Lumimaid-v0.2-8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">NeverSleep/Lumimaid-v0.2-8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/NeverSleep__Lumimaid-v0.2-8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "NeverSleep/Lumimaid-v0.2-8B", "Model sha": "4563201f29ef18c62d16e9f6fffd3931a63ccb51", "Average \u2b06\ufe0f": 24.12246989390819, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 63, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.5038109992597419, "IFEval": 50.3810999259742, "BBH Raw": 0.5237767601226618, "BBH": 31.963373781180238, "MATH Lvl 5 Raw": 0.1261329305135951, "MATH Lvl 5": 12.613293051359516, "GPQA Raw": 0.311241610738255, "GPQA": 8.165548098434002, "MUSR Raw": 0.4303020833333333, "MUSR": 12.32109375, "MMLU-PRO Raw": 0.3636136968085106, "MMLU-PRO": 29.290410756501185, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-24T00:00:00", "Submission Date": "2024-08-09T00:00:00", "Generation": 0, "Base Model": "NeverSleep/Lumimaid-v0.2-8B"}, {"eval_name": "Nexusflow_NexusRaven-V2-13B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Nexusflow/NexusRaven-V2-13B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Nexusflow/NexusRaven-V2-13B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Nexusflow__NexusRaven-V2-13B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Nexusflow/NexusRaven-V2-13B", "Model sha": "cdab7132db4a4fd64513123374ea1451d85a7ace", "Average \u2b06\ufe0f": 8.299243034538407, "Hub License": "other", "Hub \u2764\ufe0f": 460, "#Params (B)": 13, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1790781792311068, "IFEval": 17.90781792311068, "BBH Raw": 0.3948860464050733, "BBH": 15.336448395229596, "MATH Lvl 5 Raw": 0.0181268882175226, "MATH Lvl 5": 1.812688821752266, "GPQA Raw": 0.2600671140939597, "GPQA": 1.342281879194629, "MUSR Raw": 0.3736875, "MUSR": 3.7109375, "MMLU-PRO Raw": 0.1871675531914893, "MMLU-PRO": 9.685283687943262, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-12-04T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 1, "Base Model": "codellama/CodeLlama-13b-Instruct-hf"}, {"eval_name": "Nitral-AI_Hathor_Stable-v0.2-L3-8B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Nitral-AI/Hathor_Stable-v0.2-L3-8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Nitral-AI/Hathor_Stable-v0.2-L3-8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Nitral-AI__Hathor_Stable-v0.2-L3-8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Nitral-AI/Hathor_Stable-v0.2-L3-8B", "Model sha": "1c9f391c3e349f8ba51b5696290ee6db6a2b63fd", "Average \u2b06\ufe0f": 25.703958752610955, "Hub License": "other", "Hub \u2764\ufe0f": 55, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7174840534226963, "IFEval": 71.74840534226962, "BBH Raw": 0.5285819178301682, "BBH": 32.826028565585965, "MATH Lvl 5 Raw": 0.0921450151057401, "MATH Lvl 5": 9.214501510574015, "GPQA Raw": 0.2869127516778523, "GPQA": 4.921700223713646, "MUSR Raw": 0.3780625, "MUSR": 5.557812500000004, "MMLU-PRO Raw": 0.3695977393617021, "MMLU-PRO": 29.955304373522463, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-09T00:00:00", "Submission Date": "2024-07-02T00:00:00", "Generation": 0, "Base Model": "Nitral-AI/Hathor_Stable-v0.2-L3-8B"}, {"eval_name": "NotASI_FineTome-Llama3.2-1B-0929_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/NotASI/FineTome-Llama3.2-1B-0929\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">NotASI/FineTome-Llama3.2-1B-0929</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/NotASI__FineTome-Llama3.2-1B-0929-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "NotASI/FineTome-Llama3.2-1B-0929", "Model sha": "61c8742238d0cfe68a0a3f61326b84cd6624ad02", "Average \u2b06\ufe0f": 9.562948978547835, "Hub License": "llama3.2", "Hub \u2764\ufe0f": 1, "#Params (B)": 1, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.399072239435808, "IFEval": 39.9072239435808, "BBH Raw": 0.3246274874705644, "BBH": 5.741405038838561, "MATH Lvl 5 Raw": 0.0128398791540785, "MATH Lvl 5": 1.283987915407855, "GPQA Raw": 0.2726510067114094, "GPQA": 3.0201342281879207, "MUSR Raw": 0.3487604166666667, "MUSR": 2.6617187500000004, "MMLU-PRO Raw": 0.1428690159574468, "MMLU-PRO": 4.763223995271866, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-29T00:00:00", "Submission Date": "2024-10-04T00:00:00", "Generation": 2, "Base Model": "meta-llama/Llama-3.2-1B-Instruct"}, {"eval_name": "NotASI_FineTome-Llama3.2-3B-1002_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/NotASI/FineTome-Llama3.2-3B-1002\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">NotASI/FineTome-Llama3.2-3B-1002</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/NotASI__FineTome-Llama3.2-3B-1002-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "NotASI/FineTome-Llama3.2-3B-1002", "Model sha": "7c8497a24a381e3bfd77bc92e5685442768790d0", "Average \u2b06\ufe0f": 16.59875478635249, "Hub License": "llama3.2", "Hub \u2764\ufe0f": 1, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5474496558021605, "IFEval": 54.744965580216046, "BBH Raw": 0.4319470614025341, "BBH": 19.52006065248879, "MATH Lvl 5 Raw": 0.052870090634441, "MATH Lvl 5": 5.287009063444108, "GPQA Raw": 0.2508389261744966, "GPQA": 0.1118568232662209, "MUSR Raw": 0.3685104166666667, "MUSR": 3.963802083333334, "MMLU-PRO Raw": 0.2436835106382978, "MMLU-PRO": 15.96483451536643, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-04T00:00:00", "Submission Date": "2024-10-05T00:00:00", "Generation": 2, "Base Model": "meta-llama/Llama-3.2-3B-Instruct"}, {"eval_name": "NotASI_FineTome-v1.5-Llama3.2-1B-1007_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/NotASI/FineTome-v1.5-Llama3.2-1B-1007\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">NotASI/FineTome-v1.5-Llama3.2-1B-1007</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/NotASI__FineTome-v1.5-Llama3.2-1B-1007-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "NotASI/FineTome-v1.5-Llama3.2-1B-1007", "Model sha": "5e329d987e9f74dd2703a4fefa56ab8c72b5702b", "Average \u2b06\ufe0f": 8.940455389326333, "Hub License": "llama3.2", "Hub \u2764\ufe0f": 1, "#Params (B)": 1, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3923777798463632, "IFEval": 39.23777798463632, "BBH Raw": 0.3240567112148566, "BBH": 5.801724673541757, "MATH Lvl 5 Raw": 0.0135951661631419, "MATH Lvl 5": 1.3595166163141994, "GPQA Raw": 0.25, "GPQA": 0.0, "MUSR Raw": 0.3474583333333333, "MUSR": 2.498958333333334, "MMLU-PRO Raw": 0.1427027925531915, "MMLU-PRO": 4.744754728132387, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-07T00:00:00", "Submission Date": "2024-10-07T00:00:00", "Generation": 1, "Base Model": "NotASI/FineTome-v1.5-Llama3.2-1B-1007 (Merge)"}, {"eval_name": "NotASI_FineTome-v1.5-Llama3.2-3B-1007_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/NotASI/FineTome-v1.5-Llama3.2-3B-1007\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">NotASI/FineTome-v1.5-Llama3.2-3B-1007</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/NotASI__FineTome-v1.5-Llama3.2-3B-1007-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "NotASI/FineTome-v1.5-Llama3.2-3B-1007", "Model sha": "6c6e71fbcff6c00d04a3fd69084af20bf2a943c8", "Average \u2b06\ufe0f": 16.899698226725288, "Hub License": "llama3.2", "Hub \u2764\ufe0f": 1, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5507719517546776, "IFEval": 55.07719517546776, "BBH Raw": 0.4312372935321582, "BBH": 19.457219278849333, "MATH Lvl 5 Raw": 0.0513595166163142, "MATH Lvl 5": 5.13595166163142, "GPQA Raw": 0.261744966442953, "GPQA": 1.5659955257270708, "MUSR Raw": 0.3645416666666667, "MUSR": 4.067708333333334, "MMLU-PRO Raw": 0.2448470744680851, "MMLU-PRO": 16.094119385342786, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-07T00:00:00", "Submission Date": "2024-10-07T00:00:00", "Generation": 1, "Base Model": "NotASI/FineTome-v1.5-Llama3.2-3B-1007 (Merge)"}, {"eval_name": "NousResearch_Hermes-2-Pro-Llama-3-8B_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/NousResearch/Hermes-2-Pro-Llama-3-8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">NousResearch/Hermes-2-Pro-Llama-3-8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/NousResearch__Hermes-2-Pro-Llama-3-8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "NousResearch/Hermes-2-Pro-Llama-3-8B", "Model sha": "bc265d1781299ed2045214289c927c207439a729", "Average \u2b06\ufe0f": 21.629391632905307, "Hub License": "llama3", "Hub \u2764\ufe0f": 403, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5361839918084017, "IFEval": 53.61839918084017, "BBH Raw": 0.507112624310082, "BBH": 30.667993420825, "MATH Lvl 5 Raw": 0.0574018126888217, "MATH Lvl 5": 5.740181268882175, "GPQA Raw": 0.2927852348993288, "GPQA": 5.7046979865771785, "MUSR Raw": 0.4262395833333333, "MUSR": 11.246614583333336, "MMLU-PRO Raw": 0.3051861702127659, "MMLU-PRO": 22.798463356973997, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-04-30T00:00:00", "Submission Date": "2024-06-13T00:00:00", "Generation": 1, "Base Model": "NousResearch/Meta-Llama-3-8B"}, {"eval_name": "NousResearch_Hermes-2-Pro-Mistral-7B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/NousResearch/Hermes-2-Pro-Mistral-7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">NousResearch/Hermes-2-Pro-Mistral-7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/NousResearch__Hermes-2-Pro-Mistral-7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "NousResearch/Hermes-2-Pro-Mistral-7B", "Model sha": "09317b1d8da639b5d9af77c06aa17cde0f0f91c0", "Average \u2b06\ufe0f": 21.639166938124102, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 483, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5668337788179807, "IFEval": 56.68337788179808, "BBH Raw": 0.4995435330498075, "BBH": 29.427578860536, "MATH Lvl 5 Raw": 0.0483383685800604, "MATH Lvl 5": 4.833836858006042, "GPQA Raw": 0.273489932885906, "GPQA": 3.1319910514541416, "MUSR Raw": 0.43759375, "MUSR": 14.132552083333335, "MMLU-PRO Raw": 0.2946309840425531, "MMLU-PRO": 21.625664893617017, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-03-11T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 1, "Base Model": "mistralai/Mistral-7B-v0.1"}, {"eval_name": "NousResearch_Hermes-2-Theta-Llama-3-8B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/NousResearch/Hermes-2-Theta-Llama-3-8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">NousResearch/Hermes-2-Theta-Llama-3-8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/NousResearch__Hermes-2-Theta-Llama-3-8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "NousResearch/Hermes-2-Theta-Llama-3-8B", "Model sha": "885173e97ab8572b444f7db1290d5d0386e26816", "Average \u2b06\ufe0f": 24.62473094217658, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 193, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6517883659800441, "IFEval": 65.17883659800441, "BBH Raw": 0.5206672260911865, "BBH": 32.046073848075835, "MATH Lvl 5 Raw": 0.086858006042296, "MATH Lvl 5": 8.685800604229607, "GPQA Raw": 0.3036912751677852, "GPQA": 7.158836689038028, "MUSR Raw": 0.3948958333333334, "MUSR": 8.36197916666667, "MMLU-PRO Raw": 0.3368517287234042, "MMLU-PRO": 26.316858747044915, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-05-05T00:00:00", "Submission Date": "2024-07-11T00:00:00", "Generation": 2, "Base Model": "NousResearch/Meta-Llama-3-8B"}, {"eval_name": "NousResearch_Hermes-3-Llama-3.1-70B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/NousResearch/Hermes-3-Llama-3.1-70B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">NousResearch/Hermes-3-Llama-3.1-70B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/NousResearch__Hermes-3-Llama-3.1-70B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "NousResearch/Hermes-3-Llama-3.1-70B", "Model sha": "093242c69a91f8d9d5b8094c380b88772f9bd7f8", "Average \u2b06\ufe0f": 37.30631145899745, "Hub License": "llama3", "Hub \u2764\ufe0f": 79, "#Params (B)": 70, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7661438316998896, "IFEval": 76.61438316998897, "BBH Raw": 0.6755780641387483, "BBH": 53.76540869130056, "MATH Lvl 5 Raw": 0.1374622356495468, "MATH Lvl 5": 13.746223564954684, "GPQA Raw": 0.3615771812080537, "GPQA": 14.87695749440716, "MUSR Raw": 0.4948958333333333, "MUSR": 23.42864583333333, "MMLU-PRO Raw": 0.47265625, "MMLU-PRO": 41.40625, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-07-29T00:00:00", "Submission Date": "2024-08-28T00:00:00", "Generation": 1, "Base Model": "meta-llama/Meta-Llama-3.1-70B"}, {"eval_name": "NousResearch_Hermes-3-Llama-3.1-8B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/NousResearch/Hermes-3-Llama-3.1-8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">NousResearch/Hermes-3-Llama-3.1-8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/NousResearch__Hermes-3-Llama-3.1-8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "NousResearch/Hermes-3-Llama-3.1-8B", "Model sha": "aabb745a717e133b74dcae23195d2635cf5f38cc", "Average \u2b06\ufe0f": 23.49087671148001, "Hub License": "llama3", "Hub \u2764\ufe0f": 212, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6170172918966121, "IFEval": 61.70172918966122, "BBH Raw": 0.5177452540141246, "BBH": 30.724096614147957, "MATH Lvl 5 Raw": 0.0475830815709969, "MATH Lvl 5": 4.758308157099698, "GPQA Raw": 0.2978187919463087, "GPQA": 6.375838926174497, "MUSR Raw": 0.4369375, "MUSR": 13.617187499999996, "MMLU-PRO Raw": 0.3139128989361702, "MMLU-PRO": 23.768099881796687, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-07-28T00:00:00", "Submission Date": "2024-08-28T00:00:00", "Generation": 1, "Base Model": "meta-llama/Meta-Llama-3.1-8B"}, {"eval_name": "NousResearch_Nous-Hermes-2-Mistral-7B-DPO_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/NousResearch/Nous-Hermes-2-Mistral-7B-DPO\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">NousResearch/Nous-Hermes-2-Mistral-7B-DPO</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/NousResearch__Nous-Hermes-2-Mistral-7B-DPO-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "NousResearch/Nous-Hermes-2-Mistral-7B-DPO", "Model sha": "ebec0a691037d38955727d6949798429a63929dd", "Average \u2b06\ufe0f": 21.01247015664927, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 165, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5762510139762497, "IFEval": 57.62510139762497, "BBH Raw": 0.4852653665465234, "BBH": 27.792545658366084, "MATH Lvl 5 Raw": 0.0422960725075528, "MATH Lvl 5": 4.229607250755287, "GPQA Raw": 0.2927852348993288, "GPQA": 5.7046979865771785, "MUSR Raw": 0.3999791666666667, "MUSR": 8.330729166666668, "MMLU-PRO Raw": 0.3015292553191489, "MMLU-PRO": 22.392139479905435, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-02-18T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 1, "Base Model": "mistralai/Mistral-7B-v0.1"}, {"eval_name": "NousResearch_Nous-Hermes-2-Mixtral-8x7B-DPO_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/NousResearch__Nous-Hermes-2-Mixtral-8x7B-DPO-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO", "Model sha": "286ae6737d048ad1d965c2e830864df02db50f2f", "Average \u2b06\ufe0f": 27.1266043358526, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 416, "#Params (B)": 46, "Available on the hub": true, "Not_Merged": true, "MoE": false, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5896898008395501, "IFEval": 58.96898008395502, "BBH Raw": 0.5538851384033822, "BBH": 37.10778379133987, "MATH Lvl 5 Raw": 0.1087613293051359, "MATH Lvl 5": 10.876132930513595, "GPQA Raw": 0.3213087248322148, "GPQA": 9.50782997762864, "MUSR Raw": 0.4595416666666667, "MUSR": 16.676041666666666, "MMLU-PRO Raw": 0.3666057180851064, "MMLU-PRO": 29.622857565011817, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-01-11T00:00:00", "Submission Date": "2024-07-27T00:00:00", "Generation": 1, "Base Model": "mistralai/Mixtral-8x7B-v0.1"}, {"eval_name": "NousResearch_Nous-Hermes-2-Mixtral-8x7B-SFT_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/NousResearch/Nous-Hermes-2-Mixtral-8x7B-SFT\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">NousResearch/Nous-Hermes-2-Mixtral-8x7B-SFT</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/NousResearch__Nous-Hermes-2-Mixtral-8x7B-SFT-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "NousResearch/Nous-Hermes-2-Mixtral-8x7B-SFT", "Model sha": "4c06af2684730f75a6874b95e8bf6058105d9612", "Average \u2b06\ufe0f": 21.77807030737311, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 55, "#Params (B)": 46, "Available on the hub": true, "Not_Merged": true, "MoE": false, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5730783210769648, "IFEval": 57.30783210769647, "BBH Raw": 0.5057868454026635, "BBH": 30.594312778864406, "MATH Lvl 5 Raw": 0.0173716012084592, "MATH Lvl 5": 1.7371601208459215, "GPQA Raw": 0.3020134228187919, "GPQA": 6.935123042505594, "MUSR Raw": 0.421375, "MUSR": 11.138541666666669, "MMLU-PRO Raw": 0.3065990691489361, "MMLU-PRO": 22.95545212765957, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-12-26T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 1, "Base Model": "mistralai/Mixtral-8x7B-v0.1"}, {"eval_name": "NousResearch_Nous-Hermes-2-SOLAR-10.7B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/NousResearch/Nous-Hermes-2-SOLAR-10.7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">NousResearch/Nous-Hermes-2-SOLAR-10.7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/NousResearch__Nous-Hermes-2-SOLAR-10.7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "NousResearch/Nous-Hermes-2-SOLAR-10.7B", "Model sha": "14c1fbe2f71acdcd58247b30d5439bd572d52386", "Average \u2b06\ufe0f": 23.3244263418266, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 203, "#Params (B)": 10, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5278660620486975, "IFEval": 52.78660620486975, "BBH Raw": 0.5414294841140173, "BBH": 34.990894584465195, "MATH Lvl 5 Raw": 0.0521148036253776, "MATH Lvl 5": 5.211480362537765, "GPQA Raw": 0.2936241610738255, "GPQA": 5.8165548098434, "MUSR Raw": 0.43728125, "MUSR": 13.826822916666664, "MMLU-PRO Raw": 0.3458277925531915, "MMLU-PRO": 27.314199172576835, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-01-01T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 1, "Base Model": "upstage/SOLAR-10.7B-v1.0"}, {"eval_name": "NousResearch_Nous-Hermes-llama-2-7b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/NousResearch/Nous-Hermes-llama-2-7b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">NousResearch/Nous-Hermes-llama-2-7b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/NousResearch__Nous-Hermes-llama-2-7b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "NousResearch/Nous-Hermes-llama-2-7b", "Model sha": "b7c3ec54b754175e006ef75696a2ba3802697078", "Average \u2b06\ufe0f": 9.278951588465931, "Hub License": "mit", "Hub \u2764\ufe0f": 68, "#Params (B)": 6, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1729078844133565, "IFEval": 17.290788441335657, "BBH Raw": 0.3823937686034717, "BBH": 13.78941955171473, "MATH Lvl 5 Raw": 0.0067975830815709, "MATH Lvl 5": 0.6797583081570997, "GPQA Raw": 0.2634228187919463, "GPQA": 1.789709172259505, "MUSR Raw": 0.42571875, "MUSR": 11.681510416666669, "MMLU-PRO Raw": 0.1939827127659574, "MMLU-PRO": 10.442523640661936, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-07-25T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "NousResearch/Nous-Hermes-llama-2-7b"}, {"eval_name": "NousResearch_Yarn-Llama-2-13b-128k_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe9 continuously pretrained", "T": "\ud83d\udfe9", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/NousResearch/Yarn-Llama-2-13b-128k\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">NousResearch/Yarn-Llama-2-13b-128k</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/NousResearch__Yarn-Llama-2-13b-128k-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "NousResearch/Yarn-Llama-2-13b-128k", "Model sha": "4e3e87a067f64f8814c83dd5e3bad92dcf8a2391", "Average \u2b06\ufe0f": 8.393441742149912, "Hub License": null, "Hub \u2764\ufe0f": 114, "#Params (B)": 13, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1654643013869865, "IFEval": 16.546430138698653, "BBH Raw": 0.3826816443733663, "BBH": 13.505319085673955, "MATH Lvl 5 Raw": 0.0113293051359516, "MATH Lvl 5": 1.1329305135951662, "GPQA Raw": 0.2583892617449664, "GPQA": 1.1185682326621946, "MUSR Raw": 0.34575, "MUSR": 3.385416666666666, "MMLU-PRO Raw": 0.2320478723404255, "MMLU-PRO": 14.671985815602836, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-08-30T00:00:00", "Submission Date": "2024-06-13T00:00:00", "Generation": 0, "Base Model": "NousResearch/Yarn-Llama-2-13b-128k"}, {"eval_name": "NousResearch_Yarn-Llama-2-7b-128k_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe9 continuously pretrained", "T": "\ud83d\udfe9", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/NousResearch/Yarn-Llama-2-7b-128k\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">NousResearch/Yarn-Llama-2-7b-128k</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/NousResearch__Yarn-Llama-2-7b-128k-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "NousResearch/Yarn-Llama-2-7b-128k", "Model sha": "e1ceedbbf2ed28b88086794441a6c05606d15437", "Average \u2b06\ufe0f": 6.688919512253983, "Hub License": null, "Hub \u2764\ufe0f": 38, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1484782599059384, "IFEval": 14.847825990593847, "BBH Raw": 0.3248029537559773, "BBH": 6.1446917129934855, "MATH Lvl 5 Raw": 0.0075528700906344, "MATH Lvl 5": 0.7552870090634441, "GPQA Raw": 0.2600671140939597, "GPQA": 1.342281879194629, "MUSR Raw": 0.3966979166666666, "MUSR": 8.253906250000004, "MMLU-PRO Raw": 0.1791057180851064, "MMLU-PRO": 8.789524231678488, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-08-31T00:00:00", "Submission Date": "2024-06-13T00:00:00", "Generation": 0, "Base Model": "NousResearch/Yarn-Llama-2-7b-128k"}, {"eval_name": "NousResearch_Yarn-Llama-2-7b-64k_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe9 continuously pretrained", "T": "\ud83d\udfe9", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/NousResearch/Yarn-Llama-2-7b-64k\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">NousResearch/Yarn-Llama-2-7b-64k</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/NousResearch__Yarn-Llama-2-7b-64k-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "NousResearch/Yarn-Llama-2-7b-64k", "Model sha": "08491431ac3b50add7443f5d4c02850801d877be", "Average \u2b06\ufe0f": 7.122178211045956, "Hub License": null, "Hub \u2764\ufe0f": 23, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1699856381068897, "IFEval": 16.99856381068897, "BBH Raw": 0.3326277865253592, "BBH": 7.0440554144724175, "MATH Lvl 5 Raw": 0.0098187311178247, "MATH Lvl 5": 0.9818731117824772, "GPQA Raw": 0.2642617449664429, "GPQA": 1.9015659955257265, "MUSR Raw": 0.393875, "MUSR": 6.934374999999998, "MMLU-PRO Raw": 0.1798537234042553, "MMLU-PRO": 8.872635933806146, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-08-30T00:00:00", "Submission Date": "2024-06-13T00:00:00", "Generation": 0, "Base Model": "NousResearch/Yarn-Llama-2-7b-64k"}, {"eval_name": "NousResearch_Yarn-Mistral-7b-128k_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe9 continuously pretrained", "T": "\ud83d\udfe9", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/NousResearch/Yarn-Mistral-7b-128k\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">NousResearch/Yarn-Mistral-7b-128k</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/NousResearch__Yarn-Mistral-7b-128k-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "NousResearch/Yarn-Mistral-7b-128k", "Model sha": "d09f1f8ed437d61c1aff94c1beabee554843dcdd", "Average \u2b06\ufe0f": 13.155462341901265, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 570, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1933669330709184, "IFEval": 19.33669330709185, "BBH Raw": 0.4314467711273296, "BBH": 20.633112436478672, "MATH Lvl 5 Raw": 0.0249244712990936, "MATH Lvl 5": 2.492447129909366, "GPQA Raw": 0.2986577181208054, "GPQA": 6.487695749440718, "MUSR Raw": 0.4070520833333333, "MUSR": 8.948177083333333, "MMLU-PRO Raw": 0.289311835106383, "MMLU-PRO": 21.034648345153663, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-10-31T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "NousResearch/Yarn-Mistral-7b-128k"}, {"eval_name": "NousResearch_Yarn-Mistral-7b-64k_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe9 continuously pretrained", "T": "\ud83d\udfe9", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/NousResearch/Yarn-Mistral-7b-64k\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">NousResearch/Yarn-Mistral-7b-64k</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/NousResearch__Yarn-Mistral-7b-64k-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "NousResearch/Yarn-Mistral-7b-64k", "Model sha": "0273c624561fcecc8e8f4030492a9307aa60f945", "Average \u2b06\ufe0f": 13.427164944166408, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 49, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2079548930171944, "IFEval": 20.79548930171944, "BBH Raw": 0.4293190455103781, "BBH": 20.23020020918289, "MATH Lvl 5 Raw": 0.0302114803625377, "MATH Lvl 5": 3.0211480362537766, "GPQA Raw": 0.2902684563758389, "GPQA": 5.369127516778524, "MUSR Raw": 0.4123854166666666, "MUSR": 9.881510416666666, "MMLU-PRO Raw": 0.2913896276595745, "MMLU-PRO": 21.26551418439716, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-10-31T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "NousResearch/Yarn-Mistral-7b-64k"}, {"eval_name": "NousResearch_Yarn-Solar-10b-32k_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe9 continuously pretrained", "T": "\ud83d\udfe9", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/NousResearch/Yarn-Solar-10b-32k\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">NousResearch/Yarn-Solar-10b-32k</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/NousResearch__Yarn-Solar-10b-32k-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "NousResearch/Yarn-Solar-10b-32k", "Model sha": "ec3158b5276ac6644ddbdb36ccf6f9a106c98ede", "Average \u2b06\ufe0f": 15.630548494559294, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 10, "#Params (B)": 10, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1948153122603581, "IFEval": 19.48153122603581, "BBH Raw": 0.4986859152325069, "BBH": 28.99482436025671, "MATH Lvl 5 Raw": 0.0241691842900302, "MATH Lvl 5": 2.416918429003021, "GPQA Raw": 0.3028523489932886, "GPQA": 7.046979865771815, "MUSR Raw": 0.4146458333333333, "MUSR": 10.597395833333332, "MMLU-PRO Raw": 0.3272107712765957, "MMLU-PRO": 25.24564125295508, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-01-17T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "NousResearch/Yarn-Solar-10b-32k"}, {"eval_name": "NousResearch_Yarn-Solar-10b-64k_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe9 continuously pretrained", "T": "\ud83d\udfe9", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/NousResearch/Yarn-Solar-10b-64k\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">NousResearch/Yarn-Solar-10b-64k</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/NousResearch__Yarn-Solar-10b-64k-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "NousResearch/Yarn-Solar-10b-64k", "Model sha": "703818628a5e8ef637e48e8dbeb3662aa0497aff", "Average \u2b06\ufe0f": 15.061345512111492, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 15, "#Params (B)": 10, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1988867316498003, "IFEval": 19.88867316498003, "BBH Raw": 0.492199079542265, "BBH": 28.395714153595826, "MATH Lvl 5 Raw": 0.0226586102719033, "MATH Lvl 5": 2.2658610271903323, "GPQA Raw": 0.3020134228187919, "GPQA": 6.935123042505594, "MUSR Raw": 0.4014375, "MUSR": 9.013020833333336, "MMLU-PRO Raw": 0.3148271276595745, "MMLU-PRO": 23.869680851063837, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-01-17T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "NousResearch/Yarn-Solar-10b-64k"}, {"eval_name": "NucleusAI_nucleus-22B-token-500B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/NucleusAI/nucleus-22B-token-500B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">NucleusAI/nucleus-22B-token-500B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/NucleusAI__nucleus-22B-token-500B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "NucleusAI/nucleus-22B-token-500B", "Model sha": "49bb1a47c0d32b4bfa6630a4eff04a857adcd4ca", "Average \u2b06\ufe0f": 1.6334163485881146, "Hub License": "mit", "Hub \u2764\ufe0f": 25, "#Params (B)": 21, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.0256541532023918, "IFEval": 2.5654153202391874, "BBH Raw": 0.2919800780121471, "BBH": 1.8879990685708252, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.25, "GPQA": 0.0, "MUSR Raw": 0.3510520833333333, "MUSR": 3.5481770833333326, "MMLU-PRO Raw": 0.116190159574468, "MMLU-PRO": 1.798906619385342, "Maintainer's Highlight": false, "Upload To Hub Date": "2023-10-06T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "NucleusAI/nucleus-22B-token-500B"}, {"eval_name": "OEvortex_HelpingAI-15B_float16", "Precision": "float16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/OEvortex/HelpingAI-15B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">OEvortex/HelpingAI-15B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/OEvortex__HelpingAI-15B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "OEvortex/HelpingAI-15B", "Model sha": "fcc5d4eeee08c07680a2560a302de3eaa5d6f550", "Average \u2b06\ufe0f": 4.515495603660534, "Hub License": "other", "Hub \u2764\ufe0f": 12, "#Params (B)": 15, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2030091268944179, "IFEval": 20.30091268944179, "BBH Raw": 0.2936006977853758, "BBH": 1.8153805514942332, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2575503355704698, "GPQA": 1.0067114093959737, "MUSR Raw": 0.361875, "MUSR": 2.734375, "MMLU-PRO Raw": 0.1111203457446808, "MMLU-PRO": 1.2355939716312052, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-11T00:00:00", "Submission Date": "2024-07-13T00:00:00", "Generation": 0, "Base Model": "OEvortex/HelpingAI-15B"}, {"eval_name": "OEvortex_HelpingAI2-9B_float16", "Precision": "float16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/OEvortex/HelpingAI2-9B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">OEvortex/HelpingAI2-9B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/OEvortex__HelpingAI2-9B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "OEvortex/HelpingAI2-9B", "Model sha": "b45a18cf41d0d438d71d79687e098ec60dd0aec1", "Average \u2b06\ufe0f": 17.30481225863491, "Hub License": "other", "Hub \u2764\ufe0f": 22, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4413123844731977, "IFEval": 44.131238447319774, "BBH Raw": 0.4844617641983123, "BBH": 27.073241609173305, "MATH Lvl 5 Raw": 0.0407854984894259, "MATH Lvl 5": 4.078549848942599, "GPQA Raw": 0.2583892617449664, "GPQA": 1.1185682326621946, "MUSR Raw": 0.3710833333333334, "MUSR": 6.318750000000001, "MMLU-PRO Raw": 0.2899767287234042, "MMLU-PRO": 21.108525413711583, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-16T00:00:00", "Submission Date": "2024-10-11T00:00:00", "Generation": 0, "Base Model": "OEvortex/HelpingAI2-9B"}, {"eval_name": "OliveiraJLT_Sagui-7B-Instruct-v0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/OliveiraJLT/Sagui-7B-Instruct-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">OliveiraJLT/Sagui-7B-Instruct-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/OliveiraJLT__Sagui-7B-Instruct-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "OliveiraJLT/Sagui-7B-Instruct-v0.1", "Model sha": "e3032ba89a6df12b801ab3be2a29b59068aa048d", "Average \u2b06\ufe0f": 8.390585578374138, "Hub License": "other", "Hub \u2764\ufe0f": 0, "#Params (B)": 6, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2891627548238673, "IFEval": 28.91627548238673, "BBH Raw": 0.3110678914743868, "BBH": 5.043571655312187, "MATH Lvl 5 Raw": 0.0037764350453172, "MATH Lvl 5": 0.3776435045317221, "GPQA Raw": 0.2424496644295302, "GPQA": 0.0, "MUSR Raw": 0.4190520833333333, "MUSR": 10.61484375, "MMLU-PRO Raw": 0.1485206117021276, "MMLU-PRO": 5.391179078014184, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-17T00:00:00", "Submission Date": "2024-07-18T00:00:00", "Generation": 1, "Base Model": "maritaca-ai/sabia-7b"}, {"eval_name": "OmnicromsBrain_NeuralStar_FusionWriter_4x7b_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/OmnicromsBrain/NeuralStar_FusionWriter_4x7b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">OmnicromsBrain/NeuralStar_FusionWriter_4x7b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/OmnicromsBrain__NeuralStar_FusionWriter_4x7b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "OmnicromsBrain/NeuralStar_FusionWriter_4x7b", "Model sha": "fbe296d2c76acbb792cdd22e14d1c8bb13723839", "Average \u2b06\ufe0f": 20.008704452946954, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 5, "#Params (B)": 24, "Available on the hub": true, "Not_Merged": false, "MoE": false, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5963842604289951, "IFEval": 59.63842604289951, "BBH Raw": 0.4776243476695812, "BBH": 26.038439832659787, "MATH Lvl 5 Raw": 0.0453172205438066, "MATH Lvl 5": 4.531722054380665, "GPQA Raw": 0.2785234899328859, "GPQA": 3.803131991051453, "MUSR Raw": 0.401875, "MUSR": 8.201041666666667, "MMLU-PRO Raw": 0.2605551861702128, "MMLU-PRO": 17.83946513002364, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-07T00:00:00", "Submission Date": "2024-07-01T00:00:00", "Generation": 1, "Base Model": "OmnicromsBrain/NeuralStar_FusionWriter_4x7b (Merge)"}, {"eval_name": "Open-Orca_Mistral-7B-OpenOrca_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Open-Orca/Mistral-7B-OpenOrca\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Open-Orca/Mistral-7B-OpenOrca</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Open-Orca__Mistral-7B-OpenOrca-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Open-Orca/Mistral-7B-OpenOrca", "Model sha": "4a37328cef00f524d3791b1c0cc559a3cc6af14d", "Average \u2b06\ufe0f": 17.620946178257416, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 669, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4977659277384008, "IFEval": 49.77659277384008, "BBH Raw": 0.4768173517353546, "BBH": 25.840025395269805, "MATH Lvl 5 Raw": 0.0294561933534743, "MATH Lvl 5": 2.9456193353474323, "GPQA Raw": 0.2718120805369127, "GPQA": 2.9082774049217, "MUSR Raw": 0.3857812499999999, "MUSR": 5.889322916666667, "MMLU-PRO Raw": 0.2652925531914893, "MMLU-PRO": 18.36583924349882, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-09-29T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "Open-Orca/Mistral-7B-OpenOrca"}, {"eval_name": "OpenAssistant_oasst-sft-1-pythia-12b_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "GPTNeoXForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/OpenAssistant/oasst-sft-1-pythia-12b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">OpenAssistant/oasst-sft-1-pythia-12b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/OpenAssistant__oasst-sft-1-pythia-12b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "OpenAssistant/oasst-sft-1-pythia-12b", "Model sha": "293df535fe7711a5726987fc2f17dfc87de452a1", "Average \u2b06\ufe0f": 3.669242376580908, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 279, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1055388591160343, "IFEval": 10.553885911603434, "BBH Raw": 0.314662875941371, "BBH": 4.778508799161477, "MATH Lvl 5 Raw": 0.0143504531722054, "MATH Lvl 5": 1.4350453172205435, "GPQA Raw": 0.2575503355704698, "GPQA": 1.0067114093959737, "MUSR Raw": 0.3326979166666666, "MUSR": 2.987239583333334, "MMLU-PRO Raw": 0.1112865691489361, "MMLU-PRO": 1.2540632387706852, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-03-09T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "OpenAssistant/oasst-sft-1-pythia-12b"}, {"eval_name": "OpenBuddy_openbuddy-llama3-8b-v21.1-8k_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/OpenBuddy/openbuddy-llama3-8b-v21.1-8k\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">OpenBuddy/openbuddy-llama3-8b-v21.1-8k</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/OpenBuddy__openbuddy-llama3-8b-v21.1-8k-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "OpenBuddy/openbuddy-llama3-8b-v21.1-8k", "Model sha": "658508bce03ccd61cea9657e0357bd4cd10503ba", "Average \u2b06\ufe0f": 19.8985878634635, "Hub License": "other", "Hub \u2764\ufe0f": 29, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5569666263292509, "IFEval": 55.69666263292508, "BBH Raw": 0.4787500737348404, "BBH": 26.115045337590946, "MATH Lvl 5 Raw": 0.0271903323262839, "MATH Lvl 5": 2.719033232628399, "GPQA Raw": 0.2709731543624161, "GPQA": 2.796420581655479, "MUSR Raw": 0.3987708333333333, "MUSR": 10.346354166666664, "MMLU-PRO Raw": 0.2954621010638298, "MMLU-PRO": 21.71801122931442, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-20T00:00:00", "Submission Date": "2024-08-03T00:00:00", "Generation": 0, "Base Model": "OpenBuddy/openbuddy-llama3-8b-v21.1-8k"}, {"eval_name": "OpenBuddy_openbuddy-llama3-8b-v21.2-32k_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/OpenBuddy/openbuddy-llama3-8b-v21.2-32k\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">OpenBuddy/openbuddy-llama3-8b-v21.2-32k</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/OpenBuddy__openbuddy-llama3-8b-v21.2-32k-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "OpenBuddy/openbuddy-llama3-8b-v21.2-32k", "Model sha": "f3ea2dec2533a3dd97df32db2376b17875cafda2", "Average \u2b06\ufe0f": 21.842892972104035, "Hub License": "other", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6191904147661538, "IFEval": 61.91904147661538, "BBH Raw": 0.4856219845879779, "BBH": 27.252334736558797, "MATH Lvl 5 Raw": 0.0649546827794562, "MATH Lvl 5": 6.495468277945619, "GPQA Raw": 0.2793624161073825, "GPQA": 3.9149888143176734, "MUSR Raw": 0.377875, "MUSR": 5.934375000000003, "MMLU-PRO Raw": 0.3298703457446808, "MMLU-PRO": 25.54114952718676, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-18T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "OpenBuddy/openbuddy-llama3-8b-v21.2-32k"}, {"eval_name": "OpenBuddy_openbuddy-llama3.1-70b-v22.1-131k_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/OpenBuddy/openbuddy-llama3.1-70b-v22.1-131k\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">OpenBuddy/openbuddy-llama3.1-70b-v22.1-131k</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/OpenBuddy__openbuddy-llama3.1-70b-v22.1-131k-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "OpenBuddy/openbuddy-llama3.1-70b-v22.1-131k", "Model sha": "43ed945180174d79a8f6c68509161c249c884dfa", "Average \u2b06\ufe0f": 35.23235308949715, "Hub License": "other", "Hub \u2764\ufe0f": 1, "#Params (B)": 70, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7332710541363582, "IFEval": 73.32710541363582, "BBH Raw": 0.6698491606025763, "BBH": 51.94077625159233, "MATH Lvl 5 Raw": 0.0339879154078549, "MATH Lvl 5": 3.3987915407854987, "GPQA Raw": 0.375, "GPQA": 16.666666666666664, "MUSR Raw": 0.4629583333333333, "MUSR": 18.23645833333333, "MMLU-PRO Raw": 0.5304188829787234, "MMLU-PRO": 47.82432033096927, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-21T00:00:00", "Submission Date": "2024-08-24T00:00:00", "Generation": 0, "Base Model": "OpenBuddy/openbuddy-llama3.1-70b-v22.1-131k"}, {"eval_name": "OpenBuddy_openbuddy-llama3.1-8b-v22.2-131k_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/OpenBuddy/openbuddy-llama3.1-8b-v22.2-131k\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">OpenBuddy/openbuddy-llama3.1-8b-v22.2-131k</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/OpenBuddy__openbuddy-llama3.1-8b-v22.2-131k-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "OpenBuddy/openbuddy-llama3.1-8b-v22.2-131k", "Model sha": "0d9d85c7a5e4292e07c346147de56bd3991d525c", "Average \u2b06\ufe0f": 24.065705831112325, "Hub License": "other", "Hub \u2764\ufe0f": 2, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6657269378582162, "IFEval": 66.57269378582163, "BBH Raw": 0.5006515954024578, "BBH": 29.057538243651496, "MATH Lvl 5 Raw": 0.093655589123867, "MATH Lvl 5": 9.365558912386708, "GPQA Raw": 0.2793624161073825, "GPQA": 3.9149888143176734, "MUSR Raw": 0.4081041666666666, "MUSR": 9.81302083333333, "MMLU-PRO Raw": 0.3310339095744681, "MMLU-PRO": 25.67043439716312, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-28T00:00:00", "Submission Date": "2024-07-29T00:00:00", "Generation": 0, "Base Model": "OpenBuddy/openbuddy-llama3.1-8b-v22.2-131k"}, {"eval_name": "OpenBuddy_openbuddy-llama3.1-8b-v22.3-131k_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/OpenBuddy/openbuddy-llama3.1-8b-v22.3-131k\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">OpenBuddy/openbuddy-llama3.1-8b-v22.3-131k</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/OpenBuddy__openbuddy-llama3.1-8b-v22.3-131k-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "OpenBuddy/openbuddy-llama3.1-8b-v22.3-131k", "Model sha": "0097358fa1a450251b7ea1a03a5effdfded6c461", "Average \u2b06\ufe0f": 22.9277223153084, "Hub License": "other", "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5997065563815123, "IFEval": 59.97065563815122, "BBH Raw": 0.5065914870348772, "BBH": 30.3195108847562, "MATH Lvl 5 Raw": 0.0974320241691842, "MATH Lvl 5": 9.743202416918429, "GPQA Raw": 0.2793624161073825, "GPQA": 3.9149888143176734, "MUSR Raw": 0.40146875, "MUSR": 8.316927083333335, "MMLU-PRO Raw": 0.3277094414893617, "MMLU-PRO": 25.30104905437352, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-16T00:00:00", "Submission Date": "2024-08-24T00:00:00", "Generation": 0, "Base Model": "OpenBuddy/openbuddy-llama3.1-8b-v22.3-131k"}, {"eval_name": "OpenBuddy_openbuddy-llama3.2-1b-v23.1-131k_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/OpenBuddy/openbuddy-llama3.2-1b-v23.1-131k\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">OpenBuddy/openbuddy-llama3.2-1b-v23.1-131k</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/OpenBuddy__openbuddy-llama3.2-1b-v23.1-131k-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "OpenBuddy/openbuddy-llama3.2-1b-v23.1-131k", "Model sha": "71b61e0e02e55553902f0051074d2ae965413cdb", "Average \u2b06\ufe0f": 8.959801927591569, "Hub License": "llama3.2", "Hub \u2764\ufe0f": 0, "#Params (B)": 1, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3590052172679601, "IFEval": 35.90052172679601, "BBH Raw": 0.3266563226631131, "BBH": 6.043619508652057, "MATH Lvl 5 Raw": 0.0015105740181268, "MATH Lvl 5": 0.1510574018126888, "GPQA Raw": 0.2583892617449664, "GPQA": 1.1185682326621946, "MUSR Raw": 0.33421875, "MUSR": 1.2106770833333331, "MMLU-PRO Raw": 0.1840093085106383, "MMLU-PRO": 9.334367612293144, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-07T00:00:00", "Submission Date": "2024-10-09T00:00:00", "Generation": 0, "Base Model": "OpenBuddy/openbuddy-llama3.2-1b-v23.1-131k"}, {"eval_name": "OpenBuddy_openbuddy-mixtral-7bx8-v18.1-32k_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/OpenBuddy/openbuddy-mixtral-7bx8-v18.1-32k\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">OpenBuddy/openbuddy-mixtral-7bx8-v18.1-32k</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/OpenBuddy__openbuddy-mixtral-7bx8-v18.1-32k-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "OpenBuddy/openbuddy-mixtral-7bx8-v18.1-32k", "Model sha": "98596b6731058cc9cca85f3b8ac9077342cb60ae", "Average \u2b06\ufe0f": 22.115810863566978, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 14, "#Params (B)": 46, "Available on the hub": true, "Not_Merged": true, "MoE": false, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.549347952322061, "IFEval": 54.9347952322061, "BBH Raw": 0.4656177056351526, "BBH": 24.5354429684368, "MATH Lvl 5 Raw": 0.0951661631419939, "MATH Lvl 5": 9.516616314199396, "GPQA Raw": 0.3045302013422818, "GPQA": 7.270693512304249, "MUSR Raw": 0.3830520833333333, "MUSR": 5.281510416666666, "MMLU-PRO Raw": 0.3804022606382978, "MMLU-PRO": 31.15580673758865, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-02-12T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "OpenBuddy/openbuddy-mixtral-7bx8-v18.1-32k"}, {"eval_name": "OpenBuddy_openbuddy-qwen2.5llamaify-14b-v23.1-200k_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/OpenBuddy/openbuddy-qwen2.5llamaify-14b-v23.1-200k\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">OpenBuddy/openbuddy-qwen2.5llamaify-14b-v23.1-200k</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/OpenBuddy__openbuddy-qwen2.5llamaify-14b-v23.1-200k-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "OpenBuddy/openbuddy-qwen2.5llamaify-14b-v23.1-200k", "Model sha": "001e14063e2702a9b2284dc6ec889d2586dc839b", "Average \u2b06\ufe0f": 30.91701997639535, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 14, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.630880508162786, "IFEval": 63.0880508162786, "BBH Raw": 0.601319898776811, "BBH": 43.27649863201484, "MATH Lvl 5 Raw": 0.1570996978851963, "MATH Lvl 5": 15.709969788519636, "GPQA Raw": 0.3330536912751677, "GPQA": 11.0738255033557, "MUSR Raw": 0.4240416666666666, "MUSR": 11.538541666666667, "MMLU-PRO Raw": 0.4673371010638298, "MMLU-PRO": 40.81523345153664, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-23T00:00:00", "Submission Date": "2024-09-23T00:00:00", "Generation": 0, "Base Model": "OpenBuddy/openbuddy-qwen2.5llamaify-14b-v23.1-200k"}, {"eval_name": "OpenBuddy_openbuddy-qwen2.5llamaify-14b-v23.3-200k_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/OpenBuddy/openbuddy-qwen2.5llamaify-14b-v23.3-200k\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">OpenBuddy/openbuddy-qwen2.5llamaify-14b-v23.3-200k</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/OpenBuddy__openbuddy-qwen2.5llamaify-14b-v23.3-200k-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "OpenBuddy/openbuddy-qwen2.5llamaify-14b-v23.3-200k", "Model sha": "0cef6f7719c1eb3bc1ebba133508c2c6d67e635c", "Average \u2b06\ufe0f": 28.84877122066433, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 14, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6131453432448126, "IFEval": 61.31453432448127, "BBH Raw": 0.6080855261046028, "BBH": 44.1839402106242, "MATH Lvl 5 Raw": 0.0241691842900302, "MATH Lvl 5": 2.416918429003021, "GPQA Raw": 0.3271812080536913, "GPQA": 10.290827740492167, "MUSR Raw": 0.4345833333333333, "MUSR": 12.722916666666668, "MMLU-PRO Raw": 0.4794714095744681, "MMLU-PRO": 42.16348995271868, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-02T00:00:00", "Submission Date": "2024-10-11T00:00:00", "Generation": 0, "Base Model": "OpenBuddy/openbuddy-qwen2.5llamaify-14b-v23.3-200k"}, {"eval_name": "OpenBuddy_openbuddy-qwen2.5llamaify-7b-v23.1-200k_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/OpenBuddy/openbuddy-qwen2.5llamaify-7b-v23.1-200k\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">OpenBuddy/openbuddy-qwen2.5llamaify-7b-v23.1-200k</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/OpenBuddy__openbuddy-qwen2.5llamaify-7b-v23.1-200k-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "OpenBuddy/openbuddy-qwen2.5llamaify-7b-v23.1-200k", "Model sha": "91521abfec2a00f4853f6cb4dd620177617ca572", "Average \u2b06\ufe0f": 26.617031193808344, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5672582082208539, "IFEval": 56.7258208220854, "BBH Raw": 0.5509381466888461, "BBH": 36.3981275172541, "MATH Lvl 5 Raw": 0.11404833836858, "MATH Lvl 5": 11.404833836858003, "GPQA Raw": 0.3145973154362416, "GPQA": 8.612975391498878, "MUSR Raw": 0.4363229166666666, "MUSR": 13.807031250000003, "MMLU-PRO Raw": 0.394780585106383, "MMLU-PRO": 32.75339834515366, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-04T00:00:00", "Submission Date": "2024-10-10T00:00:00", "Generation": 0, "Base Model": "OpenBuddy/openbuddy-qwen2.5llamaify-7b-v23.1-200k"}, {"eval_name": "OpenBuddy_openbuddy-yi1.5-34b-v21.3-32k_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/OpenBuddy/openbuddy-yi1.5-34b-v21.3-32k\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">OpenBuddy/openbuddy-yi1.5-34b-v21.3-32k</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/OpenBuddy__openbuddy-yi1.5-34b-v21.3-32k-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "OpenBuddy/openbuddy-yi1.5-34b-v21.3-32k", "Model sha": "966be6ad502cdd50a9af94d5f003aec040cdb0b5", "Average \u2b06\ufe0f": 30.08129988640074, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 34, "Available on the hub": true, "Not_Merged": true, "MoE": false, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5420041046645123, "IFEval": 54.20041046645124, "BBH Raw": 0.6162574860411373, "BBH": 45.637092606204, "MATH Lvl 5 Raw": 0.127643504531722, "MATH Lvl 5": 12.764350453172204, "GPQA Raw": 0.348993288590604, "GPQA": 13.19910514541387, "MUSR Raw": 0.4439479166666666, "MUSR": 14.693489583333337, "MMLU-PRO Raw": 0.4599401595744681, "MMLU-PRO": 39.99335106382979, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-05T00:00:00", "Submission Date": "2024-08-30T00:00:00", "Generation": 0, "Base Model": "OpenBuddy/openbuddy-yi1.5-34b-v21.3-32k"}, {"eval_name": "OpenBuddy_openbuddy-zero-14b-v22.3-32k_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/OpenBuddy/openbuddy-zero-14b-v22.3-32k\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">OpenBuddy/openbuddy-zero-14b-v22.3-32k</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/OpenBuddy__openbuddy-zero-14b-v22.3-32k-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "OpenBuddy/openbuddy-zero-14b-v22.3-32k", "Model sha": "d9a0b6bc02f283e154c9ad6db43a5a97eed97f5b", "Average \u2b06\ufe0f": 19.14172057510425, "Hub License": "other", "Hub \u2764\ufe0f": 1, "#Params (B)": 14, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3752920029964937, "IFEval": 37.529200299649375, "BBH Raw": 0.4859759816473639, "BBH": 26.289506846678147, "MATH Lvl 5 Raw": 0.0777945619335347, "MATH Lvl 5": 7.779456193353475, "GPQA Raw": 0.3070469798657718, "GPQA": 7.606263982102905, "MUSR Raw": 0.4166041666666666, "MUSR": 11.3421875, "MMLU-PRO Raw": 0.3187333776595745, "MMLU-PRO": 24.30370862884161, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-16T00:00:00", "Submission Date": "2024-07-29T00:00:00", "Generation": 0, "Base Model": "OpenBuddy/openbuddy-zero-14b-v22.3-32k"}, {"eval_name": "OpenBuddy_openbuddy-zero-3b-v21.2-32k_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/OpenBuddy/openbuddy-zero-3b-v21.2-32k\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">OpenBuddy/openbuddy-zero-3b-v21.2-32k</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/OpenBuddy__openbuddy-zero-3b-v21.2-32k-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "OpenBuddy/openbuddy-zero-3b-v21.2-32k", "Model sha": "74e1d168c5e917219d668d1483f6355dd0464a31", "Average \u2b06\ufe0f": 11.5496567674182, "Hub License": "other", "Hub \u2764\ufe0f": 2, "#Params (B)": 4, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3802377691192702, "IFEval": 38.02377691192702, "BBH Raw": 0.3934791831798414, "BBH": 15.293406418468868, "MATH Lvl 5 Raw": 0.0090634441087613, "MATH Lvl 5": 0.906344410876133, "GPQA Raw": 0.2600671140939597, "GPQA": 1.342281879194629, "MUSR Raw": 0.3566354166666667, "MUSR": 2.24609375, "MMLU-PRO Raw": 0.2033743351063829, "MMLU-PRO": 11.486037234042552, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-02T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "OpenBuddy/openbuddy-zero-3b-v21.2-32k"}, {"eval_name": "OpenBuddy_openbuddy-zero-56b-v21.2-32k_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/OpenBuddy/openbuddy-zero-56b-v21.2-32k\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">OpenBuddy/openbuddy-zero-56b-v21.2-32k</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/OpenBuddy__openbuddy-zero-56b-v21.2-32k-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "OpenBuddy/openbuddy-zero-56b-v21.2-32k", "Model sha": "c7a1a4a6e798f75d1d3219ab9ff9f2692e29f7d5", "Average \u2b06\ufe0f": 27.9947309401676, "Hub License": "other", "Hub \u2764\ufe0f": 0, "#Params (B)": 56, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5057092957796425, "IFEval": 50.57092957796425, "BBH Raw": 0.6128345897750148, "BBH": 44.79654161573056, "MATH Lvl 5 Raw": 0.1299093655589124, "MATH Lvl 5": 12.990936555891238, "GPQA Raw": 0.3179530201342282, "GPQA": 9.060402684563762, "MUSR Raw": 0.4305208333333333, "MUSR": 12.781770833333333, "MMLU-PRO Raw": 0.4399102393617021, "MMLU-PRO": 37.76780437352246, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-10T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "OpenBuddy/openbuddy-zero-56b-v21.2-32k"}, {"eval_name": "OpenLeecher_llama3-8b-lima_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/OpenLeecher/llama3-8b-lima\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">OpenLeecher/llama3-8b-lima</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/OpenLeecher__llama3-8b-lima-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "OpenLeecher/llama3-8b-lima", "Model sha": "237a2bcb240eecd9355a091f839e42ba3d31bda5", "Average \u2b06\ufe0f": 14.672965016145518, "Hub License": "llama3", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4370658741029357, "IFEval": 43.70658741029358, "BBH Raw": 0.4295828632822993, "BBH": 19.573064881964964, "MATH Lvl 5 Raw": 0.0294561933534743, "MATH Lvl 5": 2.9456193353474323, "GPQA Raw": 0.2382550335570469, "GPQA": 0.0, "MUSR Raw": 0.3712708333333332, "MUSR": 3.7421875, "MMLU-PRO Raw": 0.2626329787234042, "MMLU-PRO": 18.070330969267136, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-01T00:00:00", "Submission Date": "2024-10-01T00:00:00", "Generation": 0, "Base Model": "OpenLeecher/llama3-8b-lima"}, {"eval_name": "Orenguteng_Llama-3.1-8B-Lexi-Uncensored_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Orenguteng/Llama-3.1-8B-Lexi-Uncensored\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Orenguteng/Llama-3.1-8B-Lexi-Uncensored</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Orenguteng__Llama-3.1-8B-Lexi-Uncensored-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Orenguteng/Llama-3.1-8B-Lexi-Uncensored", "Model sha": "56ac439ab4c7826871493ffbe2d49f2100a98e97", "Average \u2b06\ufe0f": 26.86041322229723, "Hub License": "llama3.1", "Hub \u2764\ufe0f": 40, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7776843220432896, "IFEval": 77.76843220432897, "BBH Raw": 0.5057261652642643, "BBH": 29.24254324176861, "MATH Lvl 5 Raw": 0.1382175226586102, "MATH Lvl 5": 13.821752265861026, "GPQA Raw": 0.2718120805369127, "GPQA": 2.9082774049217, "MUSR Raw": 0.3871145833333333, "MUSR": 6.422656250000002, "MMLU-PRO Raw": 0.3789893617021276, "MMLU-PRO": 30.99881796690307, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-26T00:00:00", "Submission Date": "2024-07-29T00:00:00", "Generation": 0, "Base Model": "Orenguteng/Llama-3.1-8B-Lexi-Uncensored"}, {"eval_name": "Orenguteng_Llama-3.1-8B-Lexi-Uncensored-V2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Orenguteng/Llama-3.1-8B-Lexi-Uncensored-V2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Orenguteng/Llama-3.1-8B-Lexi-Uncensored-V2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Orenguteng__Llama-3.1-8B-Lexi-Uncensored-V2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Orenguteng/Llama-3.1-8B-Lexi-Uncensored-V2", "Model sha": "2340f8fbcd2452125a798686ca90b882a08fb0d9", "Average \u2b06\ufe0f": 27.925120906061533, "Hub License": "llama3.1", "Hub \u2764\ufe0f": 64, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7791581891603169, "IFEval": 77.91581891603168, "BBH Raw": 0.5084008018783934, "BBH": 29.687032745631218, "MATH Lvl 5 Raw": 0.1691842900302115, "MATH Lvl 5": 16.91842900302115, "GPQA Raw": 0.2827181208053691, "GPQA": 4.36241610738255, "MUSR Raw": 0.3842916666666667, "MUSR": 7.76979166666667, "MMLU-PRO Raw": 0.3780751329787234, "MMLU-PRO": 30.897236997635936, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-09T00:00:00", "Submission Date": "2024-08-28T00:00:00", "Generation": 0, "Base Model": "Orenguteng/Llama-3.1-8B-Lexi-Uncensored-V2"}, {"eval_name": "P0x0_Astra-v1-12B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/P0x0/Astra-v1-12B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">P0x0/Astra-v1-12B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/P0x0__Astra-v1-12B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "P0x0/Astra-v1-12B", "Model sha": "c706e253f8d8fa838b505cbec0e1a6aeec545abc", "Average \u2b06\ufe0f": 19.460301896529675, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2805943784713449, "IFEval": 28.05943784713449, "BBH Raw": 0.5214506484138984, "BBH": 31.80990734117942, "MATH Lvl 5 Raw": 0.0966767371601208, "MATH Lvl 5": 9.667673716012084, "GPQA Raw": 0.313758389261745, "GPQA": 8.501118568232664, "MUSR Raw": 0.4051875, "MUSR": 11.381770833333327, "MMLU-PRO Raw": 0.3460771276595745, "MMLU-PRO": 27.34190307328605, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-21T00:00:00", "Submission Date": "2024-09-23T00:00:00", "Generation": 1, "Base Model": "mistralai/Mistral-Nemo-Base-2407"}, {"eval_name": "PJMixers_LLaMa-3-CursedStock-v2.0-8B_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/PJMixers/LLaMa-3-CursedStock-v2.0-8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">PJMixers/LLaMa-3-CursedStock-v2.0-8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/PJMixers__LLaMa-3-CursedStock-v2.0-8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "PJMixers/LLaMa-3-CursedStock-v2.0-8B", "Model sha": "d47cc29df363f71ffaf6cd21ac4bdeefa27359db", "Average \u2b06\ufe0f": 24.027664608348417, "Hub License": "llama3", "Hub \u2764\ufe0f": 9, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6330791189599152, "IFEval": 63.30791189599152, "BBH Raw": 0.527115950402997, "BBH": 32.56361170891586, "MATH Lvl 5 Raw": 0.0861027190332326, "MATH Lvl 5": 8.610271903323262, "GPQA Raw": 0.2743288590604026, "GPQA": 3.243847874720355, "MUSR Raw": 0.385625, "MUSR": 8.036458333333336, "MMLU-PRO Raw": 0.3556349734042553, "MMLU-PRO": 28.40388593380615, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-26T00:00:00", "Submission Date": "2024-06-27T00:00:00", "Generation": 1, "Base Model": "PJMixers/LLaMa-3-CursedStock-v2.0-8B (Merge)"}, {"eval_name": "PJMixers-Dev_LLaMa-3.2-Instruct-JankMix-v0.1-SFT-3B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/PJMixers-Dev/LLaMa-3.2-Instruct-JankMix-v0.1-SFT-3B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">PJMixers-Dev/LLaMa-3.2-Instruct-JankMix-v0.1-SFT-3B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/PJMixers-Dev__LLaMa-3.2-Instruct-JankMix-v0.1-SFT-3B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "PJMixers-Dev/LLaMa-3.2-Instruct-JankMix-v0.1-SFT-3B", "Model sha": "1286f51489b06fe67fa36d57aa87331fa37e698b", "Average \u2b06\ufe0f": 22.41221325428361, "Hub License": "llama3.2", "Hub \u2764\ufe0f": 0, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.693054428915278, "IFEval": 69.3054428915278, "BBH Raw": 0.4556166737589294, "BBH": 23.80830677255767, "MATH Lvl 5 Raw": 0.1042296072507553, "MATH Lvl 5": 10.42296072507553, "GPQA Raw": 0.2743288590604026, "GPQA": 3.243847874720355, "MUSR Raw": 0.37003125, "MUSR": 4.053906250000002, "MMLU-PRO Raw": 0.312749335106383, "MMLU-PRO": 23.63881501182033, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-12T00:00:00", "Submission Date": "2024-10-12T00:00:00", "Generation": 1, "Base Model": "PJMixers-Dev/LLaMa-3.2-Instruct-JankMix-v0.1-SFT-3B (Merge)"}, {"eval_name": "PJMixers-Dev_LLaMa-3.2-Instruct-JankMixBread-v0.1-3B_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/PJMixers-Dev/LLaMa-3.2-Instruct-JankMixBread-v0.1-3B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">PJMixers-Dev/LLaMa-3.2-Instruct-JankMixBread-v0.1-3B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/PJMixers-Dev__LLaMa-3.2-Instruct-JankMixBread-v0.1-3B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "PJMixers-Dev/LLaMa-3.2-Instruct-JankMixBread-v0.1-3B", "Model sha": "19faf7463cab41a2492cad26fc54b2fce3a05caf", "Average \u2b06\ufe0f": 19.3470642950966, "Hub License": "llama3.2", "Hub \u2764\ufe0f": 0, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5040858256093831, "IFEval": 50.40858256093832, "BBH Raw": 0.4483158594793648, "BBH": 22.759588390933697, "MATH Lvl 5 Raw": 0.107250755287009, "MATH Lvl 5": 10.725075528700906, "GPQA Raw": 0.2827181208053691, "GPQA": 4.36241610738255, "MUSR Raw": 0.3515520833333334, "MUSR": 4.677343750000003, "MMLU-PRO Raw": 0.308344414893617, "MMLU-PRO": 23.149379432624112, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-12T00:00:00", "Submission Date": "2024-10-12T00:00:00", "Generation": 1, "Base Model": "PJMixers-Dev/LLaMa-3.2-Instruct-JankMixBread-v0.1-3B (Merge)"}, {"eval_name": "PocketDoc_Dans-Instruct-CoreCurriculum-12b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/PocketDoc/Dans-Instruct-CoreCurriculum-12b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">PocketDoc/Dans-Instruct-CoreCurriculum-12b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/PocketDoc__Dans-Instruct-CoreCurriculum-12b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "PocketDoc/Dans-Instruct-CoreCurriculum-12b", "Model sha": "c50db5ba880b7edc0efd32a7f3b9d2f051c3f4a6", "Average \u2b06\ufe0f": 9.33988312617713, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 12, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2191452013989547, "IFEval": 21.91452013989548, "BBH Raw": 0.3788739075240266, "BBH": 13.232564953040011, "MATH Lvl 5 Raw": 0.0453172205438066, "MATH Lvl 5": 4.531722054380665, "GPQA Raw": 0.2827181208053691, "GPQA": 4.36241610738255, "MUSR Raw": 0.4095625, "MUSR": 9.561979166666667, "MMLU-PRO Raw": 0.1219248670212766, "MMLU-PRO": 2.4360963356973997, "Maintainer's Highlight": false, "Upload To Hub Date": "", "Submission Date": "2024-09-01T00:00:00", "Generation": 0, "Base Model": "Removed"}, {"eval_name": "PocketDoc_Dans-PersonalityEngine-v1.0.0-8b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/PocketDoc/Dans-PersonalityEngine-v1.0.0-8b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">PocketDoc/Dans-PersonalityEngine-v1.0.0-8b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/PocketDoc__Dans-PersonalityEngine-v1.0.0-8b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "PocketDoc/Dans-PersonalityEngine-v1.0.0-8b", "Model sha": "c64612e1eee1ddb3aa064a25eba8921ec3d94325", "Average \u2b06\ufe0f": 18.65353905485888, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 3, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.498190357141274, "IFEval": 49.81903571412741, "BBH Raw": 0.4732554425914936, "BBH": 25.68795976908214, "MATH Lvl 5 Raw": 0.0483383685800604, "MATH Lvl 5": 4.833836858006042, "GPQA Raw": 0.285234899328859, "GPQA": 4.697986577181204, "MUSR Raw": 0.35415625, "MUSR": 3.936197916666668, "MMLU-PRO Raw": 0.3065159574468085, "MMLU-PRO": 22.94621749408983, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-08T00:00:00", "Submission Date": "2024-10-08T00:00:00", "Generation": 1, "Base Model": "PocketDoc/Dans-PersonalityEngine-v1.0.0-8b (Merge)"}, {"eval_name": "PranavHarshan_LaMistral-V4_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/PranavHarshan/LaMistral-V4\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">PranavHarshan/LaMistral-V4</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/PranavHarshan__LaMistral-V4-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "PranavHarshan/LaMistral-V4", "Model sha": "b373c2a1ab08823b6b119899f807793c96ef7888", "Average \u2b06\ufe0f": 24.12264835913521, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.623861354539289, "IFEval": 62.38613545392891, "BBH Raw": 0.5184255342586473, "BBH": 31.091348681794813, "MATH Lvl 5 Raw": 0.0634441087613293, "MATH Lvl 5": 6.3444108761329305, "GPQA Raw": 0.3280201342281879, "GPQA": 10.402684563758392, "MUSR Raw": 0.3642916666666667, "MUSR": 5.636458333333335, "MMLU-PRO Raw": 0.3598736702127659, "MMLU-PRO": 28.874852245862886, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-01T00:00:00", "Submission Date": "2024-10-05T00:00:00", "Generation": 1, "Base Model": "PranavHarshan/LaMistral-V4 (Merge)"}, {"eval_name": "PranavHarshan_MedNarra-X1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/PranavHarshan/MedNarra-X1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">PranavHarshan/MedNarra-X1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/PranavHarshan__MedNarra-X1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "PranavHarshan/MedNarra-X1", "Model sha": "9fe294e7fd69ec56f0b7fa1a23759eed070f44bf", "Average \u2b06\ufe0f": 18.01538849207448, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.43384331351924, "IFEval": 43.384331351924, "BBH Raw": 0.4637166817977418, "BBH": 23.52349513234211, "MATH Lvl 5 Raw": 0.0400302114803625, "MATH Lvl 5": 4.003021148036254, "GPQA Raw": 0.3078859060402684, "GPQA": 7.718120805369126, "MUSR Raw": 0.35403125, "MUSR": 2.45390625, "MMLU-PRO Raw": 0.3430851063829787, "MMLU-PRO": 27.00945626477541, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-08T00:00:00", "Submission Date": "2024-10-09T00:00:00", "Generation": 1, "Base Model": "PranavHarshan/MedNarra-X1 (Merge)"}, {"eval_name": "Pretergeek_OpenChat-3.5-0106_10.7B_48Layers-Appended_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Pretergeek/OpenChat-3.5-0106_10.7B_48Layers-Appended\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Pretergeek/OpenChat-3.5-0106_10.7B_48Layers-Appended</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Pretergeek__OpenChat-3.5-0106_10.7B_48Layers-Appended-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Pretergeek/OpenChat-3.5-0106_10.7B_48Layers-Appended", "Model sha": "1091b30480f4cc91f26cb1bd7579e527f490f8d2", "Average \u2b06\ufe0f": 22.547054337229408, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 2, "#Params (B)": 10, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5960595663949432, "IFEval": 59.60595663949432, "BBH Raw": 0.4619637884426022, "BBH": 24.05717251228861, "MATH Lvl 5 Raw": 0.0679758308157099, "MATH Lvl 5": 6.797583081570997, "GPQA Raw": 0.3070469798657718, "GPQA": 7.606263982102905, "MUSR Raw": 0.42540625, "MUSR": 11.77578125, "MMLU-PRO Raw": 0.3289561170212766, "MMLU-PRO": 25.439568557919618, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-27T00:00:00", "Submission Date": "2024-07-31T00:00:00", "Generation": 1, "Base Model": "Pretergeek/OpenChat-3.5-0106_10.7B_48Layers-Appended (Merge)"}, {"eval_name": "Pretergeek_OpenChat-3.5-0106_10.7B_48Layers-Interleaved_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Pretergeek/OpenChat-3.5-0106_10.7B_48Layers-Interleaved\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Pretergeek/OpenChat-3.5-0106_10.7B_48Layers-Interleaved</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Pretergeek__OpenChat-3.5-0106_10.7B_48Layers-Interleaved-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Pretergeek/OpenChat-3.5-0106_10.7B_48Layers-Interleaved", "Model sha": "dd6bd9a8a9a2223a02a4e8aa6270accbc8d4d81a", "Average \u2b06\ufe0f": 22.50805608714082, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 2, "#Params (B)": 10, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5960595663949432, "IFEval": 59.60595663949432, "BBH Raw": 0.4619637884426022, "BBH": 24.05717251228861, "MATH Lvl 5 Raw": 0.0679758308157099, "MATH Lvl 5": 6.797583081570997, "GPQA Raw": 0.3045302013422818, "GPQA": 7.270693512304249, "MUSR Raw": 0.42540625, "MUSR": 11.77578125, "MMLU-PRO Raw": 0.3298703457446808, "MMLU-PRO": 25.54114952718676, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-10T00:00:00", "Submission Date": "2024-08-16T00:00:00", "Generation": 1, "Base Model": "Pretergeek/OpenChat-3.5-0106_10.7B_48Layers-Interleaved (Merge)"}, {"eval_name": "Pretergeek_OpenChat-3.5-0106_8.11B_36Layers-Appended_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Pretergeek/OpenChat-3.5-0106_8.11B_36Layers-Appended\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Pretergeek/OpenChat-3.5-0106_8.11B_36Layers-Appended</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Pretergeek__OpenChat-3.5-0106_8.11B_36Layers-Appended-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Pretergeek/OpenChat-3.5-0106_8.11B_36Layers-Appended", "Model sha": "e957847e013bdd2f6e852b8a1c369ddce92fca78", "Average \u2b06\ufe0f": 22.57244991725337, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 2, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5975833011963811, "IFEval": 59.75833011963812, "BBH Raw": 0.4619637884426022, "BBH": 24.05717251228861, "MATH Lvl 5 Raw": 0.0679758308157099, "MATH Lvl 5": 6.797583081570997, "GPQA Raw": 0.3070469798657718, "GPQA": 7.606263982102905, "MUSR Raw": 0.42540625, "MUSR": 11.77578125, "MMLU-PRO Raw": 0.3289561170212766, "MMLU-PRO": 25.439568557919618, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-26T00:00:00", "Submission Date": "2024-07-27T00:00:00", "Generation": 1, "Base Model": "Pretergeek/OpenChat-3.5-0106_8.11B_36Layers-Appended (Merge)"}, {"eval_name": "Pretergeek_OpenChat-3.5-0106_8.11B_36Layers-Interleaved_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Pretergeek/OpenChat-3.5-0106_8.11B_36Layers-Interleaved\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Pretergeek/OpenChat-3.5-0106_8.11B_36Layers-Interleaved</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Pretergeek__OpenChat-3.5-0106_8.11B_36Layers-Interleaved-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Pretergeek/OpenChat-3.5-0106_8.11B_36Layers-Interleaved", "Model sha": "485ebe835c6c001af0a1a6e0e40aab27bc195842", "Average \u2b06\ufe0f": 22.46666719825193, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 2, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5960595663949432, "IFEval": 59.60595663949432, "BBH Raw": 0.4621304551092688, "BBH": 24.075505845621944, "MATH Lvl 5 Raw": 0.0679758308157099, "MATH Lvl 5": 6.797583081570997, "GPQA Raw": 0.3045302013422818, "GPQA": 7.270693512304249, "MUSR Raw": 0.4240729166666666, "MUSR": 11.509114583333334, "MMLU-PRO Raw": 0.3298703457446808, "MMLU-PRO": 25.54114952718676, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-10T00:00:00", "Submission Date": "2024-08-16T00:00:00", "Generation": 1, "Base Model": "Pretergeek/OpenChat-3.5-0106_8.11B_36Layers-Interleaved (Merge)"}, {"eval_name": "Pretergeek_OpenChat-3.5-0106_8.99B_40Layers-Appended_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Pretergeek/OpenChat-3.5-0106_8.99B_40Layers-Appended\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Pretergeek/OpenChat-3.5-0106_8.99B_40Layers-Appended</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Pretergeek__OpenChat-3.5-0106_8.99B_40Layers-Appended-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Pretergeek/OpenChat-3.5-0106_8.99B_40Layers-Appended", "Model sha": "2120720b7fb2ecc27b9c03cc876316fd25b26e40", "Average \u2b06\ufe0f": 22.547054337229408, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 2, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5960595663949432, "IFEval": 59.60595663949432, "BBH Raw": 0.4619637884426022, "BBH": 24.05717251228861, "MATH Lvl 5 Raw": 0.0679758308157099, "MATH Lvl 5": 6.797583081570997, "GPQA Raw": 0.3070469798657718, "GPQA": 7.606263982102905, "MUSR Raw": 0.42540625, "MUSR": 11.77578125, "MMLU-PRO Raw": 0.3289561170212766, "MMLU-PRO": 25.439568557919618, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-26T00:00:00", "Submission Date": "2024-07-27T00:00:00", "Generation": 1, "Base Model": "Pretergeek/OpenChat-3.5-0106_8.99B_40Layers-Appended (Merge)"}, {"eval_name": "Pretergeek_OpenChat-3.5-0106_8.99B_40Layers-Interleaved_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Pretergeek/OpenChat-3.5-0106_8.99B_40Layers-Interleaved\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Pretergeek/OpenChat-3.5-0106_8.99B_40Layers-Interleaved</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Pretergeek__OpenChat-3.5-0106_8.99B_40Layers-Interleaved-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Pretergeek/OpenChat-3.5-0106_8.99B_40Layers-Interleaved", "Model sha": "b6dfa36a99179674706d5e859714afa6b8743640", "Average \u2b06\ufe0f": 22.492062778275898, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 2, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5975833011963811, "IFEval": 59.75833011963812, "BBH Raw": 0.4621304551092688, "BBH": 24.075505845621944, "MATH Lvl 5 Raw": 0.0679758308157099, "MATH Lvl 5": 6.797583081570997, "GPQA Raw": 0.3045302013422818, "GPQA": 7.270693512304249, "MUSR Raw": 0.4240729166666666, "MUSR": 11.509114583333334, "MMLU-PRO Raw": 0.3298703457446808, "MMLU-PRO": 25.54114952718676, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-10T00:00:00", "Submission Date": "2024-08-16T00:00:00", "Generation": 1, "Base Model": "Pretergeek/OpenChat-3.5-0106_8.99B_40Layers-Interleaved (Merge)"}, {"eval_name": "Pretergeek_OpenChat-3.5-0106_9.86B_44Layers-Appended_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Pretergeek/OpenChat-3.5-0106_9.86B_44Layers-Appended\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Pretergeek/OpenChat-3.5-0106_9.86B_44Layers-Appended</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Pretergeek__OpenChat-3.5-0106_9.86B_44Layers-Appended-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Pretergeek/OpenChat-3.5-0106_9.86B_44Layers-Appended", "Model sha": "8a7ef4a2c4faf8760650e26e44509920bace633a", "Average \u2b06\ufe0f": 22.547054337229408, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 2, "#Params (B)": 9, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5960595663949432, "IFEval": 59.60595663949432, "BBH Raw": 0.4619637884426022, "BBH": 24.05717251228861, "MATH Lvl 5 Raw": 0.0679758308157099, "MATH Lvl 5": 6.797583081570997, "GPQA Raw": 0.3070469798657718, "GPQA": 7.606263982102905, "MUSR Raw": 0.42540625, "MUSR": 11.77578125, "MMLU-PRO Raw": 0.3289561170212766, "MMLU-PRO": 25.439568557919618, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-27T00:00:00", "Submission Date": "2024-07-27T00:00:00", "Generation": 1, "Base Model": "Pretergeek/OpenChat-3.5-0106_9.86B_44Layers-Appended (Merge)"}, {"eval_name": "Pretergeek_openchat-3.5-0106_Rebased_Mistral-7B-v0.2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Pretergeek/openchat-3.5-0106_Rebased_Mistral-7B-v0.2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Pretergeek/openchat-3.5-0106_Rebased_Mistral-7B-v0.2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Pretergeek__openchat-3.5-0106_Rebased_Mistral-7B-v0.2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Pretergeek/openchat-3.5-0106_Rebased_Mistral-7B-v0.2", "Model sha": "31c11027a7320115af1e5c33b41bcace83420fe2", "Average \u2b06\ufe0f": 15.938983336355728, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 2, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3706210632233584, "IFEval": 37.06210632233585, "BBH Raw": 0.36271140677296, "BBH": 10.910767600799836, "MATH Lvl 5 Raw": 0.0385196374622356, "MATH Lvl 5": 3.8519637462235647, "GPQA Raw": 0.2718120805369127, "GPQA": 2.9082774049217, "MUSR Raw": 0.4840104166666667, "MUSR": 20.56796875, "MMLU-PRO Raw": 0.2829953457446808, "MMLU-PRO": 20.33281619385342, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-21T00:00:00", "Submission Date": "2024-07-21T00:00:00", "Generation": 0, "Base Model": "Pretergeek/openchat-3.5-0106_Rebased_Mistral-7B-v0.2"}, {"eval_name": "PygmalionAI_pygmalion-6b_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "GPTJForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/PygmalionAI/pygmalion-6b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">PygmalionAI/pygmalion-6b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/PygmalionAI__pygmalion-6b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "PygmalionAI/pygmalion-6b", "Model sha": "2a0d74449c8fbf0378194e95f64aa92e16297294", "Average \u2b06\ufe0f": 5.392359658909203, "Hub License": "creativeml-openrail-m", "Hub \u2764\ufe0f": 729, "#Params (B)": 6, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2091040661001697, "IFEval": 20.91040661001697, "BBH Raw": 0.3198894464386003, "BBH": 5.089577143988909, "MATH Lvl 5 Raw": 0.0060422960725075, "MATH Lvl 5": 0.6042296072507553, "GPQA Raw": 0.2491610738255033, "GPQA": 0.0, "MUSR Raw": 0.3683541666666667, "MUSR": 3.7109375, "MMLU-PRO Raw": 0.1183510638297872, "MMLU-PRO": 2.039007092198581, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-01-07T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "PygmalionAI/pygmalion-6b"}, {"eval_name": "Q-bert_MetaMath-1B_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Q-bert/MetaMath-1B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Q-bert/MetaMath-1B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Q-bert__MetaMath-1B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Q-bert/MetaMath-1B", "Model sha": "da62756f069aba78d07d4c76108e246cb91dbc35", "Average \u2b06\ufe0f": 11.32424791067333, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 1, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5300391849182392, "IFEval": 53.00391849182392, "BBH Raw": 0.3450686367792951, "BBH": 8.434610644832558, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2516778523489933, "GPQA": 0.2237136465324418, "MUSR Raw": 0.3289166666666667, "MUSR": 0.7812499999999996, "MMLU-PRO Raw": 0.1495179521276596, "MMLU-PRO": 5.501994680851065, "Maintainer's Highlight": false, "Upload To Hub Date": "", "Submission Date": "2024-09-30T00:00:00", "Generation": 0, "Base Model": "Removed"}, {"eval_name": "Qwen_Qwen1.5-0.5B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Qwen/Qwen1.5-0.5B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Qwen/Qwen1.5-0.5B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Qwen__Qwen1.5-0.5B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Qwen/Qwen1.5-0.5B", "Model sha": "8f445e3628f3500ee69f24e1303c9f10f5342a39", "Average \u2b06\ufe0f": 5.137017087672389, "Hub License": "other", "Hub \u2764\ufe0f": 143, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1705607787337597, "IFEval": 17.056077873375976, "BBH Raw": 0.3153538659142558, "BBH": 5.035475836799366, "MATH Lvl 5 Raw": 0.0045317220543806, "MATH Lvl 5": 0.4531722054380665, "GPQA Raw": 0.2541946308724832, "GPQA": 0.5592841163310973, "MUSR Raw": 0.361625, "MUSR": 4.303125, "MMLU-PRO Raw": 0.1307347074468085, "MMLU-PRO": 3.4149674940898342, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-01-22T00:00:00", "Submission Date": "2024-06-13T00:00:00", "Generation": 0, "Base Model": "Qwen/Qwen1.5-0.5B"}, {"eval_name": "Qwen_Qwen1.5-0.5B-Chat_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Qwen/Qwen1.5-0.5B-Chat\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Qwen/Qwen1.5-0.5B-Chat</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Qwen__Qwen1.5-0.5B-Chat-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Qwen/Qwen1.5-0.5B-Chat", "Model sha": "4d14e384a4b037942bb3f3016665157c8bcb70ea", "Average \u2b06\ufe0f": 5.564869039793773, "Hub License": "other", "Hub \u2764\ufe0f": 74, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.1807271373289538, "IFEval": 18.072713732895387, "BBH Raw": 0.3166662152036714, "BBH": 4.318032636938059, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2692953020134228, "GPQA": 2.572706935123044, "MUSR Raw": 0.3837083333333333, "MUSR": 6.063541666666667, "MMLU-PRO Raw": 0.1212599734042553, "MMLU-PRO": 2.362219267139479, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-01-31T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "Qwen/Qwen1.5-0.5B-Chat"}, {"eval_name": "Qwen_Qwen1.5-1.8B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Qwen/Qwen1.5-1.8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Qwen/Qwen1.5-1.8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Qwen__Qwen1.5-1.8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Qwen/Qwen1.5-1.8B", "Model sha": "7846de7ed421727b318d6605a0bfab659da2c067", "Average \u2b06\ufe0f": 9.118435120286238, "Hub License": "other", "Hub \u2764\ufe0f": 43, "#Params (B)": 1, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2154239639711521, "IFEval": 21.54239639711521, "BBH Raw": 0.3476121558366305, "BBH": 9.759901587727937, "MATH Lvl 5 Raw": 0.0226586102719033, "MATH Lvl 5": 2.2658610271903323, "GPQA Raw": 0.3053691275167785, "GPQA": 7.38255033557047, "MUSR Raw": 0.3605104166666666, "MUSR": 3.963802083333334, "MMLU-PRO Raw": 0.1881648936170212, "MMLU-PRO": 9.79609929078014, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-01-22T00:00:00", "Submission Date": "2024-06-13T00:00:00", "Generation": 0, "Base Model": "Qwen/Qwen1.5-1.8B"}, {"eval_name": "Qwen_Qwen1.5-1.8B-Chat_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Qwen/Qwen1.5-1.8B-Chat\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Qwen/Qwen1.5-1.8B-Chat</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Qwen__Qwen1.5-1.8B-Chat-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Qwen/Qwen1.5-1.8B-Chat", "Model sha": "e482ee3f73c375a627a16fdf66fd0c8279743ca6", "Average \u2b06\ufe0f": 9.006021162921042, "Hub License": "other", "Hub \u2764\ufe0f": 44, "#Params (B)": 1, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2019098214958532, "IFEval": 20.190982149585324, "BBH Raw": 0.3255912875735599, "BBH": 5.908662877770453, "MATH Lvl 5 Raw": 0.0045317220543806, "MATH Lvl 5": 0.4531722054380665, "GPQA Raw": 0.2978187919463087, "GPQA": 6.375838926174497, "MUSR Raw": 0.42596875, "MUSR": 12.179427083333335, "MMLU-PRO Raw": 0.1803523936170212, "MMLU-PRO": 8.928043735224584, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-01-30T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "Qwen/Qwen1.5-1.8B-Chat"}, {"eval_name": "Qwen_Qwen1.5-110B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Qwen/Qwen1.5-110B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Qwen/Qwen1.5-110B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Qwen__Qwen1.5-110B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Qwen/Qwen1.5-110B", "Model sha": "16659038ecdcc771c1293cf47020fa7cc2750ee8", "Average \u2b06\ufe0f": 29.556738934879004, "Hub License": "other", "Hub \u2764\ufe0f": 91, "#Params (B)": 111, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3421942667677318, "IFEval": 34.21942667677318, "BBH Raw": 0.6099964981780978, "BBH": 44.28047655387545, "MATH Lvl 5 Raw": 0.2303625377643504, "MATH Lvl 5": 23.036253776435046, "GPQA Raw": 0.3523489932885906, "GPQA": 13.646532438478744, "MUSR Raw": 0.44084375, "MUSR": 13.70546875, "MMLU-PRO Raw": 0.5360704787234043, "MMLU-PRO": 48.45227541371159, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-04-25T00:00:00", "Submission Date": "2024-06-13T00:00:00", "Generation": 0, "Base Model": "Qwen/Qwen1.5-110B"}, {"eval_name": "Qwen_Qwen1.5-110B-Chat_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Qwen/Qwen1.5-110B-Chat\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Qwen/Qwen1.5-110B-Chat</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Qwen__Qwen1.5-110B-Chat-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Qwen/Qwen1.5-110B-Chat", "Model sha": "85f86cec25901f2dbd870a86e06756903c9a876a", "Average \u2b06\ufe0f": 29.224836684325613, "Hub License": "other", "Hub \u2764\ufe0f": 123, "#Params (B)": 111, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5938864435254014, "IFEval": 59.38864435254016, "BBH Raw": 0.6183800385588633, "BBH": 44.98454525616634, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.3414429530201342, "GPQA": 12.192393736017896, "MUSR Raw": 0.4521666666666666, "MUSR": 16.287499999999994, "MMLU-PRO Raw": 0.4824634308510638, "MMLU-PRO": 42.49593676122932, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-04-25T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "Qwen/Qwen1.5-110B-Chat"}, {"eval_name": "Qwen_Qwen1.5-14B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Qwen/Qwen1.5-14B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Qwen/Qwen1.5-14B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Qwen__Qwen1.5-14B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Qwen/Qwen1.5-14B", "Model sha": "dce4b190d34470818e5bec2a92cb8233aaa02ca2", "Average \u2b06\ufe0f": 20.224674221574386, "Hub License": "other", "Hub \u2764\ufe0f": 36, "#Params (B)": 14, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2905368865720732, "IFEval": 29.05368865720732, "BBH Raw": 0.5080327493808331, "BBH": 30.063103282917453, "MATH Lvl 5 Raw": 0.1646525679758308, "MATH Lvl 5": 16.46525679758308, "GPQA Raw": 0.2944630872483221, "GPQA": 5.92841163310962, "MUSR Raw": 0.4186458333333333, "MUSR": 10.464062500000002, "MMLU-PRO Raw": 0.3643617021276595, "MMLU-PRO": 29.37352245862884, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-01-22T00:00:00", "Submission Date": "2024-06-13T00:00:00", "Generation": 0, "Base Model": "Qwen/Qwen1.5-14B"}, {"eval_name": "Qwen_Qwen1.5-14B-Chat_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Qwen/Qwen1.5-14B-Chat\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Qwen/Qwen1.5-14B-Chat</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Qwen__Qwen1.5-14B-Chat-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Qwen/Qwen1.5-14B-Chat", "Model sha": "9492b22871f43e975435455f5c616c77fe7a50ec", "Average \u2b06\ufe0f": 21.02330687787111, "Hub License": "other", "Hub \u2764\ufe0f": 110, "#Params (B)": 14, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4768082022367318, "IFEval": 47.68082022367319, "BBH Raw": 0.5228587510703555, "BBH": 32.75647930053065, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2701342281879195, "GPQA": 2.684563758389265, "MUSR Raw": 0.4399791666666666, "MUSR": 13.930729166666667, "MMLU-PRO Raw": 0.3617852393617021, "MMLU-PRO": 29.08724881796691, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-01-30T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "Qwen/Qwen1.5-14B-Chat"}, {"eval_name": "Qwen_Qwen1.5-32B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Qwen/Qwen1.5-32B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Qwen/Qwen1.5-32B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Qwen__Qwen1.5-32B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Qwen/Qwen1.5-32B", "Model sha": "cefef80dc06a65f89d1d71d0adbc56d335ca2490", "Average \u2b06\ufe0f": 26.69452624990984, "Hub License": "other", "Hub \u2764\ufe0f": 81, "#Params (B)": 32, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.329729562006587, "IFEval": 32.97295620065869, "BBH Raw": 0.5715390555959325, "BBH": 38.980351633108974, "MATH Lvl 5 Raw": 0.2666163141993957, "MATH Lvl 5": 26.66163141993957, "GPQA Raw": 0.3296979865771812, "GPQA": 10.626398210290828, "MUSR Raw": 0.4277916666666666, "MUSR": 12.040625000000004, "MMLU-PRO Raw": 0.4499667553191489, "MMLU-PRO": 38.88519503546098, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-04-01T00:00:00", "Submission Date": "2024-06-13T00:00:00", "Generation": 0, "Base Model": "Qwen/Qwen1.5-32B"}, {"eval_name": "Qwen_Qwen1.5-32B-Chat_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Qwen/Qwen1.5-32B-Chat\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Qwen/Qwen1.5-32B-Chat</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Qwen__Qwen1.5-32B-Chat-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Qwen/Qwen1.5-32B-Chat", "Model sha": "0997b012af6ddd5465d40465a8415535b2f06cfc", "Average \u2b06\ufe0f": 27.104900252772502, "Hub License": "other", "Hub \u2764\ufe0f": 106, "#Params (B)": 32, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5532199009738605, "IFEval": 55.32199009738605, "BBH Raw": 0.6066899757930234, "BBH": 44.55485402391639, "MATH Lvl 5 Raw": 0.066465256797583, "MATH Lvl 5": 6.646525679758309, "GPQA Raw": 0.3062080536912752, "GPQA": 7.494407158836691, "MUSR Raw": 0.4159791666666666, "MUSR": 10.197395833333337, "MMLU-PRO Raw": 0.4457280585106383, "MMLU-PRO": 38.41422872340425, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-04-03T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "Qwen/Qwen1.5-32B-Chat"}, {"eval_name": "Qwen_Qwen1.5-4B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Qwen/Qwen1.5-4B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Qwen/Qwen1.5-4B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Qwen__Qwen1.5-4B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Qwen/Qwen1.5-4B", "Model sha": "a66363a0c24e2155c561e4b53c658b1d3965474e", "Average \u2b06\ufe0f": 11.289834319444326, "Hub License": "other", "Hub \u2764\ufe0f": 34, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2444746605672947, "IFEval": 24.447466056729475, "BBH Raw": 0.4053897029672546, "BBH": 16.249142581095292, "MATH Lvl 5 Raw": 0.0241691842900302, "MATH Lvl 5": 2.416918429003021, "GPQA Raw": 0.2768456375838926, "GPQA": 3.5794183445190177, "MUSR Raw": 0.3604479166666667, "MUSR": 4.8226562500000005, "MMLU-PRO Raw": 0.2460106382978723, "MMLU-PRO": 16.22340425531915, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-01-22T00:00:00", "Submission Date": "2024-06-13T00:00:00", "Generation": 0, "Base Model": "Qwen/Qwen1.5-4B"}, {"eval_name": "Qwen_Qwen1.5-4B-Chat_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Qwen/Qwen1.5-4B-Chat\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Qwen/Qwen1.5-4B-Chat</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Qwen__Qwen1.5-4B-Chat-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Qwen/Qwen1.5-4B-Chat", "Model sha": "a7a4d4945d28bac955554c9abd2f74a71ebbf22f", "Average \u2b06\ufe0f": 12.325165307166374, "Hub License": "other", "Hub \u2764\ufe0f": 38, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3156657668320057, "IFEval": 31.566576683200577, "BBH Raw": 0.4005548561148611, "BBH": 16.29707852890831, "MATH Lvl 5 Raw": 0.0098187311178247, "MATH Lvl 5": 0.9818731117824772, "GPQA Raw": 0.2667785234899328, "GPQA": 2.2371364653243813, "MUSR Raw": 0.39778125, "MUSR": 7.355989583333333, "MMLU-PRO Raw": 0.2396110372340425, "MMLU-PRO": 15.512337470449172, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-01-30T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "Qwen/Qwen1.5-4B-Chat"}, {"eval_name": "Qwen_Qwen1.5-7B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Qwen/Qwen1.5-7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Qwen/Qwen1.5-7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Qwen__Qwen1.5-7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Qwen/Qwen1.5-7B", "Model sha": "831096e3a59a0789a541415da25ef195ceb802fe", "Average \u2b06\ufe0f": 15.219034679073014, "Hub License": "other", "Hub \u2764\ufe0f": 45, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2684299879874289, "IFEval": 26.842998798742894, "BBH Raw": 0.4559896407693445, "BBH": 23.075768754340448, "MATH Lvl 5 Raw": 0.0445619335347432, "MATH Lvl 5": 4.45619335347432, "GPQA Raw": 0.2986577181208054, "GPQA": 6.487695749440718, "MUSR Raw": 0.4103333333333334, "MUSR": 9.158333333333331, "MMLU-PRO Raw": 0.2916389627659574, "MMLU-PRO": 21.293218085106385, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-01-22T00:00:00", "Submission Date": "2024-06-09T00:00:00", "Generation": 0, "Base Model": "Qwen/Qwen1.5-7B"}, {"eval_name": "Qwen_Qwen1.5-7B-Chat_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Qwen/Qwen1.5-7B-Chat\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Qwen/Qwen1.5-7B-Chat</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Qwen__Qwen1.5-7B-Chat-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Qwen/Qwen1.5-7B-Chat", "Model sha": "5f4f5e69ac7f1d508f8369e977de208b4803444b", "Average \u2b06\ufe0f": 16.57617293158245, "Hub License": "other", "Hub \u2764\ufe0f": 161, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4371157417873464, "IFEval": 43.71157417873464, "BBH Raw": 0.4510053116521351, "BBH": 22.379129599952787, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.3028523489932886, "GPQA": 7.046979865771815, "MUSR Raw": 0.3779062499999999, "MUSR": 4.63828125, "MMLU-PRO Raw": 0.2951296542553192, "MMLU-PRO": 21.681072695035464, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-01-30T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "Qwen/Qwen1.5-7B-Chat"}, {"eval_name": "Qwen_Qwen1.5-MoE-A2.7B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "Qwen2MoeForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Qwen/Qwen1.5-MoE-A2.7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Qwen/Qwen1.5-MoE-A2.7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Qwen__Qwen1.5-MoE-A2.7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Qwen/Qwen1.5-MoE-A2.7B", "Model sha": "1a758c50ecb6350748b9ce0a99d2352fd9fc11c9", "Average \u2b06\ufe0f": 12.42275797734545, "Hub License": "other", "Hub \u2764\ufe0f": 190, "#Params (B)": 14, "Available on the hub": true, "Not_Merged": true, "MoE": false, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.265982038768246, "IFEval": 26.59820387682461, "BBH Raw": 0.4113515433010766, "BBH": 18.837858500547185, "MATH Lvl 5 Raw": 0.0015105740181268, "MATH Lvl 5": 0.1510574018126888, "GPQA Raw": 0.259228187919463, "GPQA": 1.230425055928408, "MUSR Raw": 0.40134375, "MUSR": 7.967968750000003, "MMLU-PRO Raw": 0.2777593085106383, "MMLU-PRO": 19.751034278959807, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-02-29T00:00:00", "Submission Date": "2024-06-13T00:00:00", "Generation": 0, "Base Model": "Qwen/Qwen1.5-MoE-A2.7B"}, {"eval_name": "Qwen_Qwen1.5-MoE-A2.7B-Chat_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2MoeForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Qwen/Qwen1.5-MoE-A2.7B-Chat\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Qwen/Qwen1.5-MoE-A2.7B-Chat</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Qwen__Qwen1.5-MoE-A2.7B-Chat-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Qwen/Qwen1.5-MoE-A2.7B-Chat", "Model sha": "ec052fda178e241c7c443468d2fa1db6618996be", "Average \u2b06\ufe0f": 14.823498043433531, "Hub License": "other", "Hub \u2764\ufe0f": 111, "#Params (B)": 14, "Available on the hub": true, "Not_Merged": true, "MoE": false, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3795385133667557, "IFEval": 37.95385133667558, "BBH Raw": 0.4272088620635824, "BBH": 20.041818895540956, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2743288590604026, "GPQA": 3.243847874720355, "MUSR Raw": 0.3898749999999999, "MUSR": 6.334375000000001, "MMLU-PRO Raw": 0.2923038563829787, "MMLU-PRO": 21.3670951536643, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-03-14T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "Qwen/Qwen1.5-MoE-A2.7B-Chat"}, {"eval_name": "Qwen_Qwen2-0.5B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Qwen/Qwen2-0.5B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Qwen/Qwen2-0.5B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Qwen__Qwen2-0.5B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Qwen/Qwen2-0.5B", "Model sha": "ff3a49fac17555b8dfc4db6709f480cc8f16a9fe", "Average \u2b06\ufe0f": 7.062282757592702, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 99, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1867223411658843, "IFEval": 18.672234116588427, "BBH Raw": 0.3253319620710724, "BBH": 7.994201896754274, "MATH Lvl 5 Raw": 0.0256797583081571, "MATH Lvl 5": 2.56797583081571, "GPQA Raw": 0.2558724832214765, "GPQA": 0.7829977628635317, "MUSR Raw": 0.3752083333333333, "MUSR": 4.601041666666668, "MMLU-PRO Raw": 0.1697972074468085, "MMLU-PRO": 7.7552452718676115, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-05-31T00:00:00", "Submission Date": "2024-06-09T00:00:00", "Generation": 0, "Base Model": "Qwen/Qwen2-0.5B"}, {"eval_name": "Qwen_Qwen2-0.5B-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Qwen/Qwen2-0.5B-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Qwen/Qwen2-0.5B-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Qwen__Qwen2-0.5B-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Qwen/Qwen2-0.5B-Instruct", "Model sha": "c291d6fce4804a1d39305f388dd32897d1f7acc4", "Average \u2b06\ufe0f": 6.385370764204122, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 156, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2246661081486012, "IFEval": 22.466610814860125, "BBH Raw": 0.3172517938486349, "BBH": 5.876044259408482, "MATH Lvl 5 Raw": 0.0166163141993957, "MATH Lvl 5": 1.6616314199395772, "GPQA Raw": 0.2466442953020134, "GPQA": 0.0, "MUSR Raw": 0.3352708333333333, "MUSR": 2.408854166666666, "MMLU-PRO Raw": 0.1530917553191489, "MMLU-PRO": 5.89908392434988, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-06-03T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 1, "Base Model": "Qwen/Qwen2-0.5B"}, {"eval_name": "Qwen_Qwen2-1.5B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Qwen/Qwen2-1.5B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Qwen/Qwen2-1.5B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Qwen__Qwen2-1.5B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Qwen/Qwen2-1.5B", "Model sha": "8a16abf2848eda07cc5253dec660bf1ce007ad7a", "Average \u2b06\ufe0f": 10.319571767384211, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 76, "#Params (B)": 1, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2113270566541221, "IFEval": 21.132705665412217, "BBH Raw": 0.3574793172057746, "BBH": 11.781833653483533, "MATH Lvl 5 Raw": 0.0626888217522658, "MATH Lvl 5": 6.268882175226587, "GPQA Raw": 0.2642617449664429, "GPQA": 1.9015659955257265, "MUSR Raw": 0.3658125, "MUSR": 3.5932291666666667, "MMLU-PRO Raw": 0.2551529255319149, "MMLU-PRO": 17.239213947990542, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-05-31T00:00:00", "Submission Date": "2024-06-09T00:00:00", "Generation": 0, "Base Model": "Qwen/Qwen2-1.5B"}, {"eval_name": "Qwen_Qwen2-1.5B-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Qwen/Qwen2-1.5B-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Qwen/Qwen2-1.5B-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Qwen__Qwen2-1.5B-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Qwen/Qwen2-1.5B-Instruct", "Model sha": "ba1cf1846d7df0a0591d6c00649f57e798519da8", "Average \u2b06\ufe0f": 13.91535071246266, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 128, "#Params (B)": 1, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3371232773485463, "IFEval": 33.712327734854625, "BBH Raw": 0.3852232408376059, "BBH": 13.695346827502664, "MATH Lvl 5 Raw": 0.0581570996978852, "MATH Lvl 5": 5.81570996978852, "GPQA Raw": 0.261744966442953, "GPQA": 1.5659955257270708, "MUSR Raw": 0.42928125, "MUSR": 12.026822916666667, "MMLU-PRO Raw": 0.2500831117021276, "MMLU-PRO": 16.675901300236408, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-06-03T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "Qwen/Qwen2-1.5B-Instruct"}, {"eval_name": "Qwen_Qwen2-57B-A14B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "Qwen2MoeForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Qwen/Qwen2-57B-A14B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Qwen/Qwen2-57B-A14B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Qwen__Qwen2-57B-A14B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Qwen/Qwen2-57B-A14B", "Model sha": "973e466c39ba76372a2ae464dbca0af3f5a5a2a9", "Average \u2b06\ufe0f": 25.0338731324107, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 46, "#Params (B)": 57, "Available on the hub": true, "Not_Merged": true, "MoE": false, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3112696534085116, "IFEval": 31.126965340851164, "BBH Raw": 0.5618204938684165, "BBH": 38.87598905034189, "MATH Lvl 5 Raw": 0.1865558912386707, "MATH Lvl 5": 18.65558912386707, "GPQA Raw": 0.3062080536912752, "GPQA": 7.494407158836691, "MUSR Raw": 0.417375, "MUSR": 10.538541666666667, "MMLU-PRO Raw": 0.4916057180851064, "MMLU-PRO": 43.51174645390071, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-05-22T00:00:00", "Submission Date": "2024-06-13T00:00:00", "Generation": 0, "Base Model": "Qwen/Qwen2-57B-A14B"}, {"eval_name": "Qwen_Qwen2-57B-A14B-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2MoeForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Qwen/Qwen2-57B-A14B-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Qwen/Qwen2-57B-A14B-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Qwen__Qwen2-57B-A14B-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Qwen/Qwen2-57B-A14B-Instruct", "Model sha": "5ea455a449e61a92a5b194ee06be807647d3e8b5", "Average \u2b06\ufe0f": 29.604489165943875, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 76, "#Params (B)": 57, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6337783747124297, "IFEval": 63.37783747124297, "BBH Raw": 0.5887606963532052, "BBH": 41.785917734842535, "MATH Lvl 5 Raw": 0.0770392749244713, "MATH Lvl 5": 7.7039274924471295, "GPQA Raw": 0.3313758389261745, "GPQA": 10.850111856823268, "MUSR Raw": 0.4361354166666666, "MUSR": 14.183593749999996, "MMLU-PRO Raw": 0.4575299202127659, "MMLU-PRO": 39.725546690307326, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-06-04T00:00:00", "Submission Date": "2024-08-14T00:00:00", "Generation": 1, "Base Model": "Qwen/Qwen2-57B-A14B"}, {"eval_name": "Qwen_Qwen2-72B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Qwen/Qwen2-72B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Qwen/Qwen2-72B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Qwen__Qwen2-72B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Qwen/Qwen2-72B", "Model sha": "87993795c78576318087f70b43fbf530eb7789e7", "Average \u2b06\ufe0f": 35.129379895213305, "Hub License": "other", "Hub \u2764\ufe0f": 188, "#Params (B)": 72, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3823610243044012, "IFEval": 38.23610243044012, "BBH Raw": 0.661734029856643, "BBH": 51.85613118695519, "MATH Lvl 5 Raw": 0.2915407854984894, "MATH Lvl 5": 29.154078549848943, "GPQA Raw": 0.3942953020134228, "GPQA": 19.239373601789712, "MUSR Raw": 0.4703645833333333, "MUSR": 19.728906250000005, "MMLU-PRO Raw": 0.5730551861702128, "MMLU-PRO": 52.56168735224587, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-05-22T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "Qwen/Qwen2-72B"}, {"eval_name": "Qwen_Qwen2-72B-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Qwen/Qwen2-72B-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Qwen/Qwen2-72B-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Qwen__Qwen2-72B-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Qwen/Qwen2-72B-Instruct", "Model sha": "1af63c698f59c4235668ec9c1395468cb7cd7e79", "Average \u2b06\ufe0f": 42.48630818371823, "Hub License": "other", "Hub \u2764\ufe0f": 666, "#Params (B)": 72, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.7989168738945996, "IFEval": 79.89168738945996, "BBH Raw": 0.697730968386067, "BBH": 57.48300911876294, "MATH Lvl 5 Raw": 0.3512084592145015, "MATH Lvl 5": 35.12084592145015, "GPQA Raw": 0.3724832214765101, "GPQA": 16.33109619686801, "MUSR Raw": 0.4560104166666667, "MUSR": 17.167968749999996, "MMLU-PRO Raw": 0.5403091755319149, "MMLU-PRO": 48.92324172576833, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-05-28T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "Qwen/Qwen2-72B"}, {"eval_name": "Qwen_Qwen2-7B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Qwen/Qwen2-7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Qwen/Qwen2-7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Qwen__Qwen2-7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Qwen/Qwen2-7B", "Model sha": "453ed1575b739b5b03ce3758b23befdb0967f40e", "Average \u2b06\ufe0f": 23.66081168731019, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 132, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3148667757106699, "IFEval": 31.48667757106699, "BBH Raw": 0.531531595001889, "BBH": 34.711136202753416, "MATH Lvl 5 Raw": 0.1880664652567975, "MATH Lvl 5": 18.80664652567976, "GPQA Raw": 0.3045302013422818, "GPQA": 7.270693512304249, "MUSR Raw": 0.4439166666666667, "MUSR": 14.322916666666666, "MMLU-PRO Raw": 0.4183011968085106, "MMLU-PRO": 35.366799645390074, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-06-04T00:00:00", "Submission Date": "2024-06-09T00:00:00", "Generation": 0, "Base Model": "Qwen/Qwen2-7B"}, {"eval_name": "Qwen_Qwen2-7B-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Qwen/Qwen2-7B-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Qwen/Qwen2-7B-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Qwen__Qwen2-7B-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Qwen/Qwen2-7B-Instruct", "Model sha": "41c66b0be1c3081f13defc6bdf946c2ef240d6a6", "Average \u2b06\ufe0f": 24.764482344118388, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 574, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5679075962889577, "IFEval": 56.79075962889577, "BBH Raw": 0.5544781563793189, "BBH": 37.80839092310167, "MATH Lvl 5 Raw": 0.0861027190332326, "MATH Lvl 5": 8.610271903323262, "GPQA Raw": 0.2978187919463087, "GPQA": 6.375838926174497, "MUSR Raw": 0.3927916666666666, "MUSR": 7.365625, "MMLU-PRO Raw": 0.3847240691489361, "MMLU-PRO": 31.636007683215123, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-06-04T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 1, "Base Model": "Qwen/Qwen2-7B"}, {"eval_name": "Qwen_Qwen2-Math-72B-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Qwen/Qwen2-Math-72B-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Qwen/Qwen2-Math-72B-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Qwen__Qwen2-Math-72B-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Qwen/Qwen2-Math-72B-Instruct", "Model sha": "5c267882f3377bcfc35882f8609098a894eeeaa8", "Average \u2b06\ufe0f": 34.78581098013775, "Hub License": "other", "Hub \u2764\ufe0f": 83, "#Params (B)": 72, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.569381463405985, "IFEval": 56.93814634059851, "BBH Raw": 0.634337660025181, "BBH": 47.96019950734914, "MATH Lvl 5 Raw": 0.3595166163141994, "MATH Lvl 5": 35.95166163141994, "GPQA Raw": 0.3682885906040268, "GPQA": 15.771812080536916, "MUSR Raw": 0.4516979166666666, "MUSR": 15.728906249999994, "MMLU-PRO Raw": 0.4272772606382978, "MMLU-PRO": 36.364140070921984, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-08-08T00:00:00", "Submission Date": "2024-08-19T00:00:00", "Generation": 0, "Base Model": "Qwen/Qwen2-Math-72B-Instruct"}, {"eval_name": "Qwen_Qwen2-Math-7B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Qwen/Qwen2-Math-7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Qwen/Qwen2-Math-7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Qwen__Qwen2-Math-7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Qwen/Qwen2-Math-7B", "Model sha": "47a44ff4136da8960adbab02b2326787086bcf6c", "Average \u2b06\ufe0f": 11.6266895266672, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 13, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2687048143370701, "IFEval": 26.87048143370701, "BBH Raw": 0.386954741074792, "BBH": 14.064494488871304, "MATH Lvl 5 Raw": 0.2243202416918429, "MATH Lvl 5": 22.432024169184288, "GPQA Raw": 0.2634228187919463, "GPQA": 1.789709172259505, "MUSR Raw": 0.3593333333333333, "MUSR": 2.4166666666666683, "MMLU-PRO Raw": 0.1196808510638298, "MMLU-PRO": 2.186761229314421, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-08-08T00:00:00", "Submission Date": "2024-08-19T00:00:00", "Generation": 0, "Base Model": "Qwen/Qwen2-Math-7B"}, {"eval_name": "Qwen_Qwen2.5-0.5B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Qwen/Qwen2.5-0.5B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Qwen/Qwen2.5-0.5B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Qwen__Qwen2.5-0.5B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Qwen/Qwen2.5-0.5B", "Model sha": "2630d3d2321bc1f1878f702166d1b2af019a7310", "Average \u2b06\ufe0f": 6.222776577036183, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 73, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1627171460613394, "IFEval": 16.271714606133948, "BBH Raw": 0.3274814815119661, "BBH": 6.953961634882263, "MATH Lvl 5 Raw": 0.0196374622356495, "MATH Lvl 5": 1.9637462235649543, "GPQA Raw": 0.2466442953020134, "GPQA": 0.0, "MUSR Raw": 0.3433333333333333, "MUSR": 2.0833333333333326, "MMLU-PRO Raw": 0.1905751329787234, "MMLU-PRO": 10.0639036643026, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-09-15T00:00:00", "Submission Date": "2024-09-19T00:00:00", "Generation": 0, "Base Model": "Qwen/Qwen2.5-0.5B"}, {"eval_name": "Qwen_Qwen2.5-0.5B-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Qwen/Qwen2.5-0.5B-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Qwen/Qwen2.5-0.5B-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Qwen__Qwen2.5-0.5B-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Qwen/Qwen2.5-0.5B-Instruct", "Model sha": "a8b602d9dafd3a75d382e62757d83d89fca3be54", "Average \u2b06\ufe0f": 8.140647319276075, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 70, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.307122878407071, "IFEval": 30.712287840707106, "BBH Raw": 0.3340729214937266, "BBH": 8.434863610588833, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2575503355704698, "GPQA": 1.0067114093959737, "MUSR Raw": 0.3328854166666666, "MUSR": 0.9440104166666662, "MMLU-PRO Raw": 0.1697140957446808, "MMLU-PRO": 7.746010638297871, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-09-16T00:00:00", "Submission Date": "2024-09-19T00:00:00", "Generation": 1, "Base Model": "Qwen/Qwen2.5-0.5B"}, {"eval_name": "Qwen_Qwen2.5-1.5B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Qwen/Qwen2.5-1.5B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Qwen/Qwen2.5-1.5B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Qwen__Qwen2.5-1.5B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Qwen/Qwen2.5-1.5B", "Model sha": "e5dfabbcffd9b0c7b31d89b82c5a6b72e663f32c", "Average \u2b06\ufe0f": 13.600938824965786, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 30, "#Params (B)": 1, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2674304179576856, "IFEval": 26.74304179576856, "BBH Raw": 0.4077950945136614, "BBH": 16.660465167691854, "MATH Lvl 5 Raw": 0.0762839879154078, "MATH Lvl 5": 7.628398791540786, "GPQA Raw": 0.285234899328859, "GPQA": 4.697986577181204, "MUSR Raw": 0.35759375, "MUSR": 5.265885416666666, "MMLU-PRO Raw": 0.2854886968085106, "MMLU-PRO": 20.609855200945624, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-09-15T00:00:00", "Submission Date": "2024-09-19T00:00:00", "Generation": 0, "Base Model": "Qwen/Qwen2.5-1.5B"}, {"eval_name": "Qwen_Qwen2.5-1.5B-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Qwen/Qwen2.5-1.5B-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Qwen__Qwen2.5-1.5B-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Qwen/Qwen2.5-1.5B-Instruct", "Model sha": "5fee7c4ed634dc66c6e318c8ac2897b8b9154536", "Average \u2b06\ufe0f": 14.968777016770265, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 68, "#Params (B)": 1, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4475569267321817, "IFEval": 44.75569267321818, "BBH Raw": 0.4288982740422907, "BBH": 19.80978649735897, "MATH Lvl 5 Raw": 0.0128398791540785, "MATH Lvl 5": 1.283987915407855, "GPQA Raw": 0.2558724832214765, "GPQA": 0.7829977628635317, "MUSR Raw": 0.3663125, "MUSR": 3.1890625000000004, "MMLU-PRO Raw": 0.2799202127659574, "MMLU-PRO": 19.99113475177305, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-09-17T00:00:00", "Submission Date": "2024-09-19T00:00:00", "Generation": 1, "Base Model": "Qwen/Qwen2.5-1.5B"}, {"eval_name": "Qwen_Qwen2.5-14B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Qwen/Qwen2.5-14B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Qwen/Qwen2.5-14B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Qwen__Qwen2.5-14B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Qwen/Qwen2.5-14B", "Model sha": "83a1904df002b00bc8db6f877821cb77dbb363b0", "Average \u2b06\ufe0f": 31.447538020440007, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 25, "#Params (B)": 14, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3694464022127954, "IFEval": 36.94464022127954, "BBH Raw": 0.616051493531774, "BBH": 45.078312404984935, "MATH Lvl 5 Raw": 0.2598187311178248, "MATH Lvl 5": 25.98187311178248, "GPQA Raw": 0.3817114093959731, "GPQA": 17.561521252796418, "MUSR Raw": 0.4502395833333333, "MUSR": 15.913281249999995, "MMLU-PRO Raw": 0.5248503989361702, "MMLU-PRO": 47.20559988179669, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-09-15T00:00:00", "Submission Date": "2024-09-19T00:00:00", "Generation": 0, "Base Model": "Qwen/Qwen2.5-14B"}, {"eval_name": "Qwen_Qwen2.5-14B-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Qwen/Qwen2.5-14B-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Qwen/Qwen2.5-14B-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Qwen__Qwen2.5-14B-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Qwen/Qwen2.5-14B-Instruct", "Model sha": "f55224c616ca27d4bcf28969a156de12c98981cf", "Average \u2b06\ufe0f": 32.18307278426168, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 76, "#Params (B)": 14, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.8157776920792386, "IFEval": 81.57776920792386, "BBH Raw": 0.6390453705906222, "BBH": 48.36070661282705, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.3221476510067114, "GPQA": 9.61968680089485, "MUSR Raw": 0.4100625, "MUSR": 10.157812500000004, "MMLU-PRO Raw": 0.4904421542553192, "MMLU-PRO": 43.382461583924346, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-09-16T00:00:00", "Submission Date": "2024-09-18T00:00:00", "Generation": 1, "Base Model": "Qwen/Qwen2.5-14B"}, {"eval_name": "Qwen_Qwen2.5-32B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Qwen/Qwen2.5-32B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Qwen/Qwen2.5-32B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Qwen__Qwen2.5-32B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Qwen/Qwen2.5-32B", "Model sha": "ff23665d01c3665be5fdb271d18a62090b65c06d", "Average \u2b06\ufe0f": 37.54220698289055, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 19, "#Params (B)": 32, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4076649955451535, "IFEval": 40.76649955451536, "BBH Raw": 0.6770522448726507, "BBH": 53.954752851332, "MATH Lvl 5 Raw": 0.3285498489425982, "MATH Lvl 5": 32.85498489425982, "GPQA Raw": 0.4119127516778523, "GPQA": 21.588366890380318, "MUSR Raw": 0.4978333333333333, "MUSR": 22.69583333333333, "MMLU-PRO Raw": 0.5805352393617021, "MMLU-PRO": 53.39280437352246, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-09-15T00:00:00", "Submission Date": "2024-09-19T00:00:00", "Generation": 0, "Base Model": "Qwen/Qwen2.5-32B"}, {"eval_name": "Qwen_Qwen2.5-32B-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Qwen/Qwen2.5-32B-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Qwen/Qwen2.5-32B-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Qwen__Qwen2.5-32B-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Qwen/Qwen2.5-32B-Instruct", "Model sha": "70e8dfb9ad18a7d499f765fe206ff065ed8ca197", "Average \u2b06\ufe0f": 36.17418497413896, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 95, "#Params (B)": 32, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.8346121623957765, "IFEval": 83.46121623957765, "BBH Raw": 0.6912525080134339, "BBH": 56.48934826159387, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.3380872483221476, "GPQA": 11.74496644295302, "MUSR Raw": 0.426125, "MUSR": 13.498958333333327, "MMLU-PRO Raw": 0.566655585106383, "MMLU-PRO": 51.85062056737589, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-09-17T00:00:00", "Submission Date": "2024-09-19T00:00:00", "Generation": 1, "Base Model": "Qwen/Qwen2.5-32B"}, {"eval_name": "Qwen_Qwen2.5-3B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Qwen/Qwen2.5-3B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Qwen/Qwen2.5-3B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Qwen__Qwen2.5-3B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Qwen/Qwen2.5-3B", "Model sha": "e4aa5ac50aa507415cda96cc99eb77ad0a3d2d34", "Average \u2b06\ufe0f": 16.957251587270786, "Hub License": "other", "Hub \u2764\ufe0f": 25, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2689541527591236, "IFEval": 26.89541527591236, "BBH Raw": 0.4612475341011634, "BBH": 24.30424172637169, "MATH Lvl 5 Raw": 0.0793051359516616, "MATH Lvl 5": 7.930513595166164, "GPQA Raw": 0.2978187919463087, "GPQA": 6.375838926174497, "MUSR Raw": 0.4303333333333333, "MUSR": 11.758333333333336, "MMLU-PRO Raw": 0.3203125, "MMLU-PRO": 24.479166666666664, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-09-15T00:00:00", "Submission Date": "2024-09-27T00:00:00", "Generation": 0, "Base Model": "Qwen/Qwen2.5-3B"}, {"eval_name": "Qwen_Qwen2.5-3B-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Qwen/Qwen2.5-3B-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Qwen/Qwen2.5-3B-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Qwen__Qwen2.5-3B-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Qwen/Qwen2.5-3B-Instruct", "Model sha": "82f42baa094a9600e39ccd80d34058aeeb3abbc1", "Average \u2b06\ufe0f": 21.03134431880069, "Hub License": "other", "Hub \u2764\ufe0f": 52, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6474919879253713, "IFEval": 64.74919879253714, "BBH Raw": 0.469276665604885, "BBH": 25.801393944088584, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2726510067114094, "GPQA": 3.0201342281879207, "MUSR Raw": 0.3967916666666666, "MUSR": 7.565625, "MMLU-PRO Raw": 0.3254654255319149, "MMLU-PRO": 25.05171394799054, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-09-17T00:00:00", "Submission Date": "2024-09-19T00:00:00", "Generation": 1, "Base Model": "Qwen/Qwen2.5-3B"}, {"eval_name": "Qwen_Qwen2.5-72B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Qwen/Qwen2.5-72B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Qwen/Qwen2.5-72B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Qwen__Qwen2.5-72B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Qwen/Qwen2.5-72B", "Model sha": "587cc4061cf6a7cc0d429d05c109447e5cf063af", "Average \u2b06\ufe0f": 37.93761889982685, "Hub License": "other", "Hub \u2764\ufe0f": 29, "#Params (B)": 72, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4137100670664947, "IFEval": 41.37100670664947, "BBH Raw": 0.6797320670694852, "BBH": 54.61505780163693, "MATH Lvl 5 Raw": 0.3610271903323263, "MATH Lvl 5": 36.102719033232624, "GPQA Raw": 0.4052013422818792, "GPQA": 20.69351230425056, "MUSR Raw": 0.477125, "MUSR": 19.640625, "MMLU-PRO Raw": 0.5968251329787234, "MMLU-PRO": 55.20279255319149, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-09-15T00:00:00", "Submission Date": "2024-09-19T00:00:00", "Generation": 0, "Base Model": "Qwen/Qwen2.5-72B"}, {"eval_name": "Qwen_Qwen2.5-72B-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Qwen/Qwen2.5-72B-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Qwen/Qwen2.5-72B-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Qwen__Qwen2.5-72B-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Qwen/Qwen2.5-72B-Instruct", "Model sha": "a13fff9ad76700c7ecff2769f75943ba8395b4a7", "Average \u2b06\ufe0f": 38.35349673672554, "Hub License": "other", "Hub \u2764\ufe0f": 321, "#Params (B)": 72, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.8650369907401251, "IFEval": 86.5036990740125, "BBH Raw": 0.7270437112480544, "BBH": 61.77823228154451, "MATH Lvl 5 Raw": 0.0128398791540785, "MATH Lvl 5": 1.283987915407855, "GPQA Raw": 0.3808724832214765, "GPQA": 17.4496644295302, "MUSR Raw": 0.4206041666666666, "MUSR": 11.808854166666668, "MMLU-PRO Raw": 0.5616688829787234, "MMLU-PRO": 51.29654255319149, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-09-16T00:00:00", "Submission Date": "2024-09-19T00:00:00", "Generation": 1, "Base Model": "Qwen/Qwen2.5-72B"}, {"eval_name": "Qwen_Qwen2.5-7B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Qwen/Qwen2.5-7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Qwen/Qwen2.5-7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Qwen__Qwen2.5-7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Qwen/Qwen2.5-7B", "Model sha": "57597c00770845ceba45271ba1b24c94bbcc7baf", "Average \u2b06\ufe0f": 24.697407658234063, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 42, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3374479713825982, "IFEval": 33.74479713825982, "BBH Raw": 0.5416303767788616, "BBH": 35.81347328754777, "MATH Lvl 5 Raw": 0.1714501510574018, "MATH Lvl 5": 17.14501510574018, "GPQA Raw": 0.3246644295302013, "GPQA": 9.955257270693512, "MUSR Raw": 0.4424270833333333, "MUSR": 14.13671875, "MMLU-PRO Raw": 0.4365026595744681, "MMLU-PRO": 37.38918439716312, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-09-15T00:00:00", "Submission Date": "2024-09-19T00:00:00", "Generation": 0, "Base Model": "Qwen/Qwen2.5-7B"}, {"eval_name": "Qwen_Qwen2.5-7B-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Qwen/Qwen2.5-7B-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Qwen/Qwen2.5-7B-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Qwen__Qwen2.5-7B-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Qwen/Qwen2.5-7B-Instruct", "Model sha": "52e20a6f5f475e5c8f6a8ebda4ae5fa6b1ea22ac", "Average \u2b06\ufe0f": 26.86677532661463, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 188, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7585251576926999, "IFEval": 75.85251576926998, "BBH Raw": 0.5394231968299095, "BBH": 34.89211675876548, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2911073825503356, "GPQA": 5.480984340044745, "MUSR Raw": 0.40203125, "MUSR": 8.453906250000001, "MMLU-PRO Raw": 0.4286901595744681, "MMLU-PRO": 36.52112884160757, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-09-16T00:00:00", "Submission Date": "2024-09-18T00:00:00", "Generation": 1, "Base Model": "Qwen/Qwen2.5-7B"}, {"eval_name": "Qwen_Qwen2.5-Coder-7B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Qwen/Qwen2.5-Coder-7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Qwen/Qwen2.5-Coder-7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Qwen__Qwen2.5-Coder-7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Qwen/Qwen2.5-Coder-7B", "Model sha": "097b213c52760d22753af1aa5cbdba94b5c99506", "Average \u2b06\ufe0f": 18.91996385215459, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 32, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.344592348302504, "IFEval": 34.4592348302504, "BBH Raw": 0.4855640553421474, "BBH": 28.43894411525553, "MATH Lvl 5 Raw": 0.1744712990936555, "MATH Lvl 5": 17.447129909365557, "GPQA Raw": 0.259228187919463, "GPQA": 1.230425055928408, "MUSR Raw": 0.3448541666666667, "MUSR": 2.1734375000000004, "MMLU-PRO Raw": 0.3679355053191489, "MMLU-PRO": 29.770611702127653, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-09-16T00:00:00", "Submission Date": "2024-09-21T00:00:00", "Generation": 1, "Base Model": "Qwen/Qwen2.5-Coder-7B (Merge)"}, {"eval_name": "Qwen_Qwen2.5-Coder-7B-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Qwen/Qwen2.5-Coder-7B-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Qwen/Qwen2.5-Coder-7B-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Qwen__Qwen2.5-Coder-7B-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Qwen/Qwen2.5-Coder-7B-Instruct", "Model sha": "3030861ab8e72c6155e1821631bf977ef40d3e5b", "Average \u2b06\ufe0f": 22.954584644512156, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 156, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.610372699991578, "IFEval": 61.037269999157786, "BBH Raw": 0.5087090028113894, "BBH": 30.4662574668053, "MATH Lvl 5 Raw": 0.0702416918429003, "MATH Lvl 5": 7.02416918429003, "GPQA Raw": 0.2785234899328859, "GPQA": 3.803131991051453, "MUSR Raw": 0.4032708333333333, "MUSR": 8.608854166666667, "MMLU-PRO Raw": 0.3410904255319149, "MMLU-PRO": 26.78782505910165, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-09-17T00:00:00", "Submission Date": "2024-09-19T00:00:00", "Generation": 1, "Base Model": "Qwen/Qwen2.5-Coder-7B-Instruct (Merge)"}, {"eval_name": "Qwen_Qwen2.5-Math-72B-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Qwen/Qwen2.5-Math-72B-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Qwen/Qwen2.5-Math-72B-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Qwen__Qwen2.5-Math-72B-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Qwen/Qwen2.5-Math-72B-Instruct", "Model sha": "3743c8fd46b002d105c1d28d180f1e531df1d40f", "Average \u2b06\ufe0f": 29.50916799125021, "Hub License": "other", "Hub \u2764\ufe0f": 12, "#Params (B)": 72, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4003466358151926, "IFEval": 40.03466358151925, "BBH Raw": 0.6452266637803764, "BBH": 48.966096029421145, "MATH Lvl 5 Raw": 0.1850453172205438, "MATH Lvl 5": 18.50453172205438, "GPQA Raw": 0.3313758389261745, "GPQA": 10.850111856823268, "MUSR Raw": 0.4472708333333333, "MUSR": 16.342187499999998, "MMLU-PRO Raw": 0.4812167553191489, "MMLU-PRO": 42.35741725768321, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-09-16T00:00:00", "Submission Date": "2024-09-29T00:00:00", "Generation": 2, "Base Model": "Qwen/Qwen2.5-72B"}, {"eval_name": "Qwen_Qwen2.5-Math-7B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe9 continuously pretrained", "T": "\ud83d\udfe9", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Qwen/Qwen2.5-Math-7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Qwen/Qwen2.5-Math-7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Qwen__Qwen2.5-Math-7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Qwen/Qwen2.5-Math-7B", "Model sha": "8daf1d676c3f24ddec5a99c5cff00a5c0e1c441c", "Average \u2b06\ufe0f": 17.47160176857572, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 13, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2459983953687327, "IFEval": 24.59983953687328, "BBH Raw": 0.4454639372840941, "BBH": 22.00876067958663, "MATH Lvl 5 Raw": 0.2832326283987915, "MATH Lvl 5": 28.323262839879156, "GPQA Raw": 0.2936241610738255, "GPQA": 5.8165548098434, "MUSR Raw": 0.3780937499999999, "MUSR": 4.995052083333334, "MMLU-PRO Raw": 0.2717752659574468, "MMLU-PRO": 19.086140661938536, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-09-16T00:00:00", "Submission Date": "2024-09-21T00:00:00", "Generation": 1, "Base Model": "Qwen/Qwen2.5-7B"}, {"eval_name": "Qwen_Qwen2.5-Math-7B-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Qwen/Qwen2.5-Math-7B-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Qwen/Qwen2.5-Math-7B-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Qwen__Qwen2.5-Math-7B-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Qwen/Qwen2.5-Math-7B-Instruct", "Model sha": "b3b4c5794bf4b68c1978bb3525afc5e0d0d6fcc4", "Average \u2b06\ufe0f": 16.22937433781395, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 23, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2635839572334738, "IFEval": 26.358395723347385, "BBH Raw": 0.438762734452786, "BBH": 21.489765755272032, "MATH Lvl 5 Raw": 0.2484894259818731, "MATH Lvl 5": 24.848942598187318, "GPQA Raw": 0.261744966442953, "GPQA": 1.5659955257270708, "MUSR Raw": 0.3647291666666666, "MUSR": 2.891145833333333, "MMLU-PRO Raw": 0.2819980053191489, "MMLU-PRO": 20.222000591016545, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-09-19T00:00:00", "Submission Date": "2024-09-19T00:00:00", "Generation": 2, "Base Model": "Qwen/Qwen2.5-7B"}, {"eval_name": "RESMPDEV_Qwen2-Wukong-0.5B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/RESMPDEV/Qwen2-Wukong-0.5B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">RESMPDEV/Qwen2-Wukong-0.5B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/RESMPDEV__Qwen2-Wukong-0.5B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "RESMPDEV/Qwen2-Wukong-0.5B", "Model sha": "52c58a4aa3d0b44c363c5761fa658243f5c53943", "Average \u2b06\ufe0f": 4.950363477111334, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 6, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.1854235650296768, "IFEval": 18.54235650296768, "BBH Raw": 0.308451428837168, "BBH": 4.19666315993673, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2365771812080536, "GPQA": 0.0, "MUSR Raw": 0.3524791666666667, "MUSR": 3.3265625, "MMLU-PRO Raw": 0.1327293882978723, "MMLU-PRO": 3.6365986997635926, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-29T00:00:00", "Submission Date": "2024-06-30T00:00:00", "Generation": 0, "Base Model": "RESMPDEV/Qwen2-Wukong-0.5B"}, {"eval_name": "RLHFlow_ArmoRM-Llama3-8B-v0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForRewardModelWithGating", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/RLHFlow/ArmoRM-Llama3-8B-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">RLHFlow/ArmoRM-Llama3-8B-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/RLHFlow__ArmoRM-Llama3-8B-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "RLHFlow/ArmoRM-Llama3-8B-v0.1", "Model sha": "eb2676d20da2f2d41082289d23c59b9f7427f955", "Average \u2b06\ufe0f": 4.705487409302649, "Hub License": "llama3", "Hub \u2764\ufe0f": 139, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.1896700753999388, "IFEval": 18.967007539993883, "BBH Raw": 0.2876467446788138, "BBH": 1.7494478703137453, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2491610738255033, "GPQA": 0.0, "MUSR Raw": 0.3948020833333333, "MUSR": 6.650260416666666, "MMLU-PRO Raw": 0.1077958776595744, "MMLU-PRO": 0.8662086288416063, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-23T00:00:00", "Submission Date": "2024-10-08T00:00:00", "Generation": 0, "Base Model": "RLHFlow/ArmoRM-Llama3-8B-v0.1"}, {"eval_name": "RLHFlow_LLaMA3-iterative-DPO-final_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/RLHFlow/LLaMA3-iterative-DPO-final\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">RLHFlow/LLaMA3-iterative-DPO-final</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/RLHFlow__LLaMA3-iterative-DPO-final-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "RLHFlow/LLaMA3-iterative-DPO-final", "Model sha": "40b73bd07a019795837f80579fe95470484ca82b", "Average \u2b06\ufe0f": 19.63634312977761, "Hub License": "llama3", "Hub \u2764\ufe0f": 41, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.53401086893886, "IFEval": 53.401086893886, "BBH Raw": 0.5058257182733729, "BBH": 29.787760272097795, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2835570469798658, "GPQA": 4.4742729306487705, "MUSR Raw": 0.3672708333333334, "MUSR": 5.075520833333335, "MMLU-PRO Raw": 0.3257147606382978, "MMLU-PRO": 25.07941784869976, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-17T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "RLHFlow/LLaMA3-iterative-DPO-final"}, {"eval_name": "RWKV_rwkv-raven-14b_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "RwkvForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/RWKV/rwkv-raven-14b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">RWKV/rwkv-raven-14b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/RWKV__rwkv-raven-14b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "RWKV/rwkv-raven-14b", "Model sha": "359c0649b4f1d10a26ebea32908035bc00d152ee", "Average \u2b06\ufe0f": 3.885056601409273, "Hub License": null, "Hub \u2764\ufe0f": 55, "#Params (B)": 14, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.0768372363107665, "IFEval": 7.683723631076655, "BBH Raw": 0.3307041176552897, "BBH": 6.763765061303336, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2290268456375838, "GPQA": 0.0, "MUSR Raw": 0.3951458333333333, "MUSR": 7.193229166666666, "MMLU-PRO Raw": 0.1150265957446808, "MMLU-PRO": 1.6696217494089831, "Maintainer's Highlight": false, "Upload To Hub Date": "2023-05-05T00:00:00", "Submission Date": "2024-07-08T00:00:00", "Generation": 0, "Base Model": "RWKV/rwkv-raven-14b"}, {"eval_name": "Rakuten_RakutenAI-7B_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Rakuten/RakutenAI-7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Rakuten/RakutenAI-7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Rakuten__RakutenAI-7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Rakuten/RakutenAI-7B", "Model sha": "c687b10cbf1aa6c34868904b62ecfcef2e0946bf", "Average \u2b06\ufe0f": 11.534390259928832, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 44, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1555971488982566, "IFEval": 15.559714889825662, "BBH Raw": 0.4314905261361543, "BBH": 20.98205231291448, "MATH Lvl 5 Raw": 0.0188821752265861, "MATH Lvl 5": 1.8882175226586104, "GPQA Raw": 0.2894295302013422, "GPQA": 5.257270693512303, "MUSR Raw": 0.3738125, "MUSR": 4.659895833333335, "MMLU-PRO Raw": 0.2877327127659574, "MMLU-PRO": 20.859190307328607, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-03-18T00:00:00", "Submission Date": "2024-09-06T00:00:00", "Generation": 0, "Base Model": "Rakuten/RakutenAI-7B"}, {"eval_name": "Rakuten_RakutenAI-7B-chat_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Rakuten/RakutenAI-7B-chat\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Rakuten/RakutenAI-7B-chat</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Rakuten__RakutenAI-7B-chat-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Rakuten/RakutenAI-7B-chat", "Model sha": "1685492c5c40f8a7f57e2cc1c8fa65e5b0c94d31", "Average \u2b06\ufe0f": 12.777919128499391, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 58, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2685552112838379, "IFEval": 26.8555211283838, "BBH Raw": 0.4316204035758174, "BBH": 20.23755200474476, "MATH Lvl 5 Raw": 0.0279456193353474, "MATH Lvl 5": 2.794561933534743, "GPQA Raw": 0.2567114093959731, "GPQA": 0.8948545861297527, "MUSR Raw": 0.3789583333333333, "MUSR": 5.903125, "MMLU-PRO Raw": 0.2798371010638298, "MMLU-PRO": 19.98190011820331, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-03-18T00:00:00", "Submission Date": "2024-09-08T00:00:00", "Generation": 0, "Base Model": "Rakuten/RakutenAI-7B-chat"}, {"eval_name": "Replete-AI_Llama3-8B-Instruct-Replete-Adapted_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Replete-AI/Llama3-8B-Instruct-Replete-Adapted\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Replete-AI/Llama3-8B-Instruct-Replete-Adapted</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Replete-AI__Llama3-8B-Instruct-Replete-Adapted-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Replete-AI/Llama3-8B-Instruct-Replete-Adapted", "Model sha": "d930f2111913da6fb7693187e1cdc817191c8e5e", "Average \u2b06\ufe0f": 22.400874344251168, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6915306941138402, "IFEval": 69.15306941138402, "BBH Raw": 0.4870261829331898, "BBH": 26.88896431517229, "MATH Lvl 5 Raw": 0.0483383685800604, "MATH Lvl 5": 4.833836858006042, "GPQA Raw": 0.2810402684563758, "GPQA": 4.138702460850116, "MUSR Raw": 0.3633958333333333, "MUSR": 2.824479166666667, "MMLU-PRO Raw": 0.3390957446808511, "MMLU-PRO": 26.56619385342789, "Maintainer's Highlight": false, "Upload To Hub Date": "", "Submission Date": "2024-07-09T00:00:00", "Generation": 0, "Base Model": "Removed"}, {"eval_name": "Replete-AI_Replete-Coder-Instruct-8b-Merged_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Replete-AI/Replete-Coder-Instruct-8b-Merged\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Replete-AI/Replete-Coder-Instruct-8b-Merged</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Replete-AI__Replete-Coder-Instruct-8b-Merged-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Replete-AI/Replete-Coder-Instruct-8b-Merged", "Model sha": "0594615bf84f0803a078b59f14eb090cec2004f3", "Average \u2b06\ufe0f": 16.314374513892584, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5387571643239937, "IFEval": 53.87571643239937, "BBH Raw": 0.4461693860075828, "BBH": 21.937706578272657, "MATH Lvl 5 Raw": 0.0709969788519637, "MATH Lvl 5": 7.099697885196375, "GPQA Raw": 0.2692953020134228, "GPQA": 2.572706935123044, "MUSR Raw": 0.36603125, "MUSR": 3.4539062499999997, "MMLU-PRO Raw": 0.1805186170212765, "MMLU-PRO": 8.946513002364064, "Maintainer's Highlight": false, "Upload To Hub Date": "", "Submission Date": "2024-07-11T00:00:00", "Generation": 0, "Base Model": "Removed"}, {"eval_name": "Replete-AI_Replete-Coder-Llama3-8B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Replete-AI/Replete-Coder-Llama3-8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Replete-AI/Replete-Coder-Llama3-8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Replete-AI__Replete-Coder-Llama3-8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Replete-AI/Replete-Coder-Llama3-8B", "Model sha": "2aca75c53e7eb2f523889ab1a279e349b8f1b0e8", "Average \u2b06\ufe0f": 11.65585948063502, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4729362535849324, "IFEval": 47.293625358493244, "BBH Raw": 0.3271277102526684, "BBH": 7.055475836799367, "MATH Lvl 5 Raw": 0.0294561933534743, "MATH Lvl 5": 2.9456193353474323, "GPQA Raw": 0.2609060402684564, "GPQA": 1.4541387024608574, "MUSR Raw": 0.3953020833333333, "MUSR": 7.512760416666666, "MMLU-PRO Raw": 0.1330618351063829, "MMLU-PRO": 3.673537234042553, "Maintainer's Highlight": false, "Upload To Hub Date": "", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "Removed"}, {"eval_name": "Replete-AI_Replete-Coder-Qwen2-1.5b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Replete-AI/Replete-Coder-Qwen2-1.5b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Replete-AI/Replete-Coder-Qwen2-1.5b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Replete-AI__Replete-Coder-Qwen2-1.5b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Replete-AI/Replete-Coder-Qwen2-1.5b", "Model sha": "86fcccbf921b7eb8a4d348e4a3cde0beb63d6626", "Average \u2b06\ufe0f": 11.070107351610863, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 1, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3014279888473694, "IFEval": 30.14279888473694, "BBH Raw": 0.3474729566669602, "BBH": 10.4265158026681, "MATH Lvl 5 Raw": 0.0090634441087613, "MATH Lvl 5": 0.906344410876133, "GPQA Raw": 0.2684563758389262, "GPQA": 2.460850111856823, "MUSR Raw": 0.4072708333333333, "MUSR": 9.742187500000002, "MMLU-PRO Raw": 0.2146775265957446, "MMLU-PRO": 12.741947399527188, "Maintainer's Highlight": false, "Upload To Hub Date": "", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "Removed"}, {"eval_name": "Replete-AI_Replete-LLM-Qwen2-7b_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Replete-AI/Replete-LLM-Qwen2-7b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Replete-AI/Replete-LLM-Qwen2-7b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Replete-AI__Replete-LLM-Qwen2-7b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Replete-AI/Replete-LLM-Qwen2-7b", "Model sha": "e3569433b23fde853683ad61f342d2c1bd01d60a", "Average \u2b06\ufe0f": 3.325393716070183, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.0904754939117098, "IFEval": 9.047549391170982, "BBH Raw": 0.2985257401126037, "BBH": 2.8429334106486, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2533557046979866, "GPQA": 0.4474272930648763, "MUSR Raw": 0.3847604166666666, "MUSR": 5.861718749999999, "MMLU-PRO Raw": 0.1157746010638298, "MMLU-PRO": 1.7527334515366433, "Maintainer's Highlight": false, "Upload To Hub Date": "", "Submission Date": "2024-08-13T00:00:00", "Generation": 0, "Base Model": "Removed"}, {"eval_name": "Replete-AI_Replete-LLM-Qwen2-7b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Replete-AI/Replete-LLM-Qwen2-7b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Replete-AI/Replete-LLM-Qwen2-7b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Replete-AI__Replete-LLM-Qwen2-7b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Replete-AI/Replete-LLM-Qwen2-7b", "Model sha": "5b75b6180b45d83124e04a00766dc19d2ad52622", "Average \u2b06\ufe0f": 3.509166955357833, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.0932481371649445, "IFEval": 9.324813716494456, "BBH Raw": 0.2976924067792704, "BBH": 2.7249704476856373, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.24748322147651, "GPQA": 0.0, "MUSR Raw": 0.3940937499999999, "MUSR": 7.26171875, "MMLU-PRO Raw": 0.1156914893617021, "MMLU-PRO": 1.7434988179669018, "Maintainer's Highlight": false, "Upload To Hub Date": "", "Submission Date": "2024-08-13T00:00:00", "Generation": 0, "Base Model": "Removed"}, {"eval_name": "Replete-AI_Replete-LLM-Qwen2-7b_Beta-Preview_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Replete-AI/Replete-LLM-Qwen2-7b_Beta-Preview\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Replete-AI/Replete-LLM-Qwen2-7b_Beta-Preview</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Replete-AI__Replete-LLM-Qwen2-7b_Beta-Preview-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Replete-AI/Replete-LLM-Qwen2-7b_Beta-Preview", "Model sha": "fe4c3fc2314db69083527ddd0c9a658fcbc54f15", "Average \u2b06\ufe0f": 3.5774317458290468, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.0857546864541638, "IFEval": 8.575468645416384, "BBH Raw": 0.2929321328066677, "BBH": 1.965676941851036, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2483221476510067, "GPQA": 0.0, "MUSR Raw": 0.3980625, "MUSR": 7.7578125, "MMLU-PRO Raw": 0.1284906914893617, "MMLU-PRO": 3.1656323877068555, "Maintainer's Highlight": false, "Upload To Hub Date": "", "Submission Date": "2024-07-26T00:00:00", "Generation": 0, "Base Model": "Removed"}, {"eval_name": "Replete-AI_Replete-LLM-V2-Llama-3.1-8b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Replete-AI/Replete-LLM-V2-Llama-3.1-8b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Replete-AI/Replete-LLM-V2-Llama-3.1-8b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Replete-AI__Replete-LLM-V2-Llama-3.1-8b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Replete-AI/Replete-LLM-V2-Llama-3.1-8b", "Model sha": "5ff5224804dcc31f536e491e52310f2e3cdc0b57", "Average \u2b06\ufe0f": 24.840693047058465, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.5514966954347797, "IFEval": 55.14966954347798, "BBH Raw": 0.5339203611594218, "BBH": 33.20757217219532, "MATH Lvl 5 Raw": 0.1321752265861027, "MATH Lvl 5": 13.217522658610273, "GPQA Raw": 0.313758389261745, "GPQA": 8.501118568232664, "MUSR Raw": 0.4000729166666667, "MUSR": 8.375781250000001, "MMLU-PRO Raw": 0.3753324468085106, "MMLU-PRO": 30.59249408983452, "Maintainer's Highlight": false, "Upload To Hub Date": "", "Submission Date": "2024-08-30T00:00:00", "Generation": 0, "Base Model": "Removed"}, {"eval_name": "RubielLabarta_LogoS-7Bx2-MoE-13B-v0.2_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/RubielLabarta/LogoS-7Bx2-MoE-13B-v0.2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">RubielLabarta/LogoS-7Bx2-MoE-13B-v0.2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/RubielLabarta__LogoS-7Bx2-MoE-13B-v0.2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "RubielLabarta/LogoS-7Bx2-MoE-13B-v0.2", "Model sha": "fb0f72b9914a81892bfeea5a04fcd9676c883d64", "Average \u2b06\ufe0f": 19.95374374264885, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 10, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": false, "MoE": false, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4378903531518593, "IFEval": 43.78903531518593, "BBH Raw": 0.5206958722481815, "BBH": 32.794801632016096, "MATH Lvl 5 Raw": 0.0475830815709969, "MATH Lvl 5": 4.758308157099698, "GPQA Raw": 0.2776845637583892, "GPQA": 3.691275167785232, "MUSR Raw": 0.4226145833333333, "MUSR": 11.493489583333336, "MMLU-PRO Raw": 0.3087599734042553, "MMLU-PRO": 23.19555260047281, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-01-21T00:00:00", "Submission Date": "2024-08-05T00:00:00", "Generation": 1, "Base Model": "RubielLabarta/LogoS-7Bx2-MoE-13B-v0.2 (Merge)"}, {"eval_name": "SaisExperiments_Evil-Alpaca-3B-L3.2_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/SaisExperiments/Evil-Alpaca-3B-L3.2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">SaisExperiments/Evil-Alpaca-3B-L3.2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/SaisExperiments__Evil-Alpaca-3B-L3.2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "SaisExperiments/Evil-Alpaca-3B-L3.2", "Model sha": "77d25b9182270a66ac60a91d646b447e1530f70e", "Average \u2b06\ufe0f": 14.961466839241911, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 3, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3251084899178623, "IFEval": 32.51084899178623, "BBH Raw": 0.4340757699220565, "BBH": 20.8519483855812, "MATH Lvl 5 Raw": 0.0566465256797583, "MATH Lvl 5": 5.664652567975831, "GPQA Raw": 0.2634228187919463, "GPQA": 1.789709172259505, "MUSR Raw": 0.4197604166666667, "MUSR": 10.936718750000004, "MMLU-PRO Raw": 0.2621343085106383, "MMLU-PRO": 18.0149231678487, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-28T00:00:00", "Submission Date": "2024-09-28T00:00:00", "Generation": 1, "Base Model": "SaisExperiments/Evil-Alpaca-3B-L3.2 (Merge)"}, {"eval_name": "SaisExperiments_Gemma-2-2B-Opus-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/SaisExperiments/Gemma-2-2B-Opus-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">SaisExperiments/Gemma-2-2B-Opus-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/SaisExperiments__Gemma-2-2B-Opus-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "SaisExperiments/Gemma-2-2B-Opus-Instruct", "Model sha": "7caa9e833d3f5713cf1b8ebd8beeb6ef02da99ea", "Average \u2b06\ufe0f": 17.05716920364964, "Hub License": "gemma", "Hub \u2764\ufe0f": 0, "#Params (B)": 2, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.474959773401242, "IFEval": 47.4959773401242, "BBH Raw": 0.4292846281445681, "BBH": 19.52953299453869, "MATH Lvl 5 Raw": 0.039274924471299, "MATH Lvl 5": 3.927492447129909, "GPQA Raw": 0.2835570469798658, "GPQA": 4.4742729306487705, "MUSR Raw": 0.4056875, "MUSR": 8.577604166666665, "MMLU-PRO Raw": 0.2650432180851064, "MMLU-PRO": 18.3381353427896, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-03T00:00:00", "Submission Date": "2024-10-07T00:00:00", "Generation": 2, "Base Model": "google/gemma-2-2b"}, {"eval_name": "SaisExperiments_Gemma-2-2B-Stheno-Filtered_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/SaisExperiments/Gemma-2-2B-Stheno-Filtered\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">SaisExperiments/Gemma-2-2B-Stheno-Filtered</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/SaisExperiments__Gemma-2-2B-Stheno-Filtered-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "SaisExperiments/Gemma-2-2B-Stheno-Filtered", "Model sha": "683443cfa90c7a06978d1c5e9ead0fb0a68b49ca", "Average \u2b06\ufe0f": 15.340045361050178, "Hub License": "gemma", "Hub \u2764\ufe0f": 1, "#Params (B)": 2, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4196554032190144, "IFEval": 41.96554032190144, "BBH Raw": 0.4149234152222183, "BBH": 17.47886723805338, "MATH Lvl 5 Raw": 0.0370090634441087, "MATH Lvl 5": 3.700906344410876, "GPQA Raw": 0.2701342281879195, "GPQA": 2.684563758389265, "MUSR Raw": 0.4002916666666666, "MUSR": 8.103125000000002, "MMLU-PRO Raw": 0.2629654255319149, "MMLU-PRO": 18.107269503546096, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-04T00:00:00", "Submission Date": "2024-10-08T00:00:00", "Generation": 2, "Base Model": "google/gemma-2-2b"}, {"eval_name": "Salesforce_LLaMA-3-8B-SFR-Iterative-DPO-R_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Salesforce/LLaMA-3-8B-SFR-Iterative-DPO-R\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Salesforce/LLaMA-3-8B-SFR-Iterative-DPO-R</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Salesforce__LLaMA-3-8B-SFR-Iterative-DPO-R-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Salesforce/LLaMA-3-8B-SFR-Iterative-DPO-R", "Model sha": "ad7d1aed82eb6d8ca4b3aad627ff76f72ab34f70", "Average \u2b06\ufe0f": 17.029765390241824, "Hub License": "llama3", "Hub \u2764\ufe0f": 73, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3815620331830653, "IFEval": 38.15620331830654, "BBH Raw": 0.5011950469666927, "BBH": 29.15028934976556, "MATH Lvl 5 Raw": 0.0015105740181268, "MATH Lvl 5": 0.1510574018126888, "GPQA Raw": 0.287751677852349, "GPQA": 5.033557046979867, "MUSR Raw": 0.3633333333333333, "MUSR": 5.550000000000002, "MMLU-PRO Raw": 0.3172373670212766, "MMLU-PRO": 24.137485224586285, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-05-09T00:00:00", "Submission Date": "2024-07-02T00:00:00", "Generation": 0, "Base Model": "Salesforce/LLaMA-3-8B-SFR-Iterative-DPO-R"}, {"eval_name": "SanjiWatsuki_Kunoichi-DPO-v2-7B_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/SanjiWatsuki/Kunoichi-DPO-v2-7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">SanjiWatsuki/Kunoichi-DPO-v2-7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/SanjiWatsuki__Kunoichi-DPO-v2-7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "SanjiWatsuki/Kunoichi-DPO-v2-7B", "Model sha": "5278247beb482c4fceff2294570236d68b74d132", "Average \u2b06\ufe0f": 20.40539748691706, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 81, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5431034100630772, "IFEval": 54.31034100630771, "BBH Raw": 0.4415592450869275, "BBH": 20.903472484123803, "MATH Lvl 5 Raw": 0.0657099697885196, "MATH Lvl 5": 6.570996978851963, "GPQA Raw": 0.2961409395973154, "GPQA": 6.152125279642054, "MUSR Raw": 0.4188333333333333, "MUSR": 11.087500000000004, "MMLU-PRO Raw": 0.3106715425531915, "MMLU-PRO": 23.407949172576835, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-01-13T00:00:00", "Submission Date": "2024-06-28T00:00:00", "Generation": 0, "Base Model": "SanjiWatsuki/Kunoichi-DPO-v2-7B"}, {"eval_name": "SanjiWatsuki_Silicon-Maid-7B_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/SanjiWatsuki/Silicon-Maid-7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">SanjiWatsuki/Silicon-Maid-7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/SanjiWatsuki__Silicon-Maid-7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "SanjiWatsuki/Silicon-Maid-7B", "Model sha": "4e43d81f3fff1091df7cb2d85e9e306d25235701", "Average \u2b06\ufe0f": 19.32397871563329, "Hub License": "cc-by-4.0", "Hub \u2764\ufe0f": 101, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5367835121920947, "IFEval": 53.67835121920948, "BBH Raw": 0.4127972831009074, "BBH": 16.692746753586437, "MATH Lvl 5 Raw": 0.059667673716012, "MATH Lvl 5": 5.966767371601208, "GPQA Raw": 0.2902684563758389, "GPQA": 5.369127516778524, "MUSR Raw": 0.4188333333333333, "MUSR": 11.087500000000004, "MMLU-PRO Raw": 0.308344414893617, "MMLU-PRO": 23.149379432624112, "Maintainer's Highlight": false, "Upload To Hub Date": "2023-12-27T00:00:00", "Submission Date": "2024-09-08T00:00:00", "Generation": 0, "Base Model": "SanjiWatsuki/Silicon-Maid-7B"}, {"eval_name": "Sao10K_Fimbulvetr-11B-v2_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Sao10K/Fimbulvetr-11B-v2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Sao10K/Fimbulvetr-11B-v2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Sao10K__Fimbulvetr-11B-v2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Sao10K/Fimbulvetr-11B-v2", "Model sha": "b2dcd534dc3a53ff84e60a53b87816185169be19", "Average \u2b06\ufe0f": 20.03185465113364, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 155, "#Params (B)": 10, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5100056738343152, "IFEval": 51.00056738343152, "BBH Raw": 0.4544495065184342, "BBH": 22.65512081005865, "MATH Lvl 5 Raw": 0.0045317220543806, "MATH Lvl 5": 0.4531722054380665, "GPQA Raw": 0.2919463087248322, "GPQA": 5.592841163310966, "MUSR Raw": 0.4353645833333333, "MUSR": 14.920572916666666, "MMLU-PRO Raw": 0.3301196808510638, "MMLU-PRO": 25.56885342789598, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-02-06T00:00:00", "Submission Date": "2024-07-01T00:00:00", "Generation": 0, "Base Model": "Sao10K/Fimbulvetr-11B-v2"}, {"eval_name": "Sao10K_L3-70B-Euryale-v2.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Sao10K/L3-70B-Euryale-v2.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Sao10K/L3-70B-Euryale-v2.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Sao10K__L3-70B-Euryale-v2.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Sao10K/L3-70B-Euryale-v2.1", "Model sha": "36ad832b771cd783ea7ad00ed39e61f679b1a7c6", "Average \u2b06\ufe0f": 35.34801470603125, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 115, "#Params (B)": 70, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7384417789243651, "IFEval": 73.84417789243652, "BBH Raw": 0.6471322811268715, "BBH": 48.70118672944805, "MATH Lvl 5 Raw": 0.2084592145015106, "MATH Lvl 5": 20.84592145015106, "GPQA Raw": 0.3313758389261745, "GPQA": 10.850111856823268, "MUSR Raw": 0.4209166666666666, "MUSR": 12.247916666666669, "MMLU-PRO Raw": 0.5103889627659575, "MMLU-PRO": 45.598773640661946, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-11T00:00:00", "Submission Date": "2024-07-01T00:00:00", "Generation": 0, "Base Model": "Sao10K/L3-70B-Euryale-v2.1"}, {"eval_name": "Sao10K_L3-70B-Euryale-v2.1_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Sao10K/L3-70B-Euryale-v2.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Sao10K/L3-70B-Euryale-v2.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Sao10K__L3-70B-Euryale-v2.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Sao10K/L3-70B-Euryale-v2.1", "Model sha": "36ad832b771cd783ea7ad00ed39e61f679b1a7c6", "Average \u2b06\ufe0f": 35.10819728101475, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 115, "#Params (B)": 70, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7281003293483512, "IFEval": 72.81003293483514, "BBH Raw": 0.6502778992745041, "BBH": 49.193003079898574, "MATH Lvl 5 Raw": 0.202416918429003, "MATH Lvl 5": 20.241691842900305, "GPQA Raw": 0.3313758389261745, "GPQA": 10.850111856823268, "MUSR Raw": 0.4195833333333333, "MUSR": 12.047916666666667, "MMLU-PRO Raw": 0.5095578457446809, "MMLU-PRO": 45.50642730496454, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-11T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "Sao10K/L3-70B-Euryale-v2.1"}, {"eval_name": "Sao10K_L3-8B-Lunaris-v1_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Sao10K/L3-8B-Lunaris-v1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Sao10K/L3-8B-Lunaris-v1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Sao10K__L3-8B-Lunaris-v1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Sao10K/L3-8B-Lunaris-v1", "Model sha": "8479c2a7ee119c935b9a02c921cc2a85b698dfe8", "Average \u2b06\ufe0f": 25.477278983891868, "Hub License": "llama3", "Hub \u2764\ufe0f": 84, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6894573066131198, "IFEval": 68.94573066131198, "BBH Raw": 0.5235299282515419, "BBH": 32.11434845509543, "MATH Lvl 5 Raw": 0.0845921450151057, "MATH Lvl 5": 8.459214501510575, "GPQA Raw": 0.3011744966442953, "GPQA": 6.823266219239373, "MUSR Raw": 0.3726666666666667, "MUSR": 5.550000000000002, "MMLU-PRO Raw": 0.3787400265957447, "MMLU-PRO": 30.971114066193856, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-26T00:00:00", "Submission Date": "2024-07-22T00:00:00", "Generation": 0, "Base Model": "Sao10K/L3-8B-Lunaris-v1"}, {"eval_name": "Sao10K_L3-8B-Stheno-v3.2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Sao10K/L3-8B-Stheno-v3.2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Sao10K/L3-8B-Stheno-v3.2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Sao10K__L3-8B-Stheno-v3.2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Sao10K/L3-8B-Stheno-v3.2", "Model sha": "4bb828f6e1b1efd648c39b1ad682c44ff260f018", "Average \u2b06\ufe0f": 25.75851242001789, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 224, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6872841837435781, "IFEval": 68.72841837435782, "BBH Raw": 0.522778637171633, "BBH": 32.02159792407502, "MATH Lvl 5 Raw": 0.0853474320241691, "MATH Lvl 5": 8.534743202416918, "GPQA Raw": 0.3104026845637584, "GPQA": 8.05369127516779, "MUSR Raw": 0.3793645833333333, "MUSR": 6.453906249999996, "MMLU-PRO Raw": 0.3768284574468085, "MMLU-PRO": 30.758717494089836, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-05T00:00:00", "Submission Date": "2024-06-30T00:00:00", "Generation": 0, "Base Model": "Sao10K/L3-8B-Stheno-v3.2"}, {"eval_name": "Sao10K_L3-8B-Stheno-v3.3-32K_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Sao10K/L3-8B-Stheno-v3.3-32K\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Sao10K/L3-8B-Stheno-v3.3-32K</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Sao10K__L3-8B-Stheno-v3.3-32K-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Sao10K/L3-8B-Stheno-v3.3-32K", "Model sha": "1a59d163e079c7e7f1542553d085853119960f0c", "Average \u2b06\ufe0f": 12.574452403567571, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 49, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4603718134549661, "IFEval": 46.03718134549661, "BBH Raw": 0.3844012923008206, "BBH": 13.51200898319754, "MATH Lvl 5 Raw": 0.0098187311178247, "MATH Lvl 5": 0.9818731117824772, "GPQA Raw": 0.2567114093959731, "GPQA": 0.8948545861297527, "MUSR Raw": 0.3725416666666667, "MUSR": 4.067708333333334, "MMLU-PRO Raw": 0.1895777925531915, "MMLU-PRO": 9.95308806146572, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-22T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "Sao10K/L3-8B-Stheno-v3.3-32K"}, {"eval_name": "Sao10K_MN-12B-Lyra-v3_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Sao10K/MN-12B-Lyra-v3\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Sao10K/MN-12B-Lyra-v3</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Sao10K__MN-12B-Lyra-v3-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Sao10K/MN-12B-Lyra-v3", "Model sha": "da76fa39d128ca84065427189bb228f2dfc6b8a3", "Average \u2b06\ufe0f": 19.27057572409939, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 33, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4486063644463357, "IFEval": 44.86063644463357, "BBH Raw": 0.4803954360397243, "BBH": 25.870963383072453, "MATH Lvl 5 Raw": 0.0717522658610271, "MATH Lvl 5": 7.175226586102719, "GPQA Raw": 0.2776845637583892, "GPQA": 3.691275167785232, "MUSR Raw": 0.4019062499999999, "MUSR": 9.038281250000004, "MMLU-PRO Raw": 0.3248836436170212, "MMLU-PRO": 24.987071513002363, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-27T00:00:00", "Submission Date": "2024-09-03T00:00:00", "Generation": 0, "Base Model": "Sao10K/MN-12B-Lyra-v3"}, {"eval_name": "SeaLLMs_SeaLLM-7B-v2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/SeaLLMs/SeaLLM-7B-v2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">SeaLLMs/SeaLLM-7B-v2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/SeaLLMs__SeaLLM-7B-v2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "SeaLLMs/SeaLLM-7B-v2", "Model sha": "35c5464399144a14915733dc690c4a74e1f71b16", "Average \u2b06\ufe0f": 17.977568029361223, "Hub License": "other", "Hub \u2764\ufe0f": 65, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3671236762900215, "IFEval": 36.71236762900216, "BBH Raw": 0.4902100795458318, "BBH": 27.43815940157093, "MATH Lvl 5 Raw": 0.0740181268882175, "MATH Lvl 5": 7.401812688821751, "GPQA Raw": 0.2785234899328859, "GPQA": 3.803131991051453, "MUSR Raw": 0.4069583333333333, "MUSR": 9.36979166666667, "MMLU-PRO Raw": 0.3082613031914893, "MMLU-PRO": 23.140144799054376, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-01-29T00:00:00", "Submission Date": "2024-09-17T00:00:00", "Generation": 0, "Base Model": "SeaLLMs/SeaLLM-7B-v2"}, {"eval_name": "SeaLLMs_SeaLLM-7B-v2.5_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "GemmaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/SeaLLMs/SeaLLM-7B-v2.5\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">SeaLLMs/SeaLLM-7B-v2.5</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/SeaLLMs__SeaLLM-7B-v2.5-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "SeaLLMs/SeaLLM-7B-v2.5", "Model sha": "a961daf713dcb31e3253ebe40d43ea5fb7a84099", "Average \u2b06\ufe0f": 18.9178792124051, "Hub License": "other", "Hub \u2764\ufe0f": 48, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4521536190640833, "IFEval": 45.21536190640833, "BBH Raw": 0.4980202959435275, "BBH": 28.73815393010281, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.276006711409396, "GPQA": 3.467561521252797, "MUSR Raw": 0.4203229166666666, "MUSR": 11.60703125, "MMLU-PRO Raw": 0.3203125, "MMLU-PRO": 24.479166666666664, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-03T00:00:00", "Submission Date": "2024-07-29T00:00:00", "Generation": 0, "Base Model": "SeaLLMs/SeaLLM-7B-v2.5"}, {"eval_name": "SeaLLMs_SeaLLMs-v3-7B-Chat_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/SeaLLMs/SeaLLMs-v3-7B-Chat\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">SeaLLMs/SeaLLMs-v3-7B-Chat</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/SeaLLMs__SeaLLMs-v3-7B-Chat-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "SeaLLMs/SeaLLMs-v3-7B-Chat", "Model sha": "67ef6dfd0a5df7af4be7a325786105a2ba4cbaf7", "Average \u2b06\ufe0f": 23.63264248307353, "Hub License": "other", "Hub \u2764\ufe0f": 39, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4376653944866288, "IFEval": 43.76653944866288, "BBH Raw": 0.5266406284595359, "BBH": 33.801622722378404, "MATH Lvl 5 Raw": 0.1510574018126888, "MATH Lvl 5": 15.105740181268882, "GPQA Raw": 0.2986577181208054, "GPQA": 6.487695749440718, "MUSR Raw": 0.417375, "MUSR": 10.471875000000002, "MMLU-PRO Raw": 0.3894614361702128, "MMLU-PRO": 32.16238179669031, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-03T00:00:00", "Submission Date": "2024-07-29T00:00:00", "Generation": 0, "Base Model": "SeaLLMs/SeaLLMs-v3-7B-Chat"}, {"eval_name": "SenseLLM_ReflectionCoder-CL-34B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/SenseLLM/ReflectionCoder-CL-34B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">SenseLLM/ReflectionCoder-CL-34B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/SenseLLM__ReflectionCoder-CL-34B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "SenseLLM/ReflectionCoder-CL-34B", "Model sha": "e939100132251cf340ba88d9bdd342faa3c3b211", "Average \u2b06\ufe0f": 11.921346194731344, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 33, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4007710652180658, "IFEval": 40.07710652180658, "BBH Raw": 0.3952930429703329, "BBH": 14.264686822563537, "MATH Lvl 5 Raw": 0.0196374622356495, "MATH Lvl 5": 1.9637462235649543, "GPQA Raw": 0.2508389261744966, "GPQA": 0.1118568232662209, "MUSR Raw": 0.4154895833333333, "MUSR": 10.402864583333336, "MMLU-PRO Raw": 0.1423703457446808, "MMLU-PRO": 4.707816193853427, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-28T00:00:00", "Submission Date": "2024-09-15T00:00:00", "Generation": 0, "Base Model": "SenseLLM/ReflectionCoder-CL-34B"}, {"eval_name": "SenseLLM_ReflectionCoder-DS-33B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/SenseLLM/ReflectionCoder-DS-33B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">SenseLLM/ReflectionCoder-DS-33B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/SenseLLM__ReflectionCoder-DS-33B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "SenseLLM/ReflectionCoder-DS-33B", "Model sha": "07ae97a21fbef0503294e1eb258ce0a308b8dc35", "Average \u2b06\ufe0f": 9.03084950277688, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 4, "#Params (B)": 33, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3786641666334215, "IFEval": 37.86641666334215, "BBH Raw": 0.3449447540164568, "BBH": 8.337659356727954, "MATH Lvl 5 Raw": 0.0203927492447129, "MATH Lvl 5": 2.0392749244712998, "GPQA Raw": 0.2743288590604026, "GPQA": 3.243847874720355, "MUSR Raw": 0.3343125, "MUSR": 0.4557291666666662, "MMLU-PRO Raw": 0.1201795212765957, "MMLU-PRO": 2.24216903073286, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-28T00:00:00", "Submission Date": "2024-09-15T00:00:00", "Generation": 0, "Base Model": "SenseLLM/ReflectionCoder-DS-33B"}, {"eval_name": "SeppeV_SmolLM_pretrained_with_sft_trained_with_1pc_data_on_a_preference_dpo_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/SeppeV/SmolLM_pretrained_with_sft_trained_with_1pc_data_on_a_preference_dpo\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">SeppeV/SmolLM_pretrained_with_sft_trained_with_1pc_data_on_a_preference_dpo</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/SeppeV__SmolLM_pretrained_with_sft_trained_with_1pc_data_on_a_preference_dpo-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "SeppeV/SmolLM_pretrained_with_sft_trained_with_1pc_data_on_a_preference_dpo", "Model sha": "6ced77bb27efc0d6f33d447b9cc8fca35976e91c", "Average \u2b06\ufe0f": 4.0981087422687, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.0955464833308953, "IFEval": 9.554648333089537, "BBH Raw": 0.3072665948660797, "BBH": 3.612865412111988, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.259228187919463, "GPQA": 1.230425055928408, "MUSR Raw": 0.4032083333333333, "MUSR": 8.401041666666666, "MMLU-PRO Raw": 0.1161070478723404, "MMLU-PRO": 1.7896719858156025, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-12T00:00:00", "Submission Date": "2024-10-12T00:00:00", "Generation": 1, "Base Model": "SeppeV/SmolLM_pretrained_with_sft_trained_with_1pc_data_on_a_preference_dpo (Merge)"}, {"eval_name": "Shreyash2010_Uma-4x4B-Instruct-v0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Adapter", "Architecture": "?", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Shreyash2010/Uma-4x4B-Instruct-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Shreyash2010/Uma-4x4B-Instruct-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Shreyash2010__Uma-4x4B-Instruct-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Shreyash2010/Uma-4x4B-Instruct-v0.1", "Model sha": "f78146bdd1632585b3520717885e0ca41ddbce69", "Average \u2b06\ufe0f": 27.456344462780297, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 3, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5516961661724225, "IFEval": 55.169616617242255, "BBH Raw": 0.5511602059856503, "BBH": 36.28453127383045, "MATH Lvl 5 Raw": 0.1495468277945619, "MATH Lvl 5": 14.954682779456194, "GPQA Raw": 0.3347315436241611, "GPQA": 11.297539149888143, "MUSR Raw": 0.4441041666666667, "MUSR": 15.146354166666663, "MMLU-PRO Raw": 0.386968085106383, "MMLU-PRO": 31.885342789598106, "Maintainer's Highlight": false, "Upload To Hub Date": "", "Submission Date": "2024-08-25T00:00:00", "Generation": 0, "Base Model": "Removed"}, {"eval_name": "SicariusSicariiStuff_2B-ad_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/SicariusSicariiStuff/2B-ad\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">SicariusSicariiStuff/2B-ad</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/SicariusSicariiStuff__2B-ad-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "SicariusSicariiStuff/2B-ad", "Model sha": "fa0e405edfb1c6e454b7a25852b5bbf5049cf132", "Average \u2b06\ufe0f": 15.755085275381234, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 2, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4378903531518593, "IFEval": 43.78903531518593, "BBH Raw": 0.4092243152399695, "BBH": 16.007592932115813, "MATH Lvl 5 Raw": 0.0400302114803625, "MATH Lvl 5": 4.003021148036254, "GPQA Raw": 0.2810402684563758, "GPQA": 4.138702460850116, "MUSR Raw": 0.4015312499999999, "MUSR": 8.124739583333335, "MMLU-PRO Raw": 0.2662067819148936, "MMLU-PRO": 18.467420212765955, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-26T00:00:00", "Submission Date": "2024-10-11T00:00:00", "Generation": 0, "Base Model": "SicariusSicariiStuff/2B-ad"}, {"eval_name": "SicariusSicariiStuff_2B_or_not_2B_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "GemmaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/SicariusSicariiStuff/2B_or_not_2B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">SicariusSicariiStuff/2B_or_not_2B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/SicariusSicariiStuff__2B_or_not_2B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "SicariusSicariiStuff/2B_or_not_2B", "Model sha": "abf87e8422284aa83a42efd7a91154f9af3c7ed3", "Average \u2b06\ufe0f": 6.55424831416411, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 22, "#Params (B)": 2, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2062316874781136, "IFEval": 20.623168747811363, "BBH Raw": 0.3415917024092019, "BBH": 7.68230049623281, "MATH Lvl 5 Raw": 0.0173716012084592, "MATH Lvl 5": 1.7371601208459215, "GPQA Raw": 0.24748322147651, "GPQA": 0.0, "MUSR Raw": 0.3790833333333334, "MUSR": 4.852083333333336, "MMLU-PRO Raw": 0.139876994680851, "MMLU-PRO": 4.43077718676123, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-11T00:00:00", "Submission Date": "2024-10-11T00:00:00", "Generation": 0, "Base Model": "SicariusSicariiStuff/2B_or_not_2B"}, {"eval_name": "SicariusSicariiStuff_Dusk_Rainbow_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/SicariusSicariiStuff/Dusk_Rainbow\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">SicariusSicariiStuff/Dusk_Rainbow</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/SicariusSicariiStuff__Dusk_Rainbow-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "SicariusSicariiStuff/Dusk_Rainbow", "Model sha": "106058ac50593d65bc4b5ae75c8c010e87cd8487", "Average \u2b06\ufe0f": 18.485421342328383, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 26, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3588057465303173, "IFEval": 35.88057465303173, "BBH Raw": 0.4771750428073618, "BBH": 25.95903682422342, "MATH Lvl 5 Raw": 0.066465256797583, "MATH Lvl 5": 6.646525679758309, "GPQA Raw": 0.3087248322147651, "GPQA": 7.829977628635347, "MUSR Raw": 0.4025208333333332, "MUSR": 7.448437499999998, "MMLU-PRO Raw": 0.3443317819148936, "MMLU-PRO": 27.14797576832151, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-16T00:00:00", "Submission Date": "2024-10-08T00:00:00", "Generation": 0, "Base Model": "SicariusSicariiStuff/Dusk_Rainbow"}, {"eval_name": "SicariusSicariiStuff_Impish_LLAMA_3B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/SicariusSicariiStuff/Impish_LLAMA_3B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">SicariusSicariiStuff/Impish_LLAMA_3B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/SicariusSicariiStuff__Impish_LLAMA_3B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "SicariusSicariiStuff/Impish_LLAMA_3B", "Model sha": "72703d3083d1a67849cbea0b7add3c1270a77cc7", "Average \u2b06\ufe0f": 17.603125741616093, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 12, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4629948536549688, "IFEval": 46.29948536549688, "BBH Raw": 0.4090510162787322, "BBH": 16.98575485690441, "MATH Lvl 5 Raw": 0.1012084592145015, "MATH Lvl 5": 10.120845921450153, "GPQA Raw": 0.287751677852349, "GPQA": 5.033557046979867, "MUSR Raw": 0.3672708333333334, "MUSR": 5.60885416666667, "MMLU-PRO Raw": 0.2941323138297872, "MMLU-PRO": 21.570257092198577, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-01T00:00:00", "Submission Date": "2024-10-07T00:00:00", "Generation": 0, "Base Model": "SicariusSicariiStuff/Impish_LLAMA_3B"}, {"eval_name": "SicariusSicariiStuff_Qwen2.5-14B_Uncencored_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/SicariusSicariiStuff/Qwen2.5-14B_Uncencored\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">SicariusSicariiStuff/Qwen2.5-14B_Uncencored</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/SicariusSicariiStuff__Qwen2.5-14B_Uncencored-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "SicariusSicariiStuff/Qwen2.5-14B_Uncencored", "Model sha": "1daf648ac2f837c66bf6bb00459e034987d9486f", "Average \u2b06\ufe0f": 31.32211898043069, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 14, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3157909901284148, "IFEval": 31.57909901284148, "BBH Raw": 0.6308941945507827, "BBH": 46.7202351109504, "MATH Lvl 5 Raw": 0.2938066465256798, "MATH Lvl 5": 29.38066465256798, "GPQA Raw": 0.3817114093959731, "GPQA": 17.561521252796418, "MUSR Raw": 0.4516666666666666, "MUSR": 15.291666666666666, "MMLU-PRO Raw": 0.526595744680851, "MMLU-PRO": 47.399527186761226, "Maintainer's Highlight": false, "Upload To Hub Date": "", "Submission Date": "2024-09-20T00:00:00", "Generation": 0, "Base Model": "Removed"}, {"eval_name": "SicariusSicariiStuff_Qwen2.5-14B_Uncensored_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/SicariusSicariiStuff/Qwen2.5-14B_Uncensored\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">SicariusSicariiStuff/Qwen2.5-14B_Uncensored</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/SicariusSicariiStuff__Qwen2.5-14B_Uncensored-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "SicariusSicariiStuff/Qwen2.5-14B_Uncensored", "Model sha": "0710a2341d269dcd56f9136fed442373d4dadc5d", "Average \u2b06\ufe0f": 31.347514560454652, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 14, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3173147249298528, "IFEval": 31.73147249298528, "BBH Raw": 0.6308941945507827, "BBH": 46.7202351109504, "MATH Lvl 5 Raw": 0.2938066465256798, "MATH Lvl 5": 29.38066465256798, "GPQA Raw": 0.3817114093959731, "GPQA": 17.561521252796418, "MUSR Raw": 0.4516666666666666, "MUSR": 15.291666666666666, "MMLU-PRO Raw": 0.526595744680851, "MMLU-PRO": 47.399527186761226, "Maintainer's Highlight": false, "Upload To Hub Date": "", "Submission Date": "2024-09-21T00:00:00", "Generation": 0, "Base Model": "Removed"}, {"eval_name": "SicariusSicariiStuff_Qwen2.5-14B_Uncensored_Instruct_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/SicariusSicariiStuff/Qwen2.5-14B_Uncensored_Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">SicariusSicariiStuff/Qwen2.5-14B_Uncensored_Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/SicariusSicariiStuff__Qwen2.5-14B_Uncensored_Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "SicariusSicariiStuff/Qwen2.5-14B_Uncensored_Instruct", "Model sha": null, "Average \u2b06\ufe0f": 28.12797658177094, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 14, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3789389929830627, "IFEval": 37.89389929830627, "BBH Raw": 0.5936792404117958, "BBH": 42.113096716972805, "MATH Lvl 5 Raw": 0.2787009063444108, "MATH Lvl 5": 27.870090634441087, "GPQA Raw": 0.3296979865771812, "GPQA": 10.626398210290828, "MUSR Raw": 0.36965625, "MUSR": 4.40703125, "MMLU-PRO Raw": 0.5127160904255319, "MMLU-PRO": 45.85734338061466, "Maintainer's Highlight": false, "Upload To Hub Date": "", "Submission Date": "2024-09-21T00:00:00", "Generation": 0, "Base Model": "Removed"}, {"eval_name": "Solshine_Brimful-merged-replete_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Solshine/Brimful-merged-replete\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Solshine/Brimful-merged-replete</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Solshine__Brimful-merged-replete-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Solshine/Brimful-merged-replete", "Model sha": "01ce8c3df6edb87d31f0e9a9651cbcbc4d4823e8", "Average \u2b06\ufe0f": 3.829474587630019, "Hub License": null, "Hub \u2764\ufe0f": 1, "#Params (B)": 12, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.1760561975558185, "IFEval": 17.605619755581856, "BBH Raw": 0.2883444769655102, "BBH": 1.992138996736096, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2575503355704698, "GPQA": 1.0067114093959737, "MUSR Raw": 0.342125, "MUSR": 1.432291666666666, "MMLU-PRO Raw": 0.1084607712765957, "MMLU-PRO": 0.9400856973995264, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-01T00:00:00", "Submission Date": "2024-10-01T00:00:00", "Generation": 1, "Base Model": "Solshine/Brimful-merged-replete (Merge)"}, {"eval_name": "Solshine_Llama-3-1-big-thoughtful-passthrough-merge-2_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Solshine/Llama-3-1-big-thoughtful-passthrough-merge-2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Solshine/Llama-3-1-big-thoughtful-passthrough-merge-2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Solshine__Llama-3-1-big-thoughtful-passthrough-merge-2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Solshine/Llama-3-1-big-thoughtful-passthrough-merge-2", "Model sha": "d48047d6577e22fdda73a1be8e18971912db66d2", "Average \u2b06\ufe0f": 6.777645791540958, "Hub License": null, "Hub \u2764\ufe0f": 1, "#Params (B)": 18, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2546665070900765, "IFEval": 25.466650709007656, "BBH Raw": 0.3209380842714462, "BBH": 5.008442306492267, "MATH Lvl 5 Raw": 0.0015105740181268, "MATH Lvl 5": 0.1510574018126888, "GPQA Raw": 0.259228187919463, "GPQA": 1.230425055928408, "MUSR Raw": 0.3889479166666666, "MUSR": 6.751822916666666, "MMLU-PRO Raw": 0.1185172872340425, "MMLU-PRO": 2.05747635933806, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-19T00:00:00", "Submission Date": "2024-09-24T00:00:00", "Generation": 1, "Base Model": "Solshine/Llama-3-1-big-thoughtful-passthrough-merge-2 (Merge)"}, {"eval_name": "Stark2008_GutenLaserPi_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Stark2008/GutenLaserPi\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Stark2008/GutenLaserPi</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Stark2008__GutenLaserPi-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Stark2008/GutenLaserPi", "Model sha": "d5ab84c6f8f0c88c16380242c7e11e8cefc934b7", "Average \u2b06\ufe0f": 21.28743157159801, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4226530051374796, "IFEval": 42.26530051374797, "BBH Raw": 0.5212342482489518, "BBH": 32.97771006701662, "MATH Lvl 5 Raw": 0.0717522658610271, "MATH Lvl 5": 7.175226586102719, "GPQA Raw": 0.2869127516778523, "GPQA": 4.921700223713646, "MUSR Raw": 0.4620208333333333, "MUSR": 16.985937499999995, "MMLU-PRO Raw": 0.3105884308510638, "MMLU-PRO": 23.39871453900709, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-11T00:00:00", "Submission Date": "2024-07-11T00:00:00", "Generation": 1, "Base Model": "Stark2008/GutenLaserPi (Merge)"}, {"eval_name": "Stark2008_LayleleFlamPi_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Stark2008/LayleleFlamPi\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Stark2008/LayleleFlamPi</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Stark2008__LayleleFlamPi-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Stark2008/LayleleFlamPi", "Model sha": "b2897d17a65dea17383f52711475c8b41567c5d0", "Average \u2b06\ufe0f": 20.69486258112838, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4284232503091796, "IFEval": 42.84232503091796, "BBH Raw": 0.5115654142581095, "BBH": 31.20740955947399, "MATH Lvl 5 Raw": 0.0558912386706948, "MATH Lvl 5": 5.589123867069486, "GPQA Raw": 0.285234899328859, "GPQA": 4.697986577181204, "MUSR Raw": 0.46084375, "MUSR": 16.57213541666667, "MMLU-PRO Raw": 0.3093417553191489, "MMLU-PRO": 23.26019503546099, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-12T00:00:00", "Submission Date": "2024-07-12T00:00:00", "Generation": 1, "Base Model": "Stark2008/LayleleFlamPi (Merge)"}, {"eval_name": "Stark2008_VisFlamCat_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Stark2008/VisFlamCat\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Stark2008/VisFlamCat</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Stark2008__VisFlamCat-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Stark2008/VisFlamCat", "Model sha": "290efa41ac83b8408cab084d093bcd9ae9abb0c9", "Average \u2b06\ufe0f": 21.164673480185755, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4365915770156517, "IFEval": 43.65915770156518, "BBH Raw": 0.5216957865099948, "BBH": 32.881396834037055, "MATH Lvl 5 Raw": 0.0657099697885196, "MATH Lvl 5": 6.570996978851963, "GPQA Raw": 0.2902684563758389, "GPQA": 5.369127516778524, "MUSR Raw": 0.4462708333333333, "MUSR": 14.68385416666667, "MMLU-PRO Raw": 0.3144115691489361, "MMLU-PRO": 23.823507683215126, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-12T00:00:00", "Submission Date": "2024-07-12T00:00:00", "Generation": 1, "Base Model": "Stark2008/VisFlamCat (Merge)"}, {"eval_name": "Syed-Hasan-8503_Phi-3-mini-4K-instruct-cpo-simpo_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Phi3ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Syed-Hasan-8503/Phi-3-mini-4K-instruct-cpo-simpo\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Syed-Hasan-8503/Phi-3-mini-4K-instruct-cpo-simpo</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Syed-Hasan-8503__Phi-3-mini-4K-instruct-cpo-simpo-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Syed-Hasan-8503/Phi-3-mini-4K-instruct-cpo-simpo", "Model sha": "2896ef357be81fd433c17801d76ce148e60a7032", "Average \u2b06\ufe0f": 25.8694459852024, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5714049832222946, "IFEval": 57.14049832222946, "BBH Raw": 0.5681534123661078, "BBH": 39.148157776889455, "MATH Lvl 5 Raw": 0.0762839879154078, "MATH Lvl 5": 7.628398791540786, "GPQA Raw": 0.3305369127516778, "GPQA": 10.738255033557047, "MUSR Raw": 0.3963541666666666, "MUSR": 8.777604166666663, "MMLU-PRO Raw": 0.3860538563829787, "MMLU-PRO": 31.783761820330973, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-24T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "Syed-Hasan-8503/Phi-3-mini-4K-instruct-cpo-simpo"}, {"eval_name": "THUDM_glm-4-9b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "ChatGLMModelM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/THUDM/glm-4-9b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">THUDM/glm-4-9b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/THUDM__glm-4-9b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "THUDM/glm-4-9b", "Model sha": "99a140996f9d4f197842fb6b1aab217a42e27ef3", "Average \u2b06\ufe0f": 18.006731731716215, "Hub License": "other", "Hub \u2764\ufe0f": 103, "#Params (B)": 9, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1426082793654171, "IFEval": 14.260827936541707, "BBH Raw": 0.5528368141665274, "BBH": 35.811283581208905, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.3162751677852349, "GPQA": 8.83668903803132, "MUSR Raw": 0.4385833333333333, "MUSR": 14.189583333333331, "MMLU-PRO Raw": 0.4144780585106383, "MMLU-PRO": 34.94200650118203, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-04T00:00:00", "Submission Date": "2024-07-04T00:00:00", "Generation": 0, "Base Model": "THUDM/glm-4-9b"}, {"eval_name": "THUDM_glm-4-9b-chat_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "ChatGLMModelM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/THUDM/glm-4-9b-chat\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">THUDM/glm-4-9b-chat</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/THUDM__glm-4-9b-chat-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "THUDM/glm-4-9b-chat", "Model sha": "04419001bc63e05e70991ade6da1f91c4aeec278", "Average \u2b06\ufe0f": 10.973477297045166, "Hub License": "other", "Hub \u2764\ufe0f": 598, "#Params (B)": 9, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.0, "IFEval": 0.0, "BBH Raw": 0.4736388429103573, "BBH": 25.205183674440235, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.313758389261745, "GPQA": 8.501118568232664, "MUSR Raw": 0.3994270833333333, "MUSR": 8.061718749999999, "MMLU-PRO Raw": 0.316655585106383, "MMLU-PRO": 24.072842789598106, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-04T00:00:00", "Submission Date": "2024-07-09T00:00:00", "Generation": 0, "Base Model": "THUDM/glm-4-9b-chat"}, {"eval_name": "THUDM_glm-4-9b-chat-1m_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "ChatGLMModel", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/THUDM/glm-4-9b-chat-1m\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">THUDM/glm-4-9b-chat-1m</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/THUDM__glm-4-9b-chat-1m-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "THUDM/glm-4-9b-chat-1m", "Model sha": "0aa722c7e0745dd21453427dd44c257dd253304f", "Average \u2b06\ufe0f": 8.922510186531982, "Hub License": "other", "Hub \u2764\ufe0f": 170, "#Params (B)": 9, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.0, "IFEval": 0.0, "BBH Raw": 0.418005782183303, "BBH": 17.10802850816805, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.3036912751677852, "GPQA": 7.158836689038028, "MUSR Raw": 0.3794583333333333, "MUSR": 5.232291666666668, "MMLU-PRO Raw": 0.3163231382978723, "MMLU-PRO": 24.03590425531915, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-04T00:00:00", "Submission Date": "2024-10-09T00:00:00", "Generation": 0, "Base Model": "THUDM/glm-4-9b-chat-1m"}, {"eval_name": "TIGER-Lab_MAmmoTH2-7B-Plus_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/TIGER-Lab/MAmmoTH2-7B-Plus\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">TIGER-Lab/MAmmoTH2-7B-Plus</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/TIGER-Lab__MAmmoTH2-7B-Plus-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "TIGER-Lab/MAmmoTH2-7B-Plus", "Model sha": "3ed578d8dda09787137e363a0dc32e3a8ed908de", "Average \u2b06\ufe0f": 21.218099923274693, "Hub License": "mit", "Hub \u2764\ufe0f": 4, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5574664113441224, "IFEval": 55.74664113441224, "BBH Raw": 0.4234694988801906, "BBH": 18.92595322755573, "MATH Lvl 5 Raw": 0.1608761329305136, "MATH Lvl 5": 16.08761329305136, "GPQA Raw": 0.2802013422818792, "GPQA": 4.026845637583895, "MUSR Raw": 0.4123541666666666, "MUSR": 10.1109375, "MMLU-PRO Raw": 0.3016954787234042, "MMLU-PRO": 22.410608747044915, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-06T00:00:00", "Submission Date": "2024-06-27T00:00:00", "Generation": 0, "Base Model": "TIGER-Lab/MAmmoTH2-7B-Plus"}, {"eval_name": "TTTXXX01_Mistral-7B-Base-SimPO2-5e-7_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/TTTXXX01/Mistral-7B-Base-SimPO2-5e-7\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">TTTXXX01/Mistral-7B-Base-SimPO2-5e-7</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/TTTXXX01__Mistral-7B-Base-SimPO2-5e-7-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "TTTXXX01/Mistral-7B-Base-SimPO2-5e-7", "Model sha": "7a271e3061165f4e1abfe26715c04e20c2ac935e", "Average \u2b06\ufe0f": 16.34192405102324, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4391891292880667, "IFEval": 43.91891292880668, "BBH Raw": 0.4319551501488277, "BBH": 20.692627382557507, "MATH Lvl 5 Raw": 0.0219033232628398, "MATH Lvl 5": 2.190332326283988, "GPQA Raw": 0.2978187919463087, "GPQA": 6.375838926174497, "MUSR Raw": 0.3604166666666666, "MUSR": 5.252083333333334, "MMLU-PRO Raw": 0.2765957446808511, "MMLU-PRO": 19.62174940898345, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-30T00:00:00", "Submission Date": "2024-09-01T00:00:00", "Generation": 2, "Base Model": "mistralai/Mistral-7B-v0.1"}, {"eval_name": "TeeZee_DoubleBagel-57B-v1.0_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/TeeZee/DoubleBagel-57B-v1.0\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">TeeZee/DoubleBagel-57B-v1.0</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/TeeZee__DoubleBagel-57B-v1.0-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "TeeZee/DoubleBagel-57B-v1.0", "Model sha": "6e10dc1fb5223d1b045dc2a19c9c267a574e520f", "Average \u2b06\ufe0f": 8.54410296272912, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 56, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2336334259764092, "IFEval": 23.363342597640923, "BBH Raw": 0.325078559362514, "BBH": 5.5227816982611495, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.276006711409396, "GPQA": 3.467561521252797, "MUSR Raw": 0.4314895833333333, "MUSR": 13.60286458333333, "MMLU-PRO Raw": 0.1477726063829787, "MMLU-PRO": 5.308067375886525, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-05T00:00:00", "Submission Date": "2024-08-10T00:00:00", "Generation": 1, "Base Model": "TeeZee/DoubleBagel-57B-v1.0 (Merge)"}, {"eval_name": "TencentARC_LLaMA-Pro-8B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/TencentARC/LLaMA-Pro-8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">TencentARC/LLaMA-Pro-8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/TencentARC__LLaMA-Pro-8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "TencentARC/LLaMA-Pro-8B", "Model sha": "7115e7179060e0623d1ee9ff4476faed7e478d8c", "Average \u2b06\ufe0f": 8.778934275693588, "Hub License": "llama2", "Hub \u2764\ufe0f": 171, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2277135777514772, "IFEval": 22.77135777514772, "BBH Raw": 0.3484197711435169, "BBH": 9.2939499758607, "MATH Lvl 5 Raw": 0.0166163141993957, "MATH Lvl 5": 1.6616314199395772, "GPQA Raw": 0.2600671140939597, "GPQA": 1.342281879194629, "MUSR Raw": 0.4018124999999999, "MUSR": 8.593229166666669, "MMLU-PRO Raw": 0.1811003989361702, "MMLU-PRO": 9.011155437352246, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-01-05T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "TencentARC/LLaMA-Pro-8B"}, {"eval_name": "TencentARC_LLaMA-Pro-8B-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/TencentARC/LLaMA-Pro-8B-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">TencentARC/LLaMA-Pro-8B-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/TencentARC__LLaMA-Pro-8B-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "TencentARC/LLaMA-Pro-8B-Instruct", "Model sha": "9850c8afce19a69d8fc4a1603a82441157514016", "Average \u2b06\ufe0f": 15.144990895303266, "Hub License": "llama2", "Hub \u2764\ufe0f": 60, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4486063644463357, "IFEval": 44.86063644463357, "BBH Raw": 0.4224205282459997, "BBH": 19.485726056875954, "MATH Lvl 5 Raw": 0.0166163141993957, "MATH Lvl 5": 1.6616314199395772, "GPQA Raw": 0.2743288590604026, "GPQA": 3.243847874720355, "MUSR Raw": 0.4190208333333333, "MUSR": 11.1109375, "MMLU-PRO Raw": 0.194564494680851, "MMLU-PRO": 10.507166075650115, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-01-06T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "TencentARC/LLaMA-Pro-8B-Instruct"}, {"eval_name": "TencentARC_MetaMath-Mistral-Pro_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/TencentARC/MetaMath-Mistral-Pro\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">TencentARC/MetaMath-Mistral-Pro</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/TencentARC__MetaMath-Mistral-Pro-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "TencentARC/MetaMath-Mistral-Pro", "Model sha": "3835d38de15ed2a04c32aca879b782fc50e390bf", "Average \u2b06\ufe0f": 12.013002201474537, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 5, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2118767093534045, "IFEval": 21.18767093534045, "BBH Raw": 0.441316185558836, "BBH": 22.37227879113455, "MATH Lvl 5 Raw": 0.04607250755287, "MATH Lvl 5": 4.607250755287009, "GPQA Raw": 0.2692953020134228, "GPQA": 2.572706935123044, "MUSR Raw": 0.3524166666666666, "MUSR": 4.985416666666668, "MMLU-PRO Raw": 0.2471742021276596, "MMLU-PRO": 16.35268912529551, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-02-26T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "TencentARC/MetaMath-Mistral-Pro"}, {"eval_name": "TencentARC_Mistral_Pro_8B_v0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/TencentARC/Mistral_Pro_8B_v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">TencentARC/Mistral_Pro_8B_v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/TencentARC__Mistral_Pro_8B_v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "TencentARC/Mistral_Pro_8B_v0.1", "Model sha": "366f159fc5b314ba2a955209d2bca4600f84dac0", "Average \u2b06\ufe0f": 14.195345928021323, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 66, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2114522799505312, "IFEval": 21.145227995053123, "BBH Raw": 0.4525975968066435, "BBH": 22.89418875876804, "MATH Lvl 5 Raw": 0.0566465256797583, "MATH Lvl 5": 5.664652567975831, "GPQA Raw": 0.2802013422818792, "GPQA": 4.026845637583895, "MUSR Raw": 0.4242291666666666, "MUSR": 11.828645833333336, "MMLU-PRO Raw": 0.2765126329787234, "MMLU-PRO": 19.61251477541371, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-02-22T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "TencentARC/Mistral_Pro_8B_v0.1"}, {"eval_name": "TheDrummer_Gemmasutra-9B-v1_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/TheDrummer/Gemmasutra-9B-v1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">TheDrummer/Gemmasutra-9B-v1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/TheDrummer__Gemmasutra-9B-v1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "TheDrummer/Gemmasutra-9B-v1", "Model sha": "21591f6a0140e095f1c6668ac7a267f214547609", "Average \u2b06\ufe0f": 22.585039679805007, "Hub License": null, "Hub \u2764\ufe0f": 19, "#Params (B)": 10, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2415513060900632, "IFEval": 24.155130609006328, "BBH Raw": 0.5886914248369671, "BBH": 41.20039631726062, "MATH Lvl 5 Raw": 0.073262839879154, "MATH Lvl 5": 7.326283987915408, "GPQA Raw": 0.3104026845637584, "GPQA": 8.05369127516779, "MUSR Raw": 0.48459375, "MUSR": 20.940885416666664, "MMLU-PRO Raw": 0.4045046542553192, "MMLU-PRO": 33.83385047281324, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-17T00:00:00", "Submission Date": "2024-09-19T00:00:00", "Generation": 1, "Base Model": "TheDrummer/Gemmasutra-9B-v1 (Merge)"}, {"eval_name": "TheDrummer_Rocinante-12B-v1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/TheDrummer/Rocinante-12B-v1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">TheDrummer/Rocinante-12B-v1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/TheDrummer__Rocinante-12B-v1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "TheDrummer/Rocinante-12B-v1", "Model sha": "74a4ae2584d45655298995198d5ab3e660364a1a", "Average \u2b06\ufe0f": 23.507750730146014, "Hub License": "other", "Hub \u2764\ufe0f": 24, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6076499244227538, "IFEval": 60.764992442275386, "BBH Raw": 0.5065452085797449, "BBH": 30.025654065607256, "MATH Lvl 5 Raw": 0.059667673716012, "MATH Lvl 5": 5.966767371601208, "GPQA Raw": 0.2911073825503356, "GPQA": 5.480984340044745, "MUSR Raw": 0.4017187499999999, "MUSR": 11.281510416666665, "MMLU-PRO Raw": 0.3477393617021276, "MMLU-PRO": 27.526595744680847, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-14T00:00:00", "Submission Date": "2024-09-03T00:00:00", "Generation": 0, "Base Model": "TheDrummer/Rocinante-12B-v1"}, {"eval_name": "TheTsar1209_qwen-carpmuscle-v0.1_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/TheTsar1209/qwen-carpmuscle-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">TheTsar1209/qwen-carpmuscle-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/TheTsar1209__qwen-carpmuscle-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "TheTsar1209/qwen-carpmuscle-v0.1", "Model sha": "7c7b06a1788aef48054c3c6d6ad90c6dc5264a81", "Average \u2b06\ufe0f": 32.589037479611385, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 14, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5621628390448454, "IFEval": 56.21628390448454, "BBH Raw": 0.643430074129922, "BBH": 48.82559521217237, "MATH Lvl 5 Raw": 0.2114803625377643, "MATH Lvl 5": 21.148036253776432, "GPQA Raw": 0.3439597315436241, "GPQA": 12.527964205816552, "MUSR Raw": 0.4161041666666666, "MUSR": 10.146354166666669, "MMLU-PRO Raw": 0.520029920212766, "MMLU-PRO": 46.669991134751776, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-05T00:00:00", "Submission Date": "2024-10-10T00:00:00", "Generation": 3, "Base Model": "Qwen/Qwen2.5-14B"}, {"eval_name": "Tijmen2_cosmosage-v3_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Tijmen2/cosmosage-v3\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Tijmen2/cosmosage-v3</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Tijmen2__cosmosage-v3-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Tijmen2/cosmosage-v3", "Model sha": "e6d4b4e6868fcf113ab5261d71c7214a1f7fbb0c", "Average \u2b06\ufe0f": 16.80086953922375, "Hub License": "mit", "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4482318027278731, "IFEval": 44.82318027278731, "BBH Raw": 0.4550637900339029, "BBH": 22.6871057550123, "MATH Lvl 5 Raw": 0.0173716012084592, "MATH Lvl 5": 1.7371601208459215, "GPQA Raw": 0.2827181208053691, "GPQA": 4.36241610738255, "MUSR Raw": 0.4198854166666666, "MUSR": 10.685677083333331, "MMLU-PRO Raw": 0.2485871010638297, "MMLU-PRO": 16.50967789598109, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-20T00:00:00", "Submission Date": "2024-08-27T00:00:00", "Generation": 1, "Base Model": "meta-llama/Meta-Llama-3-8B"}, {"eval_name": "TinyLlama_TinyLlama-1.1B-Chat-v1.0_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">TinyLlama/TinyLlama-1.1B-Chat-v1.0</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/TinyLlama__TinyLlama-1.1B-Chat-v1.0-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "TinyLlama/TinyLlama-1.1B-Chat-v1.0", "Model sha": "fe8a4ea1ffedaf415f4da2f062534de366a451e6", "Average \u2b06\ufe0f": 2.7055664347653305, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1073, "#Params (B)": 1, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.0595763684800773, "IFEval": 5.957636848007731, "BBH Raw": 0.3103562867491015, "BBH": 4.013396848486799, "MATH Lvl 5 Raw": 0.0083081570996978, "MATH Lvl 5": 0.8308157099697886, "GPQA Raw": 0.25, "GPQA": 0.0, "MUSR Raw": 0.3515208333333333, "MUSR": 4.306770833333336, "MMLU-PRO Raw": 0.1101230053191489, "MMLU-PRO": 1.124778368794326, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-12-30T00:00:00", "Submission Date": "2024-08-04T00:00:00", "Generation": 0, "Base Model": "TinyLlama/TinyLlama-1.1B-Chat-v1.0"}, {"eval_name": "TinyLlama_TinyLlama_v1.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/TinyLlama/TinyLlama_v1.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">TinyLlama/TinyLlama_v1.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/TinyLlama__TinyLlama_v1.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "TinyLlama/TinyLlama_v1.1", "Model sha": "ff3c701f2424c7625fdefb9dd470f45ef18b02d6", "Average \u2b06\ufe0f": 4.698672676403544, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 70, "#Params (B)": 1, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2000613926603633, "IFEval": 20.00613926603634, "BBH Raw": 0.3023701804507606, "BBH": 3.2103010497128146, "MATH Lvl 5 Raw": 0.0045317220543806, "MATH Lvl 5": 0.4531722054380665, "GPQA Raw": 0.2458053691275167, "GPQA": 0.0, "MUSR Raw": 0.3699687499999999, "MUSR": 3.979427083333333, "MMLU-PRO Raw": 0.1048869680851063, "MMLU-PRO": 0.542996453900708, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-03-09T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "TinyLlama/TinyLlama_v1.1"}, {"eval_name": "Trappu_Magnum-Picaro-0.7-v2-12b_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Trappu/Magnum-Picaro-0.7-v2-12b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Trappu/Magnum-Picaro-0.7-v2-12b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Trappu__Magnum-Picaro-0.7-v2-12b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Trappu/Magnum-Picaro-0.7-v2-12b", "Model sha": "2ffc46cde49eb823f5588990bd6b848cd505271e", "Average \u2b06\ufe0f": 21.415361213374982, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 6, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.300278815764394, "IFEval": 30.027881576439405, "BBH Raw": 0.5506661918828847, "BBH": 35.74623319855443, "MATH Lvl 5 Raw": 0.0475830815709969, "MATH Lvl 5": 4.758308157099698, "GPQA Raw": 0.322986577181208, "GPQA": 9.731543624161072, "MUSR Raw": 0.47271875, "MUSR": 19.556510416666665, "MMLU-PRO Raw": 0.3580452127659574, "MMLU-PRO": 28.671690307328607, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-11T00:00:00", "Submission Date": "2024-09-12T00:00:00", "Generation": 1, "Base Model": "Trappu/Magnum-Picaro-0.7-v2-12b (Merge)"}, {"eval_name": "Trappu_Nemo-Picaro-12B_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Trappu/Nemo-Picaro-12B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Trappu/Nemo-Picaro-12B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Trappu__Nemo-Picaro-12B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Trappu/Nemo-Picaro-12B", "Model sha": "d65bf383d744998ae93a5589ec886532bb7e18eb", "Average \u2b06\ufe0f": 21.198847030246853, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2577139766929525, "IFEval": 25.771397669295247, "BBH Raw": 0.5489586125997546, "BBH": 35.9731352844479, "MATH Lvl 5 Raw": 0.0747734138972809, "MATH Lvl 5": 7.477341389728097, "GPQA Raw": 0.3271812080536913, "GPQA": 10.290827740492167, "MUSR Raw": 0.47259375, "MUSR": 18.74088541666666, "MMLU-PRO Raw": 0.3604554521276595, "MMLU-PRO": 28.93949468085106, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-10T00:00:00", "Submission Date": "2024-09-22T00:00:00", "Generation": 2, "Base Model": "royallab/MN-LooseCannon-12B-v2 (Merge)"}, {"eval_name": "Tremontaine_L3-12B-Lunaris-v1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Tremontaine/L3-12B-Lunaris-v1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Tremontaine/L3-12B-Lunaris-v1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Tremontaine__L3-12B-Lunaris-v1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Tremontaine/L3-12B-Lunaris-v1", "Model sha": "7be236530a835416ebca712d51d661c4488a45de", "Average \u2b06\ufe0f": 25.3765496636056, "Hub License": null, "Hub \u2764\ufe0f": 2, "#Params (B)": 11, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6909311737301471, "IFEval": 69.0931173730147, "BBH Raw": 0.5230217237244009, "BBH": 32.1807456461844, "MATH Lvl 5 Raw": 0.0815709969788519, "MATH Lvl 5": 8.157099697885197, "GPQA Raw": 0.3095637583892617, "GPQA": 7.941834451901568, "MUSR Raw": 0.3673645833333334, "MUSR": 4.053906250000002, "MMLU-PRO Raw": 0.3774933510638298, "MMLU-PRO": 30.832594562647756, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-14T00:00:00", "Submission Date": "2024-07-15T00:00:00", "Generation": 1, "Base Model": "Tremontaine/L3-12B-Lunaris-v1 (Merge)"}, {"eval_name": "Tsunami-th_Tsunami-0.5-7B-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Tsunami-th/Tsunami-0.5-7B-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Tsunami-th/Tsunami-0.5-7B-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Tsunami-th__Tsunami-0.5-7B-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Tsunami-th/Tsunami-0.5-7B-Instruct", "Model sha": "10706336513d54c4e8962f54653f25941c4031f4", "Average \u2b06\ufe0f": 28.04341070878014, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7400153814102137, "IFEval": 74.00153814102137, "BBH Raw": 0.552369427738073, "BBH": 36.13825418700338, "MATH Lvl 5 Raw": 0.0015105740181268, "MATH Lvl 5": 0.1510574018126888, "GPQA Raw": 0.3087248322147651, "GPQA": 7.829977628635347, "MUSR Raw": 0.42571875, "MUSR": 12.214843750000002, "MMLU-PRO Raw": 0.4413231382978723, "MMLU-PRO": 37.92479314420804, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-11T00:00:00", "Submission Date": "2024-10-12T00:00:00", "Generation": 1, "Base Model": "Tsunami-th/Tsunami-0.5-7B-Instruct (Merge)"}, {"eval_name": "UCLA-AGI_Gemma-2-9B-It-SPPO-Iter1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/UCLA-AGI/Gemma-2-9B-It-SPPO-Iter1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">UCLA-AGI/Gemma-2-9B-It-SPPO-Iter1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/UCLA-AGI__Gemma-2-9B-It-SPPO-Iter1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "UCLA-AGI/Gemma-2-9B-It-SPPO-Iter1", "Model sha": "33cfd6919f22efc38f71e9d21a7e697afb418e6b", "Average \u2b06\ufe0f": 21.08816868559016, "Hub License": "gemma", "Hub \u2764\ufe0f": 3, "#Params (B)": 9, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.308221075634871, "IFEval": 30.8221075634871, "BBH Raw": 0.5968934762705508, "BBH": 41.80922962006354, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.3364093959731543, "GPQA": 11.521252796420578, "MUSR Raw": 0.4099375, "MUSR": 10.075520833333334, "MMLU-PRO Raw": 0.3907081117021276, "MMLU-PRO": 32.300901300236404, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-29T00:00:00", "Submission Date": "2024-09-21T00:00:00", "Generation": 0, "Base Model": "UCLA-AGI/Gemma-2-9B-It-SPPO-Iter1"}, {"eval_name": "UCLA-AGI_Gemma-2-9B-It-SPPO-Iter2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/UCLA-AGI/Gemma-2-9B-It-SPPO-Iter2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">UCLA-AGI/Gemma-2-9B-It-SPPO-Iter2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/UCLA-AGI__Gemma-2-9B-It-SPPO-Iter2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "UCLA-AGI/Gemma-2-9B-It-SPPO-Iter2", "Model sha": "b7590721d92bf6e0606e3dbc1ca2c229b7c534b4", "Average \u2b06\ufe0f": 21.216144486637848, "Hub License": "gemma", "Hub \u2764\ufe0f": 2, "#Params (B)": 9, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3100196367859502, "IFEval": 31.00196367859502, "BBH Raw": 0.5989880877421281, "BBH": 42.16983380174582, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.3347315436241611, "GPQA": 11.297539149888143, "MUSR Raw": 0.4139375, "MUSR": 10.942187500000005, "MMLU-PRO Raw": 0.386968085106383, "MMLU-PRO": 31.885342789598106, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-29T00:00:00", "Submission Date": "2024-08-07T00:00:00", "Generation": 0, "Base Model": "UCLA-AGI/Gemma-2-9B-It-SPPO-Iter2"}, {"eval_name": "UCLA-AGI_Gemma-2-9B-It-SPPO-Iter3_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/UCLA-AGI/Gemma-2-9B-It-SPPO-Iter3\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">UCLA-AGI/Gemma-2-9B-It-SPPO-Iter3</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/UCLA-AGI__Gemma-2-9B-It-SPPO-Iter3-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "UCLA-AGI/Gemma-2-9B-It-SPPO-Iter3", "Model sha": "2261f2a03b2e15de13a18da52590c237ecf5f188", "Average \u2b06\ufe0f": 21.467179975872483, "Hub License": "gemma", "Hub \u2764\ufe0f": 113, "#Params (B)": 9, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.316714096375395, "IFEval": 31.671409637539504, "BBH Raw": 0.6007080229268026, "BBH": 42.53675224107426, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.3389261744966443, "GPQA": 11.85682326621924, "MUSR Raw": 0.4166041666666666, "MUSR": 11.3421875, "MMLU-PRO Raw": 0.382563164893617, "MMLU-PRO": 31.395907210401887, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-29T00:00:00", "Submission Date": "2024-07-31T00:00:00", "Generation": 0, "Base Model": "UCLA-AGI/Gemma-2-9B-It-SPPO-Iter3"}, {"eval_name": "UCLA-AGI_Llama-3-Instruct-8B-SPPO-Iter1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/UCLA-AGI/Llama-3-Instruct-8B-SPPO-Iter1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">UCLA-AGI/Llama-3-Instruct-8B-SPPO-Iter1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/UCLA-AGI__Llama-3-Instruct-8B-SPPO-Iter1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "UCLA-AGI/Llama-3-Instruct-8B-SPPO-Iter1", "Model sha": "2076437f65776aeb9686c95f1f41515f70c4db27", "Average \u2b06\ufe0f": 24.45125555324819, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7298988904994304, "IFEval": 72.98988904994303, "BBH Raw": 0.5057890691082708, "BBH": 29.489353188071963, "MATH Lvl 5 Raw": 0.0959214501510574, "MATH Lvl 5": 9.59214501510574, "GPQA Raw": 0.2676174496644295, "GPQA": 2.348993288590602, "MUSR Raw": 0.3567916666666666, "MUSR": 2.165624999999999, "MMLU-PRO Raw": 0.37109375, "MMLU-PRO": 30.12152777777778, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-25T00:00:00", "Submission Date": "2024-09-21T00:00:00", "Generation": 0, "Base Model": "UCLA-AGI/Llama-3-Instruct-8B-SPPO-Iter1"}, {"eval_name": "UCLA-AGI_Llama-3-Instruct-8B-SPPO-Iter2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/UCLA-AGI/Llama-3-Instruct-8B-SPPO-Iter2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">UCLA-AGI/Llama-3-Instruct-8B-SPPO-Iter2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/UCLA-AGI__Llama-3-Instruct-8B-SPPO-Iter2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "UCLA-AGI/Llama-3-Instruct-8B-SPPO-Iter2", "Model sha": "730c7207d4b538feeb3c2e6d6f6a6ba8615a9be3", "Average \u2b06\ufe0f": 23.77659209411631, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6988745417713889, "IFEval": 69.88745417713888, "BBH Raw": 0.5088696278852957, "BBH": 29.86944932809155, "MATH Lvl 5 Raw": 0.0876132930513595, "MATH Lvl 5": 8.761329305135952, "GPQA Raw": 0.2667785234899328, "GPQA": 2.2371364653243813, "MUSR Raw": 0.3594270833333333, "MUSR": 1.995052083333335, "MMLU-PRO Raw": 0.3691821808510638, "MMLU-PRO": 29.90913120567376, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-25T00:00:00", "Submission Date": "2024-08-07T00:00:00", "Generation": 0, "Base Model": "UCLA-AGI/Llama-3-Instruct-8B-SPPO-Iter2"}, {"eval_name": "UCLA-AGI_Llama-3-Instruct-8B-SPPO-Iter3_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/UCLA-AGI/Llama-3-Instruct-8B-SPPO-Iter3\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">UCLA-AGI/Llama-3-Instruct-8B-SPPO-Iter3</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/UCLA-AGI__Llama-3-Instruct-8B-SPPO-Iter3-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "UCLA-AGI/Llama-3-Instruct-8B-SPPO-Iter3", "Model sha": "f73dafc2923acd56f115f21f76e9d14f8d19a63e", "Average \u2b06\ufe0f": 23.31575280364297, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 77, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6834122350917787, "IFEval": 68.34122350917787, "BBH Raw": 0.50795799761689, "BBH": 29.73968358044069, "MATH Lvl 5 Raw": 0.073262839879154, "MATH Lvl 5": 7.326283987915408, "GPQA Raw": 0.2651006711409396, "GPQA": 2.0134228187919474, "MUSR Raw": 0.3660624999999999, "MUSR": 3.0911458333333326, "MMLU-PRO Raw": 0.3644448138297872, "MMLU-PRO": 29.38275709219858, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-25T00:00:00", "Submission Date": "2024-07-02T00:00:00", "Generation": 0, "Base Model": "UCLA-AGI/Llama-3-Instruct-8B-SPPO-Iter3"}, {"eval_name": "UCLA-AGI_Llama-3-Instruct-8B-SPPO-Iter3_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/UCLA-AGI/Llama-3-Instruct-8B-SPPO-Iter3\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">UCLA-AGI/Llama-3-Instruct-8B-SPPO-Iter3</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/UCLA-AGI__Llama-3-Instruct-8B-SPPO-Iter3-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "UCLA-AGI/Llama-3-Instruct-8B-SPPO-Iter3", "Model sha": "f73dafc2923acd56f115f21f76e9d14f8d19a63e", "Average \u2b06\ufe0f": 23.05947024187678, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 77, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.67029814226253, "IFEval": 67.02981422625301, "BBH Raw": 0.5076407742830437, "BBH": 29.71670075746525, "MATH Lvl 5 Raw": 0.0717522658610271, "MATH Lvl 5": 7.175226586102719, "GPQA Raw": 0.2651006711409396, "GPQA": 2.0134228187919474, "MUSR Raw": 0.3647291666666667, "MUSR": 2.891145833333335, "MMLU-PRO Raw": 0.3657746010638298, "MMLU-PRO": 29.53051122931442, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-25T00:00:00", "Submission Date": "2024-06-28T00:00:00", "Generation": 0, "Base Model": "UCLA-AGI/Llama-3-Instruct-8B-SPPO-Iter3"}, {"eval_name": "UCLA-AGI_Mistral7B-PairRM-SPPO_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/UCLA-AGI/Mistral7B-PairRM-SPPO\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">UCLA-AGI/Mistral7B-PairRM-SPPO</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/UCLA-AGI__Mistral7B-PairRM-SPPO-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "UCLA-AGI/Mistral7B-PairRM-SPPO", "Model sha": "abdc173603690fcf6b333b351c291a321d2631c3", "Average \u2b06\ufe0f": 16.331403705178214, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 6, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4354922716170871, "IFEval": 43.54922716170872, "BBH Raw": 0.4438979817093698, "BBH": 22.08465647856181, "MATH Lvl 5 Raw": 0.0241691842900302, "MATH Lvl 5": 2.416918429003021, "GPQA Raw": 0.2810402684563758, "GPQA": 4.138702460850116, "MUSR Raw": 0.3964791666666666, "MUSR": 7.793229166666667, "MMLU-PRO Raw": 0.2620511968085106, "MMLU-PRO": 18.005688534278956, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-04T00:00:00", "Submission Date": "2024-09-21T00:00:00", "Generation": 0, "Base Model": "UCLA-AGI/Mistral7B-PairRM-SPPO"}, {"eval_name": "UCLA-AGI_Mistral7B-PairRM-SPPO-Iter1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/UCLA-AGI/Mistral7B-PairRM-SPPO-Iter1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">UCLA-AGI/Mistral7B-PairRM-SPPO-Iter1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/UCLA-AGI__Mistral7B-PairRM-SPPO-Iter1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "UCLA-AGI/Mistral7B-PairRM-SPPO-Iter1", "Model sha": "97252e2d868725b2fa5055adc241c5182610fb6a", "Average \u2b06\ufe0f": 17.867393327983333, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5047352136774869, "IFEval": 50.47352136774869, "BBH Raw": 0.4468056921650662, "BBH": 22.93229237099634, "MATH Lvl 5 Raw": 0.0219033232628398, "MATH Lvl 5": 2.190332326283988, "GPQA Raw": 0.2835570469798658, "GPQA": 4.4742729306487705, "MUSR Raw": 0.3991770833333333, "MUSR": 8.29713541666667, "MMLU-PRO Raw": 0.26953125, "MMLU-PRO": 18.836805555555557, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-04T00:00:00", "Submission Date": "2024-09-21T00:00:00", "Generation": 0, "Base Model": "UCLA-AGI/Mistral7B-PairRM-SPPO-Iter1"}, {"eval_name": "UCLA-AGI_Mistral7B-PairRM-SPPO-Iter2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/UCLA-AGI/Mistral7B-PairRM-SPPO-Iter2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">UCLA-AGI/Mistral7B-PairRM-SPPO-Iter2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/UCLA-AGI__Mistral7B-PairRM-SPPO-Iter2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "UCLA-AGI/Mistral7B-PairRM-SPPO-Iter2", "Model sha": "8201064df67b5762ff9f361ff1b98aae3747855c", "Average \u2b06\ufe0f": 17.004846449398197, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4445848127413041, "IFEval": 44.45848127413042, "BBH Raw": 0.4465719945610438, "BBH": 22.47992425019784, "MATH Lvl 5 Raw": 0.0151057401812688, "MATH Lvl 5": 1.5105740181268883, "GPQA Raw": 0.2885906040268456, "GPQA": 5.145413870246088, "MUSR Raw": 0.4085416666666666, "MUSR": 9.801041666666668, "MMLU-PRO Raw": 0.2677027925531915, "MMLU-PRO": 18.63364361702128, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-04T00:00:00", "Submission Date": "2024-08-07T00:00:00", "Generation": 0, "Base Model": "UCLA-AGI/Mistral7B-PairRM-SPPO-Iter2"}, {"eval_name": "UCLA-AGI_Mistral7B-PairRM-SPPO-Iter3_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/UCLA-AGI/Mistral7B-PairRM-SPPO-Iter3\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">UCLA-AGI/Mistral7B-PairRM-SPPO-Iter3</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/UCLA-AGI__Mistral7B-PairRM-SPPO-Iter3-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "UCLA-AGI/Mistral7B-PairRM-SPPO-Iter3", "Model sha": "72cd8e5435ae679249ddad7ac4cdb64c5b4590c3", "Average \u2b06\ufe0f": 16.36277626432563, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 5, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4350678422142138, "IFEval": 43.50678422142138, "BBH Raw": 0.4396587862984616, "BBH": 21.817495985928637, "MATH Lvl 5 Raw": 0.0158610271903323, "MATH Lvl 5": 1.5861027190332326, "GPQA Raw": 0.2751677852348993, "GPQA": 3.355704697986576, "MUSR Raw": 0.4071145833333333, "MUSR": 9.489322916666673, "MMLU-PRO Raw": 0.2657912234042553, "MMLU-PRO": 18.42124704491726, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-04T00:00:00", "Submission Date": "2024-08-07T00:00:00", "Generation": 0, "Base Model": "UCLA-AGI/Mistral7B-PairRM-SPPO-Iter3"}, {"eval_name": "UKzExecution_LlamaExecutor-8B-3.0.5_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/UKzExecution/LlamaExecutor-8B-3.0.5\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">UKzExecution/LlamaExecutor-8B-3.0.5</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/UKzExecution__LlamaExecutor-8B-3.0.5-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "UKzExecution/LlamaExecutor-8B-3.0.5", "Model sha": "2047978e8ab1146b8881cde3d998856594f437a4", "Average \u2b06\ufe0f": 24.264140625369013, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.740290207759855, "IFEval": 74.0290207759855, "BBH Raw": 0.5006000507021341, "BBH": 28.41381524085358, "MATH Lvl 5 Raw": 0.0853474320241691, "MATH Lvl 5": 8.534743202416918, "GPQA Raw": 0.2558724832214765, "GPQA": 0.7829977628635317, "MUSR Raw": 0.3753645833333333, "MUSR": 4.653906250000001, "MMLU-PRO Raw": 0.3625332446808511, "MMLU-PRO": 29.17036052009456, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-29T00:00:00", "Submission Date": "2024-07-30T00:00:00", "Generation": 1, "Base Model": "UKzExecution/LlamaExecutor-8B-3.0.5 (Merge)"}, {"eval_name": "Unbabel_TowerInstruct-Mistral-7B-v0.2_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Unbabel/TowerInstruct-Mistral-7B-v0.2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Unbabel/TowerInstruct-Mistral-7B-v0.2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Unbabel__TowerInstruct-Mistral-7B-v0.2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Unbabel/TowerInstruct-Mistral-7B-v0.2", "Model sha": "454bdfedc8b51f292a402aba2c560df145a0817d", "Average \u2b06\ufe0f": 11.82718844840928, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 10, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2843422119975, "IFEval": 28.43422119975, "BBH Raw": 0.388195180992626, "BBH": 14.224326422972672, "MATH Lvl 5 Raw": 0.0158610271903323, "MATH Lvl 5": 1.5861027190332326, "GPQA Raw": 0.24748322147651, "GPQA": 0.0, "MUSR Raw": 0.4522291666666667, "MUSR": 15.961979166666667, "MMLU-PRO Raw": 0.1968085106382978, "MMLU-PRO": 10.756501182033098, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-03-26T00:00:00", "Submission Date": "2024-09-06T00:00:00", "Generation": 0, "Base Model": "Unbabel/TowerInstruct-Mistral-7B-v0.2"}, {"eval_name": "Undi95_MG-FinalMix-72B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Undi95/MG-FinalMix-72B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Undi95/MG-FinalMix-72B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Undi95__MG-FinalMix-72B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Undi95/MG-FinalMix-72B", "Model sha": "6c9c2f5d052495dcd49f44bf5623d21210653c65", "Average \u2b06\ufe0f": 43.277724677689264, "Hub License": "other", "Hub \u2764\ufe0f": 3, "#Params (B)": 72, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.8013648231137825, "IFEval": 80.13648231137824, "BBH Raw": 0.6973017446417747, "BBH": 57.502411706281976, "MATH Lvl 5 Raw": 0.3361027190332326, "MATH Lvl 5": 33.610271903323266, "GPQA Raw": 0.3850671140939597, "GPQA": 18.008948545861294, "MUSR Raw": 0.4822708333333333, "MUSR": 21.2171875, "MMLU-PRO Raw": 0.542719414893617, "MMLU-PRO": 49.19104609929077, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-25T00:00:00", "Submission Date": "2024-07-13T00:00:00", "Generation": 1, "Base Model": "Undi95/MG-FinalMix-72B (Merge)"}, {"eval_name": "VAGOsolutions_Llama-3-SauerkrautLM-70b-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/VAGOsolutions/Llama-3-SauerkrautLM-70b-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">VAGOsolutions/Llama-3-SauerkrautLM-70b-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/VAGOsolutions__Llama-3-SauerkrautLM-70b-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "VAGOsolutions/Llama-3-SauerkrautLM-70b-Instruct", "Model sha": "707cfd1a93875247c0223e0c7e3d86d58c432318", "Average \u2b06\ufe0f": 37.81676608541096, "Hub License": "other", "Hub \u2764\ufe0f": 21, "#Params (B)": 70, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.8044621604010691, "IFEval": 80.44621604010692, "BBH Raw": 0.6663247245334951, "BBH": 52.02957975911792, "MATH Lvl 5 Raw": 0.2167673716012084, "MATH Lvl 5": 21.676737160120847, "GPQA Raw": 0.3280201342281879, "GPQA": 10.402684563758392, "MUSR Raw": 0.4339375, "MUSR": 13.542187500000002, "MMLU-PRO Raw": 0.5392287234042553, "MMLU-PRO": 48.8031914893617, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-24T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "VAGOsolutions/Llama-3-SauerkrautLM-70b-Instruct"}, {"eval_name": "VAGOsolutions_Llama-3-SauerkrautLM-8b-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/VAGOsolutions/Llama-3-SauerkrautLM-8b-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">VAGOsolutions/Llama-3-SauerkrautLM-8b-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/VAGOsolutions__Llama-3-SauerkrautLM-8b-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "VAGOsolutions/Llama-3-SauerkrautLM-8b-Instruct", "Model sha": "37127c44d7c0fb56cef817270c4b1a6802d8793a", "Average \u2b06\ufe0f": 26.51659732477349, "Hub License": "other", "Hub \u2764\ufe0f": 51, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.744536718130117, "IFEval": 74.45367181301171, "BBH Raw": 0.494337579362695, "BBH": 28.0492424520597, "MATH Lvl 5 Raw": 0.0574018126888217, "MATH Lvl 5": 5.740181268882175, "GPQA Raw": 0.3087248322147651, "GPQA": 7.829977628635347, "MUSR Raw": 0.4241041666666666, "MUSR": 11.2796875, "MMLU-PRO Raw": 0.3857214095744681, "MMLU-PRO": 31.746823286052013, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-19T00:00:00", "Submission Date": "2024-07-22T00:00:00", "Generation": 0, "Base Model": "VAGOsolutions/Llama-3-SauerkrautLM-8b-Instruct"}, {"eval_name": "VAGOsolutions_Llama-3.1-SauerkrautLM-70b-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/VAGOsolutions/Llama-3.1-SauerkrautLM-70b-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">VAGOsolutions/Llama-3.1-SauerkrautLM-70b-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/VAGOsolutions__Llama-3.1-SauerkrautLM-70b-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "VAGOsolutions/Llama-3.1-SauerkrautLM-70b-Instruct", "Model sha": "e8e74aa789243c25a3a8f7565780a402f5050bbb", "Average \u2b06\ufe0f": 42.24307497595168, "Hub License": "llama3.1", "Hub \u2764\ufe0f": 15, "#Params (B)": 70, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.8656365111238181, "IFEval": 86.56365111238182, "BBH Raw": 0.7006249194404001, "BBH": 57.24162100868165, "MATH Lvl 5 Raw": 0.2990936555891239, "MATH Lvl 5": 29.909365558912388, "GPQA Raw": 0.3414429530201342, "GPQA": 12.192393736017896, "MUSR Raw": 0.4710833333333333, "MUSR": 19.38541666666666, "MMLU-PRO Raw": 0.5334940159574468, "MMLU-PRO": 48.16600177304965, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-29T00:00:00", "Submission Date": "2024-08-26T00:00:00", "Generation": 0, "Base Model": "VAGOsolutions/Llama-3.1-SauerkrautLM-70b-Instruct"}, {"eval_name": "VAGOsolutions_Llama-3.1-SauerkrautLM-8b-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/VAGOsolutions/Llama-3.1-SauerkrautLM-8b-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">VAGOsolutions/Llama-3.1-SauerkrautLM-8b-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/VAGOsolutions__Llama-3.1-SauerkrautLM-8b-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "VAGOsolutions/Llama-3.1-SauerkrautLM-8b-Instruct", "Model sha": "23ca79966a4ab0a61f7ccc7a0454ffef553b66eb", "Average \u2b06\ufe0f": 28.558968351945552, "Hub License": "llama3.1", "Hub \u2764\ufe0f": 30, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.8017393848322452, "IFEval": 80.1739384832245, "BBH Raw": 0.5114932190011187, "BBH": 30.99936066535637, "MATH Lvl 5 Raw": 0.1117824773413897, "MATH Lvl 5": 11.178247734138973, "GPQA Raw": 0.2902684563758389, "GPQA": 5.369127516778524, "MUSR Raw": 0.4148020833333333, "MUSR": 11.51692708333333, "MMLU-PRO Raw": 0.3890458776595745, "MMLU-PRO": 32.116208628841605, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-25T00:00:00", "Submission Date": "2024-07-29T00:00:00", "Generation": 0, "Base Model": "VAGOsolutions/Llama-3.1-SauerkrautLM-8b-Instruct"}, {"eval_name": "VAGOsolutions_SauerkrautLM-1.5b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/VAGOsolutions/SauerkrautLM-1.5b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">VAGOsolutions/SauerkrautLM-1.5b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/VAGOsolutions__SauerkrautLM-1.5b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "VAGOsolutions/SauerkrautLM-1.5b", "Model sha": "8f5170f03e6b0355dd920adc3a7e65d0417ee14e", "Average \u2b06\ufe0f": 10.084740900829098, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 11, "#Params (B)": 1, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2404032411778525, "IFEval": 24.040324117785254, "BBH Raw": 0.3703912164863146, "BBH": 13.419518424915282, "MATH Lvl 5 Raw": 0.0249244712990936, "MATH Lvl 5": 2.492447129909366, "GPQA Raw": 0.2709731543624161, "GPQA": 2.796420581655479, "MUSR Raw": 0.37390625, "MUSR": 4.971614583333335, "MMLU-PRO Raw": 0.2150930851063829, "MMLU-PRO": 12.788120567375886, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-12T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "VAGOsolutions/SauerkrautLM-1.5b"}, {"eval_name": "VAGOsolutions_SauerkrautLM-7b-HerO_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/VAGOsolutions/SauerkrautLM-7b-HerO\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">VAGOsolutions/SauerkrautLM-7b-HerO</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/VAGOsolutions__SauerkrautLM-7b-HerO-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "VAGOsolutions/SauerkrautLM-7b-HerO", "Model sha": "3a14b437e2f375b74de3b6923e171662133347bb", "Average \u2b06\ufe0f": 19.681899863993696, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 32, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.534610389322553, "IFEval": 53.461038932255306, "BBH Raw": 0.4904434993581296, "BBH": 27.99187353683021, "MATH Lvl 5 Raw": 0.0400302114803625, "MATH Lvl 5": 4.003021148036254, "GPQA Raw": 0.2726510067114094, "GPQA": 3.0201342281879207, "MUSR Raw": 0.3923854166666666, "MUSR": 6.881510416666668, "MMLU-PRO Raw": 0.3046043882978723, "MMLU-PRO": 22.733820921985814, "Maintainer's Highlight": false, "Upload To Hub Date": "2023-11-24T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "VAGOsolutions/SauerkrautLM-7b-HerO"}, {"eval_name": "VAGOsolutions_SauerkrautLM-7b-LaserChat_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/VAGOsolutions/SauerkrautLM-7b-LaserChat\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">VAGOsolutions/SauerkrautLM-7b-LaserChat</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/VAGOsolutions__SauerkrautLM-7b-LaserChat-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "VAGOsolutions/SauerkrautLM-7b-LaserChat", "Model sha": "cb759636a3d5b0768df2f43a3d3da9b17e10e7b9", "Average \u2b06\ufe0f": 21.971082855832915, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 12, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5987823419637672, "IFEval": 59.87823419637673, "BBH Raw": 0.4543270799329568, "BBH": 22.99208011647468, "MATH Lvl 5 Raw": 0.0672205438066465, "MATH Lvl 5": 6.722054380664652, "GPQA Raw": 0.3003355704697986, "GPQA": 6.711409395973152, "MUSR Raw": 0.4148020833333333, "MUSR": 9.916927083333333, "MMLU-PRO Raw": 0.3304521276595745, "MMLU-PRO": 25.60579196217494, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-02-05T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "VAGOsolutions/SauerkrautLM-7b-LaserChat"}, {"eval_name": "VAGOsolutions_SauerkrautLM-Gemma-2b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "GemmaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/VAGOsolutions/SauerkrautLM-Gemma-2b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">VAGOsolutions/SauerkrautLM-Gemma-2b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/VAGOsolutions__SauerkrautLM-Gemma-2b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "VAGOsolutions/SauerkrautLM-Gemma-2b", "Model sha": "f9d5575c23da96f33ce77dea3b0776746b9469bc", "Average \u2b06\ufe0f": 7.577625671094733, "Hub License": "other", "Hub \u2764\ufe0f": 8, "#Params (B)": 2, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2475221301701707, "IFEval": 24.75221301701707, "BBH Raw": 0.3416315376053174, "BBH": 9.133870459903902, "MATH Lvl 5 Raw": 0.0196374622356495, "MATH Lvl 5": 1.9637462235649543, "GPQA Raw": 0.2567114093959731, "GPQA": 0.8948545861297527, "MUSR Raw": 0.3675833333333333, "MUSR": 3.514583333333334, "MMLU-PRO Raw": 0.1468583776595744, "MMLU-PRO": 5.206486406619384, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-03-06T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "VAGOsolutions/SauerkrautLM-Gemma-2b"}, {"eval_name": "VAGOsolutions_SauerkrautLM-Gemma-7b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "GemmaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/VAGOsolutions/SauerkrautLM-Gemma-7b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">VAGOsolutions/SauerkrautLM-Gemma-7b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/VAGOsolutions__SauerkrautLM-Gemma-7b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "VAGOsolutions/SauerkrautLM-Gemma-7b", "Model sha": "4296bdabf82e900235b094e5348be03ebb0ec891", "Average \u2b06\ufe0f": 14.499864611759856, "Hub License": "other", "Hub \u2764\ufe0f": 13, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3406705319662939, "IFEval": 34.06705319662939, "BBH Raw": 0.4187912789585868, "BBH": 18.492651800030927, "MATH Lvl 5 Raw": 0.0490936555891238, "MATH Lvl 5": 4.909365558912387, "GPQA Raw": 0.2860738255033557, "GPQA": 4.809843400447425, "MUSR Raw": 0.3594270833333333, "MUSR": 2.9283854166666674, "MMLU-PRO Raw": 0.2961269946808511, "MMLU-PRO": 21.79188829787234, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-02-27T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "VAGOsolutions/SauerkrautLM-Gemma-7b"}, {"eval_name": "VAGOsolutions_SauerkrautLM-Mixtral-8x7B-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/VAGOsolutions/SauerkrautLM-Mixtral-8x7B-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">VAGOsolutions/SauerkrautLM-Mixtral-8x7B-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/VAGOsolutions__SauerkrautLM-Mixtral-8x7B-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "VAGOsolutions/SauerkrautLM-Mixtral-8x7B-Instruct", "Model sha": "30ed549de7d84f68b4c6cb619f73275c99af23cc", "Average \u2b06\ufe0f": 24.286056931307016, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 21, "#Params (B)": 46, "Available on the hub": true, "Not_Merged": true, "MoE": false, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5601891869129465, "IFEval": 56.01891869129465, "BBH Raw": 0.5277342269858817, "BBH": 33.94516253986293, "MATH Lvl 5 Raw": 0.0861027190332326, "MATH Lvl 5": 8.610271903323262, "GPQA Raw": 0.2978187919463087, "GPQA": 6.375838926174497, "MUSR Raw": 0.4204166666666666, "MUSR": 11.31875, "MMLU-PRO Raw": 0.3650265957446808, "MMLU-PRO": 29.44739952718675, "Maintainer's Highlight": false, "Upload To Hub Date": "2023-12-15T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "VAGOsolutions/SauerkrautLM-Mixtral-8x7B-Instruct"}, {"eval_name": "VAGOsolutions_SauerkrautLM-Nemo-12b-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/VAGOsolutions/SauerkrautLM-Nemo-12b-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">VAGOsolutions/SauerkrautLM-Nemo-12b-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/VAGOsolutions__SauerkrautLM-Nemo-12b-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "VAGOsolutions/SauerkrautLM-Nemo-12b-Instruct", "Model sha": "fcb056465084ab2c71503a0760f46e4be79c985c", "Average \u2b06\ufe0f": 25.627440025777588, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 20, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6112969144093228, "IFEval": 61.12969144093229, "BBH Raw": 0.5214128647611115, "BBH": 32.34378307249567, "MATH Lvl 5 Raw": 0.086858006042296, "MATH Lvl 5": 8.685800604229607, "GPQA Raw": 0.3095637583892617, "GPQA": 7.941834451901568, "MUSR Raw": 0.4468958333333333, "MUSR": 17.161979166666665, "MMLU-PRO Raw": 0.3385139627659574, "MMLU-PRO": 26.50155141843972, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-22T00:00:00", "Submission Date": "2024-07-22T00:00:00", "Generation": 0, "Base Model": "VAGOsolutions/SauerkrautLM-Nemo-12b-Instruct"}, {"eval_name": "VAGOsolutions_SauerkrautLM-Phi-3-medium_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/VAGOsolutions/SauerkrautLM-Phi-3-medium\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">VAGOsolutions/SauerkrautLM-Phi-3-medium</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/VAGOsolutions__SauerkrautLM-Phi-3-medium-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "VAGOsolutions/SauerkrautLM-Phi-3-medium", "Model sha": "ebfed26a2b35ede15fe526f57029e0ad866ac66d", "Average \u2b06\ufe0f": 30.09321208454953, "Hub License": "mit", "Hub \u2764\ufe0f": 9, "#Params (B)": 13, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4408879550703245, "IFEval": 44.08879550703245, "BBH Raw": 0.6432931765847228, "BBH": 49.630350331717615, "MATH Lvl 5 Raw": 0.141238670694864, "MATH Lvl 5": 14.123867069486405, "GPQA Raw": 0.3347315436241611, "GPQA": 11.297539149888143, "MUSR Raw": 0.4845, "MUSR": 20.69583333333333, "MMLU-PRO Raw": 0.4665059840425531, "MMLU-PRO": 40.72288711583924, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-09T00:00:00", "Submission Date": "2024-09-19T00:00:00", "Generation": 0, "Base Model": "VAGOsolutions/SauerkrautLM-Phi-3-medium"}, {"eval_name": "VAGOsolutions_SauerkrautLM-SOLAR-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/VAGOsolutions/SauerkrautLM-SOLAR-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">VAGOsolutions/SauerkrautLM-SOLAR-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/VAGOsolutions__SauerkrautLM-SOLAR-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "VAGOsolutions/SauerkrautLM-SOLAR-Instruct", "Model sha": "2665d7600ccd253728453433d2434844e6f702bd", "Average \u2b06\ufe0f": 20.16424435950889, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 47, "#Params (B)": 10, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4917208562170596, "IFEval": 49.17208562170596, "BBH Raw": 0.5169447300097646, "BBH": 31.838919738784018, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.3053691275167785, "GPQA": 7.38255033557047, "MUSR Raw": 0.3965416666666666, "MUSR": 8.334374999999996, "MMLU-PRO Raw": 0.3183178191489361, "MMLU-PRO": 24.257535460992905, "Maintainer's Highlight": false, "Upload To Hub Date": "2023-12-20T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "VAGOsolutions/SauerkrautLM-SOLAR-Instruct"}, {"eval_name": "VAGOsolutions_SauerkrautLM-gemma-2-2b-it_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/VAGOsolutions/SauerkrautLM-gemma-2-2b-it\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">VAGOsolutions/SauerkrautLM-gemma-2-2b-it</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/VAGOsolutions__SauerkrautLM-gemma-2-2b-it-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "VAGOsolutions/SauerkrautLM-gemma-2-2b-it", "Model sha": "7fd35fcb32aebfc422e535739161d7528fc562d5", "Average \u2b06\ufe0f": 10.46520167420392, "Hub License": "gemma", "Hub \u2764\ufe0f": 6, "#Params (B)": 2, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.1320662508809957, "IFEval": 13.206625088099576, "BBH Raw": 0.4240837186064485, "BBH": 18.914195373183343, "MATH Lvl 5 Raw": 0.0007552870090634, "MATH Lvl 5": 0.0755287009063444, "GPQA Raw": 0.2726510067114094, "GPQA": 3.0201342281879207, "MUSR Raw": 0.3994583333333333, "MUSR": 8.765624999999998, "MMLU-PRO Raw": 0.269281914893617, "MMLU-PRO": 18.809101654846337, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-03T00:00:00", "Submission Date": "2024-08-26T00:00:00", "Generation": 0, "Base Model": "VAGOsolutions/SauerkrautLM-gemma-2-2b-it"}, {"eval_name": "VAGOsolutions_SauerkrautLM-gemma-2-9b-it_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/VAGOsolutions/SauerkrautLM-gemma-2-9b-it\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">VAGOsolutions/SauerkrautLM-gemma-2-9b-it</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/VAGOsolutions__SauerkrautLM-gemma-2-9b-it-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "VAGOsolutions/SauerkrautLM-gemma-2-9b-it", "Model sha": "8e02fc1c24e0499c74ee1186ddc46b989fe497f1", "Average \u2b06\ufe0f": 21.832650076743665, "Hub License": "gemma", "Hub \u2764\ufe0f": 4, "#Params (B)": 9, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3024009627787604, "IFEval": 30.240096277876034, "BBH Raw": 0.6072645787154746, "BBH": 43.249988966600455, "MATH Lvl 5 Raw": 0.0052870090634441, "MATH Lvl 5": 0.5287009063444109, "GPQA Raw": 0.3271812080536913, "GPQA": 10.290827740492167, "MUSR Raw": 0.4318229166666666, "MUSR": 12.34453125, "MMLU-PRO Raw": 0.4090757978723404, "MMLU-PRO": 34.34175531914893, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-12T00:00:00", "Submission Date": "2024-08-26T00:00:00", "Generation": 0, "Base Model": "VAGOsolutions/SauerkrautLM-gemma-2-9b-it"}, {"eval_name": "VIRNECT_llama-3-Korean-8B_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/VIRNECT/llama-3-Korean-8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">VIRNECT/llama-3-Korean-8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/VIRNECT__llama-3-Korean-8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "VIRNECT/llama-3-Korean-8B", "Model sha": "c658409e094ff04eeb6ab6cee2d4bc56716e45f1", "Average \u2b06\ufe0f": 20.245300698827084, "Hub License": "llama3", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5058345190760515, "IFEval": 50.58345190760515, "BBH Raw": 0.4908245308337839, "BBH": 27.322411613379888, "MATH Lvl 5 Raw": 0.0929003021148036, "MATH Lvl 5": 9.290030211480364, "GPQA Raw": 0.2709731543624161, "GPQA": 2.796420581655479, "MUSR Raw": 0.3661562499999999, "MUSR": 3.26953125, "MMLU-PRO Raw": 0.3538896276595745, "MMLU-PRO": 28.20995862884161, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-17T00:00:00", "Submission Date": "2024-07-17T00:00:00", "Generation": 0, "Base Model": "VIRNECT/llama-3-Korean-8B"}, {"eval_name": "VIRNECT_llama-3-Korean-8B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/VIRNECT/llama-3-Korean-8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">VIRNECT/llama-3-Korean-8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/VIRNECT__llama-3-Korean-8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "VIRNECT/llama-3-Korean-8B", "Model sha": "c658409e094ff04eeb6ab6cee2d4bc56716e45f1", "Average \u2b06\ufe0f": 20.17984700553752, "Hub License": "llama3", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5021376614050719, "IFEval": 50.21376614050719, "BBH Raw": 0.491837579362695, "BBH": 27.564318704783016, "MATH Lvl 5 Raw": 0.0929003021148036, "MATH Lvl 5": 9.290030211480364, "GPQA Raw": 0.2709731543624161, "GPQA": 2.796420581655479, "MUSR Raw": 0.3647916666666666, "MUSR": 3.032291666666666, "MMLU-PRO Raw": 0.3536402925531915, "MMLU-PRO": 28.1822547281324, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-17T00:00:00", "Submission Date": "2024-07-17T00:00:00", "Generation": 0, "Base Model": "VIRNECT/llama-3-Korean-8B"}, {"eval_name": "VIRNECT_llama-3-Korean-8B-r-v-0.1_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Adapter", "Architecture": "?", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/VIRNECT/llama-3-Korean-8B-r-v-0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">VIRNECT/llama-3-Korean-8B-r-v-0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/VIRNECT__llama-3-Korean-8B-r-v-0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "VIRNECT/llama-3-Korean-8B-r-v-0.1", "Model sha": "10acb1aa4f341f2d3c899d78c520b0822a909b95", "Average \u2b06\ufe0f": 18.51010431661297, "Hub License": "llama3", "Hub \u2764\ufe0f": 0, "#Params (B)": 16, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4915712531638275, "IFEval": 49.15712531638276, "BBH Raw": 0.4806156813908626, "BBH": 25.8849543311167, "MATH Lvl 5 Raw": 0.0717522658610271, "MATH Lvl 5": 7.175226586102719, "GPQA Raw": 0.2424496644295302, "GPQA": 0.0, "MUSR Raw": 0.3674895833333333, "MUSR": 3.73619791666667, "MMLU-PRO Raw": 0.3259640957446808, "MMLU-PRO": 25.10712174940898, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-18T00:00:00", "Submission Date": "2024-07-18T00:00:00", "Generation": 2, "Base Model": "MLP-KTLim/llama-3-Korean-Bllossom-8B (Merge)"}, {"eval_name": "ValiantLabs_Llama3-70B-Fireplace_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/ValiantLabs/Llama3-70B-Fireplace\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">ValiantLabs/Llama3-70B-Fireplace</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/ValiantLabs__Llama3-70B-Fireplace-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "ValiantLabs/Llama3-70B-Fireplace", "Model sha": "220079e4115733991eb19c30d5480db9696a665e", "Average \u2b06\ufe0f": 36.82311202919691, "Hub License": "llama3", "Hub \u2764\ufe0f": 3, "#Params (B)": 70, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7773596280092377, "IFEval": 77.73596280092377, "BBH Raw": 0.648899361888402, "BBH": 49.55653001638277, "MATH Lvl 5 Raw": 0.1963746223564954, "MATH Lvl 5": 19.637462235649547, "GPQA Raw": 0.3548657718120805, "GPQA": 13.982102908277405, "MUSR Raw": 0.4448541666666667, "MUSR": 16.7734375, "MMLU-PRO Raw": 0.4892785904255319, "MMLU-PRO": 43.25317671394799, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-09T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "ValiantLabs/Llama3-70B-Fireplace"}, {"eval_name": "ValiantLabs_Llama3-70B-ShiningValiant2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/ValiantLabs/Llama3-70B-ShiningValiant2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">ValiantLabs/Llama3-70B-ShiningValiant2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/ValiantLabs__Llama3-70B-ShiningValiant2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "ValiantLabs/Llama3-70B-ShiningValiant2", "Model sha": "bd6cce8da08ccefe9ec58cae3df4bf75c97d8950", "Average \u2b06\ufe0f": 30.452034306525796, "Hub License": "llama3", "Hub \u2764\ufe0f": 4, "#Params (B)": 70, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6121712611426571, "IFEval": 61.217126114265696, "BBH Raw": 0.6338341405069171, "BBH": 46.71026104076922, "MATH Lvl 5 Raw": 0.0709969788519637, "MATH Lvl 5": 7.099697885196375, "GPQA Raw": 0.3305369127516778, "GPQA": 10.738255033557047, "MUSR Raw": 0.4325729166666667, "MUSR": 13.63828125, "MMLU-PRO Raw": 0.4897772606382978, "MMLU-PRO": 43.30858451536643, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-20T00:00:00", "Submission Date": "2024-07-25T00:00:00", "Generation": 0, "Base Model": "ValiantLabs/Llama3-70B-ShiningValiant2"}, {"eval_name": "ValiantLabs_Llama3.1-8B-Cobalt_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/ValiantLabs/Llama3.1-8B-Cobalt\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">ValiantLabs/Llama3.1-8B-Cobalt</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/ValiantLabs__Llama3.1-8B-Cobalt-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "ValiantLabs/Llama3.1-8B-Cobalt", "Model sha": "3a69145a2acc1f7f51735aa3ae5d81c090249c65", "Average \u2b06\ufe0f": 20.025395756497264, "Hub License": "llama3.1", "Hub \u2764\ufe0f": 6, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3496134700372789, "IFEval": 34.96134700372789, "BBH Raw": 0.4946769968149292, "BBH": 27.41777700049443, "MATH Lvl 5 Raw": 0.11404833836858, "MATH Lvl 5": 11.404833836858003, "GPQA Raw": 0.3036912751677852, "GPQA": 7.158836689038028, "MUSR Raw": 0.3959479166666667, "MUSR": 9.82682291666667, "MMLU-PRO Raw": 0.3644448138297872, "MMLU-PRO": 29.38275709219858, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-16T00:00:00", "Submission Date": "2024-10-02T00:00:00", "Generation": 2, "Base Model": "meta-llama/Meta-Llama-3.1-8B"}, {"eval_name": "ValiantLabs_Llama3.1-8B-Cobalt_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/ValiantLabs/Llama3.1-8B-Cobalt\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">ValiantLabs/Llama3.1-8B-Cobalt</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/ValiantLabs__Llama3.1-8B-Cobalt-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "ValiantLabs/Llama3.1-8B-Cobalt", "Model sha": "3a69145a2acc1f7f51735aa3ae5d81c090249c65", "Average \u2b06\ufe0f": 25.55866436932208, "Hub License": "llama3.1", "Hub \u2764\ufe0f": 6, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7168346653545925, "IFEval": 71.68346653545925, "BBH Raw": 0.4910700749859321, "BBH": 27.235483048638358, "MATH Lvl 5 Raw": 0.1533232628398791, "MATH Lvl 5": 15.332326283987916, "GPQA Raw": 0.2860738255033557, "GPQA": 4.809843400447425, "MUSR Raw": 0.3512395833333333, "MUSR": 4.704947916666668, "MMLU-PRO Raw": 0.3662732712765957, "MMLU-PRO": 29.58591903073286, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-16T00:00:00", "Submission Date": "2024-09-20T00:00:00", "Generation": 2, "Base Model": "meta-llama/Meta-Llama-3.1-8B"}, {"eval_name": "ValiantLabs_Llama3.1-8B-Enigma_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/ValiantLabs/Llama3.1-8B-Enigma\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">ValiantLabs/Llama3.1-8B-Enigma</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/ValiantLabs__Llama3.1-8B-Enigma-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "ValiantLabs/Llama3.1-8B-Enigma", "Model sha": "332c99d80f378c77b090745a5aac10f8ab339519", "Average \u2b06\ufe0f": 16.48668817329096, "Hub License": "llama3.1", "Hub \u2764\ufe0f": 8, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2680554262689663, "IFEval": 26.80554262689663, "BBH Raw": 0.4477600088015392, "BBH": 22.012915076928262, "MATH Lvl 5 Raw": 0.0808157099697885, "MATH Lvl 5": 8.08157099697885, "GPQA Raw": 0.287751677852349, "GPQA": 5.033557046979867, "MUSR Raw": 0.4196041666666666, "MUSR": 10.2171875, "MMLU-PRO Raw": 0.3409242021276595, "MMLU-PRO": 26.769355791962173, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-11T00:00:00", "Submission Date": "2024-10-02T00:00:00", "Generation": 2, "Base Model": "meta-llama/Meta-Llama-3.1-8B"}, {"eval_name": "ValiantLabs_Llama3.1-8B-Esper2_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/ValiantLabs/Llama3.1-8B-Esper2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">ValiantLabs/Llama3.1-8B-Esper2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/ValiantLabs__Llama3.1-8B-Esper2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "ValiantLabs/Llama3.1-8B-Esper2", "Model sha": "38f24f2fe90f839acbc57e7530221acf1232e9dc", "Average \u2b06\ufe0f": 13.714223995744618, "Hub License": "llama3.1", "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2567398945907968, "IFEval": 25.673989459079685, "BBH Raw": 0.4469866863000255, "BBH": 22.195685067925837, "MATH Lvl 5 Raw": 0.0453172205438066, "MATH Lvl 5": 4.531722054380665, "GPQA Raw": 0.2726510067114094, "GPQA": 3.0201342281879207, "MUSR Raw": 0.3560729166666667, "MUSR": 5.709114583333332, "MMLU-PRO Raw": 0.2903922872340425, "MMLU-PRO": 21.15469858156028, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-02T00:00:00", "Submission Date": "2024-10-09T00:00:00", "Generation": 2, "Base Model": "meta-llama/Meta-Llama-3.1-8B"}, {"eval_name": "ValiantLabs_Llama3.1-8B-Fireplace2_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/ValiantLabs/Llama3.1-8B-Fireplace2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">ValiantLabs/Llama3.1-8B-Fireplace2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/ValiantLabs__Llama3.1-8B-Fireplace2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "ValiantLabs/Llama3.1-8B-Fireplace2", "Model sha": "be3a5c18b5e8e86a3703df1a8227f784ad2c713c", "Average \u2b06\ufe0f": 18.312602016344886, "Hub License": "llama3.1", "Hub \u2764\ufe0f": 6, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5483240025354947, "IFEval": 54.83240025354947, "BBH Raw": 0.4609817052543379, "BBH": 24.07027321429611, "MATH Lvl 5 Raw": 0.0581570996978852, "MATH Lvl 5": 5.81570996978852, "GPQA Raw": 0.2885906040268456, "GPQA": 5.145413870246088, "MUSR Raw": 0.3433020833333333, "MUSR": 4.379427083333335, "MMLU-PRO Raw": 0.2406914893617021, "MMLU-PRO": 15.632387706855791, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-23T00:00:00", "Submission Date": "2024-07-25T00:00:00", "Generation": 2, "Base Model": "meta-llama/Meta-Llama-3.1-8B"}, {"eval_name": "ValiantLabs_Llama3.1-8B-Fireplace2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/ValiantLabs/Llama3.1-8B-Fireplace2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">ValiantLabs/Llama3.1-8B-Fireplace2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/ValiantLabs__Llama3.1-8B-Fireplace2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "ValiantLabs/Llama3.1-8B-Fireplace2", "Model sha": "ef129903bbdcc59efdbe10fe9061bff473334a99", "Average \u2b06\ufe0f": 18.05446781892771, "Hub License": "llama3.1", "Hub \u2764\ufe0f": 6, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5328118281714739, "IFEval": 53.28118281714739, "BBH Raw": 0.4613311485871581, "BBH": 24.08995379001348, "MATH Lvl 5 Raw": 0.0566465256797583, "MATH Lvl 5": 5.664652567975831, "GPQA Raw": 0.2894295302013422, "GPQA": 5.257270693512303, "MUSR Raw": 0.3366666666666666, "MUSR": 4.216666666666668, "MMLU-PRO Raw": 0.2423537234042553, "MMLU-PRO": 15.817080378250589, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-23T00:00:00", "Submission Date": "2024-08-10T00:00:00", "Generation": 2, "Base Model": "meta-llama/Meta-Llama-3.1-8B"}, {"eval_name": "ValiantLabs_Llama3.1-8B-ShiningValiant2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/ValiantLabs/Llama3.1-8B-ShiningValiant2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">ValiantLabs/Llama3.1-8B-ShiningValiant2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/ValiantLabs__Llama3.1-8B-ShiningValiant2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "ValiantLabs/Llama3.1-8B-ShiningValiant2", "Model sha": "6b2b5694a192cb29ad0e4314138affa25b630c0e", "Average \u2b06\ufe0f": 24.290562986971576, "Hub License": "llama3.1", "Hub \u2764\ufe0f": 14, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6523878863637371, "IFEval": 65.23878863637371, "BBH Raw": 0.4771531572092645, "BBH": 26.35171605254804, "MATH Lvl 5 Raw": 0.1163141993957704, "MATH Lvl 5": 11.63141993957704, "GPQA Raw": 0.3171140939597315, "GPQA": 8.948545861297541, "MUSR Raw": 0.3908645833333333, "MUSR": 7.191406250000001, "MMLU-PRO Raw": 0.3374335106382978, "MMLU-PRO": 26.38150118203309, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-06T00:00:00", "Submission Date": "2024-08-10T00:00:00", "Generation": 2, "Base Model": "meta-llama/Meta-Llama-3.1-8B"}, {"eval_name": "ValiantLabs_Llama3.1-8B-ShiningValiant2_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/ValiantLabs/Llama3.1-8B-ShiningValiant2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">ValiantLabs/Llama3.1-8B-ShiningValiant2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/ValiantLabs__Llama3.1-8B-ShiningValiant2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "ValiantLabs/Llama3.1-8B-ShiningValiant2", "Model sha": "6b2b5694a192cb29ad0e4314138affa25b630c0e", "Average \u2b06\ufe0f": 16.571278862113747, "Hub License": "llama3.1", "Hub \u2764\ufe0f": 14, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2540669867063835, "IFEval": 25.406698670638352, "BBH Raw": 0.4437299048210102, "BBH": 22.518920723058404, "MATH Lvl 5 Raw": 0.0823262839879154, "MATH Lvl 5": 8.23262839879154, "GPQA Raw": 0.2927852348993288, "GPQA": 5.7046979865771785, "MUSR Raw": 0.4208125, "MUSR": 13.334895833333327, "MMLU-PRO Raw": 0.3180684840425531, "MMLU-PRO": 24.229831560283685, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-06T00:00:00", "Submission Date": "2024-10-02T00:00:00", "Generation": 2, "Base Model": "meta-llama/Meta-Llama-3.1-8B"}, {"eval_name": "ValiantLabs_Llama3.2-3B-Enigma_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/ValiantLabs/Llama3.2-3B-Enigma\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">ValiantLabs/Llama3.2-3B-Enigma</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/ValiantLabs__Llama3.2-3B-Enigma-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "ValiantLabs/Llama3.2-3B-Enigma", "Model sha": "ca6adf3a289ce47c7598139e7a312e2b4b3708ce", "Average \u2b06\ufe0f": 11.529085075074944, "Hub License": "llama3.2", "Hub \u2764\ufe0f": 6, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2786218345102107, "IFEval": 27.86218345102107, "BBH Raw": 0.3722590772046992, "BBH": 12.434025970150064, "MATH Lvl 5 Raw": 0.0339879154078549, "MATH Lvl 5": 3.3987915407854987, "GPQA Raw": 0.261744966442953, "GPQA": 1.5659955257270708, "MUSR Raw": 0.3921354166666667, "MUSR": 8.050260416666669, "MMLU-PRO Raw": 0.2427692819148936, "MMLU-PRO": 15.86325354609929, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-30T00:00:00", "Submission Date": "2024-10-02T00:00:00", "Generation": 1, "Base Model": "meta-llama/Llama-3.2-3B-Instruct"}, {"eval_name": "ValiantLabs_Llama3.2-3B-Esper2_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/ValiantLabs/Llama3.2-3B-Esper2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">ValiantLabs/Llama3.2-3B-Esper2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/ValiantLabs__Llama3.2-3B-Esper2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "ValiantLabs/Llama3.2-3B-Esper2", "Model sha": "64a2c619a2e1680ab42945fcf5b75a5242cab3a1", "Average \u2b06\ufe0f": 10.705120907097792, "Hub License": "llama3.2", "Hub \u2764\ufe0f": 3, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2749748445236417, "IFEval": 27.49748445236417, "BBH Raw": 0.380826113903661, "BBH": 13.851732907913409, "MATH Lvl 5 Raw": 0.0219033232628398, "MATH Lvl 5": 2.190332326283988, "GPQA Raw": 0.2701342281879195, "GPQA": 2.684563758389265, "MUSR Raw": 0.3549583333333333, "MUSR": 4.036458333333333, "MMLU-PRO Raw": 0.2257313829787234, "MMLU-PRO": 13.9701536643026, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-03T00:00:00", "Submission Date": "2024-10-09T00:00:00", "Generation": 1, "Base Model": "meta-llama/Llama-3.2-3B-Instruct"}, {"eval_name": "ValiantLabs_Llama3.2-3B-ShiningValiant2_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/ValiantLabs/Llama3.2-3B-ShiningValiant2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">ValiantLabs/Llama3.2-3B-ShiningValiant2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/ValiantLabs__Llama3.2-3B-ShiningValiant2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "ValiantLabs/Llama3.2-3B-ShiningValiant2", "Model sha": "1336e200485675c9b92baae17831eab17c601803", "Average \u2b06\ufe0f": 12.633115306691383, "Hub License": "llama3.2", "Hub \u2764\ufe0f": 1, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2130258824363799, "IFEval": 21.30258824363799, "BBH Raw": 0.3893266519279294, "BBH": 14.329006110061371, "MATH Lvl 5 Raw": 0.0521148036253776, "MATH Lvl 5": 5.211480362537765, "GPQA Raw": 0.2835570469798658, "GPQA": 4.4742729306487705, "MUSR Raw": 0.43728125, "MUSR": 13.426822916666667, "MMLU-PRO Raw": 0.2534906914893617, "MMLU-PRO": 17.054521276595743, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-27T00:00:00", "Submission Date": "2024-10-02T00:00:00", "Generation": 1, "Base Model": "meta-llama/Llama-3.2-3B-Instruct"}, {"eval_name": "Vikhrmodels_Vikhr-Llama3.1-8B-Instruct-R-21-09-24_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Vikhrmodels/Vikhr-Llama3.1-8B-Instruct-R-21-09-24\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Vikhrmodels/Vikhr-Llama3.1-8B-Instruct-R-21-09-24</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Vikhrmodels__Vikhr-Llama3.1-8B-Instruct-R-21-09-24-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Vikhrmodels/Vikhr-Llama3.1-8B-Instruct-R-21-09-24", "Model sha": "c0b57cf6d4444b35fc5cec0525ff5eef32af22c9", "Average \u2b06\ufe0f": 24.52413565199282, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 22, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.643145742186288, "IFEval": 64.31457421862879, "BBH Raw": 0.527224269970207, "BBH": 32.66941729424733, "MATH Lvl 5 Raw": 0.1676737160120845, "MATH Lvl 5": 16.76737160120846, "GPQA Raw": 0.2449664429530201, "GPQA": 0.0, "MUSR Raw": 0.3753958333333334, "MUSR": 5.0911458333333375, "MMLU-PRO Raw": 0.3547207446808511, "MMLU-PRO": 28.302304964539005, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-20T00:00:00", "Submission Date": "2024-09-21T00:00:00", "Generation": 1, "Base Model": "Vikhrmodels/Vikhr-Llama3.1-8B-Instruct-R-21-09-24 (Merge)"}, {"eval_name": "Vikhrmodels_Vikhr-Nemo-12B-Instruct-R-21-09-24_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Vikhrmodels/Vikhr-Nemo-12B-Instruct-R-21-09-24\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Vikhrmodels/Vikhr-Nemo-12B-Instruct-R-21-09-24</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Vikhrmodels__Vikhr-Nemo-12B-Instruct-R-21-09-24-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Vikhrmodels/Vikhr-Nemo-12B-Instruct-R-21-09-24", "Model sha": "6abd887cb631f705042c9e8085615fe4d76e9779", "Average \u2b06\ufe0f": 24.26466711357344, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 63, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5999315150467426, "IFEval": 59.993151504674266, "BBH Raw": 0.5212309052827618, "BBH": 31.41440911337631, "MATH Lvl 5 Raw": 0.1261329305135951, "MATH Lvl 5": 12.613293051359516, "GPQA Raw": 0.2911073825503356, "GPQA": 5.480984340044745, "MUSR Raw": 0.4073020833333333, "MUSR": 9.44609375, "MMLU-PRO Raw": 0.3397606382978723, "MMLU-PRO": 26.640070921985814, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-20T00:00:00", "Submission Date": "2024-09-21T00:00:00", "Generation": 1, "Base Model": "Vikhrmodels/Vikhr-Nemo-12B-Instruct-R-21-09-24 (Merge)"}, {"eval_name": "Weyaxi_Bagel-Hermes-34B-Slerp_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Weyaxi/Bagel-Hermes-34B-Slerp\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Weyaxi/Bagel-Hermes-34B-Slerp</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Weyaxi__Bagel-Hermes-34B-Slerp-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Weyaxi/Bagel-Hermes-34B-Slerp", "Model sha": "dcdcc17a2c650a95bc27129a3ddbf261dffed37f", "Average \u2b06\ufe0f": 27.05803587633669, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 34, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4602720780861448, "IFEval": 46.02720780861448, "BBH Raw": 0.5921903605860047, "BBH": 41.957047480557854, "MATH Lvl 5 Raw": 0.0490936555891238, "MATH Lvl 5": 4.909365558912387, "GPQA Raw": 0.3347315436241611, "GPQA": 11.297539149888143, "MUSR Raw": 0.4622083333333333, "MUSR": 17.009375000000002, "MMLU-PRO Raw": 0.4703291223404255, "MMLU-PRO": 41.14768026004728, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-01-12T00:00:00", "Submission Date": "2024-08-30T00:00:00", "Generation": 0, "Base Model": "Weyaxi/Bagel-Hermes-34B-Slerp"}, {"eval_name": "Weyaxi_Einstein-v4-7B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Weyaxi/Einstein-v4-7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Weyaxi/Einstein-v4-7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Weyaxi__Einstein-v4-7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Weyaxi/Einstein-v4-7B", "Model sha": "7eecd9833b8a012e23ac1df789884888b047baa0", "Average \u2b06\ufe0f": 16.730487821154178, "Hub License": "other", "Hub \u2764\ufe0f": 47, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4708129983998014, "IFEval": 47.08129983998015, "BBH Raw": 0.3849469969274177, "BBH": 14.30445141720726, "MATH Lvl 5 Raw": 0.0173716012084592, "MATH Lvl 5": 1.7371601208459215, "GPQA Raw": 0.2818791946308724, "GPQA": 4.250559284116329, "MUSR Raw": 0.4681666666666667, "MUSR": 19.02083333333333, "MMLU-PRO Raw": 0.2258976063829787, "MMLU-PRO": 13.98862293144208, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-02-22T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "mistralai/Mistral-7B-v0.1"}, {"eval_name": "Weyaxi_Einstein-v6.1-Llama3-8B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Weyaxi/Einstein-v6.1-Llama3-8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Weyaxi/Einstein-v6.1-Llama3-8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Weyaxi__Einstein-v6.1-Llama3-8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Weyaxi/Einstein-v6.1-Llama3-8B", "Model sha": "5cab6d54666b6024d0f745d61abf1842edb934e0", "Average \u2b06\ufe0f": 19.993257731011948, "Hub License": "other", "Hub \u2764\ufe0f": 65, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4568245588372186, "IFEval": 45.68245588372186, "BBH Raw": 0.5008295581095018, "BBH": 29.38377348658535, "MATH Lvl 5 Raw": 0.0574018126888217, "MATH Lvl 5": 5.740181268882175, "GPQA Raw": 0.2818791946308724, "GPQA": 4.250559284116329, "MUSR Raw": 0.42128125, "MUSR": 11.22682291666667, "MMLU-PRO Raw": 0.3130817819148936, "MMLU-PRO": 23.675753546099287, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-19T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "meta-llama/Meta-Llama-3-8B"}, {"eval_name": "Weyaxi_Einstein-v6.1-developed-by-Weyaxi-Llama3-8B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Weyaxi/Einstein-v6.1-developed-by-Weyaxi-Llama3-8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Weyaxi/Einstein-v6.1-developed-by-Weyaxi-Llama3-8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Weyaxi__Einstein-v6.1-developed-by-Weyaxi-Llama3-8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Weyaxi/Einstein-v6.1-developed-by-Weyaxi-Llama3-8B", "Model sha": "b7507e94146c0832c26609e9ab8115934d3e25b3", "Average \u2b06\ufe0f": 19.054392253129127, "Hub License": "other", "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.392702473880415, "IFEval": 39.27024738804151, "BBH Raw": 0.5043837450549643, "BBH": 29.69444747698505, "MATH Lvl 5 Raw": 0.0558912386706948, "MATH Lvl 5": 5.589123867069486, "GPQA Raw": 0.273489932885906, "GPQA": 3.1319910514541416, "MUSR Raw": 0.4332499999999999, "MUSR": 13.389583333333327, "MMLU-PRO Raw": 0.3092586436170212, "MMLU-PRO": 23.25096040189125, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-23T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "Weyaxi/Einstein-v6.1-developed-by-Weyaxi-Llama3-8B"}, {"eval_name": "Weyaxi_Einstein-v7-Qwen2-7B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Weyaxi/Einstein-v7-Qwen2-7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Weyaxi/Einstein-v7-Qwen2-7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Weyaxi__Einstein-v7-Qwen2-7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Weyaxi/Einstein-v7-Qwen2-7B", "Model sha": "d5a2f245bf98a40d196821bc378e10f35b4da81a", "Average \u2b06\ufe0f": 24.01336669057879, "Hub License": "other", "Hub \u2764\ufe0f": 33, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4099633417111043, "IFEval": 40.99633417111043, "BBH Raw": 0.5161472249498397, "BBH": 32.84181889691276, "MATH Lvl 5 Raw": 0.1518126888217522, "MATH Lvl 5": 15.181268882175228, "GPQA Raw": 0.299496644295302, "GPQA": 6.599552572706939, "MUSR Raw": 0.4399791666666666, "MUSR": 14.0640625, "MMLU-PRO Raw": 0.4095744680851064, "MMLU-PRO": 34.39716312056737, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-24T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "Qwen/Qwen2-7B"}, {"eval_name": "Weyaxi_Einstein-v8-Llama3.2-1B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Weyaxi/Einstein-v8-Llama3.2-1B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Weyaxi/Einstein-v8-Llama3.2-1B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Weyaxi__Einstein-v8-Llama3.2-1B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Weyaxi/Einstein-v8-Llama3.2-1B", "Model sha": "1edc6abcb8eedd047bc40b79d2d36c3723ff28e2", "Average \u2b06\ufe0f": 4.6278210436436655, "Hub License": "llama3.2", "Hub \u2764\ufe0f": 1, "#Params (B)": 1, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.1862225561510126, "IFEval": 18.622255615101263, "BBH Raw": 0.3018433482394315, "BBH": 3.013774178282933, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2583892617449664, "GPQA": 1.1185682326621946, "MUSR Raw": 0.36178125, "MUSR": 3.22265625, "MMLU-PRO Raw": 0.1161070478723404, "MMLU-PRO": 1.7896719858156025, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-28T00:00:00", "Submission Date": "2024-09-30T00:00:00", "Generation": 1, "Base Model": "meta-llama/Llama-3.2-1B"}, {"eval_name": "Weyaxi_SauerkrautLM-UNA-SOLAR-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Weyaxi/SauerkrautLM-UNA-SOLAR-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Weyaxi/SauerkrautLM-UNA-SOLAR-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Weyaxi__SauerkrautLM-UNA-SOLAR-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Weyaxi/SauerkrautLM-UNA-SOLAR-Instruct", "Model sha": "9678b9ca952abe0083dbfc772a56b849866bfa1a", "Average \u2b06\ufe0f": 19.70813326438918, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 26, "#Params (B)": 10, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4573243438520902, "IFEval": 45.73243438520902, "BBH Raw": 0.5166357112030591, "BBH": 31.82468678354313, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.311241610738255, "GPQA": 8.165548098434002, "MUSR Raw": 0.397875, "MUSR": 8.601041666666662, "MMLU-PRO Raw": 0.3153257978723404, "MMLU-PRO": 23.92508865248227, "Maintainer's Highlight": false, "Upload To Hub Date": "2023-12-21T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "Weyaxi/SauerkrautLM-UNA-SOLAR-Instruct"}, {"eval_name": "WizardLMTeam_WizardLM-13B-V1.0_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/WizardLMTeam/WizardLM-13B-V1.0\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">WizardLMTeam/WizardLM-13B-V1.0</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/WizardLMTeam__WizardLM-13B-V1.0-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "WizardLMTeam/WizardLM-13B-V1.0", "Model sha": "964a93aa2e78da377115bb856075a69ebe8aefa4", "Average \u2b06\ufe0f": 4.546091523510591, "Hub License": null, "Hub \u2764\ufe0f": 72, "#Params (B)": 13, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1850490033112142, "IFEval": 18.504900331121423, "BBH Raw": 0.2913444769655102, "BBH": 2.147966883446335, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.259228187919463, "GPQA": 1.230425055928408, "MUSR Raw": 0.34971875, "MUSR": 3.5481770833333326, "MMLU-PRO Raw": 0.1166057180851063, "MMLU-PRO": 1.8450797872340408, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-05-13T00:00:00", "Submission Date": "2024-06-13T00:00:00", "Generation": 0, "Base Model": "WizardLMTeam/WizardLM-13B-V1.0"}, {"eval_name": "WizardLMTeam_WizardLM-13B-V1.2_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/WizardLMTeam/WizardLM-13B-V1.2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">WizardLMTeam/WizardLM-13B-V1.2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/WizardLMTeam__WizardLM-13B-V1.2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "WizardLMTeam/WizardLM-13B-V1.2", "Model sha": "cf5f40382559f19e13874e45b39575171ca46ef8", "Average \u2b06\ufe0f": 15.152356507248276, "Hub License": "llama2", "Hub \u2764\ufe0f": 225, "#Params (B)": 13, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3392465325336773, "IFEval": 33.92465325336773, "BBH Raw": 0.4461999436460047, "BBH": 22.88865497804447, "MATH Lvl 5 Raw": 0.0173716012084592, "MATH Lvl 5": 1.7371601208459215, "GPQA Raw": 0.2609060402684564, "GPQA": 1.45413870246085, "MUSR Raw": 0.43784375, "MUSR": 14.030468750000002, "MMLU-PRO Raw": 0.2519115691489361, "MMLU-PRO": 16.87906323877068, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-07-25T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "WizardLMTeam/WizardLM-13B-V1.2"}, {"eval_name": "WizardLMTeam_WizardLM-70B-V1.0_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/WizardLMTeam/WizardLM-70B-V1.0\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">WizardLMTeam/WizardLM-70B-V1.0</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/WizardLMTeam__WizardLM-70B-V1.0-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "WizardLMTeam/WizardLM-70B-V1.0", "Model sha": "54aaecaff7d0790eb9f0ecea1cc267a94cc66949", "Average \u2b06\ufe0f": 22.321913398423053, "Hub License": "llama2", "Hub \u2764\ufe0f": 234, "#Params (B)": 70, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4951428875383981, "IFEval": 49.51428875383981, "BBH Raw": 0.5590366047184262, "BBH": 37.54335453368136, "MATH Lvl 5 Raw": 0.0347432024169184, "MATH Lvl 5": 3.474320241691843, "GPQA Raw": 0.2659395973154362, "GPQA": 2.1252796420581683, "MUSR Raw": 0.4391145833333333, "MUSR": 14.089322916666667, "MMLU-PRO Raw": 0.3446642287234042, "MMLU-PRO": 27.184914302600472, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-08-09T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "WizardLMTeam/WizardLM-70B-V1.0"}, {"eval_name": "Xclbr7_Arcanum-12b_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Xclbr7/Arcanum-12b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Xclbr7/Arcanum-12b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Xclbr7__Arcanum-12b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Xclbr7/Arcanum-12b", "Model sha": "845ac67d2b527296ae8c06da4453bf8a60f2e59b", "Average \u2b06\ufe0f": 20.48028733253652, "Hub License": "mit", "Hub \u2764\ufe0f": 0, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2906864896253053, "IFEval": 29.068648962530528, "BBH Raw": 0.5265359354118465, "BBH": 31.879959562746524, "MATH Lvl 5 Raw": 0.1027190332326284, "MATH Lvl 5": 10.27190332326284, "GPQA Raw": 0.3204697986577181, "GPQA": 9.395973154362418, "MUSR Raw": 0.4170312499999999, "MUSR": 13.528906249999997, "MMLU-PRO Raw": 0.3586269946808511, "MMLU-PRO": 28.736332742316783, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-17T00:00:00", "Submission Date": "2024-09-17T00:00:00", "Generation": 0, "Base Model": "Xclbr7/Arcanum-12b"}, {"eval_name": "Xclbr7_Hyena-12b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Xclbr7/Hyena-12b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Xclbr7/Hyena-12b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Xclbr7__Hyena-12b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Xclbr7/Hyena-12b", "Model sha": "9dd5eb77ce8e0e05e260ae4d812631fb980527fa", "Average \u2b06\ufe0f": 20.29877379669332, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3404455733010634, "IFEval": 34.04455733010634, "BBH Raw": 0.5457182415468321, "BBH": 34.665648637656034, "MATH Lvl 5 Raw": 0.0853474320241691, "MATH Lvl 5": 8.534743202416918, "GPQA Raw": 0.2978187919463087, "GPQA": 6.375838926174497, "MUSR Raw": 0.3984270833333332, "MUSR": 11.070052083333328, "MMLU-PRO Raw": 0.3439162234042553, "MMLU-PRO": 27.10180260047281, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-19T00:00:00", "Submission Date": "2024-09-19T00:00:00", "Generation": 1, "Base Model": "Xclbr7/Arcanum-12b"}, {"eval_name": "Xclbr7_caliburn-12b_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Xclbr7/caliburn-12b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Xclbr7/caliburn-12b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Xclbr7__caliburn-12b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Xclbr7/caliburn-12b", "Model sha": "f76fa67c7ca8bf7e75540baf55972ba52a46630b", "Average \u2b06\ufe0f": 22.682514166597286, "Hub License": "mit", "Hub \u2764\ufe0f": 0, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3576310855197542, "IFEval": 35.76310855197542, "BBH Raw": 0.5518630300231809, "BBH": 35.63684056756332, "MATH Lvl 5 Raw": 0.0966767371601208, "MATH Lvl 5": 9.667673716012084, "GPQA Raw": 0.3364093959731543, "GPQA": 11.521252796420578, "MUSR Raw": 0.4291875, "MUSR": 13.781770833333333, "MMLU-PRO Raw": 0.3675199468085106, "MMLU-PRO": 29.724438534278963, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-14T00:00:00", "Submission Date": "2024-09-14T00:00:00", "Generation": 0, "Base Model": "Xclbr7/caliburn-12b"}, {"eval_name": "Xclbr7_caliburn-v2-12b_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Xclbr7/caliburn-v2-12b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Xclbr7/caliburn-v2-12b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Xclbr7__caliburn-v2-12b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Xclbr7/caliburn-v2-12b", "Model sha": "fa736b3b852298dd8c047ac6dcc620161df4a79b", "Average \u2b06\ufe0f": 20.75211508372261, "Hub License": "mit", "Hub \u2764\ufe0f": 0, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2966816934622358, "IFEval": 29.66816934622357, "BBH Raw": 0.5141426125097639, "BBH": 30.387966946397217, "MATH Lvl 5 Raw": 0.0921450151057401, "MATH Lvl 5": 9.214501510574015, "GPQA Raw": 0.3263422818791946, "GPQA": 10.17897091722595, "MUSR Raw": 0.43703125, "MUSR": 14.12890625, "MMLU-PRO Raw": 0.378407579787234, "MMLU-PRO": 30.9341755319149, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-16T00:00:00", "Submission Date": "2024-09-16T00:00:00", "Generation": 0, "Base Model": "Xclbr7/caliburn-v2-12b"}, {"eval_name": "Yash21_TinyYi-7B-Test_float16", "Precision": "float16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Yash21/TinyYi-7B-Test\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Yash21/TinyYi-7B-Test</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Yash21__TinyYi-7B-Test-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Yash21/TinyYi-7B-Test", "Model sha": "7750e5de73fbcf1dcc0832b4cdabaa9713c20475", "Average \u2b06\ufe0f": 4.495167294967694, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 6, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1856485236949072, "IFEval": 18.56485236949073, "BBH Raw": 0.2909800780121471, "BBH": 2.267966388832264, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2642617449664429, "GPQA": 1.9015659955257265, "MUSR Raw": 0.3364479166666667, "MUSR": 3.22265625, "MMLU-PRO Raw": 0.109125664893617, "MMLU-PRO": 1.0139627659574466, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-01-06T00:00:00", "Submission Date": "2024-07-03T00:00:00", "Generation": 0, "Base Model": "Yash21/TinyYi-7B-Test"}, {"eval_name": "Youlln_1PARAMMYL-8B-ModelStock_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Youlln/1PARAMMYL-8B-ModelStock\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Youlln/1PARAMMYL-8B-ModelStock</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Youlln__1PARAMMYL-8B-ModelStock-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Youlln/1PARAMMYL-8B-ModelStock", "Model sha": "4ce556da5ccd1ecac8d0f3e1e94d1982f11b910d", "Average \u2b06\ufe0f": 26.01962490675772, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.5371336941537344, "IFEval": 53.71336941537343, "BBH Raw": 0.5215839663555125, "BBH": 31.799951193327704, "MATH Lvl 5 Raw": 0.1314199395770392, "MATH Lvl 5": 13.141993957703926, "GPQA Raw": 0.3238255033557047, "GPQA": 9.843400447427292, "MUSR Raw": 0.4409375, "MUSR": 14.283854166666664, "MMLU-PRO Raw": 0.4000166223404255, "MMLU-PRO": 33.335180260047274, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-20T00:00:00", "Submission Date": "2024-09-20T00:00:00", "Generation": 1, "Base Model": "Youlln/1PARAMMYL-8B-ModelStock (Merge)"}, {"eval_name": "Youlln_2PRYMMAL-Yi1.5-6B-SLERP_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Youlln/2PRYMMAL-Yi1.5-6B-SLERP\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Youlln/2PRYMMAL-Yi1.5-6B-SLERP</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Youlln__2PRYMMAL-Yi1.5-6B-SLERP-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Youlln/2PRYMMAL-Yi1.5-6B-SLERP", "Model sha": "b776bd3ce6784b96ff928b1d5ad51b2991909f2c", "Average \u2b06\ufe0f": 18.75263703863944, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 6, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2825935185308315, "IFEval": 28.259351853083157, "BBH Raw": 0.4664750429171067, "BBH": 24.495644420709063, "MATH Lvl 5 Raw": 0.0989425981873111, "MATH Lvl 5": 9.894259818731117, "GPQA Raw": 0.3070469798657718, "GPQA": 7.606263982102905, "MUSR Raw": 0.4756041666666666, "MUSR": 18.15052083333333, "MMLU-PRO Raw": 0.3169880319148936, "MMLU-PRO": 24.109781323877066, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-22T00:00:00", "Submission Date": "2024-09-23T00:00:00", "Generation": 1, "Base Model": "Youlln/2PRYMMAL-Yi1.5-6B-SLERP (Merge)"}, {"eval_name": "Youlln_3PRYMMAL-PHI3-3B-SLERP_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "Phi3ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Youlln/3PRYMMAL-PHI3-3B-SLERP\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Youlln/3PRYMMAL-PHI3-3B-SLERP</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Youlln__3PRYMMAL-PHI3-3B-SLERP-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Youlln/3PRYMMAL-PHI3-3B-SLERP", "Model sha": "9396bcf1709ac8360a95a746482520fab4295706", "Average \u2b06\ufe0f": 24.584863854798257, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3655500738041729, "IFEval": 36.555007380417294, "BBH Raw": 0.5421833887682153, "BBH": 35.82766762143187, "MATH Lvl 5 Raw": 0.1382175226586102, "MATH Lvl 5": 13.821752265861026, "GPQA Raw": 0.3263422818791946, "GPQA": 10.17897091722595, "MUSR Raw": 0.46484375, "MUSR": 17.77213541666666, "MMLU-PRO Raw": 0.4001828457446808, "MMLU-PRO": 33.353649527186754, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-23T00:00:00", "Submission Date": "2024-09-23T00:00:00", "Generation": 1, "Base Model": "Youlln/3PRYMMAL-PHI3-3B-SLERP (Merge)"}, {"eval_name": "Youlln_4PRYMMAL-GEMMA2-9B-SLERP_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Youlln/4PRYMMAL-GEMMA2-9B-SLERP\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Youlln/4PRYMMAL-GEMMA2-9B-SLERP</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Youlln__4PRYMMAL-GEMMA2-9B-SLERP-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Youlln/4PRYMMAL-GEMMA2-9B-SLERP", "Model sha": "7dac3b4ab4298113ae3103d63bb284e1ac8bf4d4", "Average \u2b06\ufe0f": 23.41176920157801, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 9, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2713766140507188, "IFEval": 27.13766140507188, "BBH Raw": 0.5922529923998928, "BBH": 42.06417191239567, "MATH Lvl 5 Raw": 0.0740181268882175, "MATH Lvl 5": 7.401812688821751, "GPQA Raw": 0.3305369127516778, "GPQA": 10.738255033557047, "MUSR Raw": 0.4671979166666666, "MUSR": 17.46640625, "MMLU-PRO Raw": 0.4209607712765957, "MMLU-PRO": 35.662307919621746, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-23T00:00:00", "Submission Date": "2024-09-23T00:00:00", "Generation": 1, "Base Model": "Youlln/4PRYMMAL-GEMMA2-9B-SLERP (Merge)"}, {"eval_name": "Youlln_ECE-PRYMMAL0.5-FT_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Youlln/ECE-PRYMMAL0.5-FT\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Youlln/ECE-PRYMMAL0.5-FT</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Youlln__ECE-PRYMMAL0.5-FT-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Youlln/ECE-PRYMMAL0.5-FT", "Model sha": "56b9fd5f26e5b6379fe4aa62e0f66b87b5c6f8e8", "Average \u2b06\ufe0f": 5.195510054664371, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1850733830680372, "IFEval": 18.507338306803724, "BBH Raw": 0.3132091118703627, "BBH": 5.151599849335524, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2558724832214765, "GPQA": 0.7829977628635317, "MUSR Raw": 0.330125, "MUSR": 1.432291666666666, "MMLU-PRO Raw": 0.147689494680851, "MMLU-PRO": 5.298832742316785, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-02T00:00:00", "Submission Date": "2024-10-02T00:00:00", "Generation": 1, "Base Model": "Youlln/ECE-PRYMMAL0.5-FT (Merge)"}, {"eval_name": "Youlln_ECE-PRYMMAL0.5B-Youri_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Youlln/ECE-PRYMMAL0.5B-Youri\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Youlln/ECE-PRYMMAL0.5B-Youri</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Youlln__ECE-PRYMMAL0.5B-Youri-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Youlln/ECE-PRYMMAL0.5B-Youri", "Model sha": "1477d3deff98f35f523aa222bc0442278d464566", "Average \u2b06\ufe0f": 3.505273892929676, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 0, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1446317991817267, "IFEval": 14.46317991817267, "BBH Raw": 0.2817357425626581, "BBH": 1.5012962555992375, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2432885906040268, "GPQA": 0.0, "MUSR Raw": 0.36965625, "MUSR": 4.007031250000002, "MMLU-PRO Raw": 0.1095412234042553, "MMLU-PRO": 1.0601359338061456, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-07T00:00:00", "Submission Date": "2024-10-07T00:00:00", "Generation": 1, "Base Model": "Youlln/ECE-PRYMMAL0.5B-Youri (Merge)"}, {"eval_name": "Youlln_ECE-PRYMMAL1B-FT-V1_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Youlln/ECE-PRYMMAL1B-FT-V1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Youlln/ECE-PRYMMAL1B-FT-V1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Youlln__ECE-PRYMMAL1B-FT-V1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Youlln/ECE-PRYMMAL1B-FT-V1", "Model sha": "d0fc3a6e93f91c8d586eb25c9f2a4ea4ca99e9f4", "Average \u2b06\ufe0f": 11.797445498917554, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 1, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2143745262569981, "IFEval": 21.43745262569981, "BBH Raw": 0.4032647427840684, "BBH": 16.18938601764277, "MATH Lvl 5 Raw": 0.0611782477341389, "MATH Lvl 5": 6.117824773413897, "GPQA Raw": 0.2785234899328859, "GPQA": 3.803131991051453, "MUSR Raw": 0.34165625, "MUSR": 3.873697916666666, "MMLU-PRO Raw": 0.2742686170212766, "MMLU-PRO": 19.36317966903073, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-12T00:00:00", "Submission Date": "2024-10-12T00:00:00", "Generation": 1, "Base Model": "Youlln/ECE-PRYMMAL1B-FT-V1 (Merge)"}, {"eval_name": "Youlln_ECE-Qwen0.5B-FT-V2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Youlln/ECE-Qwen0.5B-FT-V2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Youlln/ECE-Qwen0.5B-FT-V2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Youlln__ECE-Qwen0.5B-FT-V2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Youlln/ECE-Qwen0.5B-FT-V2", "Model sha": "c87da3f19ab74854fca30f9ca71ce5c4884ef629", "Average \u2b06\ufe0f": 7.436217677059372, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2525931195893562, "IFEval": 25.259311958935623, "BBH Raw": 0.328970813623839, "BBH": 7.632147610946966, "MATH Lvl 5 Raw": 0.0120845921450151, "MATH Lvl 5": 1.2084592145015105, "GPQA Raw": 0.2667785234899328, "GPQA": 2.2371364653243813, "MUSR Raw": 0.30628125, "MUSR": 0.8851562499999998, "MMLU-PRO Raw": 0.1665558510638297, "MMLU-PRO": 7.395094562647753, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-11T00:00:00", "Submission Date": "2024-10-11T00:00:00", "Generation": 1, "Base Model": "Youlln/ECE-Qwen0.5B-FT-V2 (Merge)"}, {"eval_name": "YoungPanda_qwenqwen_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2MoeForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/YoungPanda/qwenqwen\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">YoungPanda/qwenqwen</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/YoungPanda__qwenqwen-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "YoungPanda/qwenqwen", "Model sha": "3b5d9b63076acc8988b8f7e9734cf1d78bb39c25", "Average \u2b06\ufe0f": 4.405984681582859, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 14, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.1263968492488818, "IFEval": 12.639684924888185, "BBH Raw": 0.337898518087465, "BBH": 8.194779944827593, "MATH Lvl 5 Raw": 0.0128398791540785, "MATH Lvl 5": 1.283987915407855, "GPQA Raw": 0.25, "GPQA": 0.0, "MUSR Raw": 0.3433645833333333, "MUSR": 2.45390625, "MMLU-PRO Raw": 0.1167719414893617, "MMLU-PRO": 1.8635490543735225, "Maintainer's Highlight": false, "Upload To Hub Date": "", "Submission Date": "2024-09-12T00:00:00", "Generation": 0, "Base Model": "Removed"}, {"eval_name": "Yuma42_KangalKhan-RawRuby-7B_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/Yuma42/KangalKhan-RawRuby-7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">Yuma42/KangalKhan-RawRuby-7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/Yuma42__KangalKhan-RawRuby-7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "Yuma42/KangalKhan-RawRuby-7B", "Model sha": "54f56d4c6889eaf43fdd5f7d6dcef3c2ebe51929", "Average \u2b06\ufe0f": 20.377796494904203, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 7, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.547674614467391, "IFEval": 54.76746144673909, "BBH Raw": 0.4754727868367602, "BBH": 26.387283588738622, "MATH Lvl 5 Raw": 0.059667673716012, "MATH Lvl 5": 5.966767371601208, "GPQA Raw": 0.287751677852349, "GPQA": 5.033557046979867, "MUSR Raw": 0.3949583333333333, "MUSR": 7.636458333333337, "MMLU-PRO Raw": 0.3022772606382978, "MMLU-PRO": 22.47525118203309, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-02-17T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "Yuma42/KangalKhan-RawRuby-7B (Merge)"}, {"eval_name": "ZeusLabs_L3-Aethora-15B-V2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/ZeusLabs/L3-Aethora-15B-V2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">ZeusLabs/L3-Aethora-15B-V2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/ZeusLabs__L3-Aethora-15B-V2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "ZeusLabs/L3-Aethora-15B-V2", "Model sha": "2c601f116c37dd912c89357dbdbef879a637997e", "Average \u2b06\ufe0f": 24.572832475354407, "Hub License": "cc-by-sa-4.0", "Hub \u2764\ufe0f": 39, "#Params (B)": 15, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7208063493752133, "IFEval": 72.08063493752132, "BBH Raw": 0.5010910465463698, "BBH": 28.968504695312703, "MATH Lvl 5 Raw": 0.073262839879154, "MATH Lvl 5": 7.326283987915408, "GPQA Raw": 0.287751677852349, "GPQA": 5.033557046979867, "MUSR Raw": 0.3870833333333333, "MUSR": 6.252083333333335, "MMLU-PRO Raw": 0.3499833776595745, "MMLU-PRO": 27.77593085106383, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-27T00:00:00", "Submission Date": "2024-06-27T00:00:00", "Generation": 1, "Base Model": "ZeusLabs/L3-Aethora-15B-V2 (Merge)"}, {"eval_name": "ZhangShenao_SELM-Llama-3-8B-Instruct-iter-3_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/ZhangShenao/SELM-Llama-3-8B-Instruct-iter-3\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">ZhangShenao/SELM-Llama-3-8B-Instruct-iter-3</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/ZhangShenao__SELM-Llama-3-8B-Instruct-iter-3-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "ZhangShenao/SELM-Llama-3-8B-Instruct-iter-3", "Model sha": "9c95ccdeceed14a3c2881bc495101a1acca1385f", "Average \u2b06\ufe0f": 23.564589211130546, "Hub License": "mit", "Hub \u2764\ufe0f": 4, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6902817856620433, "IFEval": 69.02817856620433, "BBH Raw": 0.5046089390770511, "BBH": 29.07853088402274, "MATH Lvl 5 Raw": 0.0574018126888217, "MATH Lvl 5": 5.740181268882175, "GPQA Raw": 0.2583892617449664, "GPQA": 1.1185682326621946, "MUSR Raw": 0.3845104166666666, "MUSR": 5.497135416666667, "MMLU-PRO Raw": 0.3783244680851064, "MMLU-PRO": 30.92494089834515, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-25T00:00:00", "Submission Date": "2024-07-02T00:00:00", "Generation": 3, "Base Model": "meta-llama/Meta-Llama-3-8B-Instruct"}, {"eval_name": "aaditya_Llama3-OpenBioLLM-70B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/aaditya/Llama3-OpenBioLLM-70B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">aaditya/Llama3-OpenBioLLM-70B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/aaditya__Llama3-OpenBioLLM-70B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "aaditya/Llama3-OpenBioLLM-70B", "Model sha": "5f79deaf38bc5f662943d304d59cb30357e8e5bd", "Average \u2b06\ufe0f": 34.72725807565748, "Hub License": "llama3", "Hub \u2764\ufe0f": 336, "#Params (B)": 70, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7596743307756753, "IFEval": 75.96743307756752, "BBH Raw": 0.6398872375485518, "BBH": 47.14707467716792, "MATH Lvl 5 Raw": 0.18202416918429, "MATH Lvl 5": 18.202416918429005, "GPQA Raw": 0.322986577181208, "GPQA": 9.731543624161072, "MUSR Raw": 0.44171875, "MUSR": 14.348177083333336, "MMLU-PRO Raw": 0.4867021276595745, "MMLU-PRO": 42.96690307328605, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-24T00:00:00", "Submission Date": "2024-08-30T00:00:00", "Generation": 2, "Base Model": "meta-llama/Meta-Llama-3-70B"}, {"eval_name": "abacusai_Dracarys-72B-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/abacusai/Dracarys-72B-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">abacusai/Dracarys-72B-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/abacusai__Dracarys-72B-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "abacusai/Dracarys-72B-Instruct", "Model sha": "10cabc4beb57a69df51533f65e39a7ad22821370", "Average \u2b06\ufe0f": 42.370162790498696, "Hub License": "other", "Hub \u2764\ufe0f": 17, "#Params (B)": 72, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7855778224001206, "IFEval": 78.55778224001206, "BBH Raw": 0.6944066392084981, "BBH": 56.93552010003367, "MATH Lvl 5 Raw": 0.3361027190332326, "MATH Lvl 5": 33.610271903323266, "GPQA Raw": 0.3909395973154362, "GPQA": 18.791946308724835, "MUSR Raw": 0.4558229166666667, "MUSR": 16.81119791666666, "MMLU-PRO Raw": 0.5456283244680851, "MMLU-PRO": 49.51425827423168, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-08-14T00:00:00", "Submission Date": "2024-08-16T00:00:00", "Generation": 0, "Base Model": "abacusai/Dracarys-72B-Instruct"}, {"eval_name": "abacusai_Liberated-Qwen1.5-14B_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/abacusai/Liberated-Qwen1.5-14B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">abacusai/Liberated-Qwen1.5-14B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/abacusai__Liberated-Qwen1.5-14B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "abacusai/Liberated-Qwen1.5-14B", "Model sha": "cc0fa5102bfee821bb5e49f082731ccb9d1fedf1", "Average \u2b06\ufe0f": 19.70250276015258, "Hub License": "other", "Hub \u2764\ufe0f": 19, "#Params (B)": 14, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.36310212458499, "IFEval": 36.310212458499, "BBH Raw": 0.4948000917467186, "BBH": 28.020905999685464, "MATH Lvl 5 Raw": 0.1117824773413897, "MATH Lvl 5": 11.178247734138973, "GPQA Raw": 0.2835570469798658, "GPQA": 4.4742729306487705, "MUSR Raw": 0.41746875, "MUSR": 10.316927083333333, "MMLU-PRO Raw": 0.3512300531914893, "MMLU-PRO": 27.914450354609933, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-03-05T00:00:00", "Submission Date": "2024-09-05T00:00:00", "Generation": 0, "Base Model": "abacusai/Liberated-Qwen1.5-14B"}, {"eval_name": "abacusai_Llama-3-Smaug-8B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/abacusai/Llama-3-Smaug-8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">abacusai/Llama-3-Smaug-8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/abacusai__Llama-3-Smaug-8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "abacusai/Llama-3-Smaug-8B", "Model sha": "fe54a7d42160d3d8fcc3289c8c411fd9dd5e8357", "Average \u2b06\ufe0f": 18.8663525074461, "Hub License": "llama2", "Hub \u2764\ufe0f": 86, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4866753547254617, "IFEval": 48.66753547254618, "BBH Raw": 0.4930712769667174, "BBH": 27.880374189415942, "MATH Lvl 5 Raw": 0.073262839879154, "MATH Lvl 5": 7.326283987915408, "GPQA Raw": 0.2483221476510067, "GPQA": 0.0, "MUSR Raw": 0.3622499999999999, "MUSR": 5.047916666666663, "MMLU-PRO Raw": 0.3184840425531915, "MMLU-PRO": 24.27600472813239, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-04-19T00:00:00", "Submission Date": "2024-07-02T00:00:00", "Generation": 0, "Base Model": "abacusai/Llama-3-Smaug-8B"}, {"eval_name": "abacusai_Smaug-34B-v0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/abacusai/Smaug-34B-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">abacusai/Smaug-34B-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/abacusai__Smaug-34B-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "abacusai/Smaug-34B-v0.1", "Model sha": "34d54c65a0247d5eb694973106c816d9c0ad3fc2", "Average \u2b06\ufe0f": 23.75734698941308, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 60, "#Params (B)": 34, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5015625207782018, "IFEval": 50.15625207782018, "BBH Raw": 0.5357785983493821, "BBH": 34.261660667279955, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.3296979865771812, "GPQA": 10.626398210290828, "MUSR Raw": 0.397875, "MUSR": 8.134375000000004, "MMLU-PRO Raw": 0.4542885638297872, "MMLU-PRO": 39.36539598108747, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-01-25T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 1, "Base Model": "jondurbin/bagel-34b-v0.2"}, {"eval_name": "abacusai_Smaug-72B-v0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/abacusai/Smaug-72B-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">abacusai/Smaug-72B-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/abacusai__Smaug-72B-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "abacusai/Smaug-72B-v0.1", "Model sha": "a1d657156f82c24b670158406378648233487011", "Average \u2b06\ufe0f": 29.34706764050776, "Hub License": "other", "Hub \u2764\ufe0f": 465, "#Params (B)": 72, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.5167001334237601, "IFEval": 51.67001334237601, "BBH Raw": 0.5995632330786429, "BBH": 43.12510043134919, "MATH Lvl 5 Raw": 0.1676737160120845, "MATH Lvl 5": 16.76737160120846, "GPQA Raw": 0.3238255033557047, "GPQA": 9.843400447427292, "MUSR Raw": 0.4473229166666666, "MUSR": 14.415364583333334, "MMLU-PRO Raw": 0.4623503989361702, "MMLU-PRO": 40.26115543735224, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-02-02T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 1, "Base Model": "moreh/MoMo-72B-lora-1.8.7-DPO"}, {"eval_name": "abacusai_Smaug-Llama-3-70B-Instruct-32K_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/abacusai/Smaug-Llama-3-70B-Instruct-32K\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">abacusai/Smaug-Llama-3-70B-Instruct-32K</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/abacusai__Smaug-Llama-3-70B-Instruct-32K-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "abacusai/Smaug-Llama-3-70B-Instruct-32K", "Model sha": "33840982dc253968f32ef3a534ee0e025eb97482", "Average \u2b06\ufe0f": 34.72007790590135, "Hub License": "llama3", "Hub \u2764\ufe0f": 21, "#Params (B)": 70, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7761107195574409, "IFEval": 77.6110719557441, "BBH Raw": 0.6493108088828602, "BBH": 49.07037043446443, "MATH Lvl 5 Raw": 0.2122356495468278, "MATH Lvl 5": 21.22356495468278, "GPQA Raw": 0.2961409395973154, "GPQA": 6.152125279642054, "MUSR Raw": 0.4207916666666667, "MUSR": 12.432291666666664, "MMLU-PRO Raw": 0.4764793882978723, "MMLU-PRO": 41.83104314420804, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-06-11T00:00:00", "Submission Date": "2024-08-06T00:00:00", "Generation": 0, "Base Model": "abacusai/Smaug-Llama-3-70B-Instruct-32K"}, {"eval_name": "abacusai_Smaug-Mixtral-v0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/abacusai/Smaug-Mixtral-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">abacusai/Smaug-Mixtral-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/abacusai__Smaug-Mixtral-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "abacusai/Smaug-Mixtral-v0.1", "Model sha": "98fdc8315906b0a8b9e7f24bad89914869fcfc20", "Average \u2b06\ufe0f": 22.235368526294035, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 12, "#Params (B)": 46, "Available on the hub": true, "Not_Merged": true, "MoE": false, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5554428915278129, "IFEval": 55.54428915278129, "BBH Raw": 0.5162245602454115, "BBH": 31.919260543426763, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.3011744966442953, "GPQA": 6.823266219239373, "MUSR Raw": 0.4298125, "MUSR": 12.993229166666673, "MMLU-PRO Raw": 0.3351894946808511, "MMLU-PRO": 26.13216607565012, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-02-18T00:00:00", "Submission Date": "2024-08-30T00:00:00", "Generation": 0, "Base Model": "abacusai/Smaug-Mixtral-v0.1"}, {"eval_name": "abacusai_Smaug-Qwen2-72B-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/abacusai/Smaug-Qwen2-72B-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">abacusai/Smaug-Qwen2-72B-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/abacusai__Smaug-Qwen2-72B-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "abacusai/Smaug-Qwen2-72B-Instruct", "Model sha": "af015925946d0c60ef69f512c3b35f421cf8063d", "Average \u2b06\ufe0f": 41.07975891291516, "Hub License": "other", "Hub \u2764\ufe0f": 8, "#Params (B)": 72, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7825303527972447, "IFEval": 78.25303527972446, "BBH Raw": 0.6909789934583822, "BBH": 56.26617189727526, "MATH Lvl 5 Raw": 0.3534743202416918, "MATH Lvl 5": 35.34743202416919, "GPQA Raw": 0.3615771812080537, "GPQA": 14.87695749440716, "MUSR Raw": 0.4400729166666666, "MUSR": 15.175781249999998, "MMLU-PRO Raw": 0.519032579787234, "MMLU-PRO": 46.559175531914896, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-06-26T00:00:00", "Submission Date": "2024-07-29T00:00:00", "Generation": 0, "Base Model": "abacusai/Smaug-Qwen2-72B-Instruct"}, {"eval_name": "abacusai_bigstral-12b-32k_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/abacusai/bigstral-12b-32k\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">abacusai/bigstral-12b-32k</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/abacusai__bigstral-12b-32k-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "abacusai/bigstral-12b-32k", "Model sha": "b78a5385ec1b04d6c97f25e9ba1dff18dc98305f", "Average \u2b06\ufe0f": 18.04702468548196, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 43, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4193805768693732, "IFEval": 41.93805768693733, "BBH Raw": 0.4700122314782882, "BBH": 25.5569024540723, "MATH Lvl 5 Raw": 0.0098187311178247, "MATH Lvl 5": 0.9818731117824772, "GPQA Raw": 0.2927852348993288, "GPQA": 5.7046979865771785, "MUSR Raw": 0.4559791666666666, "MUSR": 15.8640625, "MMLU-PRO Raw": 0.2641289893617021, "MMLU-PRO": 18.23655437352246, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-03-06T00:00:00", "Submission Date": "2024-09-04T00:00:00", "Generation": 1, "Base Model": "abacusai/bigstral-12b-32k (Merge)"}, {"eval_name": "abacusai_bigyi-15b_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/abacusai/bigyi-15b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">abacusai/bigyi-15b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/abacusai__bigyi-15b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "abacusai/bigyi-15b", "Model sha": "b878c15531f7aaf6cf287530f1117b1308b96dc4", "Average \u2b06\ufe0f": 12.95111955799062, "Hub License": "other", "Hub \u2764\ufe0f": 11, "#Params (B)": 15, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2094032722066339, "IFEval": 20.940327220663395, "BBH Raw": 0.4345298820215116, "BBH": 19.94022305425607, "MATH Lvl 5 Raw": 0.0234138972809667, "MATH Lvl 5": 2.3413897280966767, "GPQA Raw": 0.3095637583892617, "GPQA": 7.941834451901568, "MUSR Raw": 0.35378125, "MUSR": 4.289322916666667, "MMLU-PRO Raw": 0.300282579787234, "MMLU-PRO": 22.25361997635934, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-03-06T00:00:00", "Submission Date": "2024-09-17T00:00:00", "Generation": 1, "Base Model": "abacusai/bigyi-15b (Merge)"}, {"eval_name": "abhishek_autotrain-llama3-70b-orpo-v1_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/abhishek/autotrain-llama3-70b-orpo-v1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">abhishek/autotrain-llama3-70b-orpo-v1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/abhishek__autotrain-llama3-70b-orpo-v1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "abhishek/autotrain-llama3-70b-orpo-v1", "Model sha": "053236c6846cc561c1503ba05e2b28c94855a432", "Average \u2b06\ufe0f": 14.71267209846267, "Hub License": "other", "Hub \u2764\ufe0f": 4, "#Params (B)": 70, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4233023932055834, "IFEval": 42.33023932055834, "BBH Raw": 0.5997985900252331, "BBH": 41.56536227340845, "MATH Lvl 5 Raw": 0.0045317220543806, "MATH Lvl 5": 0.4531722054380665, "GPQA Raw": 0.2441275167785234, "GPQA": 0.0, "MUSR Raw": 0.35790625, "MUSR": 2.5716145833333326, "MMLU-PRO Raw": 0.1122007978723404, "MMLU-PRO": 1.3556442080378246, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-02T00:00:00", "Submission Date": "2024-08-30T00:00:00", "Generation": 0, "Base Model": "abhishek/autotrain-llama3-70b-orpo-v1"}, {"eval_name": "abhishek_autotrain-llama3-70b-orpo-v2_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/abhishek/autotrain-llama3-70b-orpo-v2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">abhishek/autotrain-llama3-70b-orpo-v2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/abhishek__autotrain-llama3-70b-orpo-v2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "abhishek/autotrain-llama3-70b-orpo-v2", "Model sha": "a2c16a8a7fa48792eb8a1f0c50e13309c2021a63", "Average \u2b06\ufe0f": 28.4770817455055, "Hub License": "other", "Hub \u2764\ufe0f": 3, "#Params (B)": 70, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5406055931594835, "IFEval": 54.06055931594835, "BBH Raw": 0.5899473641612185, "BBH": 39.88219882979646, "MATH Lvl 5 Raw": 0.1873111782477341, "MATH Lvl 5": 18.731117824773413, "GPQA Raw": 0.2936241610738255, "GPQA": 5.8165548098434, "MUSR Raw": 0.4113333333333333, "MUSR": 9.950000000000005, "MMLU-PRO Raw": 0.4817985372340425, "MMLU-PRO": 42.4220596926714, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-04T00:00:00", "Submission Date": "2024-08-21T00:00:00", "Generation": 0, "Base Model": "abhishek/autotrain-llama3-70b-orpo-v2"}, {"eval_name": "abhishek_autotrain-llama3-orpo-v2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/abhishek/autotrain-llama3-orpo-v2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">abhishek/autotrain-llama3-orpo-v2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/abhishek__autotrain-llama3-orpo-v2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "abhishek/autotrain-llama3-orpo-v2", "Model sha": "1655d0683696a5de2eb9a59c339ee469297beb9c", "Average \u2b06\ufe0f": 12.200752076919066, "Hub License": "other", "Hub \u2764\ufe0f": 3, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4371656094717572, "IFEval": 43.71656094717572, "BBH Raw": 0.3159382888084642, "BBH": 4.380133995067516, "MATH Lvl 5 Raw": 0.0422960725075528, "MATH Lvl 5": 4.229607250755287, "GPQA Raw": 0.2667785234899328, "GPQA": 2.2371364653243813, "MUSR Raw": 0.3792395833333333, "MUSR": 5.104947916666667, "MMLU-PRO Raw": 0.2218251329787234, "MMLU-PRO": 13.536125886524822, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-22T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "abhishek/autotrain-llama3-orpo-v2"}, {"eval_name": "abhishek_autotrain-vr4a1-e5mms_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Adapter", "Architecture": "?", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/abhishek/autotrain-vr4a1-e5mms\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">abhishek/autotrain-vr4a1-e5mms</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/abhishek__autotrain-vr4a1-e5mms-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "abhishek/autotrain-vr4a1-e5mms", "Model sha": "5206a32e0bd3067aef1ce90f5528ade7d866253f", "Average \u2b06\ufe0f": 18.395617908175875, "Hub License": "other", "Hub \u2764\ufe0f": 0, "#Params (B)": 16, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.214224923203766, "IFEval": 21.4224923203766, "BBH Raw": 0.5000624442873264, "BBH": 28.45661724854773, "MATH Lvl 5 Raw": 0.1253776435045317, "MATH Lvl 5": 12.537764350453172, "GPQA Raw": 0.3196308724832215, "GPQA": 9.284116331096197, "MUSR Raw": 0.389125, "MUSR": 9.040625, "MMLU-PRO Raw": 0.366688829787234, "MMLU-PRO": 29.63209219858156, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-05T00:00:00", "Submission Date": "2024-09-06T00:00:00", "Generation": 2, "Base Model": "meta-llama/Meta-Llama-3.1-8B"}, {"eval_name": "adamo1139_Yi-34B-200K-AEZAKMI-v2_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/adamo1139/Yi-34B-200K-AEZAKMI-v2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">adamo1139/Yi-34B-200K-AEZAKMI-v2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/adamo1139__Yi-34B-200K-AEZAKMI-v2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "adamo1139/Yi-34B-200K-AEZAKMI-v2", "Model sha": "189b42b0dae6352fbe7165255aae851961c8e678", "Average \u2b06\ufe0f": 23.68887979498133, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 12, "#Params (B)": 34, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4555257827010111, "IFEval": 45.55257827010111, "BBH Raw": 0.5383819237015192, "BBH": 35.2764249557812, "MATH Lvl 5 Raw": 0.0483383685800604, "MATH Lvl 5": 4.833836858006042, "GPQA Raw": 0.3322147651006711, "GPQA": 10.96196868008949, "MUSR Raw": 0.3886041666666666, "MUSR": 6.475520833333334, "MMLU-PRO Raw": 0.4512965425531915, "MMLU-PRO": 39.03294917257684, "Maintainer's Highlight": false, "Upload To Hub Date": "2023-12-13T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "adamo1139/Yi-34B-200K-AEZAKMI-v2"}, {"eval_name": "ai21labs_Jamba-v0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "JambaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/ai21labs/Jamba-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">ai21labs/Jamba-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/ai21labs__Jamba-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "ai21labs/Jamba-v0.1", "Model sha": "ce13f3fe99555a2606d1892665bb67649032ff2d", "Average \u2b06\ufe0f": 9.11766015497909, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1171, "#Params (B)": 51, "Available on the hub": true, "Not_Merged": true, "MoE": false, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2025592095639569, "IFEval": 20.2559209563957, "BBH Raw": 0.3602260245164572, "BBH": 10.722058918870276, "MATH Lvl 5 Raw": 0.0098187311178247, "MATH Lvl 5": 0.9818731117824772, "GPQA Raw": 0.2684563758389262, "GPQA": 2.460850111856823, "MUSR Raw": 0.3590208333333333, "MUSR": 3.7109375, "MMLU-PRO Raw": 0.2491688829787234, "MMLU-PRO": 16.574320330969268, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-03-28T00:00:00", "Submission Date": "2024-09-16T00:00:00", "Generation": 0, "Base Model": "ai21labs/Jamba-v0.1"}, {"eval_name": "aixonlab_Aether-12b_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/aixonlab/Aether-12b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">aixonlab/Aether-12b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/aixonlab__Aether-12b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "aixonlab/Aether-12b", "Model sha": "c55d08a69c74f87c18ab5afb05d46359f389c91a", "Average \u2b06\ufe0f": 17.731239949843104, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2346828636905632, "IFEval": 23.46828636905633, "BBH Raw": 0.5179400750435481, "BBH": 30.55113831130312, "MATH Lvl 5 Raw": 0.0876132930513595, "MATH Lvl 5": 8.761329305135952, "GPQA Raw": 0.3162751677852349, "GPQA": 8.83668903803132, "MUSR Raw": 0.3828645833333333, "MUSR": 7.991406250000002, "MMLU-PRO Raw": 0.3410073138297872, "MMLU-PRO": 26.778590425531917, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-24T00:00:00", "Submission Date": "2024-10-09T00:00:00", "Generation": 1, "Base Model": "Xclbr7/Arcanum-12b"}, {"eval_name": "aixonlab_Grey-12b_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/aixonlab/Grey-12b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">aixonlab/Grey-12b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/aixonlab__Grey-12b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "aixonlab/Grey-12b", "Model sha": "50f56572870c49186c3679f9949a602d2d97c046", "Average \u2b06\ufe0f": 23.45496671432926, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3967993811974449, "IFEval": 39.6799381197445, "BBH Raw": 0.5698957505959833, "BBH": 38.74604345491756, "MATH Lvl 5 Raw": 0.0845921450151057, "MATH Lvl 5": 8.459214501510575, "GPQA Raw": 0.3003355704697986, "GPQA": 6.711409395973152, "MUSR Raw": 0.4516354166666667, "MUSR": 16.25442708333333, "MMLU-PRO Raw": 0.3779089095744681, "MMLU-PRO": 30.87876773049646, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-07T00:00:00", "Submission Date": "2024-10-09T00:00:00", "Generation": 2, "Base Model": "Xclbr7/Arcanum-12b"}, {"eval_name": "alcholjung_llama3_medical_tuned_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Adapter", "Architecture": "?", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/alcholjung/llama3_medical_tuned\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">alcholjung/llama3_medical_tuned</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/alcholjung__llama3_medical_tuned-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "alcholjung/llama3_medical_tuned", "Model sha": "62bd457b6fe961a42a631306577e622c83876cb6", "Average \u2b06\ufe0f": 11.306071402090678, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 16, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.0105664082412443, "IFEval": 1.0566408241244345, "BBH Raw": 0.4512943191660926, "BBH": 23.26508902496949, "MATH Lvl 5 Raw": 0.0022658610271903, "MATH Lvl 5": 0.2265861027190332, "GPQA Raw": 0.2860738255033557, "GPQA": 4.809843400447425, "MUSR Raw": 0.4660208333333333, "MUSR": 16.852604166666666, "MMLU-PRO Raw": 0.2946309840425531, "MMLU-PRO": 21.625664893617017, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-14T00:00:00", "Submission Date": "2024-08-14T00:00:00", "Generation": 0, "Base Model": "alcholjung/llama3_medical_tuned"}, {"eval_name": "allenai_OLMo-1B-hf_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "OlmoForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/allenai/OLMo-1B-hf\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">allenai/OLMo-1B-hf</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/allenai__OLMo-1B-hf-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "allenai/OLMo-1B-hf", "Model sha": "8e995430edd24416ccfa98b5b283fa07b0c9f1a9", "Average \u2b06\ufe0f": 6.470278440392426, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 13, "#Params (B)": 1, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2181966072243868, "IFEval": 21.819660722438684, "BBH Raw": 0.3051946898842932, "BBH": 3.1965463124303173, "MATH Lvl 5 Raw": 0.0075528700906344, "MATH Lvl 5": 0.7552870090634441, "GPQA Raw": 0.261744966442953, "GPQA": 1.5659955257270708, "MUSR Raw": 0.40978125, "MUSR": 9.555989583333334, "MMLU-PRO Raw": 0.1173537234042553, "MMLU-PRO": 1.9281914893617007, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-04-12T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "allenai/OLMo-1B-hf"}, {"eval_name": "allenai_OLMo-7B-Instruct-hf_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "OlmoForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/allenai/OLMo-7B-Instruct-hf\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">allenai/OLMo-7B-Instruct-hf</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/allenai__OLMo-7B-Instruct-hf-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "allenai/OLMo-7B-Instruct-hf", "Model sha": "2ea947518df93433aa71219f29b36c72ac63be95", "Average \u2b06\ufe0f": 10.76085660371239, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3472652561869174, "IFEval": 34.72652561869174, "BBH Raw": 0.3706469866662716, "BBH": 13.159933415267032, "MATH Lvl 5 Raw": 0.0083081570996978, "MATH Lvl 5": 0.8308157099697886, "GPQA Raw": 0.2709731543624161, "GPQA": 2.796420581655479, "MUSR Raw": 0.3764791666666666, "MUSR": 4.3265625, "MMLU-PRO Raw": 0.1785239361702127, "MMLU-PRO": 8.724881796690305, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-06-04T00:00:00", "Submission Date": "2024-06-27T00:00:00", "Generation": 0, "Base Model": "allenai/OLMo-7B-Instruct-hf"}, {"eval_name": "allenai_OLMo-7B-hf_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "OlmoForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/allenai/OLMo-7B-hf\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">allenai/OLMo-7B-hf</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/allenai__OLMo-7B-hf-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "allenai/OLMo-7B-hf", "Model sha": "687d934d36a05417048d0fe7482f24f389fef6aa", "Average \u2b06\ufe0f": 6.776151209771288, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 10, "#Params (B)": 6, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2719273749207658, "IFEval": 27.19273749207658, "BBH Raw": 0.3279131658736227, "BBH": 5.761987041080832, "MATH Lvl 5 Raw": 0.0067975830815709, "MATH Lvl 5": 0.6797583081570997, "GPQA Raw": 0.2726510067114094, "GPQA": 3.0201342281879207, "MUSR Raw": 0.3486666666666667, "MUSR": 2.0833333333333326, "MMLU-PRO Raw": 0.1172706117021276, "MMLU-PRO": 1.9189568557919612, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-04-12T00:00:00", "Submission Date": "2024-06-27T00:00:00", "Generation": 0, "Base Model": "allenai/OLMo-7B-hf"}, {"eval_name": "allenai_OLMoE-1B-7B-0924_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "OlmoeForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/allenai/OLMoE-1B-7B-0924\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">allenai/OLMoE-1B-7B-0924</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/allenai__OLMoE-1B-7B-0924-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "allenai/OLMoE-1B-7B-0924", "Model sha": "4fa3a6e09ed0e41639962f38bfba0fc532b90075", "Average \u2b06\ufe0f": 7.178463786041392, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 102, "#Params (B)": 6, "Available on the hub": true, "Not_Merged": true, "MoE": false, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.218471433574028, "IFEval": 21.847143357402803, "BBH Raw": 0.3393437931177341, "BBH": 8.308106894895777, "MATH Lvl 5 Raw": 0.0113293051359516, "MATH Lvl 5": 1.1329305135951662, "GPQA Raw": 0.24748322147651, "GPQA": 0.0, "MUSR Raw": 0.3487916666666666, "MUSR": 3.565625000000001, "MMLU-PRO Raw": 0.1739527925531915, "MMLU-PRO": 8.216976950354608, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-07-20T00:00:00", "Submission Date": "2024-09-30T00:00:00", "Generation": 0, "Base Model": "allenai/OLMoE-1B-7B-0924"}, {"eval_name": "allenai_OLMoE-1B-7B-0924-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "OlmoeForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/allenai/OLMoE-1B-7B-0924-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">allenai/OLMoE-1B-7B-0924-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/allenai__OLMoE-1B-7B-0924-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "allenai/OLMoE-1B-7B-0924-Instruct", "Model sha": "7f1c97f440f06ce36705e4f2b843edb5925f4498", "Average \u2b06\ufe0f": 13.207221439435314, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 77, "#Params (B)": 6, "Available on the hub": true, "Not_Merged": true, "MoE": false, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4652178442089212, "IFEval": 46.521784420892125, "BBH Raw": 0.3901610626816106, "BBH": 14.571562821337196, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2676174496644295, "GPQA": 2.348993288590602, "MUSR Raw": 0.3848229166666666, "MUSR": 6.06953125, "MMLU-PRO Raw": 0.1875831117021276, "MMLU-PRO": 9.73145685579196, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-08-13T00:00:00", "Submission Date": "2024-09-30T00:00:00", "Generation": 2, "Base Model": "allenai/OLMoE-1B-7B-0924"}, {"eval_name": "allknowingroger_Chocolatine-24B_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "Phi3ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/allknowingroger/Chocolatine-24B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">allknowingroger/Chocolatine-24B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/allknowingroger__Chocolatine-24B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "allknowingroger/Chocolatine-24B", "Model sha": "6245b82885ca4930575dbed2932ec1d32d901c0e", "Average \u2b06\ufe0f": 21.33314547377704, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 24, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1958148822901013, "IFEval": 19.581488229010137, "BBH Raw": 0.6191260063262436, "BBH": 45.78594021531884, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.3255033557046979, "GPQA": 10.067114093959727, "MUSR Raw": 0.4323229166666666, "MUSR": 12.940364583333334, "MMLU-PRO Raw": 0.4566156914893617, "MMLU-PRO": 39.623965721040186, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-02T00:00:00", "Submission Date": "2024-09-02T00:00:00", "Generation": 1, "Base Model": "allknowingroger/Chocolatine-24B (Merge)"}, {"eval_name": "allknowingroger_LimyQstar-7B-slerp_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/allknowingroger/LimyQstar-7B-slerp\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">allknowingroger/LimyQstar-7B-slerp</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/allknowingroger__LimyQstar-7B-slerp-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "allknowingroger/LimyQstar-7B-slerp", "Model sha": "6dc557c7bfd6a6f9bc8190bc8a31c3b732deca40", "Average \u2b06\ufe0f": 18.52146757100565, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3491136850224072, "IFEval": 34.91136850224072, "BBH Raw": 0.5023559424245442, "BBH": 30.194567331120084, "MATH Lvl 5 Raw": 0.059667673716012, "MATH Lvl 5": 5.966767371601208, "GPQA Raw": 0.2986577181208054, "GPQA": 6.487695749440718, "MUSR Raw": 0.4146458333333333, "MUSR": 10.197395833333337, "MMLU-PRO Raw": 0.3103390957446808, "MMLU-PRO": 23.371010638297868, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-03-23T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "allknowingroger/LimyQstar-7B-slerp (Merge)"}, {"eval_name": "allknowingroger_Llama3.1-60B_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/allknowingroger/Llama3.1-60B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">allknowingroger/Llama3.1-60B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/allknowingroger__Llama3.1-60B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "allknowingroger/Llama3.1-60B", "Model sha": "5fb1ddcce0bddc60949a9d0c2fc9f8326be5bc4e", "Average \u2b06\ufe0f": 9.951594488947729, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 61, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1814518810090559, "IFEval": 18.1451881009056, "BBH Raw": 0.3241755271938207, "BBH": 7.784282802508024, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2944630872483221, "GPQA": 5.92841163310962, "MUSR Raw": 0.3595833333333333, "MUSR": 2.18125, "MMLU-PRO Raw": 0.3310339095744681, "MMLU-PRO": 25.67043439716312, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-10T00:00:00", "Submission Date": "2024-10-08T00:00:00", "Generation": 1, "Base Model": "allknowingroger/Llama3.1-60B (Merge)"}, {"eval_name": "allknowingroger_Meme-7B-slerp_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/allknowingroger/Meme-7B-slerp\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">allknowingroger/Meme-7B-slerp</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/allknowingroger__Meme-7B-slerp-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "allknowingroger/Meme-7B-slerp", "Model sha": "7836c0f4fce70286382e61003e9a05d7559365d9", "Average \u2b06\ufe0f": 19.250904324074, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.5163754393897082, "IFEval": 51.63754393897082, "BBH Raw": 0.4660944195552204, "BBH": 24.52948594942413, "MATH Lvl 5 Raw": 0.0422960725075528, "MATH Lvl 5": 4.229607250755287, "GPQA Raw": 0.2860738255033557, "GPQA": 4.809843400447425, "MUSR Raw": 0.4223020833333333, "MUSR": 10.187760416666666, "MMLU-PRO Raw": 0.281000664893617, "MMLU-PRO": 20.111184988179662, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-22T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "allknowingroger/Meme-7B-slerp (Merge)"}, {"eval_name": "allknowingroger_MistralPhi3-11B_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/allknowingroger/MistralPhi3-11B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">allknowingroger/MistralPhi3-11B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/allknowingroger__MistralPhi3-11B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "allknowingroger/MistralPhi3-11B", "Model sha": "3afeaf24c6306c4752c320c4fd32fa2e7694e12e", "Average \u2b06\ufe0f": 21.627095011873774, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 11, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1942911474886634, "IFEval": 19.42911474886634, "BBH Raw": 0.6234314600705605, "BBH": 46.16462900339792, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.3322147651006711, "GPQA": 10.96196868008949, "MUSR Raw": 0.4266770833333333, "MUSR": 12.23463541666667, "MMLU-PRO Raw": 0.46875, "MMLU-PRO": 40.97222222222222, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-26T00:00:00", "Submission Date": "2024-09-02T00:00:00", "Generation": 1, "Base Model": "allknowingroger/MistralPhi3-11B (Merge)"}, {"eval_name": "allknowingroger_Mistralmash1-7B-s_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/allknowingroger/Mistralmash1-7B-s\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">allknowingroger/Mistralmash1-7B-s</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/allknowingroger__Mistralmash1-7B-s-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "allknowingroger/Mistralmash1-7B-s", "Model sha": "730b7b2867deef63961f002b6e1e70e7d416c599", "Average \u2b06\ufe0f": 20.69986782377317, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3961001254449305, "IFEval": 39.61001254449306, "BBH Raw": 0.5277485757172445, "BBH": 33.44855374433827, "MATH Lvl 5 Raw": 0.0793051359516616, "MATH Lvl 5": 7.930513595166164, "GPQA Raw": 0.2944630872483221, "GPQA": 5.92841163310962, "MUSR Raw": 0.4267083333333333, "MUSR": 11.805208333333333, "MMLU-PRO Raw": 0.3292885638297872, "MMLU-PRO": 25.47650709219858, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-27T00:00:00", "Submission Date": "2024-09-02T00:00:00", "Generation": 1, "Base Model": "allknowingroger/Mistralmash1-7B-s (Merge)"}, {"eval_name": "allknowingroger_Mistralmash2-7B-s_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/allknowingroger/Mistralmash2-7B-s\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">allknowingroger/Mistralmash2-7B-s</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/allknowingroger__Mistralmash2-7B-s-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "allknowingroger/Mistralmash2-7B-s", "Model sha": "3b2aafa0f931f3d3103fbc96a6da4ac36f376d78", "Average \u2b06\ufe0f": 21.25121169033037, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4101883003763348, "IFEval": 41.01883003763348, "BBH Raw": 0.530485814102601, "BBH": 33.29836428588566, "MATH Lvl 5 Raw": 0.0709969788519637, "MATH Lvl 5": 7.099697885196375, "GPQA Raw": 0.2978187919463087, "GPQA": 6.375838926174497, "MUSR Raw": 0.4372499999999999, "MUSR": 13.65625, "MMLU-PRO Raw": 0.3345246010638298, "MMLU-PRO": 26.0582890070922, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-27T00:00:00", "Submission Date": "2024-09-02T00:00:00", "Generation": 1, "Base Model": "allknowingroger/Mistralmash2-7B-s (Merge)"}, {"eval_name": "allknowingroger_MixTAO-19B-pass_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/allknowingroger/MixTAO-19B-pass\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">allknowingroger/MixTAO-19B-pass</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/allknowingroger__MixTAO-19B-pass-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "allknowingroger/MixTAO-19B-pass", "Model sha": "a41369cfcfbada9d5387051ba616bf1432b31d31", "Average \u2b06\ufe0f": 20.53947557655628, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 19, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3814368098866563, "IFEval": 38.14368098866563, "BBH Raw": 0.5128248798224987, "BBH": 31.577918110916897, "MATH Lvl 5 Raw": 0.0558912386706948, "MATH Lvl 5": 5.589123867069486, "GPQA Raw": 0.2843959731543624, "GPQA": 4.586129753914992, "MUSR Raw": 0.4782708333333333, "MUSR": 19.95052083333333, "MMLU-PRO Raw": 0.3105053191489361, "MMLU-PRO": 23.389479905437348, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-02T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "allknowingroger/MixTAO-19B-pass (Merge)"}, {"eval_name": "allknowingroger_MixTaoTruthful-13B-slerp_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/allknowingroger/MixTaoTruthful-13B-slerp\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">allknowingroger/MixTaoTruthful-13B-slerp</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/allknowingroger__MixTaoTruthful-13B-slerp-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "allknowingroger/MixTaoTruthful-13B-slerp", "Model sha": "3324d37e138c6bf0d6891e54b6dd839c8d2f35ec", "Average \u2b06\ufe0f": 20.12709479990277, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4138851580473144, "IFEval": 41.38851580473145, "BBH Raw": 0.5207335343585151, "BBH": 32.70636246605644, "MATH Lvl 5 Raw": 0.0589123867069486, "MATH Lvl 5": 5.8912386706948645, "GPQA Raw": 0.2843959731543624, "GPQA": 4.586129753914992, "MUSR Raw": 0.4292499999999999, "MUSR": 12.856249999999996, "MMLU-PRO Raw": 0.3100066489361702, "MMLU-PRO": 23.33407210401891, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-25T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "allknowingroger/MixTaoTruthful-13B-slerp (Merge)"}, {"eval_name": "allknowingroger_MultiCalm-7B-slerp_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/allknowingroger/MultiCalm-7B-slerp\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">allknowingroger/MultiCalm-7B-slerp</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/allknowingroger__MultiCalm-7B-slerp-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "allknowingroger/MultiCalm-7B-slerp", "Model sha": "1c23540e907fab4dfe0ef66edd0003e764bfe568", "Average \u2b06\ufe0f": 19.384172608637225, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3926526061960044, "IFEval": 39.26526061960044, "BBH Raw": 0.5121891599770304, "BBH": 31.46648332199455, "MATH Lvl 5 Raw": 0.0566465256797583, "MATH Lvl 5": 5.664652567975831, "GPQA Raw": 0.2827181208053691, "GPQA": 4.36241610738255, "MUSR Raw": 0.4319479166666666, "MUSR": 12.960156250000004, "MMLU-PRO Raw": 0.3032746010638298, "MMLU-PRO": 22.586066784869978, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-19T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "allknowingroger/MultiCalm-7B-slerp (Merge)"}, {"eval_name": "allknowingroger_MultiMash-12B-slerp_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/allknowingroger/MultiMash-12B-slerp\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">allknowingroger/MultiMash-12B-slerp</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/allknowingroger__MultiMash-12B-slerp-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "allknowingroger/MultiMash-12B-slerp", "Model sha": "91a6d0fe6b9271000ca713ee9ab414c782ba4c50", "Average \u2b06\ufe0f": 20.07919891590045, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3974487692655487, "IFEval": 39.74487692655487, "BBH Raw": 0.5141827379810838, "BBH": 31.92567710646836, "MATH Lvl 5 Raw": 0.0747734138972809, "MATH Lvl 5": 7.477341389728097, "GPQA Raw": 0.2768456375838926, "GPQA": 3.5794183445190177, "MUSR Raw": 0.4437916666666666, "MUSR": 14.773958333333333, "MMLU-PRO Raw": 0.3067652925531915, "MMLU-PRO": 22.973921394799056, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-20T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "allknowingroger/MultiMash-12B-slerp (Merge)"}, {"eval_name": "allknowingroger_MultiMash10-13B-slerp_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/allknowingroger/MultiMash10-13B-slerp\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">allknowingroger/MultiMash10-13B-slerp</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/allknowingroger__MultiMash10-13B-slerp-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "allknowingroger/MultiMash10-13B-slerp", "Model sha": "6def2fd1a11d4c380a19b7a3bdf263a6b80cd8f3", "Average \u2b06\ufe0f": 20.28796719743044, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4162832395820866, "IFEval": 41.62832395820867, "BBH Raw": 0.5186335995744094, "BBH": 32.45250184104656, "MATH Lvl 5 Raw": 0.0634441087613293, "MATH Lvl 5": 6.3444108761329305, "GPQA Raw": 0.2860738255033557, "GPQA": 4.809843400447425, "MUSR Raw": 0.4317916666666666, "MUSR": 12.97395833333333, "MMLU-PRO Raw": 0.3116688829787234, "MMLU-PRO": 23.51876477541371, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-27T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "allknowingroger/MultiMash10-13B-slerp (Merge)"}, {"eval_name": "allknowingroger_MultiMash11-13B-slerp_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/allknowingroger/MultiMash11-13B-slerp\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">allknowingroger/MultiMash11-13B-slerp</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/allknowingroger__MultiMash11-13B-slerp-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "allknowingroger/MultiMash11-13B-slerp", "Model sha": "1134a0adabef4a26e1d49c302baff74c4a7e9f46", "Average \u2b06\ufe0f": 20.55173532434689, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4251009543566625, "IFEval": 42.51009543566625, "BBH Raw": 0.5193864686484946, "BBH": 32.59670310684399, "MATH Lvl 5 Raw": 0.066465256797583, "MATH Lvl 5": 6.646525679758309, "GPQA Raw": 0.2827181208053691, "GPQA": 4.36241610738255, "MUSR Raw": 0.43728125, "MUSR": 14.026822916666664, "MMLU-PRO Raw": 0.3085106382978723, "MMLU-PRO": 23.167848699763592, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-27T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "allknowingroger/MultiMash11-13B-slerp (Merge)"}, {"eval_name": "allknowingroger_MultiMash2-12B-slerp_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/allknowingroger/MultiMash2-12B-slerp\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">allknowingroger/MultiMash2-12B-slerp</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/allknowingroger__MultiMash2-12B-slerp-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "allknowingroger/MultiMash2-12B-slerp", "Model sha": "e44e9563368699f753a4474b068c059d233ddee3", "Average \u2b06\ufe0f": 19.75202624703025, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4260750364588181, "IFEval": 42.60750364588182, "BBH Raw": 0.5133973498532299, "BBH": 31.617950213580304, "MATH Lvl 5 Raw": 0.0589123867069486, "MATH Lvl 5": 5.8912386706948645, "GPQA Raw": 0.2793624161073825, "GPQA": 3.9149888143176734, "MUSR Raw": 0.4228020833333333, "MUSR": 11.783593750000003, "MMLU-PRO Raw": 0.3042719414893617, "MMLU-PRO": 22.696882387706854, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-20T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "allknowingroger/MultiMash2-12B-slerp (Merge)"}, {"eval_name": "allknowingroger_MultiMash5-12B-slerp_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/allknowingroger/MultiMash5-12B-slerp\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">allknowingroger/MultiMash5-12B-slerp</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/allknowingroger__MultiMash5-12B-slerp-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "allknowingroger/MultiMash5-12B-slerp", "Model sha": "15ef0301c7ce939208d55ad13fa840662f92bce6", "Average \u2b06\ufe0f": 19.502188636114298, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4141599843969556, "IFEval": 41.41599843969557, "BBH Raw": 0.5144534995858502, "BBH": 31.85636425596493, "MATH Lvl 5 Raw": 0.0581570996978852, "MATH Lvl 5": 5.81570996978852, "GPQA Raw": 0.2776845637583892, "GPQA": 3.691275167785232, "MUSR Raw": 0.4202916666666667, "MUSR": 11.703124999999998, "MMLU-PRO Raw": 0.3027759308510638, "MMLU-PRO": 22.530658983451534, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-21T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "allknowingroger/MultiMash5-12B-slerp (Merge)"}, {"eval_name": "allknowingroger_MultiMash6-12B-slerp_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/allknowingroger/MultiMash6-12B-slerp\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">allknowingroger/MultiMash6-12B-slerp</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/allknowingroger__MultiMash6-12B-slerp-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "allknowingroger/MultiMash6-12B-slerp", "Model sha": "a04856a12b85e986e1b540cf0c7510e9ce2df09b", "Average \u2b06\ufe0f": 20.13795782005049, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.430046720479439, "IFEval": 43.0046720479439, "BBH Raw": 0.5195916915718951, "BBH": 32.403879619181005, "MATH Lvl 5 Raw": 0.0641993957703927, "MATH Lvl 5": 6.419939577039275, "GPQA Raw": 0.2743288590604026, "GPQA": 3.243847874720355, "MUSR Raw": 0.4305833333333333, "MUSR": 12.522916666666667, "MMLU-PRO Raw": 0.3090924202127659, "MMLU-PRO": 23.23249113475177, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-22T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "allknowingroger/MultiMash6-12B-slerp (Merge)"}, {"eval_name": "allknowingroger_MultiMash7-12B-slerp_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/allknowingroger/MultiMash7-12B-slerp\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">allknowingroger/MultiMash7-12B-slerp</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/allknowingroger__MultiMash7-12B-slerp-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "allknowingroger/MultiMash7-12B-slerp", "Model sha": "5f91dd41fb4b58e76c52b03ed15477a046b079df", "Average \u2b06\ufe0f": 19.716764810918303, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4212788733892738, "IFEval": 42.12788733892738, "BBH Raw": 0.5111135397195524, "BBH": 31.298150090327656, "MATH Lvl 5 Raw": 0.0649546827794562, "MATH Lvl 5": 6.495468277945619, "GPQA Raw": 0.2785234899328859, "GPQA": 3.803131991051453, "MUSR Raw": 0.4279479166666666, "MUSR": 12.026822916666667, "MMLU-PRO Raw": 0.3029421542553192, "MMLU-PRO": 22.549128250591018, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-22T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "allknowingroger/MultiMash7-12B-slerp (Merge)"}, {"eval_name": "allknowingroger_MultiMash8-13B-slerp_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/allknowingroger/MultiMash8-13B-slerp\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">allknowingroger/MultiMash8-13B-slerp</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/allknowingroger__MultiMash8-13B-slerp-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "allknowingroger/MultiMash8-13B-slerp", "Model sha": "5590ccd99f74301951f450f9d0271a99e97728c8", "Average \u2b06\ufe0f": 20.948983318311274, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4320702402957486, "IFEval": 43.20702402957486, "BBH Raw": 0.5178483059643324, "BBH": 32.27299661531551, "MATH Lvl 5 Raw": 0.0694864048338368, "MATH Lvl 5": 6.948640483383686, "GPQA Raw": 0.2885906040268456, "GPQA": 5.145413870246088, "MUSR Raw": 0.4423958333333333, "MUSR": 14.499479166666664, "MMLU-PRO Raw": 0.3125831117021276, "MMLU-PRO": 23.620345744680847, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-26T00:00:00", "Submission Date": "2024-09-02T00:00:00", "Generation": 1, "Base Model": "allknowingroger/MultiMash8-13B-slerp (Merge)"}, {"eval_name": "allknowingroger_MultiMash9-13B-slerp_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/allknowingroger/MultiMash9-13B-slerp\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">allknowingroger/MultiMash9-13B-slerp</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/allknowingroger__MultiMash9-13B-slerp-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "allknowingroger/MultiMash9-13B-slerp", "Model sha": "56dac45f387669baa04a8997ebb9ea63c65fbbd1", "Average \u2b06\ufe0f": 20.529676601531275, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4187810564856802, "IFEval": 41.87810564856802, "BBH Raw": 0.5193579939678727, "BBH": 32.55261171624742, "MATH Lvl 5 Raw": 0.0717522658610271, "MATH Lvl 5": 7.175226586102719, "GPQA Raw": 0.2802013422818792, "GPQA": 4.026845637583895, "MUSR Raw": 0.4398229166666667, "MUSR": 14.211197916666665, "MMLU-PRO Raw": 0.3100066489361702, "MMLU-PRO": 23.33407210401891, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-26T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "allknowingroger/MultiMash9-13B-slerp (Merge)"}, {"eval_name": "allknowingroger_MultiMerge-7B-slerp_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/allknowingroger/MultiMerge-7B-slerp\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">allknowingroger/MultiMerge-7B-slerp</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/allknowingroger__MultiMerge-7B-slerp-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "allknowingroger/MultiMerge-7B-slerp", "Model sha": "a026bbea09f0b1880deed62b9081e3708be0dec2", "Average \u2b06\ufe0f": 19.49189426050149, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3947758613811354, "IFEval": 39.47758613811354, "BBH Raw": 0.5140224933103638, "BBH": 31.803983321994554, "MATH Lvl 5 Raw": 0.0634441087613293, "MATH Lvl 5": 6.3444108761329305, "GPQA Raw": 0.2827181208053691, "GPQA": 4.36241610738255, "MUSR Raw": 0.4279791666666666, "MUSR": 12.330729166666671, "MMLU-PRO Raw": 0.3036901595744681, "MMLU-PRO": 22.63223995271868, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-11T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "allknowingroger/MultiMerge-7B-slerp (Merge)"}, {"eval_name": "allknowingroger_Multimash3-12B-slerp_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/allknowingroger/Multimash3-12B-slerp\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">allknowingroger/Multimash3-12B-slerp</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/allknowingroger__Multimash3-12B-slerp-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "allknowingroger/Multimash3-12B-slerp", "Model sha": "0b90bf0b5230d02b4ba63879fc3bf0b85d46c3ce", "Average \u2b06\ufe0f": 20.38261642353734, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4437104660079699, "IFEval": 44.371046600796994, "BBH Raw": 0.5176624678276028, "BBH": 32.1508911391619, "MATH Lvl 5 Raw": 0.0574018126888217, "MATH Lvl 5": 5.740181268882175, "GPQA Raw": 0.2802013422818792, "GPQA": 4.026845637583895, "MUSR Raw": 0.4343958333333333, "MUSR": 13.0328125, "MMLU-PRO Raw": 0.3067652925531915, "MMLU-PRO": 22.973921394799056, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-21T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "allknowingroger/Multimash3-12B-slerp (Merge)"}, {"eval_name": "allknowingroger_Multimerge-19B-pass_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/allknowingroger/Multimerge-19B-pass\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">allknowingroger/Multimerge-19B-pass</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/allknowingroger__Multimerge-19B-pass-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "allknowingroger/Multimerge-19B-pass", "Model sha": "e75918ed5601f400f62601cf6c0887aa936e8a52", "Average \u2b06\ufe0f": 4.536203105914491, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 19, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1773051060076153, "IFEval": 17.730510600761534, "BBH Raw": 0.2891778102988436, "BBH": 2.0803742908537424, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.259228187919463, "GPQA": 1.230425055928408, "MUSR Raw": 0.3429583333333333, "MUSR": 4.303125, "MMLU-PRO Raw": 0.1168550531914893, "MMLU-PRO": 1.8727836879432624, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-03T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "allknowingroger/Multimerge-19B-pass (Merge)"}, {"eval_name": "allknowingroger_MultiverseEx26-7B-slerp_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/allknowingroger/MultiverseEx26-7B-slerp\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">allknowingroger/MultiverseEx26-7B-slerp</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/allknowingroger__MultiverseEx26-7B-slerp-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "allknowingroger/MultiverseEx26-7B-slerp", "Model sha": "43f18d84e025693f00e9be335bf12fce96089b2f", "Average \u2b06\ufe0f": 19.607781969898323, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3938516469633905, "IFEval": 39.38516469633905, "BBH Raw": 0.5133591871690678, "BBH": 31.66377531246577, "MATH Lvl 5 Raw": 0.0702416918429003, "MATH Lvl 5": 7.02416918429003, "GPQA Raw": 0.2827181208053691, "GPQA": 4.36241610738255, "MUSR Raw": 0.4293125, "MUSR": 12.597395833333335, "MMLU-PRO Raw": 0.3035239361702128, "MMLU-PRO": 22.6137706855792, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-03-30T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "allknowingroger/MultiverseEx26-7B-slerp (Merge)"}, {"eval_name": "allknowingroger_NeuralWestSeverus-7B-slerp_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/allknowingroger/NeuralWestSeverus-7B-slerp\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">allknowingroger/NeuralWestSeverus-7B-slerp</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/allknowingroger__NeuralWestSeverus-7B-slerp-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "allknowingroger/NeuralWestSeverus-7B-slerp", "Model sha": "5ee5d6a11ffc4f9733e78994169a2e1614d5e16e", "Average \u2b06\ufe0f": 20.599841866123363, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4135604640132626, "IFEval": 41.35604640132626, "BBH Raw": 0.5244283854305991, "BBH": 33.41446681662389, "MATH Lvl 5 Raw": 0.0687311178247734, "MATH Lvl 5": 6.873111782477341, "GPQA Raw": 0.2709731543624161, "GPQA": 2.796420581655479, "MUSR Raw": 0.4528749999999999, "MUSR": 15.409375000000002, "MMLU-PRO Raw": 0.3137466755319149, "MMLU-PRO": 23.749630614657207, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-16T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "allknowingroger/NeuralWestSeverus-7B-slerp (Merge)"}, {"eval_name": "allknowingroger_Neuralcoven-7B-slerp_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/allknowingroger/Neuralcoven-7B-slerp\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">allknowingroger/Neuralcoven-7B-slerp</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/allknowingroger__Neuralcoven-7B-slerp-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "allknowingroger/Neuralcoven-7B-slerp", "Model sha": "129b40a7fd816f679ef5d4ab29fc77345f33a7b1", "Average \u2b06\ufe0f": 20.16226058241155, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3858584112377381, "IFEval": 38.58584112377381, "BBH Raw": 0.530287217712165, "BBH": 33.79913505465432, "MATH Lvl 5 Raw": 0.066465256797583, "MATH Lvl 5": 6.646525679758309, "GPQA Raw": 0.285234899328859, "GPQA": 4.697986577181204, "MUSR Raw": 0.429, "MUSR": 11.758333333333336, "MMLU-PRO Raw": 0.3293716755319149, "MMLU-PRO": 25.48574172576832, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-17T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "allknowingroger/Neuralcoven-7B-slerp (Merge)"}, {"eval_name": "allknowingroger_Neuralmultiverse-7B-slerp_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/allknowingroger/Neuralmultiverse-7B-slerp\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">allknowingroger/Neuralmultiverse-7B-slerp</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/allknowingroger__Neuralmultiverse-7B-slerp-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "allknowingroger/Neuralmultiverse-7B-slerp", "Model sha": "a65fe05e26e10a488b08264ac8ed73a49c3f263a", "Average \u2b06\ufe0f": 19.31067785097545, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3769154731667531, "IFEval": 37.69154731667531, "BBH Raw": 0.5165722210470375, "BBH": 32.10018047347172, "MATH Lvl 5 Raw": 0.0619335347432024, "MATH Lvl 5": 6.193353474320242, "GPQA Raw": 0.2843959731543624, "GPQA": 4.586129753914992, "MUSR Raw": 0.4280416666666666, "MUSR": 12.60520833333333, "MMLU-PRO Raw": 0.304188829787234, "MMLU-PRO": 22.68764775413712, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-17T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "allknowingroger/Neuralmultiverse-7B-slerp (Merge)"}, {"eval_name": "allknowingroger_Ph3della5-14B_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "Phi3ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/allknowingroger/Ph3della5-14B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">allknowingroger/Ph3della5-14B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/allknowingroger__Ph3della5-14B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "allknowingroger/Ph3della5-14B", "Model sha": "9c6819a910d4da414dd67c10da3bff3f986fefa5", "Average \u2b06\ufe0f": 29.91586161651532, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 13, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4798556718396077, "IFEval": 47.98556718396078, "BBH Raw": 0.6331746353794991, "BBH": 48.41436428305058, "MATH Lvl 5 Raw": 0.1435045317220543, "MATH Lvl 5": 14.350453172205436, "GPQA Raw": 0.3422818791946309, "GPQA": 12.304250559284116, "MUSR Raw": 0.4386145833333333, "MUSR": 14.360156249999998, "MMLU-PRO Raw": 0.4787234042553192, "MMLU-PRO": 42.08037825059102, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-05T00:00:00", "Submission Date": "2024-10-08T00:00:00", "Generation": 1, "Base Model": "allknowingroger/Ph3della5-14B (Merge)"}, {"eval_name": "allknowingroger_Ph3merge-14B_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "Phi3ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/allknowingroger/Ph3merge-14B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">allknowingroger/Ph3merge-14B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/allknowingroger__Ph3merge-14B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "allknowingroger/Ph3merge-14B", "Model sha": "6d0ddaa4e0cf4c82d7149cc726b08be5753a760a", "Average \u2b06\ufe0f": 23.532275395566582, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 13, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2701288137696866, "IFEval": 27.012881376968664, "BBH Raw": 0.638087568868341, "BBH": 48.88242371785896, "MATH Lvl 5 Raw": 0.0015105740181268, "MATH Lvl 5": 0.1510574018126888, "GPQA Raw": 0.3380872483221476, "GPQA": 11.74496644295302, "MUSR Raw": 0.4334375, "MUSR": 13.2796875, "MMLU-PRO Raw": 0.4611037234042553, "MMLU-PRO": 40.12263593380615, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-30T00:00:00", "Submission Date": "2024-09-02T00:00:00", "Generation": 1, "Base Model": "allknowingroger/Ph3merge-14B (Merge)"}, {"eval_name": "allknowingroger_Ph3merge2-14B_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "Phi3ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/allknowingroger/Ph3merge2-14B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">allknowingroger/Ph3merge2-14B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/allknowingroger__Ph3merge2-14B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "allknowingroger/Ph3merge2-14B", "Model sha": "2256ab821e286a1d8a4f0d42e00a50013e119671", "Average \u2b06\ufe0f": 7.962730746600417, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 13, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1706106464181704, "IFEval": 17.061064641817044, "BBH Raw": 0.3606937444321621, "BBH": 10.549967885447565, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2911073825503356, "GPQA": 5.480984340044745, "MUSR Raw": 0.3910833333333333, "MUSR": 6.652083333333335, "MMLU-PRO Raw": 0.1722905585106383, "MMLU-PRO": 8.03228427895981, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-30T00:00:00", "Submission Date": "2024-10-08T00:00:00", "Generation": 1, "Base Model": "allknowingroger/Ph3merge2-14B (Merge)"}, {"eval_name": "allknowingroger_Ph3merge3-14B_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "Phi3ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/allknowingroger/Ph3merge3-14B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">allknowingroger/Ph3merge3-14B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/allknowingroger__Ph3merge3-14B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "allknowingroger/Ph3merge3-14B", "Model sha": "90a036f7f136932ea525b5fd26cf2f54a66141af", "Average \u2b06\ufe0f": 7.931823747573229, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 13, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1645157072124186, "IFEval": 16.45157072124186, "BBH Raw": 0.3597431731140411, "BBH": 10.391379646236162, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.285234899328859, "GPQA": 4.697986577181204, "MUSR Raw": 0.4081979166666666, "MUSR": 8.858072916666668, "MMLU-PRO Raw": 0.1647273936170212, "MMLU-PRO": 7.191932624113473, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-30T00:00:00", "Submission Date": "2024-09-02T00:00:00", "Generation": 1, "Base Model": "allknowingroger/Ph3merge3-14B (Merge)"}, {"eval_name": "allknowingroger_Ph3task1-14B_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "Phi3ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/allknowingroger/Ph3task1-14B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">allknowingroger/Ph3task1-14B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/allknowingroger__Ph3task1-14B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "allknowingroger/Ph3task1-14B", "Model sha": "c9a5bab157dbdd281c651a5b7ea82a8bc64aa420", "Average \u2b06\ufe0f": 30.08263770418974, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 13, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4694643545791832, "IFEval": 46.94643545791833, "BBH Raw": 0.63178060736657, "BBH": 47.92690847304542, "MATH Lvl 5 Raw": 0.1389728096676737, "MATH Lvl 5": 13.897280966767372, "GPQA Raw": 0.3506711409395973, "GPQA": 13.422818791946312, "MUSR Raw": 0.4507708333333333, "MUSR": 16.81302083333333, "MMLU-PRO Raw": 0.4734042553191489, "MMLU-PRO": 41.48936170212765, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-07T00:00:00", "Submission Date": "2024-10-08T00:00:00", "Generation": 1, "Base Model": "allknowingroger/Ph3task1-14B (Merge)"}, {"eval_name": "allknowingroger_Ph3task2-14B_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "Phi3ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/allknowingroger/Ph3task2-14B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">allknowingroger/Ph3task2-14B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/allknowingroger__Ph3task2-14B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "allknowingroger/Ph3task2-14B", "Model sha": "2193bfec75bc90e87bc57863e02deefbdd195f9f", "Average \u2b06\ufe0f": 28.246055198513726, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 13, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4713127834146731, "IFEval": 47.13127834146731, "BBH Raw": 0.6098412220695854, "BBH": 44.08179620906436, "MATH Lvl 5 Raw": 0.1246223564954682, "MATH Lvl 5": 12.462235649546828, "GPQA Raw": 0.3305369127516778, "GPQA": 10.738255033557047, "MUSR Raw": 0.4535, "MUSR": 16.620833333333326, "MMLU-PRO Raw": 0.4459773936170212, "MMLU-PRO": 38.44193262411347, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-08T00:00:00", "Submission Date": "2024-10-08T00:00:00", "Generation": 1, "Base Model": "allknowingroger/Ph3task2-14B (Merge)"}, {"eval_name": "allknowingroger_Ph3task3-14B_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "Phi3ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/allknowingroger/Ph3task3-14B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">allknowingroger/Ph3task3-14B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/allknowingroger__Ph3task3-14B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "allknowingroger/Ph3task3-14B", "Model sha": "359de5c4969057206f846a41c72073b3429317fd", "Average \u2b06\ufe0f": 30.206696834902832, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 13, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4962421929369628, "IFEval": 49.62421929369628, "BBH Raw": 0.6297915743094921, "BBH": 47.99849937558212, "MATH Lvl 5 Raw": 0.1457703927492447, "MATH Lvl 5": 14.577039274924472, "GPQA Raw": 0.3414429530201342, "GPQA": 12.192393736017896, "MUSR Raw": 0.4425520833333333, "MUSR": 14.95234375, "MMLU-PRO Raw": 0.4770611702127659, "MMLU-PRO": 41.89568557919622, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-08T00:00:00", "Submission Date": "2024-10-08T00:00:00", "Generation": 1, "Base Model": "allknowingroger/Ph3task3-14B (Merge)"}, {"eval_name": "allknowingroger_Ph3unsloth-3B-slerp_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/allknowingroger/Ph3unsloth-3B-slerp\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">allknowingroger/Ph3unsloth-3B-slerp</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/allknowingroger__Ph3unsloth-3B-slerp-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "allknowingroger/Ph3unsloth-3B-slerp", "Model sha": "465444b3cdd43876717f7386ea2f3357c5fe8e53", "Average \u2b06\ufe0f": 19.61222586459792, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1894451167347083, "IFEval": 18.944511673470835, "BBH Raw": 0.5468077356147099, "BBH": 36.45877270267158, "MATH Lvl 5 Raw": 0.0687311178247734, "MATH Lvl 5": 6.873111782477341, "GPQA Raw": 0.3246644295302013, "GPQA": 9.955257270693512, "MUSR Raw": 0.4527812499999999, "MUSR": 15.430989583333336, "MMLU-PRO Raw": 0.3700964095744681, "MMLU-PRO": 30.010712174940902, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-31T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "allknowingroger/Ph3unsloth-3B-slerp (Merge)"}, {"eval_name": "allknowingroger_Phi3mash1-17B-pass_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/allknowingroger/Phi3mash1-17B-pass\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">allknowingroger/Phi3mash1-17B-pass</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/allknowingroger__Phi3mash1-17B-pass-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "allknowingroger/Phi3mash1-17B-pass", "Model sha": "fcd265996f026475c15fa44833e0481dc610e469", "Average \u2b06\ufe0f": 21.34996880563698, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 16, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.188421166948142, "IFEval": 18.8421166948142, "BBH Raw": 0.6128878795560929, "BBH": 45.25041934691859, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.3196308724832215, "GPQA": 9.284116331096197, "MUSR Raw": 0.445125, "MUSR": 14.840624999999994, "MMLU-PRO Raw": 0.4589428191489361, "MMLU-PRO": 39.882535460992905, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-28T00:00:00", "Submission Date": "2024-09-02T00:00:00", "Generation": 1, "Base Model": "allknowingroger/Phi3mash1-17B-pass (Merge)"}, {"eval_name": "allknowingroger_Quen2-65B_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/allknowingroger/Quen2-65B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">allknowingroger/Quen2-65B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/allknowingroger__Quen2-65B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "allknowingroger/Quen2-65B", "Model sha": "2259cd8ea037d0e590920e7106b0fd1641a96c1d", "Average \u2b06\ufe0f": 3.5313443657802126, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 63, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1757813712061773, "IFEval": 17.57813712061774, "BBH Raw": 0.2756516187232445, "BBH": 1.23986036838978, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.235738255033557, "GPQA": 0.0, "MUSR Raw": 0.3208541666666666, "MUSR": 1.1067708333333328, "MMLU-PRO Raw": 0.1113696808510638, "MMLU-PRO": 1.263297872340425, "Maintainer's Highlight": false, "Upload To Hub Date": "", "Submission Date": "2024-09-19T00:00:00", "Generation": 0, "Base Model": "Removed"}, {"eval_name": "allknowingroger_ROGERphi-7B-slerp_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/allknowingroger/ROGERphi-7B-slerp\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">allknowingroger/ROGERphi-7B-slerp</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/allknowingroger__ROGERphi-7B-slerp-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "allknowingroger/ROGERphi-7B-slerp", "Model sha": "a92f90ae5e4286daa2399df4951a3347aaf414e1", "Average \u2b06\ufe0f": 20.59417776995732, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3861332375873793, "IFEval": 38.61332375873792, "BBH Raw": 0.5195583428468424, "BBH": 32.81903240379116, "MATH Lvl 5 Raw": 0.066465256797583, "MATH Lvl 5": 6.646525679758309, "GPQA Raw": 0.2885906040268456, "GPQA": 5.145413870246088, "MUSR Raw": 0.46853125, "MUSR": 17.53307291666667, "MMLU-PRO Raw": 0.3052692819148936, "MMLU-PRO": 22.807697990543733, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-03-20T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "allknowingroger/ROGERphi-7B-slerp (Merge)"}, {"eval_name": "allknowingroger_RogerMerge-7B-slerp_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/allknowingroger/RogerMerge-7B-slerp\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">allknowingroger/RogerMerge-7B-slerp</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/allknowingroger__RogerMerge-7B-slerp-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "allknowingroger/RogerMerge-7B-slerp", "Model sha": "397f5c0b52a536c130982ca2a7c3056358bbdf92", "Average \u2b06\ufe0f": 19.51703087627596, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3933019942641081, "IFEval": 39.330199426410815, "BBH Raw": 0.5160176493085935, "BBH": 31.98716596760703, "MATH Lvl 5 Raw": 0.0626888217522658, "MATH Lvl 5": 6.268882175226587, "GPQA Raw": 0.2802013422818792, "GPQA": 4.026845637583895, "MUSR Raw": 0.4319791666666666, "MUSR": 12.930729166666673, "MMLU-PRO Raw": 0.3030252659574468, "MMLU-PRO": 22.55836288416076, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-11T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "allknowingroger/RogerMerge-7B-slerp (Merge)"}, {"eval_name": "allknowingroger_Strangecoven-7B-slerp_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/allknowingroger/Strangecoven-7B-slerp\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">allknowingroger/Strangecoven-7B-slerp</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/allknowingroger__Strangecoven-7B-slerp-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "allknowingroger/Strangecoven-7B-slerp", "Model sha": "8bc9d8f972d15fdd3e02c602ef4f549493bf2208", "Average \u2b06\ufe0f": 20.160919653327102, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.37464261492839, "IFEval": 37.464261492839, "BBH Raw": 0.5368022290282338, "BBH": 34.832235357083775, "MATH Lvl 5 Raw": 0.0672205438066465, "MATH Lvl 5": 6.722054380664652, "GPQA Raw": 0.2894295302013422, "GPQA": 5.257270693512303, "MUSR Raw": 0.4198854166666666, "MUSR": 10.419010416666667, "MMLU-PRO Raw": 0.3364361702127659, "MMLU-PRO": 26.27068557919622, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-16T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "allknowingroger/Strangecoven-7B-slerp (Merge)"}, {"eval_name": "allknowingroger_WestlakeMaziyar-7B-slerp_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/allknowingroger/WestlakeMaziyar-7B-slerp\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">allknowingroger/WestlakeMaziyar-7B-slerp</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/allknowingroger__WestlakeMaziyar-7B-slerp-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "allknowingroger/WestlakeMaziyar-7B-slerp", "Model sha": "751534a844b0d439fe62f98bf8882fe9ab9872e0", "Average \u2b06\ufe0f": 22.04494794463608, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4837774881758179, "IFEval": 48.3777488175818, "BBH Raw": 0.5245479952765804, "BBH": 33.34281144377223, "MATH Lvl 5 Raw": 0.0581570996978852, "MATH Lvl 5": 5.81570996978852, "GPQA Raw": 0.3036912751677852, "GPQA": 7.158836689038028, "MUSR Raw": 0.4473854166666666, "MUSR": 14.48984375, "MMLU-PRO Raw": 0.3077626329787234, "MMLU-PRO": 23.084736997635936, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-16T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "allknowingroger/WestlakeMaziyar-7B-slerp (Merge)"}, {"eval_name": "allknowingroger_YamMaths-7B-slerp_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/allknowingroger/YamMaths-7B-slerp\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">allknowingroger/YamMaths-7B-slerp</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/allknowingroger__YamMaths-7B-slerp-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "allknowingroger/YamMaths-7B-slerp", "Model sha": "bd4ac9d63ca88c80d34fa60ef5cbb56d60a39077", "Average \u2b06\ufe0f": 20.37607327140344, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4148093724650594, "IFEval": 41.48093724650594, "BBH Raw": 0.5155845857281723, "BBH": 32.1333222251701, "MATH Lvl 5 Raw": 0.0747734138972809, "MATH Lvl 5": 7.477341389728097, "GPQA Raw": 0.2802013422818792, "GPQA": 4.026845637583895, "MUSR Raw": 0.4383645833333333, "MUSR": 13.462239583333336, "MMLU-PRO Raw": 0.3130817819148936, "MMLU-PRO": 23.675753546099287, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-02T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "allknowingroger/YamMaths-7B-slerp (Merge)"}, {"eval_name": "allknowingroger_Yi-blossom-40B_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/allknowingroger/Yi-blossom-40B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">allknowingroger/Yi-blossom-40B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/allknowingroger__Yi-blossom-40B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "allknowingroger/Yi-blossom-40B", "Model sha": "d1bf1cf9339808193c5a56ef23fecdfd1012acfb", "Average \u2b06\ufe0f": 5.827458303350088, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 18, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2008858717092869, "IFEval": 20.08858717092869, "BBH Raw": 0.3215044225814354, "BBH": 5.539183494900659, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2743288590604026, "GPQA": 3.243847874720355, "MUSR Raw": 0.3842604166666666, "MUSR": 5.199218749999999, "MMLU-PRO Raw": 0.1080452127659574, "MMLU-PRO": 0.8939125295508273, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-15T00:00:00", "Submission Date": "2024-09-19T00:00:00", "Generation": 1, "Base Model": "allknowingroger/Yi-blossom-40B (Merge)"}, {"eval_name": "allknowingroger_Yibuddy-35B_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/allknowingroger/Yibuddy-35B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">allknowingroger/Yibuddy-35B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/allknowingroger__Yibuddy-35B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "allknowingroger/Yibuddy-35B", "Model sha": "592e1e52b97ec88a80ba3b496c19f2498ada4ea3", "Average \u2b06\ufe0f": 27.70411719464045, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 34, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4234774841864032, "IFEval": 42.34774841864032, "BBH Raw": 0.5916185369526096, "BBH": 42.80824233844326, "MATH Lvl 5 Raw": 0.1223564954682779, "MATH Lvl 5": 12.235649546827794, "GPQA Raw": 0.3557046979865771, "GPQA": 14.093959731543624, "MUSR Raw": 0.4504583333333333, "MUSR": 15.973958333333329, "MMLU-PRO Raw": 0.4488863031914893, "MMLU-PRO": 38.765144799054376, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-17T00:00:00", "Submission Date": "2024-10-08T00:00:00", "Generation": 1, "Base Model": "allknowingroger/Yibuddy-35B (Merge)"}, {"eval_name": "allknowingroger_Yillama-40B_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/allknowingroger/Yillama-40B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">allknowingroger/Yillama-40B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/allknowingroger__Yillama-40B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "allknowingroger/Yillama-40B", "Model sha": "65db687755e716481a218cac99d20619d78e41f7", "Average \u2b06\ufe0f": 8.31148742313468, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 34, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1696864320004255, "IFEval": 16.968643200042553, "BBH Raw": 0.4062885537188835, "BBH": 15.875797412234048, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2827181208053691, "GPQA": 4.36241610738255, "MUSR Raw": 0.3500625, "MUSR": 1.7578124999999991, "MMLU-PRO Raw": 0.1981382978723404, "MMLU-PRO": 10.904255319148934, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-16T00:00:00", "Submission Date": "2024-09-19T00:00:00", "Generation": 1, "Base Model": "allknowingroger/Yillama-40B (Merge)"}, {"eval_name": "allknowingroger_Yislerp-34B_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/allknowingroger/Yislerp-34B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">allknowingroger/Yislerp-34B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/allknowingroger__Yislerp-34B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "allknowingroger/Yislerp-34B", "Model sha": "131ad918edd652271510ee8dba63d3e7319df133", "Average \u2b06\ufe0f": 29.059046641801743, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 34, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3691970637907419, "IFEval": 36.91970637907419, "BBH Raw": 0.6158722731484186, "BBH": 45.9816957285586, "MATH Lvl 5 Raw": 0.195619335347432, "MATH Lvl 5": 19.561933534743204, "GPQA Raw": 0.3582214765100671, "GPQA": 14.429530201342288, "MUSR Raw": 0.456625, "MUSR": 15.778125000000005, "MMLU-PRO Raw": 0.4751496010638298, "MMLU-PRO": 41.68328900709219, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-16T00:00:00", "Submission Date": "2024-09-19T00:00:00", "Generation": 1, "Base Model": "allknowingroger/Yislerp-34B (Merge)"}, {"eval_name": "allknowingroger_Yislerp2-34B_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/allknowingroger/Yislerp2-34B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">allknowingroger/Yislerp2-34B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/allknowingroger__Yislerp2-34B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "allknowingroger/Yislerp2-34B", "Model sha": "3147cf866736b786347928b655c887e8b9c07bfc", "Average \u2b06\ufe0f": 30.10657407002722, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 34, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3999465861691423, "IFEval": 39.99465861691424, "BBH Raw": 0.6245771970170245, "BBH": 47.20230580445542, "MATH Lvl 5 Raw": 0.2099697885196374, "MATH Lvl 5": 20.996978851963743, "GPQA Raw": 0.3640939597315436, "GPQA": 15.212527964205815, "MUSR Raw": 0.45296875, "MUSR": 15.854427083333327, "MMLU-PRO Raw": 0.472406914893617, "MMLU-PRO": 41.37854609929077, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-17T00:00:00", "Submission Date": "2024-10-08T00:00:00", "Generation": 1, "Base Model": "allknowingroger/Yislerp2-34B (Merge)"}, {"eval_name": "allknowingroger_Yunconglong-13B-slerp_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/allknowingroger/Yunconglong-13B-slerp\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">allknowingroger/Yunconglong-13B-slerp</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/allknowingroger__Yunconglong-13B-slerp-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "allknowingroger/Yunconglong-13B-slerp", "Model sha": "dead687b7342d875bd8ac73bfcd34b88a2e5564c", "Average \u2b06\ufe0f": 19.48681112928892, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4241767399389176, "IFEval": 42.41767399389176, "BBH Raw": 0.5165807158493828, "BBH": 32.14072892807635, "MATH Lvl 5 Raw": 0.0475830815709969, "MATH Lvl 5": 4.758308157099698, "GPQA Raw": 0.2810402684563758, "GPQA": 4.138702460850116, "MUSR Raw": 0.4160729166666666, "MUSR": 10.842447916666664, "MMLU-PRO Raw": 0.3036070478723404, "MMLU-PRO": 22.623005319148938, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-25T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "allknowingroger/Yunconglong-13B-slerp (Merge)"}, {"eval_name": "allknowingroger_limyClown-7B-slerp_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/allknowingroger/limyClown-7B-slerp\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">allknowingroger/limyClown-7B-slerp</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/allknowingroger__limyClown-7B-slerp-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "allknowingroger/limyClown-7B-slerp", "Model sha": "732a1ed0c2c7007297ad9d9797793073825f65ca", "Average \u2b06\ufe0f": 19.62835999388974, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4017451473202215, "IFEval": 40.17451473202215, "BBH Raw": 0.5147517317055973, "BBH": 31.9314661071385, "MATH Lvl 5 Raw": 0.0641993957703927, "MATH Lvl 5": 6.419939577039275, "GPQA Raw": 0.2810402684563758, "GPQA": 4.138702460850116, "MUSR Raw": 0.4293125, "MUSR": 12.464062500000004, "MMLU-PRO Raw": 0.3037732712765957, "MMLU-PRO": 22.64147458628841, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-03-23T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "allknowingroger/limyClown-7B-slerp (Merge)"}, {"eval_name": "allknowingroger_llama3-Jallabi-40B-s_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/allknowingroger/llama3-Jallabi-40B-s\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">allknowingroger/llama3-Jallabi-40B-s</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/allknowingroger__llama3-Jallabi-40B-s-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "allknowingroger/llama3-Jallabi-40B-s", "Model sha": "a86d8cc3530fb466245b2cac55f25c28d0bd8c22", "Average \u2b06\ufe0f": 5.029701636906855, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 18, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.192068156934711, "IFEval": 19.2068156934711, "BBH Raw": 0.3252242419852629, "BBH": 5.957911562958214, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2374161073825503, "GPQA": 0.0, "MUSR Raw": 0.3749583333333333, "MUSR": 4.036458333333333, "MMLU-PRO Raw": 0.1087932180851063, "MMLU-PRO": 0.9770242316784856, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-15T00:00:00", "Submission Date": "2024-09-19T00:00:00", "Generation": 1, "Base Model": "allknowingroger/llama3-Jallabi-40B-s (Merge)"}, {"eval_name": "allknowingroger_llama3AnFeng-40B_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/allknowingroger/llama3AnFeng-40B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">allknowingroger/llama3AnFeng-40B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/allknowingroger__llama3AnFeng-40B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "allknowingroger/llama3AnFeng-40B", "Model sha": "5995441962287970ffc98ad9b292e14420bf49ca", "Average \u2b06\ufe0f": 9.237994378100716, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 39, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1742077687203287, "IFEval": 17.42077687203287, "BBH Raw": 0.3794080447660335, "BBH": 12.476996185725282, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.3062080536912752, "GPQA": 7.494407158836691, "MUSR Raw": 0.3939999999999999, "MUSR": 7.149999999999999, "MMLU-PRO Raw": 0.1979720744680851, "MMLU-PRO": 10.885786052009454, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-13T00:00:00", "Submission Date": "2024-09-19T00:00:00", "Generation": 1, "Base Model": "allknowingroger/llama3AnFeng-40B (Merge)"}, {"eval_name": "allura-org_MoE-Girl-1BA-7BT_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "OlmoeForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/allura-org/MoE-Girl-1BA-7BT\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">allura-org/MoE-Girl-1BA-7BT</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/allura-org__MoE-Girl-1BA-7BT-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "allura-org/MoE-Girl-1BA-7BT", "Model sha": "ecfac73ab9e7f2ee006d6a2ad9c8e86a85deab2b", "Average \u2b06\ufe0f": 6.377622874144957, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 6, "#Params (B)": 6, "Available on the hub": true, "Not_Merged": true, "MoE": false, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2705033754881492, "IFEval": 27.050337548814923, "BBH Raw": 0.3139175363262408, "BBH": 4.8423440285205, "MATH Lvl 5 Raw": 0.0135951661631419, "MATH Lvl 5": 1.3595166163141994, "GPQA Raw": 0.2583892617449664, "GPQA": 1.1185682326621946, "MUSR Raw": 0.3435520833333333, "MUSR": 1.47734375, "MMLU-PRO Raw": 0.1217586436170212, "MMLU-PRO": 2.4176270685579198, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-08T00:00:00", "Submission Date": "2024-10-10T00:00:00", "Generation": 1, "Base Model": "allenai/OLMoE-1B-7B-0924"}, {"eval_name": "aloobun_Meta-Llama-3-7B-28Layers_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/aloobun/Meta-Llama-3-7B-28Layers\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">aloobun/Meta-Llama-3-7B-28Layers</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/aloobun__Meta-Llama-3-7B-28Layers-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "aloobun/Meta-Llama-3-7B-28Layers", "Model sha": "9822e6b8d4de0c0f2964d299f6fcef72385a0341", "Average \u2b06\ufe0f": 13.136516078457651, "Hub License": "llama3", "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1963645349893837, "IFEval": 19.636453498938373, "BBH Raw": 0.4437497014253391, "BBH": 22.096530251343516, "MATH Lvl 5 Raw": 0.0135951661631419, "MATH Lvl 5": 1.3595166163141994, "GPQA Raw": 0.2944630872483221, "GPQA": 5.92841163310962, "MUSR Raw": 0.3589270833333333, "MUSR": 5.7992187500000005, "MMLU-PRO Raw": 0.3159906914893617, "MMLU-PRO": 23.99896572104019, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-10T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "aloobun/Meta-Llama-3-7B-28Layers (Merge)"}, {"eval_name": "alpindale_WizardLM-2-8x22B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/alpindale/WizardLM-2-8x22B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">alpindale/WizardLM-2-8x22B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/alpindale__WizardLM-2-8x22B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "alpindale/WizardLM-2-8x22B", "Model sha": "087834da175523cffd66a7e19583725e798c1b4f", "Average \u2b06\ufe0f": 32.60587963230125, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 384, "#Params (B)": 140, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.5272166739805937, "IFEval": 52.72166739805937, "BBH Raw": 0.6377307938917097, "BBH": 48.57616817936264, "MATH Lvl 5 Raw": 0.222809667673716, "MATH Lvl 5": 22.2809667673716, "GPQA Raw": 0.3817114093959731, "GPQA": 17.561521252796418, "MUSR Raw": 0.4387083333333333, "MUSR": 14.538541666666667, "MMLU-PRO Raw": 0.4596077127659574, "MMLU-PRO": 39.95641252955083, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-16T00:00:00", "Submission Date": "2024-06-28T00:00:00", "Generation": 0, "Base Model": "alpindale/WizardLM-2-8x22B"}, {"eval_name": "alpindale_magnum-72b-v1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/alpindale/magnum-72b-v1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">alpindale/magnum-72b-v1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/alpindale__magnum-72b-v1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "alpindale/magnum-72b-v1", "Model sha": "fef27e0f235ae8858b84b765db773a2a954110dd", "Average \u2b06\ufe0f": 42.173767736520254, "Hub License": "other", "Hub \u2764\ufe0f": 160, "#Params (B)": 72, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7606484128778308, "IFEval": 76.06484128778308, "BBH Raw": 0.6982215794373214, "BBH": 57.65318485514271, "MATH Lvl 5 Raw": 0.3527190332326284, "MATH Lvl 5": 35.27190332326284, "GPQA Raw": 0.3909395973154362, "GPQA": 18.791946308724835, "MUSR Raw": 0.4489375, "MUSR": 15.617187499999998, "MMLU-PRO Raw": 0.5467918882978723, "MMLU-PRO": 49.64354314420804, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-17T00:00:00", "Submission Date": "2024-07-25T00:00:00", "Generation": 2, "Base Model": "Qwen/Qwen2-72B"}, {"eval_name": "altomek_YiSM-34B-0rn_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/altomek/YiSM-34B-0rn\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">altomek/YiSM-34B-0rn</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/altomek__YiSM-34B-0rn-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "altomek/YiSM-34B-0rn", "Model sha": "7a481c67cbdd5c846d6aaab5ef9f1eebfad812c2", "Average \u2b06\ufe0f": 30.146957020628463, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 34, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.428373382624769, "IFEval": 42.83733826247689, "BBH Raw": 0.6140009573868866, "BBH": 45.38292724900714, "MATH Lvl 5 Raw": 0.2061933534743202, "MATH Lvl 5": 20.619335347432024, "GPQA Raw": 0.3716442953020134, "GPQA": 16.21923937360179, "MUSR Raw": 0.445, "MUSR": 14.758333333333333, "MMLU-PRO Raw": 0.4695811170212766, "MMLU-PRO": 41.06456855791962, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-26T00:00:00", "Submission Date": "2024-06-27T00:00:00", "Generation": 1, "Base Model": "altomek/YiSM-34B-0rn (Merge)"}, {"eval_name": "amazon_MegaBeam-Mistral-7B-300k_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/amazon/MegaBeam-Mistral-7B-300k\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">amazon/MegaBeam-Mistral-7B-300k</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/amazon__MegaBeam-Mistral-7B-300k-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "amazon/MegaBeam-Mistral-7B-300k", "Model sha": "42572e5c9a0747b19af5c5c9962d122622f32295", "Average \u2b06\ufe0f": 17.022470504123003, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 15, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.520347123410329, "IFEval": 52.0347123410329, "BBH Raw": 0.4227731731112974, "BBH": 19.291805959592, "MATH Lvl 5 Raw": 0.0211480362537764, "MATH Lvl 5": 2.114803625377644, "GPQA Raw": 0.273489932885906, "GPQA": 3.1319910514541416, "MUSR Raw": 0.3979999999999999, "MUSR": 8.350000000000003, "MMLU-PRO Raw": 0.2549035904255319, "MMLU-PRO": 17.211510047281322, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-13T00:00:00", "Submission Date": "2024-10-07T00:00:00", "Generation": 0, "Base Model": "amazon/MegaBeam-Mistral-7B-300k"}, {"eval_name": "amd_AMD-Llama-135m_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/amd/AMD-Llama-135m\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">amd/AMD-Llama-135m</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/amd__AMD-Llama-135m-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "amd/AMD-Llama-135m", "Model sha": "8f9c39b5ed86d422ab332ed1ecf042fdaeb57903", "Average \u2b06\ufe0f": 4.759627159992882, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 102, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1842245242622907, "IFEval": 18.42245242622907, "BBH Raw": 0.2973931917569524, "BBH": 2.4854950529752244, "MATH Lvl 5 Raw": 0.0052870090634441, "MATH Lvl 5": 0.5287009063444109, "GPQA Raw": 0.2525167785234899, "GPQA": 0.3355704697986553, "MUSR Raw": 0.3779687499999999, "MUSR": 4.912760416666667, "MMLU-PRO Raw": 0.1168550531914893, "MMLU-PRO": 1.8727836879432624, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-07-19T00:00:00", "Submission Date": "2024-09-29T00:00:00", "Generation": 0, "Base Model": "amd/AMD-Llama-135m"}, {"eval_name": "amd_AMD-Llama-135m_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/amd/AMD-Llama-135m\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">amd/AMD-Llama-135m</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/amd__AMD-Llama-135m-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "amd/AMD-Llama-135m", "Model sha": "8f9c39b5ed86d422ab332ed1ecf042fdaeb57903", "Average \u2b06\ufe0f": 5.191212208507016, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 102, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1918431982694805, "IFEval": 19.18431982694805, "BBH Raw": 0.2969444974878025, "BBH": 2.537952680477511, "MATH Lvl 5 Raw": 0.0052870090634441, "MATH Lvl 5": 0.5287009063444109, "GPQA Raw": 0.2583892617449664, "GPQA": 1.1185682326621946, "MUSR Raw": 0.3845729166666666, "MUSR": 5.904947916666668, "MMLU-PRO Raw": 0.1168550531914893, "MMLU-PRO": 1.8727836879432624, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-07-19T00:00:00", "Submission Date": "2024-10-01T00:00:00", "Generation": 0, "Base Model": "amd/AMD-Llama-135m"}, {"eval_name": "anakin87_gemma-2b-orpo_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "GemmaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/anakin87/gemma-2b-orpo\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">anakin87/gemma-2b-orpo</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/anakin87__gemma-2b-orpo-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "anakin87/gemma-2b-orpo", "Model sha": "bf6bfe30c31c18620767ad60d0bff89343804230", "Average \u2b06\ufe0f": 7.171413177265958, "Hub License": "other", "Hub \u2764\ufe0f": 27, "#Params (B)": 2, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2477969565198118, "IFEval": 24.779695651981186, "BBH Raw": 0.3426170943561775, "BBH": 7.94944502776896, "MATH Lvl 5 Raw": 0.0120845921450151, "MATH Lvl 5": 1.2084592145015105, "GPQA Raw": 0.261744966442953, "GPQA": 1.5659955257270708, "MUSR Raw": 0.3727604166666666, "MUSR": 4.128385416666667, "MMLU-PRO Raw": 0.1305684840425532, "MMLU-PRO": 3.3964982269503543, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-03-24T00:00:00", "Submission Date": "2024-07-06T00:00:00", "Generation": 1, "Base Model": "google/gemma-2b"}, {"eval_name": "anthracite-org_magnum-v1-72b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/anthracite-org/magnum-v1-72b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">anthracite-org/magnum-v1-72b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/anthracite-org__magnum-v1-72b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "anthracite-org/magnum-v1-72b", "Model sha": "f8f85021bace7e8250ed8559c5b78b8b34f0c4cc", "Average \u2b06\ufe0f": 42.2076280596093, "Hub License": "other", "Hub \u2764\ufe0f": 160, "#Params (B)": 72, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7606484128778308, "IFEval": 76.06484128778308, "BBH Raw": 0.6982215794373214, "BBH": 57.65318485514271, "MATH Lvl 5 Raw": 0.3527190332326284, "MATH Lvl 5": 35.27190332326284, "GPQA Raw": 0.3909395973154362, "GPQA": 18.791946308724835, "MUSR Raw": 0.4489375, "MUSR": 15.617187499999998, "MMLU-PRO Raw": 0.5486203457446809, "MMLU-PRO": 49.84670508274232, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-17T00:00:00", "Submission Date": "2024-09-21T00:00:00", "Generation": 2, "Base Model": "Qwen/Qwen2-72B"}, {"eval_name": "anthracite-org_magnum-v2-12b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/anthracite-org/magnum-v2-12b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">anthracite-org/magnum-v2-12b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/anthracite-org__magnum-v2-12b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "anthracite-org/magnum-v2-12b", "Model sha": null, "Average \u2b06\ufe0f": 18.68252851199905, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 74, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.376166349729828, "IFEval": 37.6166349729828, "BBH Raw": 0.5020864013200114, "BBH": 28.785551595365877, "MATH Lvl 5 Raw": 0.0475830815709969, "MATH Lvl 5": 4.758308157099698, "GPQA Raw": 0.2911073825503356, "GPQA": 5.480984340044745, "MUSR Raw": 0.41790625, "MUSR": 11.371614583333336, "MMLU-PRO Raw": 0.3167386968085106, "MMLU-PRO": 24.08207742316785, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-03T00:00:00", "Submission Date": "2024-09-05T00:00:00", "Generation": 1, "Base Model": "mistralai/Mistral-Nemo-Base-2407"}, {"eval_name": "anthracite-org_magnum-v2-72b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/anthracite-org/magnum-v2-72b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">anthracite-org/magnum-v2-72b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/anthracite-org__magnum-v2-72b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "anthracite-org/magnum-v2-72b", "Model sha": "c9c5826ef42b9fcc8a8e1079be574481cf0b6cc6", "Average \u2b06\ufe0f": 41.1534664260354, "Hub License": "other", "Hub \u2764\ufe0f": 31, "#Params (B)": 72, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7560273407891063, "IFEval": 75.60273407891063, "BBH Raw": 0.7005076514129516, "BBH": 57.85470432085098, "MATH Lvl 5 Raw": 0.3164652567975831, "MATH Lvl 5": 31.64652567975831, "GPQA Raw": 0.3859060402684564, "GPQA": 18.12080536912752, "MUSR Raw": 0.4371875, "MUSR": 14.181770833333331, "MMLU-PRO Raw": 0.5456283244680851, "MMLU-PRO": 49.51425827423168, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-18T00:00:00", "Submission Date": "2024-09-05T00:00:00", "Generation": 2, "Base Model": "Qwen/Qwen2-72B"}, {"eval_name": "anthracite-org_magnum-v2.5-12b-kto_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/anthracite-org/magnum-v2.5-12b-kto\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">anthracite-org/magnum-v2.5-12b-kto</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/anthracite-org__magnum-v2.5-12b-kto-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "anthracite-org/magnum-v2.5-12b-kto", "Model sha": "aee0374e5a43e950c9977b0004dede1c57be2999", "Average \u2b06\ufe0f": 18.85690882138339, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 39, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3865576669902525, "IFEval": 38.65576669902525, "BBH Raw": 0.5076961186254344, "BBH": 29.625059445981027, "MATH Lvl 5 Raw": 0.0445619335347432, "MATH Lvl 5": 4.45619335347432, "GPQA Raw": 0.2936241610738255, "GPQA": 5.8165548098434, "MUSR Raw": 0.4086354166666666, "MUSR": 9.979427083333336, "MMLU-PRO Raw": 0.3214760638297872, "MMLU-PRO": 24.608451536643024, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-12T00:00:00", "Submission Date": "2024-08-29T00:00:00", "Generation": 2, "Base Model": "mistralai/Mistral-Nemo-Base-2407"}, {"eval_name": "anthracite-org_magnum-v3-27b-kto_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/anthracite-org/magnum-v3-27b-kto\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">anthracite-org/magnum-v3-27b-kto</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/anthracite-org__magnum-v3-27b-kto-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "anthracite-org/magnum-v3-27b-kto", "Model sha": "96fbb750b3150e5fe9d6d2fcf757f49310d99a43", "Average \u2b06\ufe0f": 28.8964959291872, "Hub License": "gemma", "Hub \u2764\ufe0f": 11, "#Params (B)": 27, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5674831668860845, "IFEval": 56.74831668860845, "BBH Raw": 0.586040577894583, "BBH": 41.1601029248443, "MATH Lvl 5 Raw": 0.154833836858006, "MATH Lvl 5": 15.483383685800604, "GPQA Raw": 0.3557046979865771, "GPQA": 14.093959731543624, "MUSR Raw": 0.3854687499999999, "MUSR": 9.916927083333327, "MMLU-PRO Raw": 0.4237865691489361, "MMLU-PRO": 35.976285460992905, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-06T00:00:00", "Submission Date": "2024-09-15T00:00:00", "Generation": 1, "Base Model": "anthracite-org/magnum-v3-27b-kto (Merge)"}, {"eval_name": "anthracite-org_magnum-v3-34b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/anthracite-org/magnum-v3-34b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">anthracite-org/magnum-v3-34b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/anthracite-org__magnum-v3-34b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "anthracite-org/magnum-v3-34b", "Model sha": "3bcd8c3dbb93021a5ce22203c690a1a084cafb73", "Average \u2b06\ufe0f": 29.38914276453973, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 27, "#Params (B)": 34, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5115294086357531, "IFEval": 51.15294086357531, "BBH Raw": 0.6087828692085228, "BBH": 44.32790341462959, "MATH Lvl 5 Raw": 0.1782477341389728, "MATH Lvl 5": 17.82477341389728, "GPQA Raw": 0.360738255033557, "GPQA": 14.76510067114094, "MUSR Raw": 0.3872395833333333, "MUSR": 6.571614583333336, "MMLU-PRO Raw": 0.4752327127659574, "MMLU-PRO": 41.692523640661946, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-22T00:00:00", "Submission Date": "2024-09-18T00:00:00", "Generation": 0, "Base Model": "anthracite-org/magnum-v3-34b"}, {"eval_name": "anthracite-org_magnum-v3-9b-chatml_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/anthracite-org/magnum-v3-9b-chatml\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">anthracite-org/magnum-v3-9b-chatml</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/anthracite-org__magnum-v3-9b-chatml-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "anthracite-org/magnum-v3-9b-chatml", "Model sha": "96c2d023c56ef73be095ffbae8cedd7243ebca84", "Average \u2b06\ufe0f": 19.290118383367403, "Hub License": "gemma", "Hub \u2764\ufe0f": 21, "#Params (B)": 9, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1274706667198588, "IFEval": 12.747066671985886, "BBH Raw": 0.5427688488887096, "BBH": 35.31787541238543, "MATH Lvl 5 Raw": 0.0566465256797583, "MATH Lvl 5": 5.664652567975831, "GPQA Raw": 0.3456375838926174, "GPQA": 12.751677852348994, "MUSR Raw": 0.4432291666666666, "MUSR": 13.236979166666666, "MMLU-PRO Raw": 0.4242021276595745, "MMLU-PRO": 36.022458628841605, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-27T00:00:00", "Submission Date": "2024-09-18T00:00:00", "Generation": 1, "Base Model": "IntervitensInc/gemma-2-9b-chatml"}, {"eval_name": "anthracite-org_magnum-v3-9b-customgemma2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/anthracite-org/magnum-v3-9b-customgemma2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">anthracite-org/magnum-v3-9b-customgemma2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/anthracite-org__magnum-v3-9b-customgemma2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "anthracite-org/magnum-v3-9b-customgemma2", "Model sha": "9a7cd3d47434bed2bd80e34e45c74e413f8baaa8", "Average \u2b06\ufe0f": 19.02403349058159, "Hub License": "gemma", "Hub \u2764\ufe0f": 15, "#Params (B)": 9, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1272955757390391, "IFEval": 12.729557573903907, "BBH Raw": 0.5340136936916174, "BBH": 34.11678334094384, "MATH Lvl 5 Raw": 0.0611782477341389, "MATH Lvl 5": 6.117824773413897, "GPQA Raw": 0.3288590604026846, "GPQA": 10.514541387024613, "MUSR Raw": 0.45646875, "MUSR": 15.058593749999998, "MMLU-PRO Raw": 0.4204621010638298, "MMLU-PRO": 35.606900118203306, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-27T00:00:00", "Submission Date": "2024-09-18T00:00:00", "Generation": 1, "Base Model": "google/gemma-2-9b"}, {"eval_name": "apple_DCLM-7B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "OpenLMModel", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/apple/DCLM-7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">apple/DCLM-7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/apple__DCLM-7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "apple/DCLM-7B", "Model sha": "c85bfa168f999ce27e954808bc005a2748fda5c5", "Average \u2b06\ufe0f": 13.986977121551304, "Hub License": "apple-ascl", "Hub \u2764\ufe0f": 817, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2172723928066419, "IFEval": 21.727239280664197, "BBH Raw": 0.4232142366818416, "BBH": 19.760934974772244, "MATH Lvl 5 Raw": 0.0294561933534743, "MATH Lvl 5": 2.9456193353474323, "GPQA Raw": 0.3154362416107382, "GPQA": 8.7248322147651, "MUSR Raw": 0.3920729166666667, "MUSR": 7.309114583333334, "MMLU-PRO Raw": 0.3110871010638298, "MMLU-PRO": 23.45412234042553, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-11T00:00:00", "Submission Date": "2024-08-16T00:00:00", "Generation": 0, "Base Model": "apple/DCLM-7B"}, {"eval_name": "arcee-ai_Arcee-Nova_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/arcee-ai/Arcee-Nova\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">arcee-ai/Arcee-Nova</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/arcee-ai__Arcee-Nova-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "arcee-ai/Arcee-Nova", "Model sha": "ec3bfe88b83f81481daa04b6789c1e0d32827dc5", "Average \u2b06\ufe0f": 43.49951548828528, "Hub License": "other", "Hub \u2764\ufe0f": 38, "#Params (B)": 72, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7907485471881275, "IFEval": 79.07485471881274, "BBH Raw": 0.694196965855899, "BBH": 56.74098753952074, "MATH Lvl 5 Raw": 0.404833836858006, "MATH Lvl 5": 40.48338368580061, "GPQA Raw": 0.3850671140939597, "GPQA": 18.008948545861294, "MUSR Raw": 0.4561666666666666, "MUSR": 17.220833333333328, "MMLU-PRO Raw": 0.5452127659574468, "MMLU-PRO": 49.46808510638298, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-16T00:00:00", "Submission Date": "2024-09-19T00:00:00", "Generation": 0, "Base Model": "arcee-ai/Arcee-Nova"}, {"eval_name": "arcee-ai_Arcee-Spark_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/arcee-ai/Arcee-Spark\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">arcee-ai/Arcee-Spark</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/arcee-ai__Arcee-Spark-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "arcee-ai/Arcee-Spark", "Model sha": "3fe368ea5fd32bc4a8d1bcf42510416f7fa28668", "Average \u2b06\ufe0f": 25.53645563140378, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 85, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5620874834328471, "IFEval": 56.208748343284704, "BBH Raw": 0.5489474198567446, "BBH": 37.13852245584468, "MATH Lvl 5 Raw": 0.1231117824773413, "MATH Lvl 5": 12.31117824773414, "GPQA Raw": 0.3070469798657718, "GPQA": 7.606263982102905, "MUSR Raw": 0.4020937499999999, "MUSR": 8.595052083333334, "MMLU-PRO Raw": 0.3822307180851064, "MMLU-PRO": 31.358968676122927, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-22T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "arcee-ai/Arcee-Spark"}, {"eval_name": "arcee-ai_Arcee-Spark_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/arcee-ai/Arcee-Spark\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">arcee-ai/Arcee-Spark</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/arcee-ai__Arcee-Spark-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "arcee-ai/Arcee-Spark", "Model sha": "3fe368ea5fd32bc4a8d1bcf42510416f7fa28668", "Average \u2b06\ufe0f": 25.329875696018075, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 85, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.571829412625168, "IFEval": 57.18294126251679, "BBH Raw": 0.5480864114714127, "BBH": 36.92439043586489, "MATH Lvl 5 Raw": 0.107250755287009, "MATH Lvl 5": 10.725075528700906, "GPQA Raw": 0.3062080536912752, "GPQA": 7.494407158836691, "MUSR Raw": 0.4007604166666667, "MUSR": 8.395052083333335, "MMLU-PRO Raw": 0.3813164893617021, "MMLU-PRO": 31.257387706855795, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-22T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "arcee-ai/Arcee-Spark"}, {"eval_name": "arcee-ai_Llama-3.1-SuperNova-Lite_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/arcee-ai/Llama-3.1-SuperNova-Lite\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">arcee-ai/Llama-3.1-SuperNova-Lite</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/arcee-ai__Llama-3.1-SuperNova-Lite-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "arcee-ai/Llama-3.1-SuperNova-Lite", "Model sha": "76246ca4448c1a11787daee0958b60ab27f17774", "Average \u2b06\ufe0f": 29.72770365820581, "Hub License": "llama3", "Hub \u2764\ufe0f": 165, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.8017393848322452, "IFEval": 80.1739384832245, "BBH Raw": 0.5151992115104819, "BBH": 31.572340212980667, "MATH Lvl 5 Raw": 0.154833836858006, "MATH Lvl 5": 15.483383685800604, "GPQA Raw": 0.3062080536912752, "GPQA": 7.494407158836691, "MUSR Raw": 0.4163229166666666, "MUSR": 11.673697916666663, "MMLU-PRO Raw": 0.3877160904255319, "MMLU-PRO": 31.96845449172577, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-10T00:00:00", "Submission Date": "2024-09-17T00:00:00", "Generation": 2, "Base Model": "meta-llama/Meta-Llama-3.1-8B"}, {"eval_name": "arcee-ai_Llama-Spark_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/arcee-ai/Llama-Spark\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">arcee-ai/Llama-Spark</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/arcee-ai__Llama-Spark-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "arcee-ai/Llama-Spark", "Model sha": "6d74a617fbb17a1ada08528f2673c89f84fb062e", "Average \u2b06\ufe0f": 24.89725704251728, "Hub License": "llama3", "Hub \u2764\ufe0f": 25, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7910732412221794, "IFEval": 79.10732412221793, "BBH Raw": 0.5053504145749979, "BBH": 29.77025370020864, "MATH Lvl 5 Raw": 0.0105740181268882, "MATH Lvl 5": 1.0574018126888218, "GPQA Raw": 0.299496644295302, "GPQA": 6.599552572706939, "MUSR Raw": 0.3593333333333333, "MUSR": 2.6166666666666667, "MMLU-PRO Raw": 0.3720910904255319, "MMLU-PRO": 30.232343380614655, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-26T00:00:00", "Submission Date": "2024-08-08T00:00:00", "Generation": 0, "Base Model": "arcee-ai/Llama-Spark"}, {"eval_name": "arcee-ai_SuperNova-Medius_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/arcee-ai/SuperNova-Medius\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">arcee-ai/SuperNova-Medius</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/arcee-ai__SuperNova-Medius-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "arcee-ai/SuperNova-Medius", "Model sha": "e34fafcac2801be1ae5c7eb744e191a08119f2af", "Average \u2b06\ufe0f": 37.21621704079038, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 91, "#Params (B)": 14, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.5560180321546829, "IFEval": 55.60180321546829, "BBH Raw": 0.6495063137600597, "BBH": 49.3042330268799, "MATH Lvl 5 Raw": 0.324773413897281, "MATH Lvl 5": 32.477341389728096, "GPQA Raw": 0.384228187919463, "GPQA": 17.897091722595075, "MUSR Raw": 0.4766875, "MUSR": 19.185937499999994, "MMLU-PRO Raw": 0.5394780585106383, "MMLU-PRO": 48.83089539007093, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-02T00:00:00", "Submission Date": "2024-10-12T00:00:00", "Generation": 1, "Base Model": "arcee-ai/SuperNova-Medius (Merge)"}, {"eval_name": "arcee-ai_raspberry-3B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/arcee-ai/raspberry-3B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">arcee-ai/raspberry-3B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/arcee-ai__raspberry-3B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "arcee-ai/raspberry-3B", "Model sha": "66bf1346c060bbfe1f1b98cd22e7a26ada69cf70", "Average \u2b06\ufe0f": 15.399533836448269, "Hub License": "other", "Hub \u2764\ufe0f": 36, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3154164284099522, "IFEval": 31.541642840995227, "BBH Raw": 0.4268928018882703, "BBH": 19.528234400992485, "MATH Lvl 5 Raw": 0.0762839879154078, "MATH Lvl 5": 7.628398791540786, "GPQA Raw": 0.2776845637583892, "GPQA": 3.691275167785232, "MUSR Raw": 0.4123229166666666, "MUSR": 9.40703125, "MMLU-PRO Raw": 0.285405585106383, "MMLU-PRO": 20.600620567375884, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-05T00:00:00", "Submission Date": "2024-10-07T00:00:00", "Generation": 1, "Base Model": "Qwen/Qwen2.5-3B"}, {"eval_name": "argilla_notus-7b-v1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/argilla/notus-7b-v1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">argilla/notus-7b-v1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/argilla__notus-7b-v1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "argilla/notus-7b-v1", "Model sha": "30172203a2d41cb487bf7e2b92a821080783b2c9", "Average \u2b06\ufe0f": 18.373556838401463, "Hub License": "mit", "Hub \u2764\ufe0f": 121, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.508207112683236, "IFEval": 50.820711268323606, "BBH Raw": 0.4511857407381495, "BBH": 22.74711196116141, "MATH Lvl 5 Raw": 0.0256797583081571, "MATH Lvl 5": 2.56797583081571, "GPQA Raw": 0.2894295302013422, "GPQA": 5.257270693512303, "MUSR Raw": 0.3364166666666666, "MUSR": 6.58541666666667, "MMLU-PRO Raw": 0.3003656914893617, "MMLU-PRO": 22.26285460992908, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-11-16T00:00:00", "Submission Date": "2024-06-27T00:00:00", "Generation": 2, "Base Model": "mistralai/Mistral-7B-v0.1"}, {"eval_name": "argilla_notux-8x7b-v1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/argilla/notux-8x7b-v1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">argilla/notux-8x7b-v1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/argilla__notux-8x7b-v1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "argilla/notux-8x7b-v1", "Model sha": "0b29f9afcbae2ab4c5085638d8f5a7f6d44c6b17", "Average \u2b06\ufe0f": 24.22682122656316, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 165, "#Params (B)": 46, "Available on the hub": true, "Not_Merged": true, "MoE": false, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5422290633297429, "IFEval": 54.22290633297429, "BBH Raw": 0.5363304164516353, "BBH": 34.75806168290175, "MATH Lvl 5 Raw": 0.0845921450151057, "MATH Lvl 5": 8.459214501510575, "GPQA Raw": 0.3087248322147651, "GPQA": 7.829977628635347, "MUSR Raw": 0.41759375, "MUSR": 10.532552083333334, "MMLU-PRO Raw": 0.3660239361702128, "MMLU-PRO": 29.558215130023648, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-12-12T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 2, "Base Model": "mistralai/Mixtral-8x7B-v0.1"}, {"eval_name": "argilla-warehouse_Llama-3.1-8B-MagPie-Ultra_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/argilla-warehouse/Llama-3.1-8B-MagPie-Ultra\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">argilla-warehouse/Llama-3.1-8B-MagPie-Ultra</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/argilla-warehouse__Llama-3.1-8B-MagPie-Ultra-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "argilla-warehouse/Llama-3.1-8B-MagPie-Ultra", "Model sha": "1e12f20ca5db84f65a6db793a65100433aac0ac6", "Average \u2b06\ufe0f": 19.45875971727332, "Hub License": "llama3.1", "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5756514935925566, "IFEval": 57.565149359255656, "BBH Raw": 0.4619613463446861, "BBH": 23.51631036482765, "MATH Lvl 5 Raw": 0.0536253776435045, "MATH Lvl 5": 5.362537764350453, "GPQA Raw": 0.2667785234899328, "GPQA": 2.2371364653243813, "MUSR Raw": 0.35425, "MUSR": 4.247916666666669, "MMLU-PRO Raw": 0.3144115691489361, "MMLU-PRO": 23.823507683215126, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-09-26T00:00:00", "Submission Date": "2024-09-30T00:00:00", "Generation": 1, "Base Model": "meta-llama/Llama-3.1-8B"}, {"eval_name": "athirdpath_Llama-3.1-Instruct_NSFW-pretrained_e1-plus_reddit_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/athirdpath/Llama-3.1-Instruct_NSFW-pretrained_e1-plus_reddit\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">athirdpath/Llama-3.1-Instruct_NSFW-pretrained_e1-plus_reddit</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/athirdpath__Llama-3.1-Instruct_NSFW-pretrained_e1-plus_reddit-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "athirdpath/Llama-3.1-Instruct_NSFW-pretrained_e1-plus_reddit", "Model sha": "42eaee4de10302fec7c0c20ad96f527cfb0b10a3", "Average \u2b06\ufe0f": 20.74194912684736, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4521037513796726, "IFEval": 45.21037513796726, "BBH Raw": 0.4939066588253951, "BBH": 28.01590901759341, "MATH Lvl 5 Raw": 0.0883685800604229, "MATH Lvl 5": 8.836858006042297, "GPQA Raw": 0.2919463087248322, "GPQA": 5.592841163310966, "MUSR Raw": 0.3863958333333333, "MUSR": 8.299479166666666, "MMLU-PRO Raw": 0.3564660904255319, "MMLU-PRO": 28.496232269503547, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-30T00:00:00", "Submission Date": "2024-08-01T00:00:00", "Generation": 1, "Base Model": "athirdpath/Llama-3.1-Instruct_NSFW-pretrained_e1"}, {"eval_name": "automerger_YamshadowExperiment28-7B_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/automerger/YamshadowExperiment28-7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">automerger/YamshadowExperiment28-7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/automerger__YamshadowExperiment28-7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "automerger/YamshadowExperiment28-7B", "Model sha": "76972ed8aacba1fd14f78e6f8d347f087f8b6800", "Average \u2b06\ufe0f": 19.82132944549716, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 23, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4070156074770498, "IFEval": 40.701560747704974, "BBH Raw": 0.5150030227855061, "BBH": 31.980235156677427, "MATH Lvl 5 Raw": 0.0574018126888217, "MATH Lvl 5": 5.740181268882175, "GPQA Raw": 0.2869127516778523, "GPQA": 4.921700223713646, "MUSR Raw": 0.4306145833333333, "MUSR": 12.693489583333337, "MMLU-PRO Raw": 0.3060172872340425, "MMLU-PRO": 22.89080969267139, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-03-18T00:00:00", "Submission Date": "2024-06-29T00:00:00", "Generation": 1, "Base Model": "automerger/YamshadowExperiment28-7B (Merge)"}, {"eval_name": "awnr_Mistral-7B-v0.1-signtensors-1-over-2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/awnr/Mistral-7B-v0.1-signtensors-1-over-2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">awnr/Mistral-7B-v0.1-signtensors-1-over-2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/awnr__Mistral-7B-v0.1-signtensors-1-over-2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "awnr/Mistral-7B-v0.1-signtensors-1-over-2", "Model sha": "9575327242f8539eac59b6d788beccf54a6f9414", "Average \u2b06\ufe0f": 14.257193911777046, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 2, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2179217808747456, "IFEval": 21.792178087474564, "BBH Raw": 0.4422884892437673, "BBH": 22.40015255970937, "MATH Lvl 5 Raw": 0.0271903323262839, "MATH Lvl 5": 2.719033232628399, "GPQA Raw": 0.3070469798657718, "GPQA": 7.606263982102905, "MUSR Raw": 0.4006041666666666, "MUSR": 8.80885416666667, "MMLU-PRO Raw": 0.2999501329787234, "MMLU-PRO": 22.21668144208038, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-27T00:00:00", "Submission Date": "2024-07-30T00:00:00", "Generation": 0, "Base Model": "awnr/Mistral-7B-v0.1-signtensors-1-over-2"}, {"eval_name": "awnr_Mistral-7B-v0.1-signtensors-1-over-4_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/awnr/Mistral-7B-v0.1-signtensors-1-over-4\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">awnr/Mistral-7B-v0.1-signtensors-1-over-4</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/awnr__Mistral-7B-v0.1-signtensors-1-over-4-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "awnr/Mistral-7B-v0.1-signtensors-1-over-4", "Model sha": "b288ab9d8adfd2963a44a7935bb47649f55bcbee", "Average \u2b06\ufe0f": 8.709433197510963, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2133007087860211, "IFEval": 21.330070878602108, "BBH Raw": 0.3507094740284628, "BBH": 9.22769372478478, "MATH Lvl 5 Raw": 0.0226586102719033, "MATH Lvl 5": 2.2658610271903323, "GPQA Raw": 0.2701342281879195, "GPQA": 2.684563758389265, "MUSR Raw": 0.34603125, "MUSR": 2.187239583333333, "MMLU-PRO Raw": 0.2310505319148936, "MMLU-PRO": 14.561170212765957, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-29T00:00:00", "Submission Date": "2024-07-29T00:00:00", "Generation": 0, "Base Model": "awnr/Mistral-7B-v0.1-signtensors-1-over-4"}, {"eval_name": "awnr_Mistral-7B-v0.1-signtensors-3-over-8_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/awnr/Mistral-7B-v0.1-signtensors-3-over-8\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">awnr/Mistral-7B-v0.1-signtensors-3-over-8</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/awnr__Mistral-7B-v0.1-signtensors-3-over-8-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "awnr/Mistral-7B-v0.1-signtensors-3-over-8", "Model sha": "fa368f705ace05da2fef25c030fe740cf1fef176", "Average \u2b06\ufe0f": 13.725352082619835, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2394291590756969, "IFEval": 23.94291590756969, "BBH Raw": 0.4299940969601492, "BBH": 20.435230589690025, "MATH Lvl 5 Raw": 0.0279456193353474, "MATH Lvl 5": 2.794561933534743, "GPQA Raw": 0.3036912751677852, "GPQA": 7.158836689038028, "MUSR Raw": 0.38175, "MUSR": 5.785416666666667, "MMLU-PRO Raw": 0.3001163563829787, "MMLU-PRO": 22.23515070921986, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-29T00:00:00", "Submission Date": "2024-07-29T00:00:00", "Generation": 0, "Base Model": "awnr/Mistral-7B-v0.1-signtensors-3-over-8"}, {"eval_name": "awnr_Mistral-7B-v0.1-signtensors-5-over-16_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/awnr/Mistral-7B-v0.1-signtensors-5-over-16\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">awnr/Mistral-7B-v0.1-signtensors-5-over-16</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/awnr__Mistral-7B-v0.1-signtensors-5-over-16-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "awnr/Mistral-7B-v0.1-signtensors-5-over-16", "Model sha": "5ea13b3d0723237889e1512bc70dae72f71884d1", "Average \u2b06\ufe0f": 12.15864791851745, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2118268416689938, "IFEval": 21.18268416689938, "BBH Raw": 0.4124151161773006, "BBH": 17.543031293477835, "MATH Lvl 5 Raw": 0.0219033232628398, "MATH Lvl 5": 2.190332326283988, "GPQA Raw": 0.2810402684563758, "GPQA": 4.138702460850116, "MUSR Raw": 0.3686041666666667, "MUSR": 6.142187500000003, "MMLU-PRO Raw": 0.2957945478723404, "MMLU-PRO": 21.75494976359338, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-29T00:00:00", "Submission Date": "2024-07-29T00:00:00", "Generation": 0, "Base Model": "awnr/Mistral-7B-v0.1-signtensors-5-over-16"}, {"eval_name": "awnr_Mistral-7B-v0.1-signtensors-7-over-16_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/awnr/Mistral-7B-v0.1-signtensors-7-over-16\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">awnr/Mistral-7B-v0.1-signtensors-7-over-16</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/awnr__Mistral-7B-v0.1-signtensors-7-over-16-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "awnr/Mistral-7B-v0.1-signtensors-7-over-16", "Model sha": "0e1f2cb0a81c38fc6c567d9c007883ab62fae266", "Average \u2b06\ufe0f": 14.14599980116308, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2293625358493242, "IFEval": 22.936253584932423, "BBH Raw": 0.4315820818987619, "BBH": 21.040436509874464, "MATH Lvl 5 Raw": 0.0324773413897281, "MATH Lvl 5": 3.2477341389728096, "GPQA Raw": 0.3036912751677852, "GPQA": 7.158836689038028, "MUSR Raw": 0.3952083333333333, "MUSR": 7.934375000000003, "MMLU-PRO Raw": 0.3030252659574468, "MMLU-PRO": 22.55836288416076, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-29T00:00:00", "Submission Date": "2024-07-29T00:00:00", "Generation": 0, "Base Model": "awnr/Mistral-7B-v0.1-signtensors-7-over-16"}, {"eval_name": "aws-prototyping_MegaBeam-Mistral-7B-512k_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/aws-prototyping/MegaBeam-Mistral-7B-512k\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">aws-prototyping/MegaBeam-Mistral-7B-512k</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/aws-prototyping__MegaBeam-Mistral-7B-512k-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "aws-prototyping/MegaBeam-Mistral-7B-512k", "Model sha": "3e3b8c4b933650eed81ede7c4395df943d2a0796", "Average \u2b06\ufe0f": 17.544717372035574, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 41, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5972586071623293, "IFEval": 59.72586071623293, "BBH Raw": 0.3662336639946533, "BBH": 12.361177501580404, "MATH Lvl 5 Raw": 0.0264350453172205, "MATH Lvl 5": 2.643504531722054, "GPQA Raw": 0.2827181208053691, "GPQA": 4.36241610738255, "MUSR Raw": 0.3993645833333333, "MUSR": 8.520572916666667, "MMLU-PRO Raw": 0.2588929521276595, "MMLU-PRO": 17.65477245862884, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-30T00:00:00", "Submission Date": "2024-10-07T00:00:00", "Generation": 0, "Base Model": "aws-prototyping/MegaBeam-Mistral-7B-512k"}, {"eval_name": "axolotl-ai-co_romulus-mistral-nemo-12b-simpo_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/axolotl-ai-co/romulus-mistral-nemo-12b-simpo\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">axolotl-ai-co/romulus-mistral-nemo-12b-simpo</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/axolotl-ai-co__romulus-mistral-nemo-12b-simpo-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "axolotl-ai-co/romulus-mistral-nemo-12b-simpo", "Model sha": "15fd3ffa46c1ea51aa5d26a1da24214e324d7cf2", "Average \u2b06\ufe0f": 23.413750039491887, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 13, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.607924750772395, "IFEval": 60.79247507723951, "BBH Raw": 0.5395057669562011, "BBH": 34.64240096637378, "MATH Lvl 5 Raw": 0.0083081570996978, "MATH Lvl 5": 0.8308157099697886, "GPQA Raw": 0.2785234899328859, "GPQA": 3.803131991051453, "MUSR Raw": 0.4233020833333333, "MUSR": 12.979427083333333, "MMLU-PRO Raw": 0.3469082446808511, "MMLU-PRO": 27.43424940898345, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-24T00:00:00", "Submission Date": "2024-09-21T00:00:00", "Generation": 1, "Base Model": "Removed"}, {"eval_name": "beomi_gemma-mling-7b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe9 continuously pretrained", "T": "\ud83d\udfe9", "Weight type": "Original", "Architecture": "GemmaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/beomi/gemma-mling-7b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">beomi/gemma-mling-7b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/beomi__gemma-mling-7b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "beomi/gemma-mling-7b", "Model sha": "3f442e28bd50db6c438ce2a15b3a003532babba0", "Average \u2b06\ufe0f": 11.178175708742884, "Hub License": "other", "Hub \u2764\ufe0f": 13, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2029093915255965, "IFEval": 20.29093915255965, "BBH Raw": 0.40675941947154, "BBH": 17.631391012223656, "MATH Lvl 5 Raw": 0.0415407854984894, "MATH Lvl 5": 4.154078549848943, "GPQA Raw": 0.25, "GPQA": 0.0, "MUSR Raw": 0.3758541666666666, "MUSR": 6.848437499999999, "MMLU-PRO Raw": 0.2632978723404255, "MMLU-PRO": 18.144208037825056, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-15T00:00:00", "Submission Date": "2024-07-17T00:00:00", "Generation": 0, "Base Model": "beomi/gemma-mling-7b"}, {"eval_name": "beowolx_CodeNinja-1.0-OpenChat-7B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/beowolx/CodeNinja-1.0-OpenChat-7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">beowolx/CodeNinja-1.0-OpenChat-7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/beowolx__CodeNinja-1.0-OpenChat-7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "beowolx/CodeNinja-1.0-OpenChat-7B", "Model sha": "9934c04c767e6ae0f792712a060f02915391d4ec", "Average \u2b06\ufe0f": 20.208920096830425, "Hub License": "mit", "Hub \u2764\ufe0f": 104, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5446770125489258, "IFEval": 54.467701254892575, "BBH Raw": 0.4441338669403703, "BBH": 21.713423267203808, "MATH Lvl 5 Raw": 0.0521148036253776, "MATH Lvl 5": 5.211480362537765, "GPQA Raw": 0.2944630872483221, "GPQA": 5.92841163310962, "MUSR Raw": 0.4243229166666666, "MUSR": 11.540364583333336, "MMLU-PRO Raw": 0.3015292553191489, "MMLU-PRO": 22.392139479905435, "Maintainer's Highlight": false, "Upload To Hub Date": "2023-12-20T00:00:00", "Submission Date": "2024-07-30T00:00:00", "Generation": 0, "Base Model": "beowolx/CodeNinja-1.0-OpenChat-7B"}, {"eval_name": "berkeley-nest_Starling-LM-7B-alpha_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/berkeley-nest/Starling-LM-7B-alpha\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">berkeley-nest/Starling-LM-7B-alpha</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/berkeley-nest__Starling-LM-7B-alpha-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "berkeley-nest/Starling-LM-7B-alpha", "Model sha": "1dddf3b95bc1391f6307299eb1c162c194bde9bd", "Average \u2b06\ufe0f": 20.63795117818425, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 553, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5480491761858536, "IFEval": 54.80491761858535, "BBH Raw": 0.4440065261164004, "BBH": 21.95402808715926, "MATH Lvl 5 Raw": 0.0717522658610271, "MATH Lvl 5": 7.175226586102719, "GPQA Raw": 0.296979865771812, "GPQA": 6.263982102908276, "MUSR Raw": 0.4120104166666666, "MUSR": 9.501302083333334, "MMLU-PRO Raw": 0.3171542553191489, "MMLU-PRO": 24.128250591016545, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-11-25T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "berkeley-nest/Starling-LM-7B-alpha"}, {"eval_name": "bigcode_starcoder2-15b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "Starcoder2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/bigcode/starcoder2-15b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">bigcode/starcoder2-15b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/bigcode__starcoder2-15b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "bigcode/starcoder2-15b", "Model sha": "46d44742909c03ac8cee08eb03fdebce02e193ec", "Average \u2b06\ufe0f": 12.438470487104045, "Hub License": "bigcode-openrail-m", "Hub \u2764\ufe0f": 562, "#Params (B)": 15, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2780223141265177, "IFEval": 27.802231412651764, "BBH Raw": 0.4447957841230437, "BBH": 20.373540752678547, "MATH Lvl 5 Raw": 0.0536253776435045, "MATH Lvl 5": 5.362537764350453, "GPQA Raw": 0.273489932885906, "GPQA": 3.1319910514541416, "MUSR Raw": 0.35009375, "MUSR": 2.9283854166666674, "MMLU-PRO Raw": 0.2352892287234042, "MMLU-PRO": 15.032136524822691, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-02-20T00:00:00", "Submission Date": "2024-06-09T00:00:00", "Generation": 0, "Base Model": "bigcode/starcoder2-15b"}, {"eval_name": "bigcode_starcoder2-3b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "Starcoder2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/bigcode/starcoder2-3b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">bigcode/starcoder2-3b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/bigcode__starcoder2-3b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "bigcode/starcoder2-3b", "Model sha": "733247c55e3f73af49ce8e9c7949bf14af205928", "Average \u2b06\ufe0f": 6.536559509561811, "Hub License": "bigcode-openrail-m", "Hub \u2764\ufe0f": 139, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2037083826469323, "IFEval": 20.370838264693237, "BBH Raw": 0.3508714138460175, "BBH": 8.909299421083569, "MATH Lvl 5 Raw": 0.0143504531722054, "MATH Lvl 5": 1.4350453172205435, "GPQA Raw": 0.2441275167785234, "GPQA": 0.0, "MUSR Raw": 0.3434583333333333, "MUSR": 1.432291666666666, "MMLU-PRO Raw": 0.1636469414893617, "MMLU-PRO": 7.071882387706856, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-11-29T00:00:00", "Submission Date": "2024-06-09T00:00:00", "Generation": 0, "Base Model": "bigcode/starcoder2-3b"}, {"eval_name": "bigcode_starcoder2-7b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "Starcoder2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/bigcode/starcoder2-7b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">bigcode/starcoder2-7b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/bigcode__starcoder2-7b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "bigcode/starcoder2-7b", "Model sha": "a3d33687b51284b528abeb17830776ffd24892a9", "Average \u2b06\ufe0f": 8.205321558755733, "Hub License": "bigcode-openrail-m", "Hub \u2764\ufe0f": 157, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2209193827932108, "IFEval": 22.09193827932109, "BBH Raw": 0.3660985766912303, "BBH": 11.395110106503443, "MATH Lvl 5 Raw": 0.0256797583081571, "MATH Lvl 5": 2.56797583081571, "GPQA Raw": 0.2516778523489933, "GPQA": 0.2237136465324418, "MUSR Raw": 0.3793333333333333, "MUSR": 5.8166666666666655, "MMLU-PRO Raw": 0.1642287234042553, "MMLU-PRO": 7.1365248226950335, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-02-20T00:00:00", "Submission Date": "2024-06-09T00:00:00", "Generation": 0, "Base Model": "bigcode/starcoder2-7b"}, {"eval_name": "bigscience_bloom-1b1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "BloomForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/bigscience/bloom-1b1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">bigscience/bloom-1b1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/bigscience__bloom-1b1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "bigscience/bloom-1b1", "Model sha": "eb3dd7399312f5f94fd13f41d2f318117d3eb1e4", "Average \u2b06\ufe0f": 3.962215291979836, "Hub License": "bigscience-bloom-rail-1.0", "Hub \u2764\ufe0f": 59, "#Params (B)": 1, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1373378192085887, "IFEval": 13.733781920858878, "BBH Raw": 0.3107276237737039, "BBH": 4.042705269260129, "MATH Lvl 5 Raw": 0.0015105740181268, "MATH Lvl 5": 0.1510574018126888, "GPQA Raw": 0.259228187919463, "GPQA": 1.230425055928408, "MUSR Raw": 0.3699999999999999, "MUSR": 3.416666666666666, "MMLU-PRO Raw": 0.1107878989361702, "MMLU-PRO": 1.198655437352245, "Maintainer's Highlight": true, "Upload To Hub Date": "2022-05-19T00:00:00", "Submission Date": "2024-06-13T00:00:00", "Generation": 0, "Base Model": "bigscience/bloom-1b1"}, {"eval_name": "bigscience_bloom-1b7_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "BloomForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/bigscience/bloom-1b7\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">bigscience/bloom-1b7</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/bigscience__bloom-1b7-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "bigscience/bloom-1b7", "Model sha": "cc72a88036c2fb937d65efeacc57a0c2ef5d6fe5", "Average \u2b06\ufe0f": 3.971225779835847, "Hub License": "bigscience-bloom-rail-1.0", "Hub \u2764\ufe0f": 117, "#Params (B)": 1, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1043896860330589, "IFEval": 10.438968603305897, "BBH Raw": 0.314054919904072, "BBH": 4.39745292760164, "MATH Lvl 5 Raw": 0.0007552870090634, "MATH Lvl 5": 0.0755287009063444, "GPQA Raw": 0.2583892617449664, "GPQA": 1.1185682326621946, "MUSR Raw": 0.3885729166666666, "MUSR": 6.838281250000001, "MMLU-PRO Raw": 0.108626994680851, "MMLU-PRO": 0.958554964539006, "Maintainer's Highlight": true, "Upload To Hub Date": "2022-05-19T00:00:00", "Submission Date": "2024-06-13T00:00:00", "Generation": 0, "Base Model": "bigscience/bloom-1b7"}, {"eval_name": "bigscience_bloom-3b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "BloomForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/bigscience/bloom-3b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">bigscience/bloom-3b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/bigscience__bloom-3b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "bigscience/bloom-3b", "Model sha": "52bc5b43010b4844513826b8be3f78c7344c37d7", "Average \u2b06\ufe0f": 4.262012960471914, "Hub License": "bigscience-bloom-rail-1.0", "Hub \u2764\ufe0f": 88, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1270961050013963, "IFEval": 12.709610500139627, "BBH Raw": 0.3062918592346337, "BBH": 3.4200982840077354, "MATH Lvl 5 Raw": 0.0007552870090634, "MATH Lvl 5": 0.0755287009063444, "GPQA Raw": 0.2399328859060402, "GPQA": 0.0, "MUSR Raw": 0.3980625, "MUSR": 7.891145833333333, "MMLU-PRO Raw": 0.11328125, "MMLU-PRO": 1.4756944444444438, "Maintainer's Highlight": true, "Upload To Hub Date": "2022-05-19T00:00:00", "Submission Date": "2024-06-13T00:00:00", "Generation": 0, "Base Model": "bigscience/bloom-3b"}, {"eval_name": "bigscience_bloom-560m_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "BloomForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/bigscience/bloom-560m\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">bigscience/bloom-560m</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/bigscience__bloom-560m-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "bigscience/bloom-560m", "Model sha": "ac2ae5fab2ce3f9f40dc79b5ca9f637430d24971", "Average \u2b06\ufe0f": 3.456891131891464, "Hub License": "bigscience-bloom-rail-1.0", "Hub \u2764\ufe0f": 345, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.0620243176992601, "IFEval": 6.202431769926019, "BBH Raw": 0.3025950541549823, "BBH": 2.885363608028119, "MATH Lvl 5 Raw": 0.0007552870090634, "MATH Lvl 5": 0.0755287009063444, "GPQA Raw": 0.261744966442953, "GPQA": 1.5659955257270708, "MUSR Raw": 0.4030833333333333, "MUSR": 8.185416666666667, "MMLU-PRO Raw": 0.116439494680851, "MMLU-PRO": 1.8266105200945613, "Maintainer's Highlight": true, "Upload To Hub Date": "2022-05-19T00:00:00", "Submission Date": "2024-06-13T00:00:00", "Generation": 0, "Base Model": "bigscience/bloom-560m"}, {"eval_name": "bigscience_bloom-7b1_float16", "Precision": "float16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "BloomForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/bigscience/bloom-7b1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">bigscience/bloom-7b1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/bigscience__bloom-7b1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "bigscience/bloom-7b1", "Model sha": "6232703e399354503377bf59dfbb8397fd569e4a", "Average \u2b06\ufe0f": 3.707393424124113, "Hub License": "bigscience-bloom-rail-1.0", "Hub \u2764\ufe0f": 196, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1322169621049925, "IFEval": 13.221696210499251, "BBH Raw": 0.3113718529627139, "BBH": 4.038808518979752, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2642617449664429, "GPQA": 1.9015659955257265, "MUSR Raw": 0.3486979166666666, "MUSR": 1.920572916666666, "MMLU-PRO Raw": 0.1104554521276595, "MMLU-PRO": 1.1617169030732852, "Maintainer's Highlight": true, "Upload To Hub Date": "2022-05-19T00:00:00", "Submission Date": "2024-06-13T00:00:00", "Generation": 0, "Base Model": "bigscience/bloom-7b1"}, {"eval_name": "bosonai_Higgs-Llama-3-70B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Adapter", "Architecture": "?", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/bosonai/Higgs-Llama-3-70B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">bosonai/Higgs-Llama-3-70B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/bosonai__Higgs-Llama-3-70B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "bosonai/Higgs-Llama-3-70B", "Model sha": "b2c7540768046dfdae7a0cb846a7da6c41d826b1", "Average \u2b06\ufe0f": 31.9518833707526, "Hub License": "other", "Hub \u2764\ufe0f": 210, "#Params (B)": 70, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5560678998390935, "IFEval": 55.60678998390936, "BBH Raw": 0.625765879603832, "BBH": 45.89740563396065, "MATH Lvl 5 Raw": 0.1578549848942598, "MATH Lvl 5": 15.78549848942598, "GPQA Raw": 0.3666107382550335, "GPQA": 15.548098434004473, "MUSR Raw": 0.4470833333333333, "MUSR": 15.518750000000002, "MMLU-PRO Raw": 0.4901928191489361, "MMLU-PRO": 43.35475768321512, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-05T00:00:00", "Submission Date": "2024-08-30T00:00:00", "Generation": 1, "Base Model": "meta-llama/Meta-Llama-3-70B"}, {"eval_name": "bunnycore_HyperLlama-3.1-8B_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/bunnycore/HyperLlama-3.1-8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">bunnycore/HyperLlama-3.1-8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/bunnycore__HyperLlama-3.1-8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "bunnycore/HyperLlama-3.1-8B", "Model sha": "659b18ffaee2c1e8dbe8a9a56a44502325d71696", "Average \u2b06\ufe0f": 28.07133220117423, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 3, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7883005979689446, "IFEval": 78.83005979689446, "BBH Raw": 0.5103385292046213, "BBH": 29.80665561261375, "MATH Lvl 5 Raw": 0.1601208459214501, "MATH Lvl 5": 16.012084592145015, "GPQA Raw": 0.2869127516778523, "GPQA": 4.921700223713646, "MUSR Raw": 0.3829270833333333, "MUSR": 7.932552083333335, "MMLU-PRO Raw": 0.3783244680851064, "MMLU-PRO": 30.92494089834515, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-04T00:00:00", "Submission Date": "2024-09-05T00:00:00", "Generation": 0, "Base Model": "bunnycore/HyperLlama-3.1-8B"}, {"eval_name": "bunnycore_Llama-3.1-8B-TitanFusion-Mix_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/bunnycore/Llama-3.1-8B-TitanFusion-Mix\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">bunnycore/Llama-3.1-8B-TitanFusion-Mix</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/bunnycore__Llama-3.1-8B-TitanFusion-Mix-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "bunnycore/Llama-3.1-8B-TitanFusion-Mix", "Model sha": "9eb89de7df048276ccbc4405ce4f005f9185f82e", "Average \u2b06\ufe0f": 24.773073618248414, "Hub License": null, "Hub \u2764\ufe0f": 2, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4924954675815725, "IFEval": 49.24954675815725, "BBH Raw": 0.5755964197928182, "BBH": 39.53548333481336, "MATH Lvl 5 Raw": 0.11404833836858, "MATH Lvl 5": 11.404833836858003, "GPQA Raw": 0.2953020134228188, "GPQA": 6.040268456375841, "MUSR Raw": 0.4316979166666666, "MUSR": 12.462239583333336, "MMLU-PRO Raw": 0.3695146276595745, "MMLU-PRO": 29.94606973995272, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-23T00:00:00", "Submission Date": "2024-09-23T00:00:00", "Generation": 1, "Base Model": "bunnycore/Llama-3.1-8B-TitanFusion-Mix (Merge)"}, {"eval_name": "bunnycore_Llama-3.1-8B-TitanFusion-v3_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/bunnycore/Llama-3.1-8B-TitanFusion-v3\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">bunnycore/Llama-3.1-8B-TitanFusion-v3</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/bunnycore__Llama-3.1-8B-TitanFusion-v3-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "bunnycore/Llama-3.1-8B-TitanFusion-v3", "Model sha": "ea8269ac3b2e9c0dc855a9089251ebdb273ada16", "Average \u2b06\ufe0f": 24.017722898503237, "Hub License": null, "Hub \u2764\ufe0f": 2, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4809549772381725, "IFEval": 48.095497723817246, "BBH Raw": 0.5262113071794826, "BBH": 32.072941144614084, "MATH Lvl 5 Raw": 0.1299093655589124, "MATH Lvl 5": 12.990936555891238, "GPQA Raw": 0.3087248322147651, "GPQA": 7.829977628635347, "MUSR Raw": 0.4302083333333333, "MUSR": 11.942708333333334, "MMLU-PRO Raw": 0.3805684840425531, "MMLU-PRO": 31.174276004728128, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-22T00:00:00", "Submission Date": "2024-09-22T00:00:00", "Generation": 1, "Base Model": "bunnycore/Llama-3.1-8B-TitanFusion-v3 (Merge)"}, {"eval_name": "byroneverson_Yi-1.5-9B-Chat-16K-abliterated_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/byroneverson/Yi-1.5-9B-Chat-16K-abliterated\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">byroneverson/Yi-1.5-9B-Chat-16K-abliterated</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/byroneverson__Yi-1.5-9B-Chat-16K-abliterated-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "byroneverson/Yi-1.5-9B-Chat-16K-abliterated", "Model sha": "84a6eaa723633bbefc7cfac9c64bf0e0a4d39065", "Average \u2b06\ufe0f": 26.36908204583267, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 2, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5528453392553979, "IFEval": 55.28453392553979, "BBH Raw": 0.5282050829986801, "BBH": 32.843258967002555, "MATH Lvl 5 Raw": 0.1064954682779456, "MATH Lvl 5": 10.649546827794564, "GPQA Raw": 0.3129194630872483, "GPQA": 8.389261744966444, "MUSR Raw": 0.4734375, "MUSR": 19.6796875, "MMLU-PRO Raw": 0.382313829787234, "MMLU-PRO": 31.36820330969267, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-03T00:00:00", "Submission Date": "2024-09-03T00:00:00", "Generation": 1, "Base Model": "01-ai/Yi-1.5-9B-Chat-16K"}, {"eval_name": "byroneverson_Yi-1.5-9B-Chat-abliterated_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/byroneverson/Yi-1.5-9B-Chat-abliterated\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">byroneverson/Yi-1.5-9B-Chat-abliterated</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/byroneverson__Yi-1.5-9B-Chat-abliterated-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "byroneverson/Yi-1.5-9B-Chat-abliterated", "Model sha": "4e26c200cdf2dc50dd50cdd9fe5b74887e9fa94a", "Average \u2b06\ufe0f": 25.137075529902816, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 2, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5723291976400395, "IFEval": 57.23291976400395, "BBH Raw": 0.5401219363002313, "BBH": 34.35218727198406, "MATH Lvl 5 Raw": 0.0981873111782477, "MATH Lvl 5": 9.818731117824774, "GPQA Raw": 0.2919463087248322, "GPQA": 5.592841163310966, "MUSR Raw": 0.4388645833333333, "MUSR": 13.658072916666669, "MMLU-PRO Raw": 0.3715093085106383, "MMLU-PRO": 30.167700945626475, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-04T00:00:00", "Submission Date": "2024-09-17T00:00:00", "Generation": 1, "Base Model": "01-ai/Yi-1.5-9B-Chat"}, {"eval_name": "c10x_Q-Pluse_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/c10x/Q-Pluse\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">c10x/Q-Pluse</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/c10x__Q-Pluse-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "c10x/Q-Pluse", "Model sha": null, "Average \u2b06\ufe0f": 3.634370763516103, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.1122831863898899, "IFEval": 11.228318638988991, "BBH Raw": 0.2875111436321769, "BBH": 1.9479450969539605, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2466442953020134, "GPQA": 0.0, "MUSR Raw": 0.3938124999999999, "MUSR": 7.126562500000001, "MMLU-PRO Raw": 0.1135305851063829, "MMLU-PRO": 1.5033983451536632, "Maintainer's Highlight": false, "Upload To Hub Date": "", "Submission Date": "2024-10-10T00:00:00", "Generation": 0, "Base Model": "Removed"}, {"eval_name": "c10x_longthinker_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/c10x/longthinker\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">c10x/longthinker</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/c10x__longthinker-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "c10x/longthinker", "Model sha": "e1bb4a2c2782ab52be7a8fa2e5905f08b7cfd464", "Average \u2b06\ufe0f": 19.47207601771772, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3608791340310376, "IFEval": 36.08791340310377, "BBH Raw": 0.4927488805336454, "BBH": 28.4247368611983, "MATH Lvl 5 Raw": 0.1563444108761329, "MATH Lvl 5": 15.634441087613292, "GPQA Raw": 0.2642617449664429, "GPQA": 1.9015659955257265, "MUSR Raw": 0.3909583333333333, "MUSR": 6.703125000000001, "MMLU-PRO Raw": 0.3527260638297872, "MMLU-PRO": 28.08067375886525, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-10T00:00:00", "Submission Date": "2024-10-10T00:00:00", "Generation": 1, "Base Model": "c10x/longthinker (Merge)"}, {"eval_name": "carsenk_flippa-v6_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Adapter", "Architecture": "?", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/carsenk/flippa-v6\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">carsenk/flippa-v6</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/carsenk__flippa-v6-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "carsenk/flippa-v6", "Model sha": "5206a32e0bd3067aef1ce90f5528ade7d866253f", "Average \u2b06\ufe0f": 20.549780923421363, "Hub License": "llama3.1", "Hub \u2764\ufe0f": 1, "#Params (B)": 16, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3439429602344003, "IFEval": 34.39429602344003, "BBH Raw": 0.5046972457053399, "BBH": 29.993501279427136, "MATH Lvl 5 Raw": 0.1268882175226586, "MATH Lvl 5": 12.68882175226586, "GPQA Raw": 0.2927852348993288, "GPQA": 5.7046979865771785, "MUSR Raw": 0.408875, "MUSR": 10.876041666666667, "MMLU-PRO Raw": 0.3667719414893617, "MMLU-PRO": 29.6413268321513, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-24T00:00:00", "Submission Date": "2024-08-24T00:00:00", "Generation": 2, "Base Model": "meta-llama/Meta-Llama-3.1-8B"}, {"eval_name": "carsenk_phi3.5_mini_exp_825_uncensored_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/carsenk/phi3.5_mini_exp_825_uncensored\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">carsenk/phi3.5_mini_exp_825_uncensored</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/carsenk__phi3.5_mini_exp_825_uncensored-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "carsenk/phi3.5_mini_exp_825_uncensored", "Model sha": "6b208dc3df02e0d5ef0c3fe5899f9f31618f2e94", "Average \u2b06\ufe0f": 3.4668751054130524, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.1364136047908438, "IFEval": 13.641360479084383, "BBH Raw": 0.2964734514791826, "BBH": 1.827812730226084, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2491610738255033, "GPQA": 0.0, "MUSR Raw": 0.3644166666666666, "MUSR": 3.385416666666666, "MMLU-PRO Raw": 0.1175199468085106, "MMLU-PRO": 1.9466607565011809, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-29T00:00:00", "Submission Date": "2024-08-29T00:00:00", "Generation": 1, "Base Model": "unsloth/phi-3.5-mini-instruct-bnb-4bit"}, {"eval_name": "cat-searcher_gemma-2-9b-it-sppo-iter-1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/cat-searcher/gemma-2-9b-it-sppo-iter-1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">cat-searcher/gemma-2-9b-it-sppo-iter-1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/cat-searcher__gemma-2-9b-it-sppo-iter-1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "cat-searcher/gemma-2-9b-it-sppo-iter-1", "Model sha": "b29a3a5cef93ee044e2297fcb40bd2976415e900", "Average \u2b06\ufe0f": 20.553948052865767, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 9, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3014767483610154, "IFEval": 30.147674836101544, "BBH Raw": 0.5971867698707507, "BBH": 41.67630770023723, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.3447986577181208, "GPQA": 12.639821029082771, "MUSR Raw": 0.3926666666666666, "MUSR": 7.15, "MMLU-PRO Raw": 0.3853889627659574, "MMLU-PRO": 31.709884751773053, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-23T00:00:00", "Submission Date": "2024-08-09T00:00:00", "Generation": 1, "Base Model": "cat-searcher/gemma-2-9b-it-sppo-iter-0"}, {"eval_name": "cat-searcher_gemma-2-9b-it-sppo-iter-1-evol-1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/cat-searcher/gemma-2-9b-it-sppo-iter-1-evol-1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">cat-searcher/gemma-2-9b-it-sppo-iter-1-evol-1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/cat-searcher__gemma-2-9b-it-sppo-iter-1-evol-1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "cat-searcher/gemma-2-9b-it-sppo-iter-1-evol-1", "Model sha": "c2d7b76786151aecfa5972a2a3e937feb2d2c48b", "Average \u2b06\ufe0f": 20.103005917547325, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 9, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2941827683878775, "IFEval": 29.418276838787747, "BBH Raw": 0.5939369622672414, "BBH": 41.10464026733791, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.3406040268456375, "GPQA": 12.080536912751676, "MUSR Raw": 0.3925729166666666, "MUSR": 6.904947916666669, "MMLU-PRO Raw": 0.3799867021276595, "MMLU-PRO": 31.109633569739948, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-05T00:00:00", "Submission Date": "2024-08-09T00:00:00", "Generation": 2, "Base Model": "cat-searcher/gemma-2-9b-it-sppo-iter-0"}, {"eval_name": "cgato_TheSalt-L3-8b-v0.3.2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/cgato/TheSalt-L3-8b-v0.3.2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">cgato/TheSalt-L3-8b-v0.3.2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/cgato__TheSalt-L3-8b-v0.3.2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "cgato/TheSalt-L3-8b-v0.3.2", "Model sha": "5cf08e2bf9590ebcd14ba021e113def28c65afa2", "Average \u2b06\ufe0f": 7.18589140317824, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2705033754881492, "IFEval": 27.050337548814923, "BBH Raw": 0.2967965317600307, "BBH": 2.612714473502145, "MATH Lvl 5 Raw": 0.0347432024169184, "MATH Lvl 5": 3.474320241691843, "GPQA Raw": 0.2659395973154362, "GPQA": 2.1252796420581683, "MUSR Raw": 0.3896249999999999, "MUSR": 6.3031250000000005, "MMLU-PRO Raw": 0.1139461436170212, "MMLU-PRO": 1.549571513002364, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-18T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "cgato/TheSalt-L3-8b-v0.3.2"}, {"eval_name": "chargoddard_prometheus-2-llama-3-8b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/chargoddard/prometheus-2-llama-3-8b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">chargoddard/prometheus-2-llama-3-8b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/chargoddard__prometheus-2-llama-3-8b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "chargoddard/prometheus-2-llama-3-8b", "Model sha": "90a728ac98e5b4169f88ae4945e357cf45477568", "Average \u2b06\ufe0f": 19.15521630970393, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 2, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5288900118352637, "IFEval": 52.889001183526375, "BBH Raw": 0.4931144581470071, "BBH": 27.80383919259717, "MATH Lvl 5 Raw": 0.0725075528700906, "MATH Lvl 5": 7.250755287009064, "GPQA Raw": 0.2726510067114094, "GPQA": 3.0201342281879207, "MUSR Raw": 0.3395833333333333, "MUSR": 0.7812499999999996, "MMLU-PRO Raw": 0.3086768617021276, "MMLU-PRO": 23.186317966903072, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-26T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "chargoddard/prometheus-2-llama-3-8b (Merge)"}, {"eval_name": "chujiezheng_Llama-3-Instruct-8B-SimPO-ExPO_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/chujiezheng/Llama-3-Instruct-8B-SimPO-ExPO\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">chujiezheng/Llama-3-Instruct-8B-SimPO-ExPO</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/chujiezheng__Llama-3-Instruct-8B-SimPO-ExPO-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "chujiezheng/Llama-3-Instruct-8B-SimPO-ExPO", "Model sha": "3fcaa9fe99691659eb197487e9a343f601bf63f2", "Average \u2b06\ufe0f": 21.972344167758195, "Hub License": "llama3", "Hub \u2764\ufe0f": 15, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6433707008515184, "IFEval": 64.33707008515184, "BBH Raw": 0.4764515968840137, "BBH": 25.86828225174116, "MATH Lvl 5 Raw": 0.0052870090634441, "MATH Lvl 5": 0.5287009063444109, "GPQA Raw": 0.2869127516778523, "GPQA": 4.921700223713646, "MUSR Raw": 0.3920104166666667, "MUSR": 9.501302083333336, "MMLU-PRO Raw": 0.340093085106383, "MMLU-PRO": 26.677009456264773, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-26T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "chujiezheng/Llama-3-Instruct-8B-SimPO-ExPO"}, {"eval_name": "chujiezheng_Mistral7B-PairRM-SPPO-ExPO_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/chujiezheng/Mistral7B-PairRM-SPPO-ExPO\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">chujiezheng/Mistral7B-PairRM-SPPO-ExPO</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/chujiezheng__Mistral7B-PairRM-SPPO-ExPO-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "chujiezheng/Mistral7B-PairRM-SPPO-ExPO", "Model sha": "d3e8342a63e5ae096f450f2467a92168db12768c", "Average \u2b06\ufe0f": 13.466091487182831, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.367348634955252, "IFEval": 36.7348634955252, "BBH Raw": 0.3882191262277366, "BBH": 13.678635807519433, "MATH Lvl 5 Raw": 0.0090634441087613, "MATH Lvl 5": 0.906344410876133, "GPQA Raw": 0.2768456375838926, "GPQA": 3.5794183445190177, "MUSR Raw": 0.4055312499999999, "MUSR": 8.658072916666667, "MMLU-PRO Raw": 0.2551529255319149, "MMLU-PRO": 17.239213947990542, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-04T00:00:00", "Submission Date": "2024-09-21T00:00:00", "Generation": 0, "Base Model": "chujiezheng/Mistral7B-PairRM-SPPO-ExPO"}, {"eval_name": "cloudyu_Llama-3-70Bx2-MOE_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/cloudyu/Llama-3-70Bx2-MOE\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">cloudyu/Llama-3-70Bx2-MOE</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/cloudyu__Llama-3-70Bx2-MOE-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "cloudyu/Llama-3-70Bx2-MOE", "Model sha": "b8bd85e8db8e4ec352b93441c92e0ae1334bf5a7", "Average \u2b06\ufe0f": 35.35176196990127, "Hub License": "llama3", "Hub \u2764\ufe0f": 1, "#Params (B)": 126, "Available on the hub": true, "Not_Merged": true, "MoE": false, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.5482486469234964, "IFEval": 54.82486469234964, "BBH Raw": 0.6636234572270707, "BBH": 51.42213772529595, "MATH Lvl 5 Raw": 0.1986404833836858, "MATH Lvl 5": 19.86404833836858, "GPQA Raw": 0.3934563758389262, "GPQA": 19.12751677852349, "MUSR Raw": 0.4811875, "MUSR": 20.8484375, "MMLU-PRO Raw": 0.5142121010638298, "MMLU-PRO": 46.02356678486997, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-20T00:00:00", "Submission Date": "2024-06-27T00:00:00", "Generation": 0, "Base Model": "cloudyu/Llama-3-70Bx2-MOE"}, {"eval_name": "cloudyu_Mixtral_34Bx2_MoE_60B_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/cloudyu/Mixtral_34Bx2_MoE_60B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">cloudyu/Mixtral_34Bx2_MoE_60B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/cloudyu__Mixtral_34Bx2_MoE_60B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "cloudyu/Mixtral_34Bx2_MoE_60B", "Model sha": "d01642769ccc782e1db1fc26cb25097aecb98e23", "Average \u2b06\ufe0f": 27.42234744058517, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 111, "#Params (B)": 60, "Available on the hub": true, "Not_Merged": true, "MoE": false, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4537770892343427, "IFEval": 45.37770892343427, "BBH Raw": 0.5869701263465353, "BBH": 41.20912905359096, "MATH Lvl 5 Raw": 0.0657099697885196, "MATH Lvl 5": 6.570996978851963, "GPQA Raw": 0.3380872483221476, "GPQA": 11.74496644295302, "MUSR Raw": 0.4625208333333333, "MUSR": 17.78177083333333, "MMLU-PRO Raw": 0.4766456117021276, "MMLU-PRO": 41.84951241134751, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-01-05T00:00:00", "Submission Date": "2024-08-22T00:00:00", "Generation": 0, "Base Model": "cloudyu/Mixtral_34Bx2_MoE_60B"}, {"eval_name": "cloudyu_Yi-34Bx2-MoE-60B-DPO_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/cloudyu/Yi-34Bx2-MoE-60B-DPO\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">cloudyu/Yi-34Bx2-MoE-60B-DPO</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/cloudyu__Yi-34Bx2-MoE-60B-DPO-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "cloudyu/Yi-34Bx2-MoE-60B-DPO", "Model sha": "5c2d31042229ee06246064100b781dd926cb0ffd", "Average \u2b06\ufe0f": 25.9050331206614, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 3, "#Params (B)": 60, "Available on the hub": true, "Not_Merged": true, "MoE": false, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.531887613753729, "IFEval": 53.1887613753729, "BBH Raw": 0.516831447641953, "BBH": 31.259298004231464, "MATH Lvl 5 Raw": 0.0619335347432024, "MATH Lvl 5": 6.193353474320242, "GPQA Raw": 0.3221476510067114, "GPQA": 9.61968680089485, "MUSR Raw": 0.43746875, "MUSR": 14.316927083333333, "MMLU-PRO Raw": 0.4676695478723404, "MMLU-PRO": 40.8521719858156, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-01-23T00:00:00", "Submission Date": "2024-08-06T00:00:00", "Generation": 0, "Base Model": "cloudyu/Yi-34Bx2-MoE-60B-DPO"}, {"eval_name": "cognitivecomputations_dolphin-2.9-llama3-8b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/cognitivecomputations/dolphin-2.9-llama3-8b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">cognitivecomputations/dolphin-2.9-llama3-8b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/cognitivecomputations__dolphin-2.9-llama3-8b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "cognitivecomputations/dolphin-2.9-llama3-8b", "Model sha": "5aeb036f9215c558b483a654a8c6e1cc22e841bf", "Average \u2b06\ufe0f": 18.302168187437868, "Hub License": "other", "Hub \u2764\ufe0f": 410, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3850339321888145, "IFEval": 38.503393218881456, "BBH Raw": 0.4949922016660918, "BBH": 27.858929260905125, "MATH Lvl 5 Raw": 0.0506042296072507, "MATH Lvl 5": 5.060422960725076, "GPQA Raw": 0.2869127516778523, "GPQA": 4.921700223713646, "MUSR Raw": 0.43753125, "MUSR": 13.791406250000003, "MMLU-PRO Raw": 0.277094414893617, "MMLU-PRO": 19.67715721040189, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-04-20T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 1, "Base Model": "meta-llama/Meta-Llama-3-8B"}, {"eval_name": "cognitivecomputations_dolphin-2.9.1-llama-3-70b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/cognitivecomputations/dolphin-2.9.1-llama-3-70b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">cognitivecomputations/dolphin-2.9.1-llama-3-70b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/cognitivecomputations__dolphin-2.9.1-llama-3-70b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "cognitivecomputations/dolphin-2.9.1-llama-3-70b", "Model sha": "31adf616c3c9176d147e0a62e9fedb7bf97678ac", "Average \u2b06\ufe0f": 23.40699437184128, "Hub License": "llama3", "Hub \u2764\ufe0f": 36, "#Params (B)": 70, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3760167466765959, "IFEval": 37.60167466765959, "BBH Raw": 0.5204919312821467, "BBH": 31.101151872569243, "MATH Lvl 5 Raw": 0.0543806646525679, "MATH Lvl 5": 5.438066465256798, "GPQA Raw": 0.3087248322147651, "GPQA": 7.829977628635347, "MUSR Raw": 0.4975624999999999, "MUSR": 23.6953125, "MMLU-PRO Raw": 0.4129820478723404, "MMLU-PRO": 34.77578309692671, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-05-22T00:00:00", "Submission Date": "2024-06-27T00:00:00", "Generation": 1, "Base Model": "meta-llama/Meta-Llama-3-70B"}, {"eval_name": "cognitivecomputations_dolphin-2.9.1-yi-1.5-34b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/cognitivecomputations/dolphin-2.9.1-yi-1.5-34b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">cognitivecomputations/dolphin-2.9.1-yi-1.5-34b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/cognitivecomputations__dolphin-2.9.1-yi-1.5-34b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "cognitivecomputations/dolphin-2.9.1-yi-1.5-34b", "Model sha": "1ec522298a6935c881df6dc29d3669833bd8672d", "Average \u2b06\ufe0f": 27.728150672300192, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 34, "#Params (B)": 34, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3852588908540451, "IFEval": 38.52588908540451, "BBH Raw": 0.6076225600626862, "BBH": 44.17408874277273, "MATH Lvl 5 Raw": 0.1518126888217522, "MATH Lvl 5": 15.181268882175228, "GPQA Raw": 0.3431208053691275, "GPQA": 12.416107382550338, "MUSR Raw": 0.4597916666666666, "MUSR": 16.97395833333334, "MMLU-PRO Raw": 0.4518783244680851, "MMLU-PRO": 39.09759160756501, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-05-18T00:00:00", "Submission Date": "2024-07-27T00:00:00", "Generation": 1, "Base Model": "01-ai/Yi-1.5-34B"}, {"eval_name": "cognitivecomputations_dolphin-2.9.1-yi-1.5-9b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/cognitivecomputations/dolphin-2.9.1-yi-1.5-9b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">cognitivecomputations/dolphin-2.9.1-yi-1.5-9b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/cognitivecomputations__dolphin-2.9.1-yi-1.5-9b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "cognitivecomputations/dolphin-2.9.1-yi-1.5-9b", "Model sha": "91f0a521e3e2a0675a3549aa5d3f40717068de94", "Average \u2b06\ufe0f": 24.84667276479162, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 26, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4465329769456154, "IFEval": 44.653297694561545, "BBH Raw": 0.5484314644603556, "BBH": 35.7760897255686, "MATH Lvl 5 Raw": 0.1042296072507553, "MATH Lvl 5": 10.42296072507553, "GPQA Raw": 0.3380872483221476, "GPQA": 11.74496644295302, "MUSR Raw": 0.4348020833333333, "MUSR": 13.516927083333336, "MMLU-PRO Raw": 0.3966921542553192, "MMLU-PRO": 32.96579491725768, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-05-18T00:00:00", "Submission Date": "2024-08-02T00:00:00", "Generation": 1, "Base Model": "01-ai/Yi-1.5-9B"}, {"eval_name": "cognitivecomputations_dolphin-2.9.2-Phi-3-Medium_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/cognitivecomputations/dolphin-2.9.2-Phi-3-Medium\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">cognitivecomputations/dolphin-2.9.2-Phi-3-Medium</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/cognitivecomputations__dolphin-2.9.2-Phi-3-Medium-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "cognitivecomputations/dolphin-2.9.2-Phi-3-Medium", "Model sha": "0470c5b912b51fa6e27d87a8ea7feafacd8cb101", "Average \u2b06\ufe0f": 25.656309036468706, "Hub License": "mit", "Hub \u2764\ufe0f": 16, "#Params (B)": -1, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4247762603226107, "IFEval": 42.47762603226107, "BBH Raw": 0.6456739302686527, "BBH": 49.72194030508101, "MATH Lvl 5 Raw": 0.0052870090634441, "MATH Lvl 5": 0.5287009063444109, "GPQA Raw": 0.3271812080536913, "GPQA": 10.290827740492167, "MUSR Raw": 0.4190520833333333, "MUSR": 11.414843750000005, "MMLU-PRO Raw": 0.4555352393617021, "MMLU-PRO": 39.50391548463357, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-05-31T00:00:00", "Submission Date": "2024-08-05T00:00:00", "Generation": 1, "Base Model": "cognitivecomputations/dolphin-2.9.2-Phi-3-Medium (Merge)"}, {"eval_name": "cognitivecomputations_dolphin-2.9.2-Phi-3-Medium-abliterated_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/cognitivecomputations/dolphin-2.9.2-Phi-3-Medium-abliterated\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">cognitivecomputations/dolphin-2.9.2-Phi-3-Medium-abliterated</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/cognitivecomputations__dolphin-2.9.2-Phi-3-Medium-abliterated-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "cognitivecomputations/dolphin-2.9.2-Phi-3-Medium-abliterated", "Model sha": "d50be5f22ca9745a2a3175996611d6a840318b7f", "Average \u2b06\ufe0f": 25.590063720348784, "Hub License": "mit", "Hub \u2764\ufe0f": 15, "#Params (B)": 13, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3612536957495001, "IFEval": 36.12536957495002, "BBH Raw": 0.612322545411745, "BBH": 45.44126655093765, "MATH Lvl 5 Raw": 0.1238670694864048, "MATH Lvl 5": 12.386706948640484, "GPQA Raw": 0.3280201342281879, "GPQA": 10.402684563758392, "MUSR Raw": 0.4111770833333333, "MUSR": 10.363802083333336, "MMLU-PRO Raw": 0.4493849734042553, "MMLU-PRO": 38.820552600472816, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-06-03T00:00:00", "Submission Date": "2024-06-27T00:00:00", "Generation": 1, "Base Model": "cognitivecomputations/dolphin-2.9.2-Phi-3-Medium-abliterated (Merge)"}, {"eval_name": "cognitivecomputations_dolphin-2.9.2-Phi-3-Medium-abliterated_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/cognitivecomputations/dolphin-2.9.2-Phi-3-Medium-abliterated\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">cognitivecomputations/dolphin-2.9.2-Phi-3-Medium-abliterated</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/cognitivecomputations__dolphin-2.9.2-Phi-3-Medium-abliterated-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "cognitivecomputations/dolphin-2.9.2-Phi-3-Medium-abliterated", "Model sha": "d50be5f22ca9745a2a3175996611d6a840318b7f", "Average \u2b06\ufe0f": 25.593252942758426, "Hub License": "mit", "Hub \u2764\ufe0f": 15, "#Params (B)": 13, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4123614232458765, "IFEval": 41.23614232458765, "BBH Raw": 0.638289226729353, "BBH": 48.38534691270737, "MATH Lvl 5 Raw": 0.0052870090634441, "MATH Lvl 5": 0.5287009063444109, "GPQA Raw": 0.3288590604026846, "GPQA": 10.514541387024613, "MUSR Raw": 0.4349270833333333, "MUSR": 13.732552083333337, "MMLU-PRO Raw": 0.4524601063829787, "MMLU-PRO": 39.1622340425532, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-06-03T00:00:00", "Submission Date": "2024-08-05T00:00:00", "Generation": 1, "Base Model": "cognitivecomputations/dolphin-2.9.2-Phi-3-Medium-abliterated (Merge)"}, {"eval_name": "cognitivecomputations_dolphin-2.9.2-qwen2-72b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/cognitivecomputations/dolphin-2.9.2-qwen2-72b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">cognitivecomputations/dolphin-2.9.2-qwen2-72b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/cognitivecomputations__dolphin-2.9.2-qwen2-72b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "cognitivecomputations/dolphin-2.9.2-qwen2-72b", "Model sha": "e79582577c2bf2af304221af0e8308b7e7d46ca1", "Average \u2b06\ufe0f": 35.418001280660704, "Hub License": "other", "Hub \u2764\ufe0f": 59, "#Params (B)": 72, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6343778950961227, "IFEval": 63.43778950961227, "BBH Raw": 0.6296364939584073, "BBH": 47.69617372826186, "MATH Lvl 5 Raw": 0.1865558912386707, "MATH Lvl 5": 18.65558912386707, "GPQA Raw": 0.3699664429530201, "GPQA": 15.99552572706935, "MUSR Raw": 0.4520729166666666, "MUSR": 17.042447916666664, "MMLU-PRO Raw": 0.547124335106383, "MMLU-PRO": 49.680481678487006, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-05-27T00:00:00", "Submission Date": "2024-09-19T00:00:00", "Generation": 1, "Base Model": "Qwen/Qwen2-72B"}, {"eval_name": "cognitivecomputations_dolphin-2.9.2-qwen2-7b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/cognitivecomputations/dolphin-2.9.2-qwen2-7b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">cognitivecomputations/dolphin-2.9.2-qwen2-7b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/cognitivecomputations__dolphin-2.9.2-qwen2-7b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "cognitivecomputations/dolphin-2.9.2-qwen2-7b", "Model sha": "c443c4eb5138ed746ac49ed98bf3c183dc5380ac", "Average \u2b06\ufe0f": 20.95737925433143, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 59, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3534599307614906, "IFEval": 35.34599307614906, "BBH Raw": 0.4893826375919559, "BBH": 27.914874953255534, "MATH Lvl 5 Raw": 0.1155589123867069, "MATH Lvl 5": 11.555891238670696, "GPQA Raw": 0.2902684563758389, "GPQA": 5.369127516778524, "MUSR Raw": 0.4191458333333333, "MUSR": 11.65989583333333, "MMLU-PRO Raw": 0.4050864361702128, "MMLU-PRO": 33.89849290780142, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-05-24T00:00:00", "Submission Date": "2024-07-10T00:00:00", "Generation": 1, "Base Model": "Qwen/Qwen2-7B"}, {"eval_name": "cognitivecomputations_dolphin-2.9.3-Yi-1.5-34B-32k_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/cognitivecomputations/dolphin-2.9.3-Yi-1.5-34B-32k\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">cognitivecomputations/dolphin-2.9.3-Yi-1.5-34B-32k</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/cognitivecomputations__dolphin-2.9.3-Yi-1.5-34B-32k-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "cognitivecomputations/dolphin-2.9.3-Yi-1.5-34B-32k", "Model sha": "ff4eee6438194a670a95dff3118b5231eb568610", "Average \u2b06\ufe0f": 26.846620311618697, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 17, "#Params (B)": 34, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3639266036339136, "IFEval": 36.39266036339136, "BBH Raw": 0.6046995537773227, "BBH": 43.40647565235176, "MATH Lvl 5 Raw": 0.1518126888217522, "MATH Lvl 5": 15.181268882175228, "GPQA Raw": 0.3431208053691275, "GPQA": 12.416107382550338, "MUSR Raw": 0.4310520833333333, "MUSR": 13.348177083333333, "MMLU-PRO Raw": 0.4630152925531915, "MMLU-PRO": 40.33503250591017, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-06-23T00:00:00", "Submission Date": "2024-07-27T00:00:00", "Generation": 1, "Base Model": "01-ai/Yi-1.5-34B-32k"}, {"eval_name": "cognitivecomputations_dolphin-2.9.3-mistral-7B-32k_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/cognitivecomputations/dolphin-2.9.3-mistral-7B-32k\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">cognitivecomputations/dolphin-2.9.3-mistral-7B-32k</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/cognitivecomputations__dolphin-2.9.3-mistral-7B-32k-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "cognitivecomputations/dolphin-2.9.3-mistral-7B-32k", "Model sha": "4f4273ee8e7930dd64e2c6121c79d12546b883e2", "Average \u2b06\ufe0f": 19.31093159907319, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 43, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4126362495955177, "IFEval": 41.26362495955176, "BBH Raw": 0.4812540148106201, "BBH": 26.906353891780515, "MATH Lvl 5 Raw": 0.0483383685800604, "MATH Lvl 5": 4.833836858006042, "GPQA Raw": 0.285234899328859, "GPQA": 4.697986577181204, "MUSR Raw": 0.4642604166666667, "MUSR": 17.932552083333338, "MMLU-PRO Raw": 0.2820811170212766, "MMLU-PRO": 20.231235224586285, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-06-25T00:00:00", "Submission Date": "2024-07-04T00:00:00", "Generation": 1, "Base Model": "mistralai/Mistral-7B-v0.3"}, {"eval_name": "cognitivecomputations_dolphin-2.9.3-mistral-nemo-12b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/cognitivecomputations/dolphin-2.9.3-mistral-nemo-12b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">cognitivecomputations/dolphin-2.9.3-mistral-nemo-12b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/cognitivecomputations__dolphin-2.9.3-mistral-nemo-12b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "cognitivecomputations/dolphin-2.9.3-mistral-nemo-12b", "Model sha": "7b535c900688fc836fbeebaeb7133910b09bafda", "Average \u2b06\ufe0f": 24.582199220299653, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 79, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5600894515441251, "IFEval": 56.00894515441252, "BBH Raw": 0.5480369183144175, "BBH": 36.08275865915292, "MATH Lvl 5 Raw": 0.0506042296072507, "MATH Lvl 5": 5.060422960725076, "GPQA Raw": 0.3154362416107382, "GPQA": 8.7248322147651, "MUSR Raw": 0.4429895833333333, "MUSR": 15.20703125, "MMLU-PRO Raw": 0.3376828457446808, "MMLU-PRO": 26.409205082742314, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-07-23T00:00:00", "Submission Date": "2024-07-26T00:00:00", "Generation": 1, "Base Model": "mistralai/Mistral-Nemo-Base-2407"}, {"eval_name": "cognitivecomputations_dolphin-2.9.4-gemma2-2b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/cognitivecomputations/dolphin-2.9.4-gemma2-2b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">cognitivecomputations/dolphin-2.9.4-gemma2-2b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/cognitivecomputations__dolphin-2.9.4-gemma2-2b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "cognitivecomputations/dolphin-2.9.4-gemma2-2b", "Model sha": "5c0854beb88a6711221771d1b13d51f733e6ca06", "Average \u2b06\ufe0f": 9.709324155874114, "Hub License": "gemma", "Hub \u2764\ufe0f": 27, "#Params (B)": 2, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.0895512794939649, "IFEval": 8.955127949396491, "BBH Raw": 0.4081318741105521, "BBH": 17.3676325443774, "MATH Lvl 5 Raw": 0.0415407854984894, "MATH Lvl 5": 4.154078549848943, "GPQA Raw": 0.2843959731543624, "GPQA": 4.586129753914992, "MUSR Raw": 0.41796875, "MUSR": 10.912760416666666, "MMLU-PRO Raw": 0.2105219414893617, "MMLU-PRO": 12.28021572104019, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-08-24T00:00:00", "Submission Date": "2024-08-25T00:00:00", "Generation": 1, "Base Model": "google/gemma-2-2b"}, {"eval_name": "cognitivecomputations_dolphin-2.9.4-llama3.1-8b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/cognitivecomputations/dolphin-2.9.4-llama3.1-8b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">cognitivecomputations/dolphin-2.9.4-llama3.1-8b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/cognitivecomputations__dolphin-2.9.4-llama3.1-8b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "cognitivecomputations/dolphin-2.9.4-llama3.1-8b", "Model sha": "7b73d1b7760bf9abac168de3d388b30d1ca1a138", "Average \u2b06\ufe0f": 6.95562754717428, "Hub License": "llama3.1", "Hub \u2764\ufe0f": 79, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2757239679605668, "IFEval": 27.572396796056683, "BBH Raw": 0.3523626385083256, "BBH": 8.972088688921525, "MATH Lvl 5 Raw": 0.0015105740181268, "MATH Lvl 5": 0.1510574018126888, "GPQA Raw": 0.2634228187919463, "GPQA": 1.789709172259505, "MUSR Raw": 0.3236145833333333, "MUSR": 0.6184895833333329, "MMLU-PRO Raw": 0.1236702127659574, "MMLU-PRO": 2.6300236406619386, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-08-04T00:00:00", "Submission Date": "2024-09-17T00:00:00", "Generation": 1, "Base Model": "meta-llama/Meta-Llama-3.1-8B"}, {"eval_name": "collaiborateorg_Collaiborator-MEDLLM-Llama-3-8B-v2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/collaiborateorg/Collaiborator-MEDLLM-Llama-3-8B-v2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">collaiborateorg/Collaiborator-MEDLLM-Llama-3-8B-v2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/collaiborateorg__Collaiborator-MEDLLM-Llama-3-8B-v2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "collaiborateorg/Collaiborator-MEDLLM-Llama-3-8B-v2", "Model sha": "2560556d655d0ecaefec10f579c92292d65fb28b", "Average \u2b06\ufe0f": 17.888694754140822, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.380887157187374, "IFEval": 38.08871571873739, "BBH Raw": 0.4648027954489896, "BBH": 23.64850317610825, "MATH Lvl 5 Raw": 0.0536253776435045, "MATH Lvl 5": 5.362537764350453, "GPQA Raw": 0.3330536912751677, "GPQA": 11.0738255033557, "MUSR Raw": 0.3434270833333333, "MUSR": 1.5950520833333328, "MMLU-PRO Raw": 0.3480718085106383, "MMLU-PRO": 27.56353427895981, "Maintainer's Highlight": false, "Upload To Hub Date": "", "Submission Date": "2024-06-27T00:00:00", "Generation": 0, "Base Model": "Removed"}, {"eval_name": "cstr_llama3.1-8b-spaetzle-v90_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/cstr/llama3.1-8b-spaetzle-v90\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">cstr/llama3.1-8b-spaetzle-v90</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/cstr__llama3.1-8b-spaetzle-v90-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "cstr/llama3.1-8b-spaetzle-v90", "Model sha": "717e5c3d31ed2465cd7cf927327adf677a9420b5", "Average \u2b06\ufe0f": 27.591016985406124, "Hub License": "llama3", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7356192679867197, "IFEval": 73.56192679867198, "BBH Raw": 0.5302860633332208, "BBH": 32.76366579584106, "MATH Lvl 5 Raw": 0.1336858006042296, "MATH Lvl 5": 13.36858006042296, "GPQA Raw": 0.2827181208053691, "GPQA": 4.36241610738255, "MUSR Raw": 0.4134374999999999, "MUSR": 11.146354166666663, "MMLU-PRO Raw": 0.3730884308510638, "MMLU-PRO": 30.34315898345153, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-15T00:00:00", "Submission Date": "2024-09-15T00:00:00", "Generation": 1, "Base Model": "cstr/llama3.1-8b-spaetzle-v90 (Merge)"}, {"eval_name": "cyberagent_calm3-22b-chat_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/cyberagent/calm3-22b-chat\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">cyberagent/calm3-22b-chat</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/cyberagent__calm3-22b-chat-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "cyberagent/calm3-22b-chat", "Model sha": "055922aa0f0fb1fbfbc97a2e31134532485ee99b", "Average \u2b06\ufe0f": 21.27488472867771, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 63, "#Params (B)": 22, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.509131327100981, "IFEval": 50.9131327100981, "BBH Raw": 0.4991683247746046, "BBH": 29.52088396885831, "MATH Lvl 5 Raw": 0.0589123867069486, "MATH Lvl 5": 5.8912386706948645, "GPQA Raw": 0.2768456375838926, "GPQA": 3.5794183445190177, "MUSR Raw": 0.4553229166666666, "MUSR": 16.082031249999996, "MMLU-PRO Raw": 0.2949634308510638, "MMLU-PRO": 21.66260342789598, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-01T00:00:00", "Submission Date": "2024-07-04T00:00:00", "Generation": 0, "Base Model": "cyberagent/calm3-22b-chat"}, {"eval_name": "darkc0de_BuddyGlassNeverSleeps_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/darkc0de/BuddyGlassNeverSleeps\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">darkc0de/BuddyGlassNeverSleeps</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/darkc0de__BuddyGlassNeverSleeps-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "darkc0de/BuddyGlassNeverSleeps", "Model sha": "f8849498f02c94b68ef0308a7bf6637264949a7d", "Average \u2b06\ufe0f": 19.732524776598908, "Hub License": null, "Hub \u2764\ufe0f": 2, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4239019135892764, "IFEval": 42.390191358927645, "BBH Raw": 0.4977228165364681, "BBH": 28.477953494418696, "MATH Lvl 5 Raw": 0.0574018126888217, "MATH Lvl 5": 5.740181268882175, "GPQA Raw": 0.2944630872483221, "GPQA": 5.92841163310962, "MUSR Raw": 0.3992708333333333, "MUSR": 8.608854166666669, "MMLU-PRO Raw": 0.3452460106382978, "MMLU-PRO": 27.249556737588648, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-16T00:00:00", "Submission Date": "2024-09-16T00:00:00", "Generation": 1, "Base Model": "darkc0de/BuddyGlassNeverSleeps (Merge)"}, {"eval_name": "darkc0de_BuddyGlass_v0.3_Xortron7MethedUpSwitchedUp_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/darkc0de/BuddyGlass_v0.3_Xortron7MethedUpSwitchedUp\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">darkc0de/BuddyGlass_v0.3_Xortron7MethedUpSwitchedUp</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/darkc0de__BuddyGlass_v0.3_Xortron7MethedUpSwitchedUp-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "darkc0de/BuddyGlass_v0.3_Xortron7MethedUpSwitchedUp", "Model sha": "57367fefe01c7d9653c303b28449b416fc777d93", "Average \u2b06\ufe0f": 22.03872875377341, "Hub License": null, "Hub \u2764\ufe0f": 1, "#Params (B)": 0, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4358424535787266, "IFEval": 43.58424535787267, "BBH Raw": 0.5243087998656722, "BBH": 31.869311081858005, "MATH Lvl 5 Raw": 0.1110271903323262, "MATH Lvl 5": 11.10271903323263, "GPQA Raw": 0.2986577181208054, "GPQA": 6.487695749440718, "MUSR Raw": 0.4143333333333334, "MUSR": 9.491666666666667, "MMLU-PRO Raw": 0.3672706117021276, "MMLU-PRO": 29.696734633569736, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-10T00:00:00", "Submission Date": "2024-09-15T00:00:00", "Generation": 1, "Base Model": "darkc0de/BuddyGlass_v0.3_Xortron7MethedUpSwitchedUp (Merge)"}, {"eval_name": "databricks_dbrx-instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "DbrxForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/databricks/dbrx-instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">databricks/dbrx-instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/databricks__dbrx-instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "databricks/dbrx-instruct", "Model sha": "c0a9245908c187da8f43a81e538e67ff360904ea", "Average \u2b06\ufe0f": 25.19901027244322, "Hub License": "other", "Hub \u2764\ufe0f": 1098, "#Params (B)": 131, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5415796752616391, "IFEval": 54.15796752616392, "BBH Raw": 0.5428960796934387, "BBH": 35.96381960359357, "MATH Lvl 5 Raw": 0.0687311178247734, "MATH Lvl 5": 6.873111782477341, "GPQA Raw": 0.3414429530201342, "GPQA": 12.192393736017896, "MUSR Raw": 0.4269270833333333, "MUSR": 12.19921875, "MMLU-PRO Raw": 0.3682679521276595, "MMLU-PRO": 29.807550236406616, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-03-26T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "databricks/dbrx-instruct"}, {"eval_name": "databricks_dolly-v1-6b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "GPTJForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/databricks/dolly-v1-6b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">databricks/dolly-v1-6b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/databricks__dolly-v1-6b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "databricks/dolly-v1-6b", "Model sha": "c9a85b3a322b402e20c839c702c725afe0cb454d", "Average \u2b06\ufe0f": 6.893114892840058, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 310, "#Params (B)": 6, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2224431175946488, "IFEval": 22.244311759464885, "BBH Raw": 0.3172089528774696, "BBH": 4.7813091701327, "MATH Lvl 5 Raw": 0.0135951661631419, "MATH Lvl 5": 1.3595166163141994, "GPQA Raw": 0.2642617449664429, "GPQA": 1.9015659955257265, "MUSR Raw": 0.4004166666666666, "MUSR": 8.118750000000002, "MMLU-PRO Raw": 0.1265791223404255, "MMLU-PRO": 2.953235815602837, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-03-23T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "databricks/dolly-v1-6b"}, {"eval_name": "databricks_dolly-v2-12b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "GPTNeoXForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/databricks/dolly-v2-12b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">databricks/dolly-v2-12b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/databricks__dolly-v2-12b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "databricks/dolly-v2-12b", "Model sha": "19308160448536e378e3db21a73a751579ee7fdd", "Average \u2b06\ufe0f": 6.383023820314098, "Hub License": "mit", "Hub \u2764\ufe0f": 1948, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2355073427394867, "IFEval": 23.55073427394868, "BBH Raw": 0.3319973167377127, "BBH": 6.377894137452961, "MATH Lvl 5 Raw": 0.0143504531722054, "MATH Lvl 5": 1.4350453172205435, "GPQA Raw": 0.2407718120805369, "GPQA": 0.0, "MUSR Raw": 0.37390625, "MUSR": 5.504947916666668, "MMLU-PRO Raw": 0.1128656914893617, "MMLU-PRO": 1.4295212765957446, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-04-11T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "databricks/dolly-v2-12b"}, {"eval_name": "databricks_dolly-v2-3b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "GPTNeoXForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/databricks/dolly-v2-3b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">databricks/dolly-v2-3b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/databricks__dolly-v2-3b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "databricks/dolly-v2-3b", "Model sha": "f6c9be08f16fe4d3a719bee0a4a7c7415b5c65df", "Average \u2b06\ufe0f": 5.448600841258123, "Hub License": "mit", "Hub \u2764\ufe0f": 287, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2247159758330119, "IFEval": 22.4715975833012, "BBH Raw": 0.3079278596154484, "BBH": 3.3247689565453875, "MATH Lvl 5 Raw": 0.0060422960725075, "MATH Lvl 5": 0.6042296072507553, "GPQA Raw": 0.2609060402684564, "GPQA": 1.45413870246085, "MUSR Raw": 0.33378125, "MUSR": 3.22265625, "MMLU-PRO Raw": 0.1145279255319148, "MMLU-PRO": 1.6142139479905429, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-04-13T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "databricks/dolly-v2-3b"}, {"eval_name": "databricks_dolly-v2-7b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "GPTNeoXForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/databricks/dolly-v2-7b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">databricks/dolly-v2-7b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/databricks__dolly-v2-7b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "databricks/dolly-v2-7b", "Model sha": "d632f0c8b75b1ae5b26b250d25bfba4e99cb7c6f", "Average \u2b06\ufe0f": 5.571831773906653, "Hub License": "mit", "Hub \u2764\ufe0f": 147, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2009856070781083, "IFEval": 20.098560707810837, "BBH Raw": 0.3173062812207032, "BBH": 5.449892512817211, "MATH Lvl 5 Raw": 0.0098187311178247, "MATH Lvl 5": 0.9818731117824772, "GPQA Raw": 0.2684563758389262, "GPQA": 2.460850111856823, "MUSR Raw": 0.3553020833333333, "MUSR": 2.779427083333333, "MMLU-PRO Raw": 0.1149434840425532, "MMLU-PRO": 1.6603871158392434, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-04-13T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "databricks/dolly-v2-7b"}, {"eval_name": "davidkim205_Rhea-72b-v0.5_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/davidkim205/Rhea-72b-v0.5\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">davidkim205/Rhea-72b-v0.5</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/davidkim205__Rhea-72b-v0.5-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "davidkim205/Rhea-72b-v0.5", "Model sha": "bc3806efb23d2713e6630a748d9747fd76b27169", "Average \u2b06\ufe0f": 4.022621505499882, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 133, "#Params (B)": 72, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.0145380922618651, "IFEval": 1.4538092261865183, "BBH Raw": 0.3078339592906859, "BBH": 3.6707473002836015, "MATH Lvl 5 Raw": 0.0551359516616314, "MATH Lvl 5": 5.5135951661631415, "GPQA Raw": 0.2525167785234899, "GPQA": 0.3355704697986553, "MUSR Raw": 0.4241354166666666, "MUSR": 11.316927083333333, "MMLU-PRO Raw": 0.1166057180851063, "MMLU-PRO": 1.8450797872340408, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-03-22T00:00:00", "Submission Date": "2024-09-15T00:00:00", "Generation": 0, "Base Model": "davidkim205/Rhea-72b-v0.5"}, {"eval_name": "davidkim205_nox-solar-10.7b-v4_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/davidkim205/nox-solar-10.7b-v4\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">davidkim205/nox-solar-10.7b-v4</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/davidkim205__nox-solar-10.7b-v4-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "davidkim205/nox-solar-10.7b-v4", "Model sha": "5f4be6cb7d8398b84689148d15f3838f2e01e104", "Average \u2b06\ufe0f": 18.489144848488248, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 11, "#Params (B)": 10, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3753418706809044, "IFEval": 37.534187068090446, "BBH Raw": 0.4814038018918371, "BBH": 26.631088145699614, "MATH Lvl 5 Raw": 0.0067975830815709, "MATH Lvl 5": 0.6797583081570997, "GPQA Raw": 0.3070469798657718, "GPQA": 7.606263982102905, "MUSR Raw": 0.42984375, "MUSR": 12.563802083333334, "MMLU-PRO Raw": 0.3332779255319149, "MMLU-PRO": 25.919769503546096, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-03-16T00:00:00", "Submission Date": "2024-10-04T00:00:00", "Generation": 0, "Base Model": "davidkim205/nox-solar-10.7b-v4"}, {"eval_name": "deepseek-ai_deepseek-llm-67b-chat_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/deepseek-ai/deepseek-llm-67b-chat\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">deepseek-ai/deepseek-llm-67b-chat</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/deepseek-ai__deepseek-llm-67b-chat-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "deepseek-ai/deepseek-llm-67b-chat", "Model sha": "79648bef7658bb824e4630740f6e1484c1b0620b", "Average \u2b06\ufe0f": 26.870047786116405, "Hub License": "other", "Hub \u2764\ufe0f": 177, "#Params (B)": 67, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5587153197959193, "IFEval": 55.87153197959192, "BBH Raw": 0.5243416179742358, "BBH": 33.22524192534525, "MATH Lvl 5 Raw": 0.066465256797583, "MATH Lvl 5": 6.646525679758309, "GPQA Raw": 0.3162751677852349, "GPQA": 8.83668903803132, "MUSR Raw": 0.5058645833333334, "MUSR": 23.93307291666666, "MMLU-PRO Raw": 0.3943650265957447, "MMLU-PRO": 32.70722517730496, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-11-29T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "deepseek-ai/deepseek-llm-67b-chat"}, {"eval_name": "deepseek-ai_deepseek-llm-7b-base_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/deepseek-ai/deepseek-llm-7b-base\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">deepseek-ai/deepseek-llm-7b-base</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/deepseek-ai__deepseek-llm-7b-base-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "deepseek-ai/deepseek-llm-7b-base", "Model sha": "7683fea62db869066ddaff6a41d032262c490d4f", "Average \u2b06\ufe0f": 8.101217266693423, "Hub License": "other", "Hub \u2764\ufe0f": 35, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.217871913190335, "IFEval": 21.787191319033496, "BBH Raw": 0.3503031582929952, "BBH": 9.76792479590425, "MATH Lvl 5 Raw": 0.0120845921450151, "MATH Lvl 5": 1.2084592145015105, "GPQA Raw": 0.273489932885906, "GPQA": 3.1319910514541416, "MUSR Raw": 0.3737812499999999, "MUSR": 3.755989583333332, "MMLU-PRO Raw": 0.1806017287234042, "MMLU-PRO": 8.955747635933804, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-11-29T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "deepseek-ai/deepseek-llm-7b-base"}, {"eval_name": "deepseek-ai_deepseek-llm-7b-chat_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/deepseek-ai/deepseek-llm-7b-chat\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">deepseek-ai/deepseek-llm-7b-chat</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/deepseek-ai__deepseek-llm-7b-chat-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "deepseek-ai/deepseek-llm-7b-chat", "Model sha": "afbda8b347ec881666061fa67447046fc5164ec8", "Average \u2b06\ufe0f": 14.772804383415462, "Hub License": "other", "Hub \u2764\ufe0f": 75, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4170822307034225, "IFEval": 41.70822307034224, "BBH Raw": 0.3632079760108669, "BBH": 11.258949371501748, "MATH Lvl 5 Raw": 0.0173716012084592, "MATH Lvl 5": 1.7371601208459215, "GPQA Raw": 0.2659395973154362, "GPQA": 2.1252796420581683, "MUSR Raw": 0.4667708333333333, "MUSR": 19.21302083333333, "MMLU-PRO Raw": 0.2133477393617021, "MMLU-PRO": 12.594193262411348, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-11-29T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "deepseek-ai/deepseek-llm-7b-chat"}, {"eval_name": "deepseek-ai_deepseek-moe-16b-base_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "DeepseekForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/deepseek-ai/deepseek-moe-16b-base\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">deepseek-ai/deepseek-moe-16b-base</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/deepseek-ai__deepseek-moe-16b-base-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "deepseek-ai/deepseek-moe-16b-base", "Model sha": "521d2bc4fb69a3f3ae565310fcc3b65f97af2580", "Average \u2b06\ufe0f": 7.365628857118445, "Hub License": "other", "Hub \u2764\ufe0f": 81, "#Params (B)": 16, "Available on the hub": true, "Not_Merged": true, "MoE": false, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2449744455821664, "IFEval": 24.49744455821664, "BBH Raw": 0.3409461055246395, "BBH": 8.355555779389382, "MATH Lvl 5 Raw": 0.0181268882175226, "MATH Lvl 5": 1.812688821752266, "GPQA Raw": 0.2541946308724832, "GPQA": 0.5592841163310973, "MUSR Raw": 0.36578125, "MUSR": 3.355989583333334, "MMLU-PRO Raw": 0.1505152925531915, "MMLU-PRO": 5.612810283687943, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-01-08T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "deepseek-ai/deepseek-moe-16b-base"}, {"eval_name": "deepseek-ai_deepseek-moe-16b-chat_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "DeepseekForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/deepseek-ai/deepseek-moe-16b-chat\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">deepseek-ai/deepseek-moe-16b-chat</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/deepseek-ai__deepseek-moe-16b-chat-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "deepseek-ai/deepseek-moe-16b-chat", "Model sha": "eefd8ac7e8dc90e095129fe1a537d5e236b2e57c", "Average \u2b06\ufe0f": 10.139557822520734, "Hub License": "other", "Hub \u2764\ufe0f": 112, "#Params (B)": 16, "Available on the hub": true, "Not_Merged": true, "MoE": false, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.366299197241098, "IFEval": 36.62991972410981, "BBH Raw": 0.3274953026448241, "BBH": 6.573749026890635, "MATH Lvl 5 Raw": 0.0166163141993957, "MATH Lvl 5": 1.6616314199395772, "GPQA Raw": 0.2248322147651006, "GPQA": 0.0, "MUSR Raw": 0.3807604166666666, "MUSR": 5.261718750000001, "MMLU-PRO Raw": 0.1963929521276596, "MMLU-PRO": 10.710328014184398, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-01-09T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "deepseek-ai/deepseek-moe-16b-chat"}, {"eval_name": "dfurman_CalmeRys-78B-Orpo-v0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/dfurman/CalmeRys-78B-Orpo-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">dfurman/CalmeRys-78B-Orpo-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/dfurman__CalmeRys-78B-Orpo-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "dfurman/CalmeRys-78B-Orpo-v0.1", "Model sha": "7988deb48419c3f56bb24c139c23e5c476ec03f8", "Average \u2b06\ufe0f": 50.77815087058889, "Hub License": "mit", "Hub \u2764\ufe0f": 16, "#Params (B)": 77, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.8163273447785211, "IFEval": 81.6327344778521, "BBH Raw": 0.7262282792249927, "BBH": 61.92476379259157, "MATH Lvl 5 Raw": 0.3791540785498489, "MATH Lvl 5": 37.91540785498489, "GPQA Raw": 0.4001677852348993, "GPQA": 20.02237136465324, "MUSR Raw": 0.5901770833333333, "MUSR": 36.37213541666666, "MMLU-PRO Raw": 0.7012134308510638, "MMLU-PRO": 66.80149231678487, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-24T00:00:00", "Submission Date": "2024-09-24T00:00:00", "Generation": 1, "Base Model": "dfurman/CalmeRys-78B-Orpo-v0.1 (Merge)"}, {"eval_name": "dfurman_Llama-3-70B-Orpo-v0.1_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Adapter", "Architecture": "?", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/dfurman/Llama-3-70B-Orpo-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">dfurman/Llama-3-70B-Orpo-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/dfurman__Llama-3-70B-Orpo-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "dfurman/Llama-3-70B-Orpo-v0.1", "Model sha": "6bf3be5f7f427164c879f7a4ec9ccb6b22aa6631", "Average \u2b06\ufe0f": 17.922417964829112, "Hub License": "llama3", "Hub \u2764\ufe0f": 2, "#Params (B)": 70, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2049074234143184, "IFEval": 20.490742341431847, "BBH Raw": 0.465523763470155, "BBH": 24.09381654636037, "MATH Lvl 5 Raw": 0.1351963746223565, "MATH Lvl 5": 13.51963746223565, "GPQA Raw": 0.2575503355704698, "GPQA": 1.0067114093959737, "MUSR Raw": 0.4534375, "MUSR": 16.2796875, "MMLU-PRO Raw": 0.3892952127659574, "MMLU-PRO": 32.14391252955083, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-26T00:00:00", "Submission Date": "2024-08-30T00:00:00", "Generation": 1, "Base Model": "dfurman/Llama-3-70B-Orpo-v0.1 (Merge)"}, {"eval_name": "dfurman_Llama-3-8B-Orpo-v0.1_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Adapter", "Architecture": "?", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/dfurman/Llama-3-8B-Orpo-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">dfurman/Llama-3-8B-Orpo-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/dfurman__Llama-3-8B-Orpo-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "dfurman/Llama-3-8B-Orpo-v0.1", "Model sha": "f02aef830e12a50892ac065826d5eb3dfc7675d1", "Average \u2b06\ufe0f": 10.756011142762684, "Hub License": "llama3", "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2835177329485764, "IFEval": 28.351773294857644, "BBH Raw": 0.3842420919898036, "BBH": 13.68074574746978, "MATH Lvl 5 Raw": 0.0438066465256797, "MATH Lvl 5": 4.380664652567976, "GPQA Raw": 0.2609060402684564, "GPQA": 1.45413870246085, "MUSR Raw": 0.3566354166666667, "MUSR": 2.24609375, "MMLU-PRO Raw": 0.2298038563829787, "MMLU-PRO": 14.42265070921986, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-26T00:00:00", "Submission Date": "2024-08-30T00:00:00", "Generation": 1, "Base Model": "dfurman/Llama-3-8B-Orpo-v0.1 (Merge)"}, {"eval_name": "dfurman_Llama-3-8B-Orpo-v0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/dfurman/Llama-3-8B-Orpo-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">dfurman/Llama-3-8B-Orpo-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/dfurman__Llama-3-8B-Orpo-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "dfurman/Llama-3-8B-Orpo-v0.1", "Model sha": "f02aef830e12a50892ac065826d5eb3dfc7675d1", "Average \u2b06\ufe0f": 11.013217362129728, "Hub License": "llama3", "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3000039894147528, "IFEval": 30.00039894147528, "BBH Raw": 0.3852967582460245, "BBH": 13.773376256003464, "MATH Lvl 5 Raw": 0.0377643504531722, "MATH Lvl 5": 3.776435045317221, "GPQA Raw": 0.261744966442953, "GPQA": 1.5659955257270708, "MUSR Raw": 0.357875, "MUSR": 2.734375, "MMLU-PRO Raw": 0.2280585106382978, "MMLU-PRO": 14.22872340425532, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-26T00:00:00", "Submission Date": "2024-08-30T00:00:00", "Generation": 1, "Base Model": "dfurman/Llama-3-8B-Orpo-v0.1 (Merge)"}, {"eval_name": "dfurman_Qwen2-72B-Orpo-v0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/dfurman/Qwen2-72B-Orpo-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">dfurman/Qwen2-72B-Orpo-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/dfurman__Qwen2-72B-Orpo-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "dfurman/Qwen2-72B-Orpo-v0.1", "Model sha": "26c7bbaa728822c60bb47b2808972140653aae4c", "Average \u2b06\ufe0f": 43.31630790696215, "Hub License": "other", "Hub \u2764\ufe0f": 4, "#Params (B)": 72, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7879759039348928, "IFEval": 78.79759039348927, "BBH Raw": 0.6969024790545039, "BBH": 57.41436351018751, "MATH Lvl 5 Raw": 0.3542296072507553, "MATH Lvl 5": 35.422960725075534, "GPQA Raw": 0.384228187919463, "GPQA": 17.897091722595075, "MUSR Raw": 0.4784270833333333, "MUSR": 20.87005208333333, "MMLU-PRO Raw": 0.5454621010638298, "MMLU-PRO": 49.49578900709219, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-05T00:00:00", "Submission Date": "2024-08-22T00:00:00", "Generation": 1, "Base Model": "dfurman/Qwen2-72B-Orpo-v0.1 (Merge)"}, {"eval_name": "dicta-il_dictalm2.0_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe9 continuously pretrained", "T": "\ud83d\udfe9", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/dicta-il/dictalm2.0\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">dicta-il/dictalm2.0</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/dicta-il__dictalm2.0-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "dicta-il/dictalm2.0", "Model sha": "f8ab3208e95a7b44a9a2fbb9bbbdd8ea11be509d", "Average \u2b06\ufe0f": 11.8448328783167, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 10, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2413274555955974, "IFEval": 24.132745559559744, "BBH Raw": 0.4017869112495909, "BBH": 16.48984561578202, "MATH Lvl 5 Raw": 0.0151057401812688, "MATH Lvl 5": 1.5105740181268883, "GPQA Raw": 0.2919463087248322, "GPQA": 5.592841163310966, "MUSR Raw": 0.3819687499999999, "MUSR": 5.512760416666668, "MMLU-PRO Raw": 0.2604720744680851, "MMLU-PRO": 17.830230496453904, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-10T00:00:00", "Submission Date": "2024-07-31T00:00:00", "Generation": 0, "Base Model": "dicta-il/dictalm2.0"}, {"eval_name": "dicta-il_dictalm2.0-instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/dicta-il/dictalm2.0-instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">dicta-il/dictalm2.0-instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/dicta-il__dictalm2.0-instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "dicta-il/dictalm2.0-instruct", "Model sha": "257c6023d6ac1bfa12110b7b17e7600da7da4e1e", "Average \u2b06\ufe0f": 16.577811600535515, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 18, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4412126491043763, "IFEval": 44.12126491043764, "BBH Raw": 0.4256078498591287, "BBH": 19.68807585119424, "MATH Lvl 5 Raw": 0.0105740181268882, "MATH Lvl 5": 1.0574018126888218, "GPQA Raw": 0.3028523489932886, "GPQA": 7.046979865771815, "MUSR Raw": 0.3945833333333333, "MUSR": 9.722916666666668, "MMLU-PRO Raw": 0.2604720744680851, "MMLU-PRO": 17.830230496453904, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-14T00:00:00", "Submission Date": "2024-07-31T00:00:00", "Generation": 1, "Base Model": "dicta-il/dictalm2.0"}, {"eval_name": "distilbert_distilgpt2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "GPT2LMHeadModel", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/distilbert/distilgpt2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">distilbert/distilgpt2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/distilbert__distilgpt2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "distilbert/distilgpt2", "Model sha": "2290a62682d06624634c1f46a6ad5be0f47f38aa", "Average \u2b06\ufe0f": 3.901568892678573, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 431, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.0611001032815152, "IFEval": 6.110010328151527, "BBH Raw": 0.3037988148650536, "BBH": 2.835219845513963, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.259228187919463, "GPQA": 1.230425055928408, "MUSR Raw": 0.4207291666666666, "MUSR": 11.1578125, "MMLU-PRO Raw": 0.1186835106382978, "MMLU-PRO": 2.0759456264775418, "Maintainer's Highlight": true, "Upload To Hub Date": "2022-03-02T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "distilbert/distilgpt2"}, {"eval_name": "djuna_G2-GSHT_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/djuna/G2-GSHT\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">djuna/G2-GSHT</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/djuna__G2-GSHT-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "djuna/G2-GSHT", "Model sha": "afa34f893a74af2a21b71f83d7bcc16aa818d157", "Average \u2b06\ufe0f": 21.95096470184211, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 10, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5630116978505919, "IFEval": 56.3011697850592, "BBH Raw": 0.5269730491270207, "BBH": 30.99205901512568, "MATH Lvl 5 Raw": 0.0317220543806646, "MATH Lvl 5": 3.1722054380664653, "GPQA Raw": 0.3255033557046979, "GPQA": 10.067114093959727, "MUSR Raw": 0.4005729166666666, "MUSR": 8.171614583333332, "MMLU-PRO Raw": 0.3070146276595745, "MMLU-PRO": 23.00162529550828, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-09T00:00:00", "Submission Date": "2024-10-05T00:00:00", "Generation": 1, "Base Model": "djuna/G2-GSHT (Merge)"}, {"eval_name": "djuna_Gemma-2-gemmama-9b_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/djuna/Gemma-2-gemmama-9b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">djuna/Gemma-2-gemmama-9b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/djuna__Gemma-2-gemmama-9b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "djuna/Gemma-2-gemmama-9b", "Model sha": "1d6c53ad18970ac082e86bfa0159789b6a6e79c0", "Average \u2b06\ufe0f": 25.54250714906874, "Hub License": null, "Hub \u2764\ufe0f": 2, "#Params (B)": 10, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7703404743857409, "IFEval": 77.0340474385741, "BBH Raw": 0.5420037856495951, "BBH": 32.916050576064585, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.3355704697986577, "GPQA": 11.409395973154364, "MUSR Raw": 0.4031458333333333, "MUSR": 8.459895833333333, "MMLU-PRO Raw": 0.3109208776595745, "MMLU-PRO": 23.43565307328605, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-31T00:00:00", "Submission Date": "2024-10-05T00:00:00", "Generation": 1, "Base Model": "djuna/Gemma-2-gemmama-9b (Merge)"}, {"eval_name": "djuna_L3.1-ForStHS_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/djuna/L3.1-ForStHS\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">djuna/L3.1-ForStHS</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/djuna__L3.1-ForStHS-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "djuna/L3.1-ForStHS", "Model sha": "f5442e1f27e4a0c469504624ea85afdc6907c9cc", "Average \u2b06\ufe0f": 27.995689142073758, "Hub License": null, "Hub \u2764\ufe0f": 3, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7813313120298586, "IFEval": 78.13313120298585, "BBH Raw": 0.5202703381267152, "BBH": 31.3912168031268, "MATH Lvl 5 Raw": 0.1291540785498489, "MATH Lvl 5": 12.915407854984895, "GPQA Raw": 0.2911073825503356, "GPQA": 5.480984340044745, "MUSR Raw": 0.4026458333333333, "MUSR": 9.664062500000002, "MMLU-PRO Raw": 0.3735039893617021, "MMLU-PRO": 30.38933215130024, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-10T00:00:00", "Submission Date": "2024-09-15T00:00:00", "Generation": 1, "Base Model": "djuna/L3.1-ForStHS (Merge)"}, {"eval_name": "djuna_L3.1-Suze-Vume-calc_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/djuna/L3.1-Suze-Vume-calc\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">djuna/L3.1-Suze-Vume-calc</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/djuna__L3.1-Suze-Vume-calc-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "djuna/L3.1-Suze-Vume-calc", "Model sha": "830c07d136ecd8171805078606f00c4ee69f21c3", "Average \u2b06\ufe0f": 25.74902162359581, "Hub License": null, "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7296739318341999, "IFEval": 72.96739318341999, "BBH Raw": 0.516421105092519, "BBH": 31.136638199988276, "MATH Lvl 5 Raw": 0.0989425981873111, "MATH Lvl 5": 9.894259818731117, "GPQA Raw": 0.2818791946308724, "GPQA": 4.250559284116329, "MUSR Raw": 0.3842916666666666, "MUSR": 8.303124999999996, "MMLU-PRO Raw": 0.3514793882978723, "MMLU-PRO": 27.942154255319146, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-26T00:00:00", "Submission Date": "2024-09-04T00:00:00", "Generation": 1, "Base Model": "djuna/L3.1-Suze-Vume-calc (Merge)"}, {"eval_name": "djuna_MN-Chinofun_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/djuna/MN-Chinofun\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">djuna/MN-Chinofun</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/djuna__MN-Chinofun-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "djuna/MN-Chinofun", "Model sha": "71b47c86f32e107b407fada44ec6b893c5eb8bb0", "Average \u2b06\ufe0f": 24.25583804714945, "Hub License": null, "Hub \u2764\ufe0f": 3, "#Params (B)": 12, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6110220880596817, "IFEval": 61.102208805968175, "BBH Raw": 0.4952703381267153, "BBH": 28.48357519092637, "MATH Lvl 5 Raw": 0.1049848942598187, "MATH Lvl 5": 10.498489425981871, "GPQA Raw": 0.2961409395973154, "GPQA": 6.152125279642054, "MUSR Raw": 0.4083541666666666, "MUSR": 10.377604166666664, "MMLU-PRO Raw": 0.3602892287234042, "MMLU-PRO": 28.921025413711572, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-16T00:00:00", "Submission Date": "2024-09-23T00:00:00", "Generation": 1, "Base Model": "djuna/MN-Chinofun (Merge)"}, {"eval_name": "dnhkng_RYS-Medium_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe9 continuously pretrained", "T": "\ud83d\udfe9", "Weight type": "Original", "Architecture": "Phi3ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/dnhkng/RYS-Medium\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">dnhkng/RYS-Medium</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/dnhkng__RYS-Medium-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "dnhkng/RYS-Medium", "Model sha": "de09a79e6b2efdcc97490a37b770764e62749fd0", "Average \u2b06\ufe0f": 25.94422727612673, "Hub License": "mit", "Hub \u2764\ufe0f": 3, "#Params (B)": 18, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4406131287206833, "IFEval": 44.06131287206833, "BBH Raw": 0.6284726872432828, "BBH": 47.73420132486152, "MATH Lvl 5 Raw": 0.0777945619335347, "MATH Lvl 5": 7.779456193353475, "GPQA Raw": 0.3280201342281879, "GPQA": 10.402684563758392, "MUSR Raw": 0.4069270833333333, "MUSR": 8.732552083333331, "MMLU-PRO Raw": 0.4325964095744681, "MMLU-PRO": 36.95515661938535, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-17T00:00:00", "Submission Date": "2024-07-17T00:00:00", "Generation": 0, "Base Model": "dnhkng/RYS-Medium"}, {"eval_name": "dnhkng_RYS-Llama-3-8B-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/dnhkng/RYS-Llama-3-8B-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">dnhkng/RYS-Llama-3-8B-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/dnhkng__RYS-Llama-3-8B-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "dnhkng/RYS-Llama-3-8B-Instruct", "Model sha": "293ab00d1e2be2752f97d5568fde2b09f6a1caae", "Average \u2b06\ufe0f": 21.80948168529132, "Hub License": "mit", "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6957772044841022, "IFEval": 69.57772044841022, "BBH Raw": 0.4808708123069005, "BBH": 25.373015462245583, "MATH Lvl 5 Raw": 0.0619335347432024, "MATH Lvl 5": 6.193353474320242, "GPQA Raw": 0.2575503355704698, "GPQA": 1.0067114093959737, "MUSR Raw": 0.33834375, "MUSR": 0.2929687499999995, "MMLU-PRO Raw": 0.355718085106383, "MMLU-PRO": 28.413120567375884, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-06T00:00:00", "Submission Date": "2024-08-07T00:00:00", "Generation": 0, "Base Model": "dnhkng/RYS-Llama-3-8B-Instruct"}, {"eval_name": "dnhkng_RYS-Llama-3-Huge-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/dnhkng/RYS-Llama-3-Huge-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">dnhkng/RYS-Llama-3-Huge-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/dnhkng__RYS-Llama-3-Huge-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "dnhkng/RYS-Llama-3-Huge-Instruct", "Model sha": "cfe14a5339e88a7a89f075d9d48215d45f64acaf", "Average \u2b06\ufe0f": 34.36706733560015, "Hub License": "mit", "Hub \u2764\ufe0f": 1, "#Params (B)": 99, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7685917809190725, "IFEval": 76.85917809190724, "BBH Raw": 0.6480872171360044, "BBH": 49.07372077223325, "MATH Lvl 5 Raw": 0.2122356495468278, "MATH Lvl 5": 21.22356495468278, "GPQA Raw": 0.2609060402684564, "GPQA": 1.45413870246085, "MUSR Raw": 0.4207604166666667, "MUSR": 11.92838541666667, "MMLU-PRO Raw": 0.510970744680851, "MMLU-PRO": 45.66341607565011, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-06T00:00:00", "Submission Date": "2024-08-07T00:00:00", "Generation": 0, "Base Model": "dnhkng/RYS-Llama-3-Huge-Instruct"}, {"eval_name": "dnhkng_RYS-Llama-3-Large-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/dnhkng/RYS-Llama-3-Large-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">dnhkng/RYS-Llama-3-Large-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/dnhkng__RYS-Llama-3-Large-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "dnhkng/RYS-Llama-3-Large-Instruct", "Model sha": "01e3208aaf7bf6d2b09737960c701ec6628977fe", "Average \u2b06\ufe0f": 35.779806266044154, "Hub License": "mit", "Hub \u2764\ufe0f": 1, "#Params (B)": 73, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.8050616807847621, "IFEval": 80.50616807847622, "BBH Raw": 0.65252690724939, "BBH": 49.66553902889135, "MATH Lvl 5 Raw": 0.2182779456193353, "MATH Lvl 5": 21.827794561933533, "GPQA Raw": 0.2894295302013422, "GPQA": 5.257270693512303, "MUSR Raw": 0.41803125, "MUSR": 11.453906250000005, "MMLU-PRO Raw": 0.5137134308510638, "MMLU-PRO": 45.96815898345154, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-06T00:00:00", "Submission Date": "2024-08-07T00:00:00", "Generation": 0, "Base Model": "dnhkng/RYS-Llama-3-Large-Instruct"}, {"eval_name": "dnhkng_RYS-Llama-3.1-8B-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Adapter", "Architecture": "?", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/dnhkng/RYS-Llama-3.1-8B-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">dnhkng/RYS-Llama-3.1-8B-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/dnhkng__RYS-Llama-3.1-8B-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "dnhkng/RYS-Llama-3.1-8B-Instruct", "Model sha": "d4e2393403dcae19860da7c29519c8fe6fbf2fad", "Average \u2b06\ufe0f": 26.43666417772775, "Hub License": "mit", "Hub \u2764\ufe0f": 11, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7684920455502511, "IFEval": 76.84920455502511, "BBH Raw": 0.5163645317446665, "BBH": 31.085445296018975, "MATH Lvl 5 Raw": 0.1132930513595166, "MATH Lvl 5": 11.329305135951662, "GPQA Raw": 0.2676174496644295, "GPQA": 2.348993288590602, "MUSR Raw": 0.3681041666666667, "MUSR": 7.679687500000001, "MMLU-PRO Raw": 0.3639461436170212, "MMLU-PRO": 29.32734929078014, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-08T00:00:00", "Submission Date": "2024-08-30T00:00:00", "Generation": 0, "Base Model": "dnhkng/RYS-Llama-3.1-8B-Instruct"}, {"eval_name": "dnhkng_RYS-Llama3.1-Large_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/dnhkng/RYS-Llama3.1-Large\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">dnhkng/RYS-Llama3.1-Large</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/dnhkng__RYS-Llama3.1-Large-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "dnhkng/RYS-Llama3.1-Large", "Model sha": "52cc979de78155b33689efa48f52a8aab184bd86", "Average \u2b06\ufe0f": 41.5975372302863, "Hub License": "mit", "Hub \u2764\ufe0f": 1, "#Params (B)": 81, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.8492001223420524, "IFEval": 84.92001223420525, "BBH Raw": 0.6899112229777242, "BBH": 55.41486404819653, "MATH Lvl 5 Raw": 0.283987915407855, "MATH Lvl 5": 28.3987915407855, "GPQA Raw": 0.3741610738255033, "GPQA": 16.554809843400445, "MUSR Raw": 0.4553958333333334, "MUSR": 17.091145833333332, "MMLU-PRO Raw": 0.5248503989361702, "MMLU-PRO": 47.20559988179669, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-11T00:00:00", "Submission Date": "2024-08-22T00:00:00", "Generation": 0, "Base Model": "dnhkng/RYS-Llama3.1-Large"}, {"eval_name": "dnhkng_RYS-Phi-3-medium-4k-instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "Phi3ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/dnhkng/RYS-Phi-3-medium-4k-instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">dnhkng/RYS-Phi-3-medium-4k-instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/dnhkng__RYS-Phi-3-medium-4k-instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "dnhkng/RYS-Phi-3-medium-4k-instruct", "Model sha": "1009e916b1ff8c9a53bc9d8ff48bea2a15ccde26", "Average \u2b06\ufe0f": 28.37616729095963, "Hub License": "mit", "Hub \u2764\ufe0f": 1, "#Params (B)": 17, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4391392616036561, "IFEval": 43.913926160365605, "BBH Raw": 0.6226313539198264, "BBH": 46.748970518349154, "MATH Lvl 5 Raw": 0.1178247734138972, "MATH Lvl 5": 11.782477341389727, "GPQA Raw": 0.3548657718120805, "GPQA": 13.982102908277405, "MUSR Raw": 0.42528125, "MUSR": 11.093489583333332, "MMLU-PRO Raw": 0.484624335106383, "MMLU-PRO": 42.73603723404255, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-06T00:00:00", "Submission Date": "2024-08-07T00:00:00", "Generation": 0, "Base Model": "dnhkng/RYS-Phi-3-medium-4k-instruct"}, {"eval_name": "dnhkng_RYS-XLarge_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/dnhkng/RYS-XLarge\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">dnhkng/RYS-XLarge</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/dnhkng__RYS-XLarge-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "dnhkng/RYS-XLarge", "Model sha": "0f84dd9dde60f383e1e2821496befb4ce9a11ef6", "Average \u2b06\ufe0f": 44.75357825862317, "Hub License": "mit", "Hub \u2764\ufe0f": 69, "#Params (B)": 77, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.7995662619627034, "IFEval": 79.95662619627035, "BBH Raw": 0.7050033079850099, "BBH": 58.77356748233938, "MATH Lvl 5 Raw": 0.3897280966767371, "MATH Lvl 5": 38.97280966767372, "GPQA Raw": 0.384228187919463, "GPQA": 17.897091722595075, "MUSR Raw": 0.49696875, "MUSR": 23.72109375, "MMLU-PRO Raw": 0.5428025265957447, "MMLU-PRO": 49.20028073286053, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-24T00:00:00", "Submission Date": "2024-08-07T00:00:00", "Generation": 0, "Base Model": "dnhkng/RYS-XLarge"}, {"eval_name": "dnhkng_RYS-XLarge-base_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Adapter", "Architecture": "?", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/dnhkng/RYS-XLarge-base\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">dnhkng/RYS-XLarge-base</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/dnhkng__RYS-XLarge-base-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "dnhkng/RYS-XLarge-base", "Model sha": "c718b3d9e24916e3b0347d3fdaa5e5a097c2f603", "Average \u2b06\ufe0f": 43.55554667715547, "Hub License": "mit", "Hub \u2764\ufe0f": 3, "#Params (B)": 77, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7910233735377686, "IFEval": 79.10233735377686, "BBH Raw": 0.7047291858548728, "BBH": 58.69214607657639, "MATH Lvl 5 Raw": 0.3466767371601209, "MATH Lvl 5": 34.66767371601209, "GPQA Raw": 0.3791946308724832, "GPQA": 17.225950782997764, "MUSR Raw": 0.4902708333333334, "MUSR": 22.4171875, "MMLU-PRO Raw": 0.5430518617021277, "MMLU-PRO": 49.22798463356975, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-02T00:00:00", "Submission Date": "2024-08-30T00:00:00", "Generation": 0, "Base Model": "dnhkng/RYS-XLarge-base"}, {"eval_name": "dreamgen_WizardLM-2-7B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/dreamgen/WizardLM-2-7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">dreamgen/WizardLM-2-7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/dreamgen__WizardLM-2-7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "dreamgen/WizardLM-2-7B", "Model sha": "b5f2d7bff91445a47331dcce588aee009d11d255", "Average \u2b06\ufe0f": 14.739073308992722, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 34, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4582984259542458, "IFEval": 45.82984259542458, "BBH Raw": 0.3486785616397201, "BBH": 9.213113542615597, "MATH Lvl 5 Raw": 0.0249244712990936, "MATH Lvl 5": 2.492447129909366, "GPQA Raw": 0.2869127516778523, "GPQA": 4.921700223713646, "MUSR Raw": 0.3940937499999999, "MUSR": 7.528385416666667, "MMLU-PRO Raw": 0.2660405585106383, "MMLU-PRO": 18.44895094562648, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-16T00:00:00", "Submission Date": "2024-06-27T00:00:00", "Generation": 0, "Base Model": "dreamgen/WizardLM-2-7B"}, {"eval_name": "dustinwloring1988_Reflexis-8b-chat-v1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/dustinwloring1988/Reflexis-8b-chat-v1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">dustinwloring1988/Reflexis-8b-chat-v1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/dustinwloring1988__Reflexis-8b-chat-v1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "dustinwloring1988/Reflexis-8b-chat-v1", "Model sha": "e96bd9694ae87a4f612825310eb7afaea5b0aa28", "Average \u2b06\ufe0f": 17.20218138332147, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3657750324694034, "IFEval": 36.57750324694034, "BBH Raw": 0.4663596290293861, "BBH": 24.10995815732617, "MATH Lvl 5 Raw": 0.1064954682779456, "MATH Lvl 5": 10.649546827794564, "GPQA Raw": 0.2541946308724832, "GPQA": 0.5592841163310973, "MUSR Raw": 0.3753958333333333, "MUSR": 4.824479166666667, "MMLU-PRO Raw": 0.3384308510638298, "MMLU-PRO": 26.492316784869978, "Maintainer's Highlight": false, "Upload To Hub Date": "", "Submission Date": "2024-09-14T00:00:00", "Generation": 0, "Base Model": "Removed"}, {"eval_name": "dustinwloring1988_Reflexis-8b-chat-v2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/dustinwloring1988/Reflexis-8b-chat-v2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">dustinwloring1988/Reflexis-8b-chat-v2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/dustinwloring1988__Reflexis-8b-chat-v2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "dustinwloring1988/Reflexis-8b-chat-v2", "Model sha": "817408ebfaa7ba0ea9433e1de4bfa120d38d2a0f", "Average \u2b06\ufe0f": 18.27663380631257, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3912042270065648, "IFEval": 39.12042270065648, "BBH Raw": 0.4723801894580715, "BBH": 24.89219630627393, "MATH Lvl 5 Raw": 0.1163141993957704, "MATH Lvl 5": 11.63141993957704, "GPQA Raw": 0.2701342281879195, "GPQA": 2.684563758389265, "MUSR Raw": 0.3526354166666667, "MUSR": 4.912760416666669, "MMLU-PRO Raw": 0.3377659574468085, "MMLU-PRO": 26.41843971631205, "Maintainer's Highlight": false, "Upload To Hub Date": "", "Submission Date": "2024-09-14T00:00:00", "Generation": 0, "Base Model": "Removed"}, {"eval_name": "dustinwloring1988_Reflexis-8b-chat-v3_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/dustinwloring1988/Reflexis-8b-chat-v3\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">dustinwloring1988/Reflexis-8b-chat-v3</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/dustinwloring1988__Reflexis-8b-chat-v3-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "dustinwloring1988/Reflexis-8b-chat-v3", "Model sha": "dcfa1a6a9f94a099286891d732b17cbbe97a644e", "Average \u2b06\ufe0f": 20.37438408598048, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.536733644507684, "IFEval": 53.6733644507684, "BBH Raw": 0.4658310598309874, "BBH": 24.168293247720744, "MATH Lvl 5 Raw": 0.1132930513595166, "MATH Lvl 5": 11.329305135951662, "GPQA Raw": 0.2424496644295302, "GPQA": 0.0, "MUSR Raw": 0.3511770833333333, "MUSR": 4.763802083333334, "MMLU-PRO Raw": 0.3548038563829787, "MMLU-PRO": 28.311539598108748, "Maintainer's Highlight": false, "Upload To Hub Date": "", "Submission Date": "2024-09-14T00:00:00", "Generation": 0, "Base Model": "Removed"}, {"eval_name": "dustinwloring1988_Reflexis-8b-chat-v4_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/dustinwloring1988/Reflexis-8b-chat-v4\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">dustinwloring1988/Reflexis-8b-chat-v4</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/dustinwloring1988__Reflexis-8b-chat-v4-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "dustinwloring1988/Reflexis-8b-chat-v4", "Model sha": "81e20c2e40f2028818d5d6d27ec9e0d503ae8cc1", "Average \u2b06\ufe0f": 18.3672930135766, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4697890486132351, "IFEval": 46.97890486132352, "BBH Raw": 0.4686014066001118, "BBH": 24.33177003879756, "MATH Lvl 5 Raw": 0.0929003021148036, "MATH Lvl 5": 9.290030211480364, "GPQA Raw": 0.2340604026845637, "GPQA": 0.0, "MUSR Raw": 0.3393020833333333, "MUSR": 3.0460937500000003, "MMLU-PRO Raw": 0.3390126329787234, "MMLU-PRO": 26.55695921985816, "Maintainer's Highlight": false, "Upload To Hub Date": "", "Submission Date": "2024-09-14T00:00:00", "Generation": 0, "Base Model": "Removed"}, {"eval_name": "dustinwloring1988_Reflexis-8b-chat-v5_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/dustinwloring1988/Reflexis-8b-chat-v5\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">dustinwloring1988/Reflexis-8b-chat-v5</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/dustinwloring1988__Reflexis-8b-chat-v5-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "dustinwloring1988/Reflexis-8b-chat-v5", "Model sha": "12970eec99f458a3982eb502b71b6df0bc74bb52", "Average \u2b06\ufe0f": 18.410388569949173, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4237523105360443, "IFEval": 42.37523105360444, "BBH Raw": 0.4781685533183147, "BBH": 25.195784260224865, "MATH Lvl 5 Raw": 0.11404833836858, "MATH Lvl 5": 11.404833836858003, "GPQA Raw": 0.2709731543624161, "GPQA": 2.796420581655479, "MUSR Raw": 0.3353645833333333, "MUSR": 4.053906250000002, "MMLU-PRO Raw": 0.3217253989361702, "MMLU-PRO": 24.63615543735224, "Maintainer's Highlight": false, "Upload To Hub Date": "", "Submission Date": "2024-09-14T00:00:00", "Generation": 0, "Base Model": "Removed"}, {"eval_name": "dustinwloring1988_Reflexis-8b-chat-v6_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/dustinwloring1988/Reflexis-8b-chat-v6\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">dustinwloring1988/Reflexis-8b-chat-v6</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/dustinwloring1988__Reflexis-8b-chat-v6-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "dustinwloring1988/Reflexis-8b-chat-v6", "Model sha": "a0b30a21a8eea9a32a2767755dc2dbd44eeb383f", "Average \u2b06\ufe0f": 20.28195182698768, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4938939790866014, "IFEval": 49.38939790866013, "BBH Raw": 0.4809537068664902, "BBH": 26.11610264109281, "MATH Lvl 5 Raw": 0.1261329305135951, "MATH Lvl 5": 12.613293051359516, "GPQA Raw": 0.2625838926174497, "GPQA": 1.6778523489932915, "MUSR Raw": 0.3753333333333333, "MUSR": 4.3500000000000005, "MMLU-PRO Raw": 0.347905585106383, "MMLU-PRO": 27.54506501182033, "Maintainer's Highlight": false, "Upload To Hub Date": "", "Submission Date": "2024-09-14T00:00:00", "Generation": 0, "Base Model": "Removed"}, {"eval_name": "dustinwloring1988_Reflexis-8b-chat-v7_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/dustinwloring1988/Reflexis-8b-chat-v7\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">dustinwloring1988/Reflexis-8b-chat-v7</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/dustinwloring1988__Reflexis-8b-chat-v7-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "dustinwloring1988/Reflexis-8b-chat-v7", "Model sha": "e8d990012ccd855e65d51cb7cfd1762632a8f217", "Average \u2b06\ufe0f": 18.65491698721236, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3980482896492417, "IFEval": 39.80482896492418, "BBH Raw": 0.4809830787114964, "BBH": 25.98749682684877, "MATH Lvl 5 Raw": 0.1367069486404833, "MATH Lvl 5": 13.670694864048338, "GPQA Raw": 0.261744966442953, "GPQA": 1.5659955257270708, "MUSR Raw": 0.32215625, "MUSR": 1.5361979166666664, "MMLU-PRO Raw": 0.3642785904255319, "MMLU-PRO": 29.364287825059105, "Maintainer's Highlight": false, "Upload To Hub Date": "", "Submission Date": "2024-09-14T00:00:00", "Generation": 0, "Base Model": "Removed"}, {"eval_name": "dzakwan_dzakwan-MoE-4x7b-Beta_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/dzakwan/dzakwan-MoE-4x7b-Beta\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">dzakwan/dzakwan-MoE-4x7b-Beta</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/dzakwan__dzakwan-MoE-4x7b-Beta-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "dzakwan/dzakwan-MoE-4x7b-Beta", "Model sha": "e89f82f2afa1961335de5a6d6d05bd850d1d61d9", "Average \u2b06\ufe0f": 20.59306941779329, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 24, "Available on the hub": true, "Not_Merged": false, "MoE": false, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4442601187072523, "IFEval": 44.42601187072523, "BBH Raw": 0.514044131159397, "BBH": 32.074208465442545, "MATH Lvl 5 Raw": 0.0672205438066465, "MATH Lvl 5": 6.722054380664652, "GPQA Raw": 0.2860738255033557, "GPQA": 4.809843400447425, "MUSR Raw": 0.4267395833333333, "MUSR": 12.109114583333335, "MMLU-PRO Raw": 0.3107546542553192, "MMLU-PRO": 23.41718380614657, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-26T00:00:00", "Submission Date": "2024-08-05T00:00:00", "Generation": 1, "Base Model": "dzakwan/dzakwan-MoE-4x7b-Beta (Merge)"}, {"eval_name": "ehristoforu_Gemma2-9B-it-psy10k-mental_health_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/ehristoforu/Gemma2-9B-it-psy10k-mental_health\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">ehristoforu/Gemma2-9B-it-psy10k-mental_health</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/ehristoforu__Gemma2-9B-it-psy10k-mental_health-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "ehristoforu/Gemma2-9B-it-psy10k-mental_health", "Model sha": "4adc2d61d530d23026493d29e6191e06cf549fc6", "Average \u2b06\ufe0f": 26.50014305237002, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 9, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5886658510529839, "IFEval": 58.866585105298384, "BBH Raw": 0.5539376944027642, "BBH": 35.56600949863266, "MATH Lvl 5 Raw": 0.1216012084592145, "MATH Lvl 5": 12.16012084592145, "GPQA Raw": 0.337248322147651, "GPQA": 11.6331096196868, "MUSR Raw": 0.4086041666666666, "MUSR": 9.3421875, "MMLU-PRO Raw": 0.3828956117021276, "MMLU-PRO": 31.432845744680847, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-16T00:00:00", "Submission Date": "2024-07-31T00:00:00", "Generation": 2, "Base Model": "unsloth/gemma-2-9b-it-bnb-4bit"}, {"eval_name": "ehristoforu_Gemma2-9b-it-train6_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/ehristoforu/Gemma2-9b-it-train6\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">ehristoforu/Gemma2-9b-it-train6</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/ehristoforu__Gemma2-9b-it-train6-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "ehristoforu/Gemma2-9b-it-train6", "Model sha": "e72bf00b427c22c48b468818cf75300a373a0c8a", "Average \u2b06\ufe0f": 28.746474151419974, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 2, "#Params (B)": 9, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7025215317579578, "IFEval": 70.25215317579578, "BBH Raw": 0.5898092579133603, "BBH": 40.98762530159646, "MATH Lvl 5 Raw": 0.0838368580060422, "MATH Lvl 5": 8.38368580060423, "GPQA Raw": 0.3288590604026846, "GPQA": 10.514541387024613, "MUSR Raw": 0.4084166666666666, "MUSR": 9.652083333333335, "MMLU-PRO Raw": 0.3941988031914893, "MMLU-PRO": 32.68875591016548, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-22T00:00:00", "Submission Date": "2024-07-31T00:00:00", "Generation": 6, "Base Model": "unsloth/gemma-2-9b-it-bnb-4bit"}, {"eval_name": "elinas_Chronos-Gold-12B-1.0_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/elinas/Chronos-Gold-12B-1.0\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">elinas/Chronos-Gold-12B-1.0</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/elinas__Chronos-Gold-12B-1.0-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "elinas/Chronos-Gold-12B-1.0", "Model sha": "cf76a4621b9dfc0c2e6d930756e6c7c9ce2b260b", "Average \u2b06\ufe0f": 21.40017197666454, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 24, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3165656014929277, "IFEval": 31.65656014929277, "BBH Raw": 0.5514664110708439, "BBH": 35.90894700063131, "MATH Lvl 5 Raw": 0.0438066465256797, "MATH Lvl 5": 4.380664652567976, "GPQA Raw": 0.3179530201342282, "GPQA": 9.060402684563762, "MUSR Raw": 0.4739895833333333, "MUSR": 19.41536458333333, "MMLU-PRO Raw": 0.351811835106383, "MMLU-PRO": 27.979092789598106, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-21T00:00:00", "Submission Date": "2024-09-15T00:00:00", "Generation": 1, "Base Model": "mistralai/Mistral-Nemo-Base-2407"}, {"eval_name": "euclaise_ReMask-3B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "StableLmForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/euclaise/ReMask-3B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">euclaise/ReMask-3B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/euclaise__ReMask-3B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "euclaise/ReMask-3B", "Model sha": "e094dae96097c2bc6f758101ee269c089b65a2cf", "Average \u2b06\ufe0f": 7.256640238874923, "Hub License": "cc-by-sa-4.0", "Hub \u2764\ufe0f": 14, "#Params (B)": 2, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2419269759792905, "IFEval": 24.192697597929048, "BBH Raw": 0.3516779692917367, "BBH": 8.742082990875964, "MATH Lvl 5 Raw": 0.0173716012084592, "MATH Lvl 5": 1.7371601208459215, "GPQA Raw": 0.2667785234899328, "GPQA": 2.2371364653243813, "MUSR Raw": 0.33409375, "MUSR": 2.6617187500000004, "MMLU-PRO Raw": 0.135721409574468, "MMLU-PRO": 3.969045508274229, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-03-28T00:00:00", "Submission Date": "2024-08-10T00:00:00", "Generation": 0, "Base Model": "euclaise/ReMask-3B"}, {"eval_name": "facebook_opt-1.3b_float16", "Precision": "float16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "OPTForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/facebook/opt-1.3b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">facebook/opt-1.3b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/facebook__opt-1.3b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "facebook/opt-1.3b", "Model sha": "3f5c25d0bc631cb57ac65913f76e22c2dfb61d62", "Average \u2b06\ufe0f": 5.251513100569197, "Hub License": "other", "Hub \u2764\ufe0f": 149, "#Params (B)": 1, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2383298536771322, "IFEval": 23.83298536771322, "BBH Raw": 0.3093947052760125, "BBH": 3.6480520895226793, "MATH Lvl 5 Raw": 0.0075528700906344, "MATH Lvl 5": 0.7552870090634441, "GPQA Raw": 0.2424496644295302, "GPQA": 0.0, "MUSR Raw": 0.342, "MUSR": 2.0833333333333326, "MMLU-PRO Raw": 0.1107047872340425, "MMLU-PRO": 1.1894208037825047, "Maintainer's Highlight": true, "Upload To Hub Date": "2022-05-11T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "facebook/opt-1.3b"}, {"eval_name": "facebook_opt-30b_float16", "Precision": "float16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "OPTForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/facebook/opt-30b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">facebook/opt-30b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/facebook__opt-30b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "facebook/opt-30b", "Model sha": "ceea0a90ac0f6fae7c2c34bcb40477438c152546", "Average \u2b06\ufe0f": 6.201345407060512, "Hub License": "other", "Hub \u2764\ufe0f": 133, "#Params (B)": 30, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2452991396162183, "IFEval": 24.52991396162183, "BBH Raw": 0.3070344752562337, "BBH": 3.4984293851759607, "MATH Lvl 5 Raw": 0.0060422960725075, "MATH Lvl 5": 0.6042296072507553, "GPQA Raw": 0.2692953020134228, "GPQA": 2.572706935123044, "MUSR Raw": 0.3604166666666666, "MUSR": 4.185416666666667, "MMLU-PRO Raw": 0.1163563829787234, "MMLU-PRO": 1.8173758865248215, "Maintainer's Highlight": true, "Upload To Hub Date": "2022-05-11T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "facebook/opt-30b"}, {"eval_name": "failspy_Llama-3-8B-Instruct-MopeyMule_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/failspy/Llama-3-8B-Instruct-MopeyMule\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">failspy/Llama-3-8B-Instruct-MopeyMule</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/failspy__Llama-3-8B-Instruct-MopeyMule-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "failspy/Llama-3-8B-Instruct-MopeyMule", "Model sha": "d1cbf407efe727c6b9fc94f22d51ff4915e1856e", "Average \u2b06\ufe0f": 15.550015774864372, "Hub License": "other", "Hub \u2764\ufe0f": 66, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6750444376476638, "IFEval": 67.50444376476638, "BBH Raw": 0.383874490132152, "BBH": 13.620495859752507, "MATH Lvl 5 Raw": 0.0143504531722054, "MATH Lvl 5": 1.4350453172205435, "GPQA Raw": 0.2390939597315436, "GPQA": 0.0, "MUSR Raw": 0.3513020833333333, "MUSR": 2.24609375, "MMLU-PRO Raw": 0.1764461436170212, "MMLU-PRO": 8.494015957446807, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-30T00:00:00", "Submission Date": "2024-09-21T00:00:00", "Generation": 0, "Base Model": "failspy/Llama-3-8B-Instruct-MopeyMule"}, {"eval_name": "failspy_Llama-3-8B-Instruct-abliterated_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/failspy/Llama-3-8B-Instruct-abliterated\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">failspy/Llama-3-8B-Instruct-abliterated</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/failspy__Llama-3-8B-Instruct-abliterated-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "failspy/Llama-3-8B-Instruct-abliterated", "Model sha": "dd67dd055661e4cbcedb0ed2431693d9cc3be6e0", "Average \u2b06\ufe0f": 19.07696305631573, "Hub License": "llama3", "Hub \u2764\ufe0f": 9, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5908888416069362, "IFEval": 59.08888416069362, "BBH Raw": 0.4353752684977051, "BBH": 18.86459884908717, "MATH Lvl 5 Raw": 0.0317220543806646, "MATH Lvl 5": 3.1722054380664653, "GPQA Raw": 0.276006711409396, "GPQA": 3.467561521252797, "MUSR Raw": 0.4115833333333333, "MUSR": 10.514583333333334, "MMLU-PRO Raw": 0.2741855053191489, "MMLU-PRO": 19.35394503546099, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-07T00:00:00", "Submission Date": "2024-07-03T00:00:00", "Generation": 0, "Base Model": "failspy/Llama-3-8B-Instruct-abliterated"}, {"eval_name": "failspy_Meta-Llama-3-70B-Instruct-abliterated-v3.5_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Adapter", "Architecture": "?", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/failspy/Meta-Llama-3-70B-Instruct-abliterated-v3.5\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">failspy/Meta-Llama-3-70B-Instruct-abliterated-v3.5</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/failspy__Meta-Llama-3-70B-Instruct-abliterated-v3.5-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "failspy/Meta-Llama-3-70B-Instruct-abliterated-v3.5", "Model sha": "fc951b03d92972ab52ad9392e620eba6173526b9", "Average \u2b06\ufe0f": 29.96570861841094, "Hub License": "llama3", "Hub \u2764\ufe0f": 35, "#Params (B)": 70, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7746867201248244, "IFEval": 77.46867201248244, "BBH Raw": 0.574710022890038, "BBH": 37.87133313079306, "MATH Lvl 5 Raw": 0.1185800604229607, "MATH Lvl 5": 11.858006042296072, "GPQA Raw": 0.296979865771812, "GPQA": 6.263982102908276, "MUSR Raw": 0.3981874999999999, "MUSR": 7.9734375, "MMLU-PRO Raw": 0.4452293882978723, "MMLU-PRO": 38.35882092198581, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-28T00:00:00", "Submission Date": "2024-08-30T00:00:00", "Generation": 0, "Base Model": "failspy/Meta-Llama-3-70B-Instruct-abliterated-v3.5"}, {"eval_name": "failspy_Phi-3-medium-4k-instruct-abliterated-v3_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Phi3ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/failspy/Phi-3-medium-4k-instruct-abliterated-v3\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">failspy/Phi-3-medium-4k-instruct-abliterated-v3</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/failspy__Phi-3-medium-4k-instruct-abliterated-v3-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "failspy/Phi-3-medium-4k-instruct-abliterated-v3", "Model sha": "959b09eacf6cae85a8eb21b25e998addc89a367b", "Average \u2b06\ufe0f": 31.54900597688469, "Hub License": "mit", "Hub \u2764\ufe0f": 21, "#Params (B)": 13, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6319299458769398, "IFEval": 63.19299458769399, "BBH Raw": 0.6304799176474429, "BBH": 46.73283933573803, "MATH Lvl 5 Raw": 0.141238670694864, "MATH Lvl 5": 14.123867069486405, "GPQA Raw": 0.3171140939597315, "GPQA": 8.948545861297541, "MUSR Raw": 0.4604166666666667, "MUSR": 18.51875, "MMLU-PRO Raw": 0.4399933510638298, "MMLU-PRO": 37.77703900709219, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-22T00:00:00", "Submission Date": "2024-07-29T00:00:00", "Generation": 0, "Base Model": "failspy/Phi-3-medium-4k-instruct-abliterated-v3"}, {"eval_name": "failspy_llama-3-70B-Instruct-abliterated_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/failspy/llama-3-70B-Instruct-abliterated\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">failspy/llama-3-70B-Instruct-abliterated</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/failspy__llama-3-70B-Instruct-abliterated-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "failspy/llama-3-70B-Instruct-abliterated", "Model sha": "53ae9dafe8b3d163e05d75387575f8e9f43253d0", "Average \u2b06\ufe0f": 35.78931372669722, "Hub License": "llama3", "Hub \u2764\ufe0f": 87, "#Params (B)": 70, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.8023389052159382, "IFEval": 80.23389052159382, "BBH Raw": 0.6464853840398571, "BBH": 48.93981832466943, "MATH Lvl 5 Raw": 0.2371601208459214, "MATH Lvl 5": 23.716012084592144, "GPQA Raw": 0.2894295302013422, "GPQA": 5.257270693512303, "MUSR Raw": 0.4127604166666667, "MUSR": 10.528385416666673, "MMLU-PRO Raw": 0.5145445478723404, "MMLU-PRO": 46.06050531914893, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-07T00:00:00", "Submission Date": "2024-07-03T00:00:00", "Generation": 0, "Base Model": "failspy/llama-3-70B-Instruct-abliterated"}, {"eval_name": "fblgit_UNA-SimpleSmaug-34b-v1beta_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/fblgit/UNA-SimpleSmaug-34b-v1beta\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">fblgit/UNA-SimpleSmaug-34b-v1beta</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/fblgit__UNA-SimpleSmaug-34b-v1beta-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "fblgit/UNA-SimpleSmaug-34b-v1beta", "Model sha": "4b62fccfc7e44c0a02c11a5279d98fafa6b922ba", "Average \u2b06\ufe0f": 23.12139676764886, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 20, "#Params (B)": 34, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4556255180698325, "IFEval": 45.56255180698325, "BBH Raw": 0.5286654104993475, "BBH": 32.775788922324494, "MATH Lvl 5 Raw": 0.0015105740181268, "MATH Lvl 5": 0.1510574018126888, "GPQA Raw": 0.3171140939597315, "GPQA": 8.948545861297541, "MUSR Raw": 0.4255625, "MUSR": 11.961979166666667, "MMLU-PRO Raw": 0.4539561170212766, "MMLU-PRO": 39.328457446808514, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-02-05T00:00:00", "Submission Date": "2024-06-30T00:00:00", "Generation": 2, "Base Model": "jondurbin/bagel-34b-v0.2"}, {"eval_name": "fblgit_UNA-TheBeagle-7b-v1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/fblgit/UNA-TheBeagle-7b-v1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">fblgit/UNA-TheBeagle-7b-v1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/fblgit__UNA-TheBeagle-7b-v1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "fblgit/UNA-TheBeagle-7b-v1", "Model sha": "866d3ee19f983728e21a624f8a27574960073f27", "Average \u2b06\ufe0f": 19.507701492963708, "Hub License": "cc-by-nc-nd-4.0", "Hub \u2764\ufe0f": 36, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.36887236975669, "IFEval": 36.887236975669, "BBH Raw": 0.5028691097522866, "BBH": 30.173396964633465, "MATH Lvl 5 Raw": 0.0687311178247734, "MATH Lvl 5": 6.873111782477341, "GPQA Raw": 0.2843959731543624, "GPQA": 4.586129753914992, "MUSR Raw": 0.4564375, "MUSR": 16.088020833333328, "MMLU-PRO Raw": 0.3019448138297872, "MMLU-PRO": 22.43831264775413, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-01-09T00:00:00", "Submission Date": "2024-06-30T00:00:00", "Generation": 0, "Base Model": "fblgit/UNA-TheBeagle-7b-v1"}, {"eval_name": "fblgit_UNA-ThePitbull-21.4B-v2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/fblgit/UNA-ThePitbull-21.4B-v2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">fblgit/UNA-ThePitbull-21.4B-v2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/fblgit__UNA-ThePitbull-21.4B-v2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "fblgit/UNA-ThePitbull-21.4B-v2", "Model sha": "f12aac93ae9c852550a16816e16116c4f8e7dec0", "Average \u2b06\ufe0f": 22.598572825844183, "Hub License": "afl-3.0", "Hub \u2764\ufe0f": 15, "#Params (B)": 21, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3790387283518841, "IFEval": 37.90387283518841, "BBH Raw": 0.635038821016254, "BBH": 46.78807384004312, "MATH Lvl 5 Raw": 0.0959214501510574, "MATH Lvl 5": 9.59214501510574, "GPQA Raw": 0.3020134228187919, "GPQA": 6.935123042505594, "MUSR Raw": 0.3921666666666666, "MUSR": 6.420833333333333, "MMLU-PRO Raw": 0.3515625, "MMLU-PRO": 27.95138888888889, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-28T00:00:00", "Submission Date": "2024-06-30T00:00:00", "Generation": 0, "Base Model": "fblgit/UNA-ThePitbull-21.4B-v2"}, {"eval_name": "fblgit_juanako-7b-UNA_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/fblgit/juanako-7b-UNA\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">fblgit/juanako-7b-UNA</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/fblgit__juanako-7b-UNA-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "fblgit/juanako-7b-UNA", "Model sha": "b8ac85b603d5ee1ac619b2e1d0b3bb86c4eecb0c", "Average \u2b06\ufe0f": 20.774951198264507, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 23, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4837276204914073, "IFEval": 48.37276204914072, "BBH Raw": 0.507001145736535, "BBH": 30.415072015961297, "MATH Lvl 5 Raw": 0.0287009063444108, "MATH Lvl 5": 2.8700906344410875, "GPQA Raw": 0.2961409395973154, "GPQA": 6.152125279642054, "MUSR Raw": 0.4644999999999999, "MUSR": 17.162499999999994, "MMLU-PRO Raw": 0.277094414893617, "MMLU-PRO": 19.67715721040189, "Maintainer's Highlight": false, "Upload To Hub Date": "2023-11-27T00:00:00", "Submission Date": "2024-06-30T00:00:00", "Generation": 0, "Base Model": "fblgit/juanako-7b-UNA"}, {"eval_name": "fblgit_una-cybertron-7b-v2-bf16_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/fblgit/una-cybertron-7b-v2-bf16\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">fblgit/una-cybertron-7b-v2-bf16</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/fblgit__una-cybertron-7b-v2-bf16-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "fblgit/una-cybertron-7b-v2-bf16", "Model sha": "7ab101a153740aec39e95ec02831c56f4eab7910", "Average \u2b06\ufe0f": 17.091443551622127, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 116, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4737108649494452, "IFEval": 47.37108649494452, "BBH Raw": 0.3973388920486269, "BBH": 14.966964848379982, "MATH Lvl 5 Raw": 0.0332326283987915, "MATH Lvl 5": 3.3232628398791544, "GPQA Raw": 0.2978187919463087, "GPQA": 6.375838926174497, "MUSR Raw": 0.4473229166666666, "MUSR": 14.482031250000004, "MMLU-PRO Raw": 0.2442652925531915, "MMLU-PRO": 16.02947695035461, "Maintainer's Highlight": false, "Upload To Hub Date": "2023-12-02T00:00:00", "Submission Date": "2024-06-30T00:00:00", "Generation": 0, "Base Model": "fblgit/una-cybertron-7b-v2-bf16"}, {"eval_name": "flammenai_Mahou-1.2a-llama3-8B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/flammenai/Mahou-1.2a-llama3-8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">flammenai/Mahou-1.2a-llama3-8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/flammenai__Mahou-1.2a-llama3-8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "flammenai/Mahou-1.2a-llama3-8B", "Model sha": "3318b6f5f1839644bee287a3e5390f3e9f565a9e", "Average \u2b06\ufe0f": 21.652792366213856, "Hub License": "llama3", "Hub \u2764\ufe0f": 6, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.50925655039739, "IFEval": 50.925655039739, "BBH Raw": 0.5093660540433169, "BBH": 28.972587655292436, "MATH Lvl 5 Raw": 0.0755287009063444, "MATH Lvl 5": 7.552870090634441, "GPQA Raw": 0.2885906040268456, "GPQA": 5.145413870246088, "MUSR Raw": 0.3846666666666666, "MUSR": 6.016666666666668, "MMLU-PRO Raw": 0.3817320478723404, "MMLU-PRO": 31.303560874704488, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-25T00:00:00", "Submission Date": "2024-09-03T00:00:00", "Generation": 1, "Base Model": "flammenai/Mahou-1.2a-llama3-8B (Merge)"}, {"eval_name": "flammenai_Mahou-1.2a-mistral-7B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/flammenai/Mahou-1.2a-mistral-7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">flammenai/Mahou-1.2a-mistral-7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/flammenai__Mahou-1.2a-mistral-7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "flammenai/Mahou-1.2a-mistral-7B", "Model sha": "d45f61cca04da0c3359573102853fca1a0d3b252", "Average \u2b06\ufe0f": 19.402757033416574, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 6, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4552010886669592, "IFEval": 45.52010886669592, "BBH Raw": 0.5118111474458115, "BBH": 31.166750037107487, "MATH Lvl 5 Raw": 0.0581570996978852, "MATH Lvl 5": 5.81570996978852, "GPQA Raw": 0.2718120805369127, "GPQA": 2.9082774049217, "MUSR Raw": 0.389625, "MUSR": 6.969791666666668, "MMLU-PRO Raw": 0.3163231382978723, "MMLU-PRO": 24.03590425531915, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-18T00:00:00", "Submission Date": "2024-09-03T00:00:00", "Generation": 1, "Base Model": "flammenai/Mahou-1.2a-mistral-7B (Merge)"}, {"eval_name": "flammenai_Mahou-1.5-mistral-nemo-12B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/flammenai/Mahou-1.5-mistral-nemo-12B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">flammenai/Mahou-1.5-mistral-nemo-12B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/flammenai__Mahou-1.5-mistral-nemo-12B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "flammenai/Mahou-1.5-mistral-nemo-12B", "Model sha": "852561e74f1785bf7225bb28395db1fd9431fe31", "Average \u2b06\ufe0f": 26.281096291963603, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 12, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6751441730164851, "IFEval": 67.5144173016485, "BBH Raw": 0.5522361927910235, "BBH": 36.260510188013406, "MATH Lvl 5 Raw": 0.0506042296072507, "MATH Lvl 5": 5.060422960725076, "GPQA Raw": 0.276006711409396, "GPQA": 3.467561521252797, "MUSR Raw": 0.4520416666666667, "MUSR": 16.471874999999997, "MMLU-PRO Raw": 0.3602061170212766, "MMLU-PRO": 28.911790780141843, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-06T00:00:00", "Submission Date": "2024-10-07T00:00:00", "Generation": 1, "Base Model": "flammenai/Mahou-1.5-mistral-nemo-12B (Merge)"}, {"eval_name": "flammenai_flammen15-gutenberg-DPO-v1-7B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/flammenai/flammen15-gutenberg-DPO-v1-7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">flammenai/flammen15-gutenberg-DPO-v1-7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/flammenai__flammen15-gutenberg-DPO-v1-7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "flammenai/flammen15-gutenberg-DPO-v1-7B", "Model sha": "550cd9548cba1265cb1771c85ebe498789fdecb5", "Average \u2b06\ufe0f": 21.46164102738607, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4798058041551971, "IFEval": 47.98058041551971, "BBH Raw": 0.5202983979716951, "BBH": 32.66511308584827, "MATH Lvl 5 Raw": 0.0672205438066465, "MATH Lvl 5": 6.722054380664652, "GPQA Raw": 0.2843959731543624, "GPQA": 4.586129753914992, "MUSR Raw": 0.4293125, "MUSR": 12.530729166666667, "MMLU-PRO Raw": 0.3185671542553192, "MMLU-PRO": 24.28523936170213, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-05T00:00:00", "Submission Date": "2024-07-10T00:00:00", "Generation": 1, "Base Model": "flammenai/flammen15-gutenberg-DPO-v1-7B (Merge)"}, {"eval_name": "freewheelin_free-evo-qwen72b-v0.8-re_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/freewheelin/free-evo-qwen72b-v0.8-re\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">freewheelin/free-evo-qwen72b-v0.8-re</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/freewheelin__free-evo-qwen72b-v0.8-re-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "freewheelin/free-evo-qwen72b-v0.8-re", "Model sha": "24e301d8fbef8ada12be42156b01c827ff594962", "Average \u2b06\ufe0f": 32.172816159886224, "Hub License": "mit", "Hub \u2764\ufe0f": 4, "#Params (B)": 72, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.533086654521115, "IFEval": 53.30866545211151, "BBH Raw": 0.6127477065378042, "BBH": 45.31740264996691, "MATH Lvl 5 Raw": 0.1623867069486405, "MATH Lvl 5": 16.238670694864048, "GPQA Raw": 0.3565436241610738, "GPQA": 14.205816554809845, "MUSR Raw": 0.4871666666666667, "MUSR": 20.962499999999995, "MMLU-PRO Raw": 0.4870345744680851, "MMLU-PRO": 43.00384160756501, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-02T00:00:00", "Submission Date": "2024-09-15T00:00:00", "Generation": 0, "Base Model": "freewheelin/free-evo-qwen72b-v0.8-re"}, {"eval_name": "freewheelin_free-solar-evo-v0.1_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/freewheelin/free-solar-evo-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">freewheelin/free-solar-evo-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/freewheelin__free-solar-evo-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "freewheelin/free-solar-evo-v0.1", "Model sha": "233efd607ae0abbd7b46eded2ee7889892b7bdbb", "Average \u2b06\ufe0f": 16.295570875162888, "Hub License": "mit", "Hub \u2764\ufe0f": 1, "#Params (B)": 10, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2050071587831398, "IFEval": 20.500715878313983, "BBH Raw": 0.4502211109638701, "BBH": 22.63518273833165, "MATH Lvl 5 Raw": 0.0007552870090634, "MATH Lvl 5": 0.0755287009063444, "GPQA Raw": 0.2911073825503356, "GPQA": 5.480984340044745, "MUSR Raw": 0.4945833333333334, "MUSR": 22.25625, "MMLU-PRO Raw": 0.3414228723404255, "MMLU-PRO": 26.824763593380613, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-18T00:00:00", "Submission Date": "2024-08-07T00:00:00", "Generation": 0, "Base Model": "freewheelin/free-solar-evo-v0.1"}, {"eval_name": "freewheelin_free-solar-evo-v0.11_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/freewheelin/free-solar-evo-v0.11\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">freewheelin/free-solar-evo-v0.11</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/freewheelin__free-solar-evo-v0.11-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "freewheelin/free-solar-evo-v0.11", "Model sha": "17fc24a557bd3c3836abc9f6a367c803cba0cccd", "Average \u2b06\ufe0f": 16.641293877570874, "Hub License": "mit", "Hub \u2764\ufe0f": 0, "#Params (B)": 10, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2026589449327783, "IFEval": 20.265894493277838, "BBH Raw": 0.4545155032474882, "BBH": 23.18242496978891, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.285234899328859, "GPQA": 4.697986577181204, "MUSR Raw": 0.5052187499999999, "MUSR": 24.28567708333333, "MMLU-PRO Raw": 0.3467420212765957, "MMLU-PRO": 27.41578014184397, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-24T00:00:00", "Submission Date": "2024-08-07T00:00:00", "Generation": 0, "Base Model": "freewheelin/free-solar-evo-v0.11"}, {"eval_name": "freewheelin_free-solar-evo-v0.13_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/freewheelin/free-solar-evo-v0.13\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">freewheelin/free-solar-evo-v0.13</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/freewheelin__free-solar-evo-v0.13-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "freewheelin/free-solar-evo-v0.13", "Model sha": "2a7eb72f84c54898630f9db470eee0f936a64396", "Average \u2b06\ufe0f": 17.20449145515274, "Hub License": "mit", "Hub \u2764\ufe0f": 1, "#Params (B)": 10, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2320598234905606, "IFEval": 23.20598234905606, "BBH Raw": 0.4554839670962904, "BBH": 23.35420388572778, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2885906040268456, "GPQA": 5.145413870246088, "MUSR Raw": 0.50515625, "MUSR": 24.077864583333326, "MMLU-PRO Raw": 0.3469913563829787, "MMLU-PRO": 27.44348404255319, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-28T00:00:00", "Submission Date": "2024-08-07T00:00:00", "Generation": 0, "Base Model": "freewheelin/free-solar-evo-v0.13"}, {"eval_name": "gabrielmbmb_SmolLM-1.7B-Instruct-IFEval_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/gabrielmbmb/SmolLM-1.7B-Instruct-IFEval\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">gabrielmbmb/SmolLM-1.7B-Instruct-IFEval</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/gabrielmbmb__SmolLM-1.7B-Instruct-IFEval-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "gabrielmbmb/SmolLM-1.7B-Instruct-IFEval", "Model sha": "ac5d711adc05ccfe1b1b912d5561d98f6afeeb40", "Average \u2b06\ufe0f": 5.222835726155844, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 1, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2305859563735333, "IFEval": 23.05859563735333, "BBH Raw": 0.313843378282092, "BBH": 4.50167515878636, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2533557046979866, "GPQA": 0.4474272930648763, "MUSR Raw": 0.3327604166666666, "MUSR": 1.5950520833333328, "MMLU-PRO Raw": 0.1156083776595744, "MMLU-PRO": 1.7342641843971618, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-01T00:00:00", "Submission Date": "2024-10-11T00:00:00", "Generation": 2, "Base Model": "HuggingFaceTB/SmolLM-1.7B"}, {"eval_name": "gaverfraxz_Meta-Llama-3.1-8B-Instruct-HalfAbliterated-DELLA_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/gaverfraxz/Meta-Llama-3.1-8B-Instruct-HalfAbliterated-DELLA\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">gaverfraxz/Meta-Llama-3.1-8B-Instruct-HalfAbliterated-DELLA</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/gaverfraxz__Meta-Llama-3.1-8B-Instruct-HalfAbliterated-DELLA-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "gaverfraxz/Meta-Llama-3.1-8B-Instruct-HalfAbliterated-DELLA", "Model sha": "6b0271a98b8875a65972ed54b0d636d8236ea60b", "Average \u2b06\ufe0f": 11.919581981532884, "Hub License": "llama3.1", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4009461561988856, "IFEval": 40.094615619888565, "BBH Raw": 0.3984844272016949, "BBH": 15.276579446085892, "MATH Lvl 5 Raw": 0.0083081570996978, "MATH Lvl 5": 0.8308157099697886, "GPQA Raw": 0.2843959731543624, "GPQA": 4.586129753914992, "MUSR Raw": 0.3650416666666666, "MUSR": 3.463541666666668, "MMLU-PRO Raw": 0.1653922872340425, "MMLU-PRO": 7.265809692671395, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-22T00:00:00", "Submission Date": "2024-09-23T00:00:00", "Generation": 1, "Base Model": "gaverfraxz/Meta-Llama-3.1-8B-Instruct-HalfAbliterated-DELLA (Merge)"}, {"eval_name": "gaverfraxz_Meta-Llama-3.1-8B-Instruct-HalfAbliterated-TIES_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/gaverfraxz/Meta-Llama-3.1-8B-Instruct-HalfAbliterated-TIES\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">gaverfraxz/Meta-Llama-3.1-8B-Instruct-HalfAbliterated-TIES</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/gaverfraxz__Meta-Llama-3.1-8B-Instruct-HalfAbliterated-TIES-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "gaverfraxz/Meta-Llama-3.1-8B-Instruct-HalfAbliterated-TIES", "Model sha": "80569e49b5aba960a5cd91281dd9eef92aeff9a3", "Average \u2b06\ufe0f": 20.772455642473016, "Hub License": "llama3.1", "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4550514856137271, "IFEval": 45.50514856137272, "BBH Raw": 0.5043660783243713, "BBH": 28.91423515333936, "MATH Lvl 5 Raw": 0.1163141993957704, "MATH Lvl 5": 11.63141993957704, "GPQA Raw": 0.2667785234899328, "GPQA": 2.2371364653243813, "MUSR Raw": 0.37375, "MUSR": 6.58541666666667, "MMLU-PRO Raw": 0.3678523936170212, "MMLU-PRO": 29.76137706855792, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-19T00:00:00", "Submission Date": "2024-09-19T00:00:00", "Generation": 1, "Base Model": "gaverfraxz/Meta-Llama-3.1-8B-Instruct-HalfAbliterated-TIES (Merge)"}, {"eval_name": "gbueno86_Brinebreath-Llama-3.1-70B_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/gbueno86/Brinebreath-Llama-3.1-70B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">gbueno86/Brinebreath-Llama-3.1-70B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/gbueno86__Brinebreath-Llama-3.1-70B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "gbueno86/Brinebreath-Llama-3.1-70B", "Model sha": "c508ecf356167e8c498c6fa3937ba30a82208983", "Average \u2b06\ufe0f": 36.29275614704682, "Hub License": "llama3.1", "Hub \u2764\ufe0f": 1, "#Params (B)": 70, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5532952565858589, "IFEval": 55.32952565858589, "BBH Raw": 0.6880562247706813, "BBH": 55.46361848802468, "MATH Lvl 5 Raw": 0.2998489425981873, "MATH Lvl 5": 29.984894259818727, "GPQA Raw": 0.3464765100671141, "GPQA": 12.863534675615217, "MUSR Raw": 0.4540625, "MUSR": 17.49114583333333, "MMLU-PRO Raw": 0.5196143617021277, "MMLU-PRO": 46.62381796690308, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-23T00:00:00", "Submission Date": "2024-08-29T00:00:00", "Generation": 1, "Base Model": "gbueno86/Brinebreath-Llama-3.1-70B (Merge)"}, {"eval_name": "gbueno86_Meta-LLama-3-Cat-Smaug-LLama-70b_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/gbueno86/Meta-LLama-3-Cat-Smaug-LLama-70b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">gbueno86/Meta-LLama-3-Cat-Smaug-LLama-70b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/gbueno86__Meta-LLama-3-Cat-Smaug-LLama-70b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "gbueno86/Meta-LLama-3-Cat-Smaug-LLama-70b", "Model sha": "2d73b7e1c7157df482555944d6a6b1362bc6c3c5", "Average \u2b06\ufe0f": 38.26813710120556, "Hub License": "llama3", "Hub \u2764\ufe0f": 1, "#Params (B)": 70, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.8071849359698933, "IFEval": 80.71849359698932, "BBH Raw": 0.6674314931312052, "BBH": 51.50838639894525, "MATH Lvl 5 Raw": 0.2681268882175227, "MATH Lvl 5": 26.812688821752268, "GPQA Raw": 0.3271812080536913, "GPQA": 10.290827740492167, "MUSR Raw": 0.4368229166666666, "MUSR": 15.002864583333327, "MMLU-PRO Raw": 0.5074800531914894, "MMLU-PRO": 45.27556146572104, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-24T00:00:00", "Submission Date": "2024-06-27T00:00:00", "Generation": 1, "Base Model": "gbueno86/Meta-LLama-3-Cat-Smaug-LLama-70b (Merge)"}, {"eval_name": "ghost-x_ghost-8b-beta-1608_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/ghost-x/ghost-8b-beta-1608\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">ghost-x/ghost-8b-beta-1608</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/ghost-x__ghost-8b-beta-1608-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "ghost-x/ghost-8b-beta-1608", "Model sha": "6d1b3853aab774af5a4db21ff9d5764918fb48f5", "Average \u2b06\ufe0f": 15.09054680435488, "Hub License": "other", "Hub \u2764\ufe0f": 28, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4272740772262042, "IFEval": 42.72740772262043, "BBH Raw": 0.4516549610035291, "BBH": 23.46396385965484, "MATH Lvl 5 Raw": 0.0120845921450151, "MATH Lvl 5": 1.2084592145015105, "GPQA Raw": 0.2583892617449664, "GPQA": 1.1185682326621946, "MUSR Raw": 0.3515833333333333, "MUSR": 1.58125, "MMLU-PRO Raw": 0.2839926861702128, "MMLU-PRO": 20.44363179669031, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-18T00:00:00", "Submission Date": "2024-09-17T00:00:00", "Generation": 1, "Base Model": "ghost-x/ghost-8b-beta"}, {"eval_name": "glaiveai_Reflection-Llama-3.1-70B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/glaiveai/Reflection-Llama-3.1-70B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">glaiveai/Reflection-Llama-3.1-70B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/glaiveai__Reflection-Llama-3.1-70B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "glaiveai/Reflection-Llama-3.1-70B", "Model sha": "086bd2658e00345808b31758ebb8f7e2c6d9897c", "Average \u2b06\ufe0f": 29.92481574831361, "Hub License": null, "Hub \u2764\ufe0f": 9, "#Params (B)": 69, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5990571683134085, "IFEval": 59.90571683134084, "BBH Raw": 0.5681010035620444, "BBH": 37.96048632437056, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.3145973154362416, "GPQA": 8.612975391498878, "MUSR Raw": 0.43803125, "MUSR": 13.720572916666663, "MMLU-PRO Raw": 0.6341422872340425, "MMLU-PRO": 59.349143026004725, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-19T00:00:00", "Submission Date": "2024-10-07T00:00:00", "Generation": 0, "Base Model": "glaiveai/Reflection-Llama-3.1-70B"}, {"eval_name": "google_codegemma-1.1-2b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "GemmaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/google/codegemma-1.1-2b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">google/codegemma-1.1-2b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/google__codegemma-1.1-2b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "google/codegemma-1.1-2b", "Model sha": "9d69e500da236427eab5867552ffc87108964f4d", "Average \u2b06\ufe0f": 7.020574851688036, "Hub License": "gemma", "Hub \u2764\ufe0f": 17, "#Params (B)": 2, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2293625358493242, "IFEval": 22.936253584932423, "BBH Raw": 0.3353417790248454, "BBH": 7.551225280004151, "MATH Lvl 5 Raw": 0.0060422960725075, "MATH Lvl 5": 0.6042296072507553, "GPQA Raw": 0.2651006711409396, "GPQA": 2.0134228187919474, "MUSR Raw": 0.3871458333333333, "MUSR": 5.9265625, "MMLU-PRO Raw": 0.1278257978723404, "MMLU-PRO": 3.0917553191489344, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-04-30T00:00:00", "Submission Date": "2024-08-12T00:00:00", "Generation": 0, "Base Model": "google/codegemma-1.1-2b"}, {"eval_name": "google_flan-t5-base_float16", "Precision": "float16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "T5ForConditionalGeneration", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/google/flan-t5-base\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">google/flan-t5-base</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/google__flan-t5-base-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "google/flan-t5-base", "Model sha": "7bcac572ce56db69c1ea7c8af255c5d7c9672fc2", "Average \u2b06\ufe0f": 6.239408489533947, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 788, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1890705550162457, "IFEval": 18.907055501624576, "BBH Raw": 0.3525980599300322, "BBH": 11.33769367730488, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2382550335570469, "GPQA": 0.0, "MUSR Raw": 0.3671145833333333, "MUSR": 3.22265625, "MMLU-PRO Raw": 0.135721409574468, "MMLU-PRO": 3.969045508274229, "Maintainer's Highlight": true, "Upload To Hub Date": "2022-10-21T00:00:00", "Submission Date": "2024-08-14T00:00:00", "Generation": 0, "Base Model": "google/flan-t5-base"}, {"eval_name": "google_flan-t5-large_float16", "Precision": "float16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "T5ForConditionalGeneration", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/google/flan-t5-large\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">google/flan-t5-large</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/google__flan-t5-large-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "google/flan-t5-large", "Model sha": "0613663d0d48ea86ba8cb3d7a44f0f65dc596a2a", "Average \u2b06\ufe0f": 9.41894870600608, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 575, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2200949037442873, "IFEval": 22.009490374428736, "BBH Raw": 0.4153115035679431, "BBH": 17.510018280067285, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2508389261744966, "GPQA": 0.1118568232662209, "MUSR Raw": 0.4083229166666666, "MUSR": 9.007031249999999, "MMLU-PRO Raw": 0.170877659574468, "MMLU-PRO": 7.87529550827423, "Maintainer's Highlight": true, "Upload To Hub Date": "2022-10-21T00:00:00", "Submission Date": "2024-08-14T00:00:00", "Generation": 0, "Base Model": "google/flan-t5-large"}, {"eval_name": "google_flan-t5-small_float16", "Precision": "float16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "T5ForConditionalGeneration", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/google/flan-t5-small\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">google/flan-t5-small</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/google__flan-t5-small-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "google/flan-t5-small", "Model sha": "0fc9ddf78a1e988dac52e2dac162b0ede4fd74ab", "Average \u2b06\ufe0f": 6.003780642360629, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 263, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1524255641697363, "IFEval": 15.24255641697363, "BBH Raw": 0.3282901097640842, "BBH": 6.36311196167965, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2609060402684564, "GPQA": 1.45413870246085, "MUSR Raw": 0.4122916666666666, "MUSR": 10.36979166666667, "MMLU-PRO Raw": 0.1233377659574468, "MMLU-PRO": 2.5930851063829774, "Maintainer's Highlight": true, "Upload To Hub Date": "2022-10-21T00:00:00", "Submission Date": "2024-06-27T00:00:00", "Generation": 0, "Base Model": "google/flan-t5-small"}, {"eval_name": "google_flan-t5-xl_float16", "Precision": "float16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "T5ForConditionalGeneration", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/google/flan-t5-xl\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">google/flan-t5-xl</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/google__flan-t5-xl-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "google/flan-t5-xl", "Model sha": "7d6315df2c2fb742f0f5b556879d730926ca9001", "Average \u2b06\ufe0f": 11.591779528533316, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 464, "#Params (B)": 2, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2237418937308563, "IFEval": 22.374189373085635, "BBH Raw": 0.4531063606211231, "BBH": 22.6950558112154, "MATH Lvl 5 Raw": 0.0007552870090634, "MATH Lvl 5": 0.0755287009063444, "GPQA Raw": 0.2525167785234899, "GPQA": 0.3355704697986553, "MUSR Raw": 0.41809375, "MUSR": 11.328385416666668, "MMLU-PRO Raw": 0.2146775265957446, "MMLU-PRO": 12.741947399527188, "Maintainer's Highlight": true, "Upload To Hub Date": "2022-10-21T00:00:00", "Submission Date": "2024-08-07T00:00:00", "Generation": 0, "Base Model": "google/flan-t5-xl"}, {"eval_name": "google_flan-t5-xl_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "T5ForConditionalGeneration", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/google/flan-t5-xl\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">google/flan-t5-xl</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/google__flan-t5-xl-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "google/flan-t5-xl", "Model sha": "7d6315df2c2fb742f0f5b556879d730926ca9001", "Average \u2b06\ufe0f": 11.58716743755607, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 464, "#Params (B)": 2, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2206944241279804, "IFEval": 22.06944241279804, "BBH Raw": 0.4537217215569396, "BBH": 22.837587663523298, "MATH Lvl 5 Raw": 0.0007552870090634, "MATH Lvl 5": 0.0755287009063444, "GPQA Raw": 0.2458053691275167, "GPQA": 0.0, "MUSR Raw": 0.42203125, "MUSR": 11.85390625, "MMLU-PRO Raw": 0.2141788563829787, "MMLU-PRO": 12.686539598108748, "Maintainer's Highlight": true, "Upload To Hub Date": "2022-10-21T00:00:00", "Submission Date": "2024-08-07T00:00:00", "Generation": 0, "Base Model": "google/flan-t5-xl"}, {"eval_name": "google_flan-t5-xxl_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "T5ForConditionalGeneration", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/google/flan-t5-xxl\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">google/flan-t5-xxl</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/google__flan-t5-xxl-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "google/flan-t5-xxl", "Model sha": "ae7c9136adc7555eeccc78cdd960dfd60fb346ce", "Average \u2b06\ufe0f": 13.485843425522548, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1183, "#Params (B)": 11, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2200450360598767, "IFEval": 22.00450360598767, "BBH Raw": 0.5065888015776924, "BBH": 30.11925560010588, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2701342281879195, "GPQA": 2.684563758389265, "MUSR Raw": 0.42175, "MUSR": 11.185416666666669, "MMLU-PRO Raw": 0.2342918882978723, "MMLU-PRO": 14.921320921985814, "Maintainer's Highlight": true, "Upload To Hub Date": "2022-10-21T00:00:00", "Submission Date": "2024-09-06T00:00:00", "Generation": 0, "Base Model": "google/flan-t5-xxl"}, {"eval_name": "google_flan-ul2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "T5ForConditionalGeneration", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/google/flan-ul2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">google/flan-ul2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/google__flan-ul2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "google/flan-ul2", "Model sha": "452d74ce28ac4a7f211d6ba3ef0717027f7a8074", "Average \u2b06\ufe0f": 13.550117524788796, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 551, "#Params (B)": 19, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2392540680948771, "IFEval": 23.925406809487715, "BBH Raw": 0.5053738049125648, "BBH": 30.02029012567709, "MATH Lvl 5 Raw": 0.0015105740181268, "MATH Lvl 5": 0.1510574018126888, "GPQA Raw": 0.287751677852349, "GPQA": 5.033557046979867, "MUSR Raw": 0.3843541666666666, "MUSR": 5.577604166666667, "MMLU-PRO Raw": 0.2493351063829787, "MMLU-PRO": 16.592789598108748, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-03-03T00:00:00", "Submission Date": "2024-08-07T00:00:00", "Generation": 0, "Base Model": "google/flan-ul2"}, {"eval_name": "google_gemma-1.1-2b-it_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "GemmaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/google/gemma-1.1-2b-it\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">google/gemma-1.1-2b-it</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/google__gemma-1.1-2b-it-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "google/gemma-1.1-2b-it", "Model sha": "bf4924f313df5166dee1467161e886e55f2eb4d4", "Average \u2b06\ufe0f": 7.776435284352048, "Hub License": "gemma", "Hub \u2764\ufe0f": 150, "#Params (B)": 2, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3067483166886084, "IFEval": 30.674831668860847, "BBH Raw": 0.3184634974814922, "BBH": 5.862826722774347, "MATH Lvl 5 Raw": 0.0015105740181268, "MATH Lvl 5": 0.1510574018126888, "GPQA Raw": 0.2692953020134228, "GPQA": 2.572706935123044, "MUSR Raw": 0.3393958333333333, "MUSR": 2.024479166666666, "MMLU-PRO Raw": 0.1483543882978723, "MMLU-PRO": 5.372709810874704, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-03-26T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "google/gemma-1.1-2b-it"}, {"eval_name": "google_gemma-1.1-7b-it_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "GemmaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/google/gemma-1.1-7b-it\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">google/gemma-1.1-7b-it</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/google__gemma-1.1-7b-it-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "google/gemma-1.1-7b-it", "Model sha": "16128b0aeb50762ea96430c0c06a37941bf9f274", "Average \u2b06\ufe0f": 17.40405754216496, "Hub License": "gemma", "Hub \u2764\ufe0f": 263, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5039107346285633, "IFEval": 50.391073462856326, "BBH Raw": 0.3935297962833251, "BBH": 15.93420938501317, "MATH Lvl 5 Raw": 0.0317220543806646, "MATH Lvl 5": 3.1722054380664653, "GPQA Raw": 0.2936241610738255, "GPQA": 5.8165548098434, "MUSR Raw": 0.4230208333333333, "MUSR": 11.510937500000002, "MMLU-PRO Raw": 0.2583942819148936, "MMLU-PRO": 17.5993646572104, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-03-26T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "google/gemma-1.1-7b-it"}, {"eval_name": "google_gemma-2-27b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/google/gemma-2-27b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">google/gemma-2-27b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/google__gemma-2-27b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "google/gemma-2-27b", "Model sha": "938270f5272feb02779b55c2bb2fffdd0f53ff0c", "Average \u2b06\ufe0f": 23.636640653975164, "Hub License": "gemma", "Hub \u2764\ufe0f": 170, "#Params (B)": 27, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2475221301701707, "IFEval": 24.75221301701707, "BBH Raw": 0.5642908317482057, "BBH": 37.390737454186464, "MATH Lvl 5 Raw": 0.1487915407854985, "MATH Lvl 5": 14.879154078549847, "GPQA Raw": 0.3506711409395973, "GPQA": 13.422818791946312, "MUSR Raw": 0.4396354166666666, "MUSR": 13.921093749999995, "MMLU-PRO Raw": 0.4370844414893617, "MMLU-PRO": 37.4538268321513, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-06-24T00:00:00", "Submission Date": "2024-08-24T00:00:00", "Generation": 0, "Base Model": "google/gemma-2-27b"}, {"eval_name": "google_gemma-2-27b-it_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/google/gemma-2-27b-it\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">google/gemma-2-27b-it</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/google__gemma-2-27b-it-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "google/gemma-2-27b-it", "Model sha": "f6c533e5eb013c7e31fc74ef042ac4f3fb5cf40b", "Average \u2b06\ufe0f": 32.309730652062136, "Hub License": "gemma", "Hub \u2764\ufe0f": 417, "#Params (B)": 27, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7977677008116243, "IFEval": 79.77677008116243, "BBH Raw": 0.6451387433168799, "BBH": 49.27284215130387, "MATH Lvl 5 Raw": 0.0067975830815709, "MATH Lvl 5": 0.6797583081570997, "GPQA Raw": 0.375, "GPQA": 16.666666666666664, "MUSR Raw": 0.4033020833333333, "MUSR": 9.112760416666667, "MMLU-PRO Raw": 0.4451462765957447, "MMLU-PRO": 38.34958628841608, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-06-24T00:00:00", "Submission Date": "2024-08-07T00:00:00", "Generation": 1, "Base Model": "google/gemma-2-27b"}, {"eval_name": "google_gemma-2-2b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "InternLM2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/google/gemma-2-2b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">google/gemma-2-2b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/google__gemma-2-2b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "google/gemma-2-2b", "Model sha": "4d05c88d00441bf62bf87dcfd29e204c05089f36", "Average \u2b06\ufe0f": 10.129463155055184, "Hub License": "gemma", "Hub \u2764\ufe0f": 371, "#Params (B)": 2, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.1993122692234382, "IFEval": 19.931226922343825, "BBH Raw": 0.3655966996422591, "BBH": 11.755807532236112, "MATH Lvl 5 Raw": 0.0287009063444108, "MATH Lvl 5": 2.8700906344410875, "GPQA Raw": 0.2625838926174497, "GPQA": 1.6778523489932915, "MUSR Raw": 0.4231770833333333, "MUSR": 11.43046875, "MMLU-PRO Raw": 0.218001994680851, "MMLU-PRO": 13.111332742316788, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-07-16T00:00:00", "Submission Date": "2024-07-31T00:00:00", "Generation": 0, "Base Model": "google/gemma-2-2b"}, {"eval_name": "google_gemma-2-2b_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/google/gemma-2-2b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">google/gemma-2-2b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/google__gemma-2-2b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "google/gemma-2-2b", "Model sha": "0738188b3055bc98daf0fe7211f0091357e5b979", "Average \u2b06\ufe0f": 10.258910633925124, "Hub License": "gemma", "Hub \u2764\ufe0f": 371, "#Params (B)": 2, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2017602184426211, "IFEval": 20.176021844262117, "BBH Raw": 0.3708674612470255, "BBH": 12.497306228573644, "MATH Lvl 5 Raw": 0.0241691842900302, "MATH Lvl 5": 2.416918429003021, "GPQA Raw": 0.2625838926174497, "GPQA": 1.6778523489932915, "MUSR Raw": 0.421875, "MUSR": 11.267708333333331, "MMLU-PRO Raw": 0.221658909574468, "MMLU-PRO": 13.51765661938534, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-07-16T00:00:00", "Submission Date": "2024-08-04T00:00:00", "Generation": 0, "Base Model": "google/gemma-2-2b"}, {"eval_name": "google_gemma-2-2b-it_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "InternLM2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/google/gemma-2-2b-it\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">google/gemma-2-2b-it</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/google__gemma-2-2b-it-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "google/gemma-2-2b-it", "Model sha": "2b6ac3ff954ad896c115bbfa1b571cd93ea2c20f", "Average \u2b06\ufe0f": 17.046939294966545, "Hub License": "gemma", "Hub \u2764\ufe0f": 610, "#Params (B)": 2, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5668337788179807, "IFEval": 56.68337788179808, "BBH Raw": 0.419923089142747, "BBH": 17.980792881523424, "MATH Lvl 5 Raw": 0.0007552870090634, "MATH Lvl 5": 0.0755287009063444, "GPQA Raw": 0.2743288590604026, "GPQA": 3.243847874720355, "MUSR Raw": 0.3928854166666666, "MUSR": 7.077343750000001, "MMLU-PRO Raw": 0.2549867021276595, "MMLU-PRO": 17.22074468085106, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-07-16T00:00:00", "Submission Date": "2024-07-31T00:00:00", "Generation": 1, "Base Model": "google/gemma-2-2b"}, {"eval_name": "google_gemma-2-2b-jpn-it_float16", "Precision": "float16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/google/gemma-2-2b-jpn-it\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">google/gemma-2-2b-jpn-it</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/google__gemma-2-2b-jpn-it-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "google/gemma-2-2b-jpn-it", "Model sha": "6b046bbc091084a1ec89fe03e58871fde10868eb", "Average \u2b06\ufe0f": 17.11540570593849, "Hub License": "gemma", "Hub \u2764\ufe0f": 106, "#Params (B)": 2, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.5077826832803628, "IFEval": 50.77826832803628, "BBH Raw": 0.422556989006581, "BBH": 18.525626449832732, "MATH Lvl 5 Raw": 0.0347432024169184, "MATH Lvl 5": 3.474320241691843, "GPQA Raw": 0.285234899328859, "GPQA": 4.697986577181204, "MUSR Raw": 0.3963854166666666, "MUSR": 7.681510416666669, "MMLU-PRO Raw": 0.2578125, "MMLU-PRO": 17.53472222222222, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-09-25T00:00:00", "Submission Date": "2024-10-11T00:00:00", "Generation": 2, "Base Model": "google/gemma-2-2b"}, {"eval_name": "google_gemma-2-9b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/google/gemma-2-9b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">google/gemma-2-9b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/google__gemma-2-9b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "google/gemma-2-9b", "Model sha": "beb0c08e9eeb0548f3aca2ac870792825c357b7d", "Average \u2b06\ufe0f": 20.92834820611076, "Hub License": "gemma", "Hub \u2764\ufe0f": 566, "#Params (B)": 9, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2039832089965735, "IFEval": 20.39832089965736, "BBH Raw": 0.5377373397621884, "BBH": 34.09681853589784, "MATH Lvl 5 Raw": 0.1178247734138972, "MATH Lvl 5": 11.782477341389727, "GPQA Raw": 0.3288590604026846, "GPQA": 10.514541387024613, "MUSR Raw": 0.4461145833333333, "MUSR": 14.29765625, "MMLU-PRO Raw": 0.4103224734042553, "MMLU-PRO": 34.48027482269504, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-06-24T00:00:00", "Submission Date": "2024-07-11T00:00:00", "Generation": 0, "Base Model": "google/gemma-2-9b"}, {"eval_name": "google_gemma-2-9b-it_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/google/gemma-2-9b-it\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">google/gemma-2-9b-it</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/google__gemma-2-9b-it-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "google/gemma-2-9b-it", "Model sha": "1937c70277fcc5f7fb0fc772fc5bc69378996e71", "Average \u2b06\ufe0f": 28.86279046415118, "Hub License": "gemma", "Hub \u2764\ufe0f": 501, "#Params (B)": 9, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7435626360279614, "IFEval": 74.35626360279613, "BBH Raw": 0.5990342504164132, "BBH": 42.136619683664655, "MATH Lvl 5 Raw": 0.0022658610271903, "MATH Lvl 5": 0.2265861027190332, "GPQA Raw": 0.360738255033557, "GPQA": 14.76510067114094, "MUSR Raw": 0.4072708333333333, "MUSR": 9.742187500000002, "MMLU-PRO Raw": 0.3875498670212766, "MMLU-PRO": 31.949985224586293, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-06-24T00:00:00", "Submission Date": "2024-07-11T00:00:00", "Generation": 1, "Base Model": "google/gemma-2-9b"}, {"eval_name": "google_gemma-2b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "GemmaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/google/gemma-2b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">google/gemma-2b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/google__gemma-2b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "google/gemma-2b", "Model sha": "2ac59a5d7bf4e1425010f0d457dde7d146658953", "Average \u2b06\ufe0f": 7.308348916250893, "Hub License": "gemma", "Hub \u2764\ufe0f": 902, "#Params (B)": 2, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.203758250331343, "IFEval": 20.375825033134305, "BBH Raw": 0.3380993975829239, "BBH": 8.466712864840373, "MATH Lvl 5 Raw": 0.0271903323262839, "MATH Lvl 5": 2.719033232628399, "GPQA Raw": 0.2550335570469799, "GPQA": 0.6711409395973182, "MUSR Raw": 0.39778125, "MUSR": 7.555989583333336, "MMLU-PRO Raw": 0.1365525265957446, "MMLU-PRO": 4.061391843971631, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-02-08T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "google/gemma-2b"}, {"eval_name": "google_gemma-2b-it_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "GemmaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/google/gemma-2b-it\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">google/gemma-2b-it</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/google__gemma-2b-it-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "google/gemma-2b-it", "Model sha": "de144fb2268dee1066f515465df532c05e699d48", "Average \u2b06\ufe0f": 7.221453677142921, "Hub License": "gemma", "Hub \u2764\ufe0f": 668, "#Params (B)": 2, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2690295083711219, "IFEval": 26.9029508371122, "BBH Raw": 0.3150819198878846, "BBH": 5.214303022163619, "MATH Lvl 5 Raw": 0.0045317220543806, "MATH Lvl 5": 0.4531722054380665, "GPQA Raw": 0.2785234899328859, "GPQA": 3.803131991051453, "MUSR Raw": 0.334125, "MUSR": 3.0322916666666675, "MMLU-PRO Raw": 0.1353058510638297, "MMLU-PRO": 3.9228723404255295, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-02-08T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "google/gemma-2b-it"}, {"eval_name": "google_gemma-7b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "GemmaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/google/gemma-7b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">google/gemma-7b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/google__gemma-7b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "google/gemma-7b", "Model sha": "a0eac5b80dba224e6ed79d306df50b1e92c2125d", "Average \u2b06\ufe0f": 15.279173051641893, "Hub License": "gemma", "Hub \u2764\ufe0f": 3040, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2659321710838353, "IFEval": 26.59321710838353, "BBH Raw": 0.4361528523928635, "BBH": 21.11609932329174, "MATH Lvl 5 Raw": 0.0641993957703927, "MATH Lvl 5": 6.419939577039275, "GPQA Raw": 0.2869127516778523, "GPQA": 4.921700223713646, "MUSR Raw": 0.4062395833333334, "MUSR": 10.979947916666667, "MMLU-PRO Raw": 0.2947972074468085, "MMLU-PRO": 21.644134160756497, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-02-08T00:00:00", "Submission Date": "2024-06-08T00:00:00", "Generation": 0, "Base Model": "google/gemma-7b"}, {"eval_name": "google_gemma-7b-it_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "GemmaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/google/gemma-7b-it\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">google/gemma-7b-it</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/google__gemma-7b-it-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "google/gemma-7b-it", "Model sha": "18329f019fb74ca4b24f97371785268543d687d2", "Average \u2b06\ufe0f": 12.83037755095706, "Hub License": "gemma", "Hub \u2764\ufe0f": 1132, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3868324933398937, "IFEval": 38.68324933398937, "BBH Raw": 0.3645582922270171, "BBH": 11.880091344549442, "MATH Lvl 5 Raw": 0.0158610271903323, "MATH Lvl 5": 1.5861027190332326, "GPQA Raw": 0.2843959731543624, "GPQA": 4.586129753914992, "MUSR Raw": 0.4274270833333333, "MUSR": 12.528385416666667, "MMLU-PRO Raw": 0.1694647606382978, "MMLU-PRO": 7.7183067375886525, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-02-13T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 1, "Base Model": "google/gemma-7b"}, {"eval_name": "google_mt5-base_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MT5ForConditionalGeneration", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/google/mt5-base\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">google/mt5-base</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/google__mt5-base-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "google/mt5-base", "Model sha": "2eb15465c5dd7f72a8f7984306ad05ebc3dd1e1f", "Average \u2b06\ufe0f": 3.5652821226493496, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 187, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1645157072124186, "IFEval": 16.45157072124186, "BBH Raw": 0.2883160022848883, "BBH": 1.29855138817669, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2390939597315436, "GPQA": 0.0, "MUSR Raw": 0.3672083333333333, "MUSR": 2.867708333333334, "MMLU-PRO Raw": 0.1069647606382978, "MMLU-PRO": 0.7738622931442081, "Maintainer's Highlight": true, "Upload To Hub Date": "2022-03-02T00:00:00", "Submission Date": "2024-09-06T00:00:00", "Generation": 0, "Base Model": "google/mt5-base"}, {"eval_name": "google_mt5-small_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MT5ForConditionalGeneration", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/google/mt5-small\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">google/mt5-small</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/google__mt5-small-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "google/mt5-small", "Model sha": "73fb5dbe4756edadc8fbe8c769b0a109493acf7a", "Average \u2b06\ufe0f": 4.255928173277352, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 96, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1718096871855565, "IFEval": 17.180968718555654, "BBH Raw": 0.2765842029929075, "BBH": 1.070971479500891, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2424496644295302, "GPQA": 0.0, "MUSR Raw": 0.38575, "MUSR": 5.91875, "MMLU-PRO Raw": 0.112283909574468, "MMLU-PRO": 1.3648788416075646, "Maintainer's Highlight": true, "Upload To Hub Date": "2022-03-02T00:00:00", "Submission Date": "2024-09-06T00:00:00", "Generation": 0, "Base Model": "google/mt5-small"}, {"eval_name": "google_mt5-xl_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MT5ForConditionalGeneration", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/google/mt5-xl\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">google/mt5-xl</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/google__mt5-xl-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "google/mt5-xl", "Model sha": "63fc6450d80515b48e026b69ef2fbbd426433e84", "Average \u2b06\ufe0f": 5.191420153031625, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 20, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1959644853433334, "IFEval": 19.596448534333348, "BBH Raw": 0.304735837080435, "BBH": 3.2824619143354035, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2642617449664429, "GPQA": 1.9015659955257265, "MUSR Raw": 0.3795208333333333, "MUSR": 5.040104166666665, "MMLU-PRO Raw": 0.1119514627659574, "MMLU-PRO": 1.3279403073286051, "Maintainer's Highlight": true, "Upload To Hub Date": "2022-03-02T00:00:00", "Submission Date": "2024-09-06T00:00:00", "Generation": 0, "Base Model": "google/mt5-xl"}, {"eval_name": "google_mt5-xxl_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "T5ForConditionalGeneration", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/google/mt5-xxl\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">google/mt5-xxl</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/google__mt5-xxl-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "google/mt5-xxl", "Model sha": "e07c395916dfbc315d4e5e48b4a54a1e8821b5c0", "Average \u2b06\ufe0f": 5.10307678308611, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 65, "#Params (B)": 11, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2357566811615402, "IFEval": 23.575668116154027, "BBH Raw": 0.2959344159116905, "BBH": 2.504710800447747, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2416107382550335, "GPQA": 0.0, "MUSR Raw": 0.3689479166666666, "MUSR": 3.5518229166666675, "MMLU-PRO Raw": 0.108876329787234, "MMLU-PRO": 0.9862588652482256, "Maintainer's Highlight": true, "Upload To Hub Date": "2022-03-02T00:00:00", "Submission Date": "2024-09-06T00:00:00", "Generation": 0, "Base Model": "google/mt5-xxl"}, {"eval_name": "google_recurrentgemma-2b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "RecurrentGemmaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/google/recurrentgemma-2b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">google/recurrentgemma-2b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/google__recurrentgemma-2b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "google/recurrentgemma-2b", "Model sha": "195f13c55b371fc721eda0662c00c64642c70e17", "Average \u2b06\ufe0f": 6.939598296084436, "Hub License": "gemma", "Hub \u2764\ufe0f": 92, "#Params (B)": 2, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3017028151970106, "IFEval": 30.170281519701057, "BBH Raw": 0.3197358283008447, "BBH": 4.8203622310347365, "MATH Lvl 5 Raw": 0.0158610271903323, "MATH Lvl 5": 1.5861027190332326, "GPQA Raw": 0.2458053691275167, "GPQA": 0.0, "MUSR Raw": 0.3445729166666667, "MUSR": 3.1049479166666667, "MMLU-PRO Raw": 0.1176030585106382, "MMLU-PRO": 1.9558953900709208, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-04-06T00:00:00", "Submission Date": "2024-06-13T00:00:00", "Generation": 0, "Base Model": "google/recurrentgemma-2b"}, {"eval_name": "google_recurrentgemma-2b-it_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "RecurrentGemmaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/google/recurrentgemma-2b-it\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">google/recurrentgemma-2b-it</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/google__recurrentgemma-2b-it-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "google/recurrentgemma-2b-it", "Model sha": "150248167d171fbdf4b02e7d28a4b3d749e570f6", "Average \u2b06\ufe0f": 7.920376673141152, "Hub License": "gemma", "Hub \u2764\ufe0f": 109, "#Params (B)": 2, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2949329999955673, "IFEval": 29.493299999556733, "BBH Raw": 0.3330004727260655, "BBH": 7.978763840391559, "MATH Lvl 5 Raw": 0.0151057401812688, "MATH Lvl 5": 1.5105740181268883, "GPQA Raw": 0.2533557046979866, "GPQA": 0.4474272930648763, "MUSR Raw": 0.3340625, "MUSR": 3.624479166666668, "MMLU-PRO Raw": 0.1402094414893617, "MMLU-PRO": 4.467715721040189, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-04-08T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "google/recurrentgemma-2b-it"}, {"eval_name": "google_recurrentgemma-9b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "RecurrentGemmaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/google/recurrentgemma-9b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">google/recurrentgemma-9b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/google__recurrentgemma-9b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "google/recurrentgemma-9b", "Model sha": "7b0ed98fb889ba8bdfa7c690f08f2e57a7c48dae", "Average \u2b06\ufe0f": 13.495462870206554, "Hub License": "gemma", "Hub \u2764\ufe0f": 59, "#Params (B)": 9, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3115943474425635, "IFEval": 31.15943474425635, "BBH Raw": 0.3956256866942839, "BBH": 15.323368888997411, "MATH Lvl 5 Raw": 0.0536253776435045, "MATH Lvl 5": 5.362537764350453, "GPQA Raw": 0.285234899328859, "GPQA": 4.697986577181204, "MUSR Raw": 0.3802604166666667, "MUSR": 6.599218750000001, "MMLU-PRO Raw": 0.2604720744680851, "MMLU-PRO": 17.830230496453904, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-06-07T00:00:00", "Submission Date": "2024-07-04T00:00:00", "Generation": 0, "Base Model": "google/recurrentgemma-9b"}, {"eval_name": "google_recurrentgemma-9b-it_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "RecurrentGemmaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/google/recurrentgemma-9b-it\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">google/recurrentgemma-9b-it</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/google__recurrentgemma-9b-it-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "google/recurrentgemma-9b-it", "Model sha": "43e62f98c3d496a5469ef4b18c1b11e417d68d1d", "Average \u2b06\ufe0f": 19.11741007176504, "Hub License": "gemma", "Hub \u2764\ufe0f": 48, "#Params (B)": 9, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5010383560065071, "IFEval": 50.10383560065072, "BBH Raw": 0.4367189649027647, "BBH": 21.62158008474012, "MATH Lvl 5 Raw": 0.0604229607250755, "MATH Lvl 5": 6.042296072507553, "GPQA Raw": 0.2701342281879195, "GPQA": 2.684563758389265, "MUSR Raw": 0.43790625, "MUSR": 13.771614583333337, "MMLU-PRO Raw": 0.2843251329787234, "MMLU-PRO": 20.480570330969268, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-06-07T00:00:00", "Submission Date": "2024-07-05T00:00:00", "Generation": 0, "Base Model": "google/recurrentgemma-9b-it"}, {"eval_name": "google_switch-base-8_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "SwitchTransformersForConditionalGeneration", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/google/switch-base-8\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">google/switch-base-8</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/google__switch-base-8-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "google/switch-base-8", "Model sha": "92fe2d22b024d9937146fe097ba3d3a7ba146e1b", "Average \u2b06\ufe0f": 3.2959502683966075, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 14, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1585205033754881, "IFEval": 15.852050337548814, "BBH Raw": 0.2876313273066933, "BBH": 1.7024781049821334, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.25, "GPQA": 0.0, "MUSR Raw": 0.3517395833333332, "MUSR": 1.133333333333333, "MMLU-PRO Raw": 0.1097905585106382, "MMLU-PRO": 1.087839834515365, "Maintainer's Highlight": true, "Upload To Hub Date": "2022-10-24T00:00:00", "Submission Date": "2024-09-06T00:00:00", "Generation": 0, "Base Model": "google/switch-base-8"}, {"eval_name": "google_umt5-base_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "UMT5ForConditionalGeneration", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/google/umt5-base\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">google/umt5-base</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/google__umt5-base-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "google/umt5-base", "Model sha": "0de9394d54f8975e71838d309de1cb496c894ab9", "Average \u2b06\ufe0f": 3.441046025501144, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 12, "#Params (B)": -1, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.174632198123202, "IFEval": 17.463219812320197, "BBH Raw": 0.2787726232894545, "BBH": 0.8135531788472962, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2541946308724832, "GPQA": 0.5592841163310973, "MUSR Raw": 0.33821875, "MUSR": 0.9440104166666662, "MMLU-PRO Raw": 0.1077958776595744, "MMLU-PRO": 0.8662086288416063, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-07-02T00:00:00", "Submission Date": "2024-09-06T00:00:00", "Generation": 0, "Base Model": "google/umt5-base"}, {"eval_name": "gpt2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "GPT2LMHeadModel", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/gpt2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">gpt2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/gpt2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "gpt2", "Model sha": "607a30d783dfa663caf39e06633721c8d4cfcd7e", "Average \u2b06\ufe0f": 6.536202667785688, "Hub License": "mit", "Hub \u2764\ufe0f": 2293, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1807770050133645, "IFEval": 18.07770050133645, "BBH Raw": 0.3035711244213359, "BBH": 2.674981367986987, "MATH Lvl 5 Raw": 0.0022658610271903, "MATH Lvl 5": 0.2265861027190332, "GPQA Raw": 0.2583892617449664, "GPQA": 1.1185682326621946, "MUSR Raw": 0.4470520833333333, "MUSR": 15.348177083333336, "MMLU-PRO Raw": 0.1159408244680851, "MMLU-PRO": 1.7712027186761226, "Maintainer's Highlight": true, "Upload To Hub Date": "2022-03-02T00:00:00", "Submission Date": "2024-06-09T00:00:00", "Generation": 0, "Base Model": "gpt2"}, {"eval_name": "gpt2_float16", "Precision": "float16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "GPT2LMHeadModel", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/gpt2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">gpt2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/gpt2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "gpt2", "Model sha": "607a30d783dfa663caf39e06633721c8d4cfcd7e", "Average \u2b06\ufe0f": 5.977736928104574, "Hub License": "mit", "Hub \u2764\ufe0f": 2293, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.0833333333333333, "IFEval": 8.333333333333332, "BBH Raw": 0.3083333333333333, "BBH": 9.199754901960786, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2333333333333333, "GPQA": 0.0, "MUSR Raw": 0.4333333333333333, "MUSR": 18.33333333333333, "MMLU-PRO Raw": 0.1, "MMLU-PRO": 0.0, "Maintainer's Highlight": true, "Upload To Hub Date": "2022-03-02T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "gpt2"}, {"eval_name": "gradientai_Llama-3-8B-Instruct-Gradient-1048k_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/gradientai/Llama-3-8B-Instruct-Gradient-1048k\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">gradientai/Llama-3-8B-Instruct-Gradient-1048k</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/gradientai__Llama-3-8B-Instruct-Gradient-1048k-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "gradientai/Llama-3-8B-Instruct-Gradient-1048k", "Model sha": "8697fb25cb77c852311e03b4464b8467471d56a4", "Average \u2b06\ufe0f": 18.11968845841446, "Hub License": "llama3", "Hub \u2764\ufe0f": 666, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4455588948434598, "IFEval": 44.55588948434598, "BBH Raw": 0.4345903107069573, "BBH": 21.01052898715872, "MATH Lvl 5 Raw": 0.0438066465256797, "MATH Lvl 5": 4.380664652567976, "GPQA Raw": 0.2776845637583892, "GPQA": 3.691275167785232, "MUSR Raw": 0.42975, "MUSR": 13.518749999999995, "MMLU-PRO Raw": 0.2940492021276595, "MMLU-PRO": 21.56102245862884, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-04-29T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "gradientai/Llama-3-8B-Instruct-Gradient-1048k"}, {"eval_name": "grimjim_Llama-3-Instruct-8B-SPPO-Iter3-SimPO-merge_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/grimjim/Llama-3-Instruct-8B-SPPO-Iter3-SimPO-merge\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">grimjim/Llama-3-Instruct-8B-SPPO-Iter3-SimPO-merge</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/grimjim__Llama-3-Instruct-8B-SPPO-Iter3-SimPO-merge-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "grimjim/Llama-3-Instruct-8B-SPPO-Iter3-SimPO-merge", "Model sha": "7a8d334dce0a2ce948f75612b8d3a61c53d094aa", "Average \u2b06\ufe0f": 20.73597897714634, "Hub License": "llama3", "Hub \u2764\ufe0f": 2, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4271244741729721, "IFEval": 42.71244741729721, "BBH Raw": 0.4961694535006833, "BBH": 28.258014912987704, "MATH Lvl 5 Raw": 0.093655589123867, "MATH Lvl 5": 9.365558912386708, "GPQA Raw": 0.2902684563758389, "GPQA": 5.369127516778524, "MUSR Raw": 0.4043229166666666, "MUSR": 9.540364583333334, "MMLU-PRO Raw": 0.3625332446808511, "MMLU-PRO": 29.17036052009456, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-28T00:00:00", "Submission Date": "2024-06-29T00:00:00", "Generation": 1, "Base Model": "grimjim/Llama-3-Instruct-8B-SPPO-Iter3-SimPO-merge (Merge)"}, {"eval_name": "grimjim_Llama-3-Instruct-8B-SimPO-SPPO-Iter3-merge_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/grimjim/Llama-3-Instruct-8B-SimPO-SPPO-Iter3-merge\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">grimjim/Llama-3-Instruct-8B-SimPO-SPPO-Iter3-merge</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/grimjim__Llama-3-Instruct-8B-SimPO-SPPO-Iter3-merge-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "grimjim/Llama-3-Instruct-8B-SimPO-SPPO-Iter3-merge", "Model sha": "8f4d460ea20e24e48914156af7def305c0cd347f", "Average \u2b06\ufe0f": 23.58776984556935, "Hub License": "llama3", "Hub \u2764\ufe0f": 2, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6805897241541332, "IFEval": 68.05897241541332, "BBH Raw": 0.5021734091176594, "BBH": 29.07328591447649, "MATH Lvl 5 Raw": 0.0619335347432024, "MATH Lvl 5": 6.193353474320242, "GPQA Raw": 0.2625838926174497, "GPQA": 1.6778523489932915, "MUSR Raw": 0.3885104166666666, "MUSR": 6.697135416666669, "MMLU-PRO Raw": 0.3684341755319149, "MMLU-PRO": 29.82601950354609, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-28T00:00:00", "Submission Date": "2024-09-17T00:00:00", "Generation": 1, "Base Model": "grimjim/Llama-3-Instruct-8B-SimPO-SPPO-Iter3-merge (Merge)"}, {"eval_name": "grimjim_Llama-3.1-8B-Instruct-abliterated_via_adapter_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/grimjim/Llama-3.1-8B-Instruct-abliterated_via_adapter\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">grimjim/Llama-3.1-8B-Instruct-abliterated_via_adapter</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/grimjim__Llama-3.1-8B-Instruct-abliterated_via_adapter-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "grimjim/Llama-3.1-8B-Instruct-abliterated_via_adapter", "Model sha": "b37ab2f859c96b125ff1c45c7ff0e267aa229156", "Average \u2b06\ufe0f": 22.952951271877907, "Hub License": "llama3.1", "Hub \u2764\ufe0f": 26, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4869501810751029, "IFEval": 48.69501810751029, "BBH Raw": 0.510526564708187, "BBH": 29.415990262794168, "MATH Lvl 5 Raw": 0.1238670694864048, "MATH Lvl 5": 12.386706948640484, "GPQA Raw": 0.313758389261745, "GPQA": 8.501118568232664, "MUSR Raw": 0.40103125, "MUSR": 9.262239583333336, "MMLU-PRO Raw": 0.3651097074468085, "MMLU-PRO": 29.4566341607565, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-25T00:00:00", "Submission Date": "2024-09-17T00:00:00", "Generation": 1, "Base Model": "grimjim/Llama-3.1-8B-Instruct-abliterated_via_adapter (Merge)"}, {"eval_name": "grimjim_Magot-v1-Gemma2-8k-9B_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/grimjim/Magot-v1-Gemma2-8k-9B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">grimjim/Magot-v1-Gemma2-8k-9B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/grimjim__Magot-v1-Gemma2-8k-9B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "grimjim/Magot-v1-Gemma2-8k-9B", "Model sha": "afae94acb42bc0dcf1d31b7338cb79c0bcab1829", "Average \u2b06\ufe0f": 23.60552972095053, "Hub License": "gemma", "Hub \u2764\ufe0f": 2, "#Params (B)": 9, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2996781872099363, "IFEval": 29.96781872099363, "BBH Raw": 0.6019447732218105, "BBH": 42.81812817526611, "MATH Lvl 5 Raw": 0.0400302114803625, "MATH Lvl 5": 4.003021148036254, "GPQA Raw": 0.3464765100671141, "GPQA": 12.863534675615217, "MUSR Raw": 0.44884375, "MUSR": 14.905468750000004, "MMLU-PRO Raw": 0.4336768617021276, "MMLU-PRO": 37.07520685579196, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-09T00:00:00", "Submission Date": "2024-09-19T00:00:00", "Generation": 1, "Base Model": "grimjim/Magot-v1-Gemma2-8k-9B (Merge)"}, {"eval_name": "grimjim_llama-3-Nephilim-v1-8B_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/grimjim/llama-3-Nephilim-v1-8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">grimjim/llama-3-Nephilim-v1-8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/grimjim__llama-3-Nephilim-v1-8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "grimjim/llama-3-Nephilim-v1-8B", "Model sha": "642799c8c768c53e831a03a1224db875116be866", "Average \u2b06\ufe0f": 21.57867973672686, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4277239945566652, "IFEval": 42.77239945566652, "BBH Raw": 0.5131817939007638, "BBH": 29.90753748907924, "MATH Lvl 5 Raw": 0.0815709969788519, "MATH Lvl 5": 8.157099697885197, "GPQA Raw": 0.3020134228187919, "GPQA": 6.935123042505594, "MUSR Raw": 0.4136249999999999, "MUSR": 10.63645833333333, "MMLU-PRO Raw": 0.3795711436170212, "MMLU-PRO": 31.06346040189125, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-21T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "grimjim/llama-3-Nephilim-v1-8B (Merge)"}, {"eval_name": "grimjim_llama-3-Nephilim-v2-8B_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/grimjim/llama-3-Nephilim-v2-8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">grimjim/llama-3-Nephilim-v2-8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/grimjim__llama-3-Nephilim-v2-8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "grimjim/llama-3-Nephilim-v2-8B", "Model sha": "924f56cdefbfaf38deb6aee3ad301ced027e142d", "Average \u2b06\ufe0f": 20.41142816079321, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3922281767931311, "IFEval": 39.22281767931311, "BBH Raw": 0.5048214936442625, "BBH": 29.8962638406202, "MATH Lvl 5 Raw": 0.0951661631419939, "MATH Lvl 5": 9.516616314199396, "GPQA Raw": 0.299496644295302, "GPQA": 6.599552572706939, "MUSR Raw": 0.3895, "MUSR": 7.887500000000002, "MMLU-PRO Raw": 0.3641123670212766, "MMLU-PRO": 29.34581855791962, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-26T00:00:00", "Submission Date": "2024-09-18T00:00:00", "Generation": 1, "Base Model": "grimjim/llama-3-Nephilim-v2-8B (Merge)"}, {"eval_name": "grimjim_llama-3-Nephilim-v2.1-8B_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/grimjim/llama-3-Nephilim-v2.1-8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">grimjim/llama-3-Nephilim-v2.1-8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/grimjim__llama-3-Nephilim-v2.1-8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "grimjim/llama-3-Nephilim-v2.1-8B", "Model sha": "5f516d9df1778dbe53ea941a754aef73b87e8eaa", "Average \u2b06\ufe0f": 20.271321609183627, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.389505401224307, "IFEval": 38.95054012243071, "BBH Raw": 0.5095042703104161, "BBH": 29.81966445991054, "MATH Lvl 5 Raw": 0.0898791540785498, "MATH Lvl 5": 8.987915407854985, "GPQA Raw": 0.299496644295302, "GPQA": 6.599552572706939, "MUSR Raw": 0.3935, "MUSR": 7.887500000000002, "MMLU-PRO Raw": 0.3644448138297872, "MMLU-PRO": 29.38275709219858, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-09T00:00:00", "Submission Date": "2024-09-18T00:00:00", "Generation": 1, "Base Model": "grimjim/llama-3-Nephilim-v2.1-8B (Merge)"}, {"eval_name": "grimjim_llama-3-Nephilim-v3-8B_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/grimjim/llama-3-Nephilim-v3-8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">grimjim/llama-3-Nephilim-v3-8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/grimjim__llama-3-Nephilim-v3-8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "grimjim/llama-3-Nephilim-v3-8B", "Model sha": "fd012ba05116aad7dc297d0a866ddb3345a056a1", "Average \u2b06\ufe0f": 20.538048288132487, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 11, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4173825449806513, "IFEval": 41.73825449806513, "BBH Raw": 0.5012671264428366, "BBH": 28.955635498374203, "MATH Lvl 5 Raw": 0.0913897280966767, "MATH Lvl 5": 9.138972809667674, "GPQA Raw": 0.2953020134228188, "GPQA": 6.040268456375841, "MUSR Raw": 0.3989270833333334, "MUSR": 8.332552083333338, "MMLU-PRO Raw": 0.3612034574468085, "MMLU-PRO": 29.02260638297872, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-14T00:00:00", "Submission Date": "2024-08-26T00:00:00", "Generation": 1, "Base Model": "grimjim/llama-3-Nephilim-v3-8B (Merge)"}, {"eval_name": "gupta-tanish_llama-7b-dpo-baseline_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/gupta-tanish/llama-7b-dpo-baseline\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">gupta-tanish/llama-7b-dpo-baseline</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/gupta-tanish__llama-7b-dpo-baseline-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "gupta-tanish/llama-7b-dpo-baseline", "Model sha": "1b5f1ef3ffa3b550619fbf64c33b6fd79e1bd559", "Average \u2b06\ufe0f": 11.844701987636071, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 6, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2693043347207631, "IFEval": 26.93043347207632, "BBH Raw": 0.3896894398264714, "BBH": 14.380522116367189, "MATH Lvl 5 Raw": 0.0188821752265861, "MATH Lvl 5": 1.8882175226586104, "GPQA Raw": 0.2625838926174497, "GPQA": 1.6778523489932915, "MUSR Raw": 0.445625, "MUSR": 14.769791666666668, "MMLU-PRO Raw": 0.2027925531914893, "MMLU-PRO": 11.421394799054372, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-29T00:00:00", "Submission Date": "2024-09-29T00:00:00", "Generation": 1, "Base Model": "gupta-tanish/llama-7b-dpo-baseline (Merge)"}, {"eval_name": "h2oai_h2o-danube3-4b-base_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe9 continuously pretrained", "T": "\ud83d\udfe9", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/h2oai/h2o-danube3-4b-base\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">h2oai/h2o-danube3-4b-base</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/h2oai__h2o-danube3-4b-base-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "h2oai/h2o-danube3-4b-base", "Model sha": "6bdf2f1e317143c998b88d9e9d72facc621a863f", "Average \u2b06\ufe0f": 9.990143814859607, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 19, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.233808516957229, "IFEval": 23.380851695722903, "BBH Raw": 0.3599083951265592, "BBH": 10.564444044561542, "MATH Lvl 5 Raw": 0.0166163141993957, "MATH Lvl 5": 1.6616314199395767, "GPQA Raw": 0.2911073825503356, "GPQA": 5.480984340044745, "MUSR Raw": 0.3778125, "MUSR": 6.526562500000002, "MMLU-PRO Raw": 0.2109375, "MMLU-PRO": 12.326388888888888, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-04T00:00:00", "Submission Date": "2024-08-10T00:00:00", "Generation": 0, "Base Model": "h2oai/h2o-danube3-4b-base"}, {"eval_name": "h2oai_h2o-danube3-4b-chat_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/h2oai/h2o-danube3-4b-chat\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">h2oai/h2o-danube3-4b-chat</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/h2oai__h2o-danube3-4b-chat-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "h2oai/h2o-danube3-4b-chat", "Model sha": "1e5c6fa6620f8bf078958069ab4581cd88e0202c", "Average \u2b06\ufe0f": 11.357249421166255, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 62, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3628771659197596, "IFEval": 36.28771659197596, "BBH Raw": 0.3466170643135169, "BBH": 8.839702966263845, "MATH Lvl 5 Raw": 0.0279456193353474, "MATH Lvl 5": 2.794561933534743, "GPQA Raw": 0.2600671140939597, "GPQA": 1.342281879194629, "MUSR Raw": 0.378125, "MUSR": 5.232291666666669, "MMLU-PRO Raw": 0.2228224734042553, "MMLU-PRO": 13.6469414893617, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-04T00:00:00", "Submission Date": "2024-07-15T00:00:00", "Generation": 0, "Base Model": "h2oai/h2o-danube3-4b-chat"}, {"eval_name": "h2oai_h2o-danube3-500m-chat_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/h2oai/h2o-danube3-500m-chat\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">h2oai/h2o-danube3-500m-chat</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/h2oai__h2o-danube3-500m-chat-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "h2oai/h2o-danube3-500m-chat", "Model sha": "c202f976c26875541e738ea978c8158fa536da9a", "Average \u2b06\ufe0f": 5.015618524753995, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 30, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2207941594968018, "IFEval": 22.079415949680183, "BBH Raw": 0.3034691168308313, "BBH": 3.065370444981646, "MATH Lvl 5 Raw": 0.0052870090634441, "MATH Lvl 5": 0.5287009063444109, "GPQA Raw": 0.2307046979865771, "GPQA": 0.0, "MUSR Raw": 0.3433958333333333, "MUSR": 2.824479166666667, "MMLU-PRO Raw": 0.1143617021276595, "MMLU-PRO": 1.595744680851063, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-04T00:00:00", "Submission Date": "2024-10-11T00:00:00", "Generation": 0, "Base Model": "h2oai/h2o-danube3-500m-chat"}, {"eval_name": "haoranxu_ALMA-13B-R_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Adapter", "Architecture": "?", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/haoranxu/ALMA-13B-R\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">haoranxu/ALMA-13B-R</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/haoranxu__ALMA-13B-R-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "haoranxu/ALMA-13B-R", "Model sha": "b69ebad694274b929cfcf3db29dd7bb93d752e39", "Average \u2b06\ufe0f": 3.587775291474459, "Hub License": "mit", "Hub \u2764\ufe0f": 76, "#Params (B)": 13, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.0039218163362101, "IFEval": 0.3921816336210145, "BBH Raw": 0.345656261205981, "BBH": 8.819669166822672, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2575503355704698, "GPQA": 1.0067114093959737, "MUSR Raw": 0.3527916666666666, "MUSR": 2.232291666666667, "MMLU-PRO Raw": 0.1816821808510638, "MMLU-PRO": 9.075797872340424, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-01-17T00:00:00", "Submission Date": "2024-10-01T00:00:00", "Generation": 0, "Base Model": "haoranxu/ALMA-13B-R"}, {"eval_name": "haoranxu_Llama-3-Instruct-8B-CPO-SimPO_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/haoranxu/Llama-3-Instruct-8B-CPO-SimPO\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">haoranxu/Llama-3-Instruct-8B-CPO-SimPO</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/haoranxu__Llama-3-Instruct-8B-CPO-SimPO-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "haoranxu/Llama-3-Instruct-8B-CPO-SimPO", "Model sha": "3ca4b5c3a6395ff090e1039d55ac1f6120777302", "Average \u2b06\ufe0f": 24.482741283682987, "Hub License": "mit", "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7046447869430887, "IFEval": 70.46447869430888, "BBH Raw": 0.5048301774821616, "BBH": 29.762188091412483, "MATH Lvl 5 Raw": 0.0770392749244713, "MATH Lvl 5": 7.7039274924471295, "GPQA Raw": 0.2927852348993288, "GPQA": 5.7046979865771785, "MUSR Raw": 0.3566666666666667, "MUSR": 3.4166666666666674, "MMLU-PRO Raw": 0.3686003989361702, "MMLU-PRO": 29.84448877068557, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-19T00:00:00", "Submission Date": "2024-07-28T00:00:00", "Generation": 0, "Base Model": "haoranxu/Llama-3-Instruct-8B-CPO-SimPO"}, {"eval_name": "haoranxu_Llama-3-Instruct-8B-SimPO_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/haoranxu/Llama-3-Instruct-8B-SimPO\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">haoranxu/Llama-3-Instruct-8B-SimPO</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/haoranxu__Llama-3-Instruct-8B-SimPO-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "haoranxu/Llama-3-Instruct-8B-SimPO", "Model sha": "8346770280fa169d41d737785dd63a66e9d94501", "Average \u2b06\ufe0f": 24.713790664620785, "Hub License": "llama3", "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7347449212533854, "IFEval": 73.47449212533854, "BBH Raw": 0.4979236015141501, "BBH": 28.2263760762505, "MATH Lvl 5 Raw": 0.0709969788519637, "MATH Lvl 5": 7.099697885196375, "GPQA Raw": 0.2902684563758389, "GPQA": 5.369127516778524, "MUSR Raw": 0.3566041666666666, "MUSR": 3.7421875, "MMLU-PRO Raw": 0.3733377659574468, "MMLU-PRO": 30.37086288416076, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-07T00:00:00", "Submission Date": "2024-07-28T00:00:00", "Generation": 1, "Base Model": "meta-llama/Meta-Llama-3-8B-Instruct"}, {"eval_name": "hon9kon9ize_CantoneseLLMChat-v0.5_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe9 continuously pretrained", "T": "\ud83d\udfe9", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/hon9kon9ize/CantoneseLLMChat-v0.5\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">hon9kon9ize/CantoneseLLMChat-v0.5</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/hon9kon9ize__CantoneseLLMChat-v0.5-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "hon9kon9ize/CantoneseLLMChat-v0.5", "Model sha": "812eb4f168c3ea258ebb220393401db9578e0f67", "Average \u2b06\ufe0f": 15.733214715552077, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 9, "#Params (B)": 6, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3230849701015528, "IFEval": 32.30849701015528, "BBH Raw": 0.4345238880305924, "BBH": 20.761385180655164, "MATH Lvl 5 Raw": 0.0279456193353474, "MATH Lvl 5": 2.794561933534743, "GPQA Raw": 0.2776845637583892, "GPQA": 3.691275167785232, "MUSR Raw": 0.4706458333333334, "MUSR": 18.13072916666667, "MMLU-PRO Raw": 0.2504155585106383, "MMLU-PRO": 16.712839834515364, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-01T00:00:00", "Submission Date": "2024-07-07T00:00:00", "Generation": 0, "Base Model": "hon9kon9ize/CantoneseLLMChat-v0.5"}, {"eval_name": "hon9kon9ize_CantoneseLLMChat-v1.0-7B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/hon9kon9ize/CantoneseLLMChat-v1.0-7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">hon9kon9ize/CantoneseLLMChat-v1.0-7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/hon9kon9ize__CantoneseLLMChat-v1.0-7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "hon9kon9ize/CantoneseLLMChat-v1.0-7B", "Model sha": "4703b1afc7aab8e3a8059432fd1c4b0aba011482", "Average \u2b06\ufe0f": 22.975169028632774, "Hub License": "other", "Hub \u2764\ufe0f": 1, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4454835392314614, "IFEval": 44.54835392314614, "BBH Raw": 0.4865734655539633, "BBH": 28.53613616746739, "MATH Lvl 5 Raw": 0.1790030211480362, "MATH Lvl 5": 17.900302114803626, "GPQA Raw": 0.3221476510067114, "GPQA": 9.61968680089485, "MUSR Raw": 0.3882916666666667, "MUSR": 6.303125000000004, "MMLU-PRO Raw": 0.3784906914893617, "MMLU-PRO": 30.94341016548463, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-02T00:00:00", "Submission Date": "2024-10-10T00:00:00", "Generation": 1, "Base Model": "Removed"}, {"eval_name": "huggyllama_llama-13b_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/huggyllama/llama-13b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">huggyllama/llama-13b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/huggyllama__llama-13b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "huggyllama/llama-13b", "Model sha": "bf57045473f207bb1de1ed035ace226f4d9f9bba", "Average \u2b06\ufe0f": 9.253715113860263, "Hub License": "other", "Hub \u2764\ufe0f": 137, "#Params (B)": 13, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2410526292459562, "IFEval": 24.10526292459563, "BBH Raw": 0.3987892558117458, "BBH": 16.145707376925767, "MATH Lvl 5 Raw": 0.0120845921450151, "MATH Lvl 5": 1.2084592145015105, "GPQA Raw": 0.2550335570469799, "GPQA": 0.6711409395973182, "MUSR Raw": 0.34621875, "MUSR": 2.8106770833333345, "MMLU-PRO Raw": 0.1952293882978723, "MMLU-PRO": 10.581043144208037, "Maintainer's Highlight": false, "Upload To Hub Date": "2023-04-03T00:00:00", "Submission Date": "2024-07-04T00:00:00", "Generation": 0, "Base Model": "huggyllama/llama-13b"}, {"eval_name": "huggyllama_llama-65b_float16", "Precision": "float16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/huggyllama/llama-65b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">huggyllama/llama-65b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/huggyllama__llama-65b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "huggyllama/llama-65b", "Model sha": "49707c5313d34d1c5a846e29cf2a2a650c22c8ee", "Average \u2b06\ufe0f": 13.536974153117828, "Hub License": "other", "Hub \u2764\ufe0f": 74, "#Params (B)": 65, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2525931195893562, "IFEval": 25.259311958935623, "BBH Raw": 0.4702556052882764, "BBH": 25.254277114598622, "MATH Lvl 5 Raw": 0.0219033232628398, "MATH Lvl 5": 2.190332326283988, "GPQA Raw": 0.276006711409396, "GPQA": 3.467561521252797, "MUSR Raw": 0.3594583333333332, "MUSR": 1.9656249999999984, "MMLU-PRO Raw": 0.3077626329787234, "MMLU-PRO": 23.084736997635936, "Maintainer's Highlight": false, "Upload To Hub Date": "2023-04-04T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "huggyllama/llama-65b"}, {"eval_name": "huggyllama_llama-7b_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/huggyllama/llama-7b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">huggyllama/llama-7b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/huggyllama__llama-7b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "huggyllama/llama-7b", "Model sha": "4782ad278652c7c71b72204d462d6d01eaaf7549", "Average \u2b06\ufe0f": 6.389823692285343, "Hub License": "other", "Hub \u2764\ufe0f": 285, "#Params (B)": 6, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2500953026857626, "IFEval": 25.009530268576263, "BBH Raw": 0.3277313478289856, "BBH": 7.076660678102023, "MATH Lvl 5 Raw": 0.0067975830815709, "MATH Lvl 5": 0.6797583081570997, "GPQA Raw": 0.2525167785234899, "GPQA": 0.3355704697986553, "MUSR Raw": 0.3353958333333333, "MUSR": 1.7578124999999991, "MMLU-PRO Raw": 0.1313164893617021, "MMLU-PRO": 3.4796099290780127, "Maintainer's Highlight": false, "Upload To Hub Date": "2023-04-03T00:00:00", "Submission Date": "2024-07-04T00:00:00", "Generation": 0, "Base Model": "huggyllama/llama-7b"}, {"eval_name": "huihui-ai_Qwen2.5-7B-Instruct-abliterated_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/huihui-ai/Qwen2.5-7B-Instruct-abliterated\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">huihui-ai/Qwen2.5-7B-Instruct-abliterated</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/huihui-ai__Qwen2.5-7B-Instruct-abliterated-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "huihui-ai/Qwen2.5-7B-Instruct-abliterated", "Model sha": "c04c14c82962506e2b16f58f9f6b0a2e60a6afde", "Average \u2b06\ufe0f": 26.6475056681965, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 2, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7546033413564897, "IFEval": 75.46033413564896, "BBH Raw": 0.5261589972829911, "BBH": 32.886673214320496, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.3154362416107382, "GPQA": 8.7248322147651, "MUSR Raw": 0.3966666666666666, "MUSR": 7.483333333333333, "MMLU-PRO Raw": 0.41796875, "MMLU-PRO": 35.32986111111111, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-19T00:00:00", "Submission Date": "2024-09-24T00:00:00", "Generation": 2, "Base Model": "Qwen/Qwen2.5-7B"}, {"eval_name": "huihui-ai_Qwen2.5-7B-Instruct-abliterated-v2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/huihui-ai/Qwen2.5-7B-Instruct-abliterated-v2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">huihui-ai/Qwen2.5-7B-Instruct-abliterated-v2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/huihui-ai__Qwen2.5-7B-Instruct-abliterated-v2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "huihui-ai/Qwen2.5-7B-Instruct-abliterated-v2", "Model sha": "05d179c1108cc2dc1c1a16a8255ac6f57eac5d32", "Average \u2b06\ufe0f": 26.999904985788007, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 9, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7606484128778308, "IFEval": 76.06484128778308, "BBH Raw": 0.5376688442794247, "BBH": 34.369626512494015, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.3087248322147651, "GPQA": 7.829977628635347, "MUSR Raw": 0.3980625, "MUSR": 8.091145833333334, "MMLU-PRO Raw": 0.4207945478723404, "MMLU-PRO": 35.643838652482266, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-22T00:00:00", "Submission Date": "2024-09-24T00:00:00", "Generation": 2, "Base Model": "Qwen/Qwen2.5-7B"}, {"eval_name": "iRyanBell_ARC1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/iRyanBell/ARC1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">iRyanBell/ARC1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/iRyanBell__ARC1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "iRyanBell/ARC1", "Model sha": "28176c0fb77fa43e1410766faf35d2a2681566e9", "Average \u2b06\ufe0f": 19.48544130669547, "Hub License": "llama3", "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.441112913735555, "IFEval": 44.1112913735555, "BBH Raw": 0.4902999658144703, "BBH": 26.56449513263172, "MATH Lvl 5 Raw": 0.0581570996978852, "MATH Lvl 5": 5.81570996978852, "GPQA Raw": 0.2944630872483221, "GPQA": 5.92841163310962, "MUSR Raw": 0.3990520833333333, "MUSR": 8.148177083333335, "MMLU-PRO Raw": 0.3371010638297872, "MMLU-PRO": 26.34456264775413, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-30T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "iRyanBell/ARC1"}, {"eval_name": "iRyanBell_ARC1-II_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/iRyanBell/ARC1-II\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">iRyanBell/ARC1-II</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/iRyanBell__ARC1-II-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "iRyanBell/ARC1-II", "Model sha": "c81076b9bdaac0722b33e411a49b07a296e8fae8", "Average \u2b06\ufe0f": 9.320256405776588, "Hub License": "llama3", "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1708356050834009, "IFEval": 17.083560508340092, "BBH Raw": 0.3381778102988435, "BBH": 7.246229410679451, "MATH Lvl 5 Raw": 0.0075528700906344, "MATH Lvl 5": 0.7552870090634441, "GPQA Raw": 0.2718120805369127, "GPQA": 2.9082774049217, "MUSR Raw": 0.4912916666666667, "MUSR": 20.31145833333333, "MMLU-PRO Raw": 0.1685505319148936, "MMLU-PRO": 7.616725768321511, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-12T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "iRyanBell/ARC1-II"}, {"eval_name": "ibivibiv_colossus_120b_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/ibivibiv/colossus_120b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">ibivibiv/colossus_120b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/ibivibiv__colossus_120b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "ibivibiv/colossus_120b", "Model sha": "b4c11f98bd874bfa454a0bb46153335cfb9b06a3", "Average \u2b06\ufe0f": 25.27673402040248, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 117, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4275987712602561, "IFEval": 42.759877126025614, "BBH Raw": 0.6061408586494191, "BBH": 44.07149752747837, "MATH Lvl 5 Raw": 0.0483383685800604, "MATH Lvl 5": 4.833836858006042, "GPQA Raw": 0.3087248322147651, "GPQA": 7.829977628635347, "MUSR Raw": 0.4733125, "MUSR": 19.2640625, "MMLU-PRO Raw": 0.3961103723404255, "MMLU-PRO": 32.901152482269495, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-12T00:00:00", "Submission Date": "2024-06-27T00:00:00", "Generation": 0, "Base Model": "ibivibiv/colossus_120b"}, {"eval_name": "ibivibiv_multimaster-7b-v6_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/ibivibiv/multimaster-7b-v6\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">ibivibiv/multimaster-7b-v6</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/ibivibiv__multimaster-7b-v6-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "ibivibiv/multimaster-7b-v6", "Model sha": "7b3bfecb654c86565c65cd510dd1138cb3e75087", "Average \u2b06\ufe0f": 21.02682808929153, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 35, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4473075883101283, "IFEval": 44.73075883101282, "BBH Raw": 0.519351871026721, "BBH": 32.40128043389345, "MATH Lvl 5 Raw": 0.0521148036253776, "MATH Lvl 5": 5.211480362537765, "GPQA Raw": 0.3036912751677852, "GPQA": 7.158836689038028, "MUSR Raw": 0.4395729166666666, "MUSR": 13.379947916666673, "MMLU-PRO Raw": 0.3095079787234042, "MMLU-PRO": 23.278664302600472, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-02-24T00:00:00", "Submission Date": "2024-06-28T00:00:00", "Generation": 0, "Base Model": "ibivibiv/multimaster-7b-v6"}, {"eval_name": "ibm_merlinite-7b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/ibm/merlinite-7b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">ibm/merlinite-7b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/ibm__merlinite-7b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "ibm/merlinite-7b", "Model sha": "233d12759d5bb9344231dafdb51310ec19d79c0e", "Average \u2b06\ufe0f": 16.738445769074524, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 103, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2498703440205322, "IFEval": 24.98703440205322, "BBH Raw": 0.50071326118705, "BBH": 29.97724776968684, "MATH Lvl 5 Raw": 0.0234138972809667, "MATH Lvl 5": 2.3413897280966767, "GPQA Raw": 0.296979865771812, "GPQA": 6.263982102908276, "MUSR Raw": 0.4411562499999999, "MUSR": 13.877864583333334, "MMLU-PRO Raw": 0.3068484042553192, "MMLU-PRO": 22.9831560283688, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-03-02T00:00:00", "Submission Date": "2024-06-09T00:00:00", "Generation": 1, "Base Model": "mistralai/Mistral-7B-v0.1"}, {"eval_name": "ibm-granite_granite-7b-base_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/ibm-granite/granite-7b-base\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">ibm-granite/granite-7b-base</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/ibm-granite__granite-7b-base-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "ibm-granite/granite-7b-base", "Model sha": "23fcb4cb5b69f8a122fb944491e9f1ad664ba37b", "Average \u2b06\ufe0f": 7.745056411205006, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 26, "#Params (B)": 6, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2414271909644188, "IFEval": 24.142719096441887, "BBH Raw": 0.3480437271610618, "BBH": 9.050800002899097, "MATH Lvl 5 Raw": 0.0060422960725075, "MATH Lvl 5": 0.6042296072507553, "GPQA Raw": 0.2458053691275167, "GPQA": 0.0, "MUSR Raw": 0.3554895833333333, "MUSR": 3.402864583333334, "MMLU-PRO Raw": 0.1834275265957446, "MMLU-PRO": 9.269725177304965, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-04-19T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "ibm-granite/granite-7b-base"}, {"eval_name": "ibm-granite_granite-7b-instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/ibm-granite/granite-7b-instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">ibm-granite/granite-7b-instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/ibm-granite__granite-7b-instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "ibm-granite/granite-7b-instruct", "Model sha": "c6d1adfa5cdba2c8344e055bb7de87b7935250a8", "Average \u2b06\ufe0f": 11.795785334826531, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 3, "#Params (B)": 6, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2972313461615181, "IFEval": 29.72313461615181, "BBH Raw": 0.3722952960326952, "BBH": 12.639328702465264, "MATH Lvl 5 Raw": 0.0060422960725075, "MATH Lvl 5": 0.6042296072507553, "GPQA Raw": 0.285234899328859, "GPQA": 4.697986577181204, "MUSR Raw": 0.4019999999999999, "MUSR": 8.816666666666668, "MMLU-PRO Raw": 0.2286402925531915, "MMLU-PRO": 14.293365839243496, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-05-19T00:00:00", "Submission Date": "2024-10-02T00:00:00", "Generation": 1, "Base Model": "ibm/granite-7b-base"}, {"eval_name": "icefog72_Ice0.15-02.10-RP_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/icefog72/Ice0.15-02.10-RP\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">icefog72/Ice0.15-02.10-RP</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/icefog72__Ice0.15-02.10-RP-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "icefog72/Ice0.15-02.10-RP", "Model sha": "ab67a8b63836ec7c8e6729d79d9dfd2708b20eb3", "Average \u2b06\ufe0f": 21.403210643279284, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 7, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.5343355629729118, "IFEval": 53.43355629729119, "BBH Raw": 0.4976384736188401, "BBH": 30.130104071068587, "MATH Lvl 5 Raw": 0.0521148036253776, "MATH Lvl 5": 5.211480362537765, "GPQA Raw": 0.2776845637583892, "GPQA": 3.691275167785232, "MUSR Raw": 0.4319791666666666, "MUSR": 12.997395833333336, "MMLU-PRO Raw": 0.3065990691489361, "MMLU-PRO": 22.95545212765957, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-02T00:00:00", "Submission Date": "2024-10-02T00:00:00", "Generation": 0, "Base Model": "icefog72/Ice0.15-02.10-RP"}, {"eval_name": "icefog72_Ice0.16-02.10-RP_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/icefog72/Ice0.16-02.10-RP\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">icefog72/Ice0.16-02.10-RP</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/icefog72__Ice0.16-02.10-RP-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "icefog72/Ice0.16-02.10-RP", "Model sha": "cb5c4d8a2e74efb41eae8b6dff8d06252c0a795d", "Average \u2b06\ufe0f": 20.95053744863503, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.5069083365470286, "IFEval": 50.69083365470286, "BBH Raw": 0.4945564313654156, "BBH": 29.58232083302582, "MATH Lvl 5 Raw": 0.0513595166163142, "MATH Lvl 5": 5.13595166163142, "GPQA Raw": 0.2793624161073825, "GPQA": 3.9149888143176734, "MUSR Raw": 0.433375, "MUSR": 13.405208333333327, "MMLU-PRO Raw": 0.3067652925531915, "MMLU-PRO": 22.973921394799056, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-02T00:00:00", "Submission Date": "2024-10-02T00:00:00", "Generation": 0, "Base Model": "icefog72/Ice0.16-02.10-RP"}, {"eval_name": "icefog72_Ice0.17-03.10-RP_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/icefog72/Ice0.17-03.10-RP\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">icefog72/Ice0.17-03.10-RP</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/icefog72__Ice0.17-03.10-RP-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "icefog72/Ice0.17-03.10-RP", "Model sha": "ca5a429546334784d94bcab0eb52c5f22f433680", "Average \u2b06\ufe0f": 21.30111122040719, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.5123538876846767, "IFEval": 51.23538876846767, "BBH Raw": 0.5006815748225494, "BBH": 30.37626243817209, "MATH Lvl 5 Raw": 0.0543806646525679, "MATH Lvl 5": 5.438066465256798, "GPQA Raw": 0.2818791946308724, "GPQA": 4.250559284116329, "MUSR Raw": 0.433375, "MUSR": 13.338541666666664, "MMLU-PRO Raw": 0.3085106382978723, "MMLU-PRO": 23.167848699763592, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-03T00:00:00", "Submission Date": "2024-10-03T00:00:00", "Generation": 0, "Base Model": "icefog72/Ice0.17-03.10-RP"}, {"eval_name": "icefog72_Ice0.7-29.09-RP_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/icefog72/Ice0.7-29.09-RP\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">icefog72/Ice0.7-29.09-RP</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/icefog72__Ice0.7-29.09-RP-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "icefog72/Ice0.7-29.09-RP", "Model sha": "932f2687137eebcafa9b90fe06e73ed272e0be81", "Average \u2b06\ufe0f": 21.474517716036228, "Hub License": null, "Hub \u2764\ufe0f": 1, "#Params (B)": 7, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.5175744801570943, "IFEval": 51.75744801570943, "BBH Raw": 0.5047661992357916, "BBH": 30.72587571429055, "MATH Lvl 5 Raw": 0.0619335347432024, "MATH Lvl 5": 6.193353474320242, "GPQA Raw": 0.287751677852349, "GPQA": 5.033557046979867, "MUSR Raw": 0.4237916666666666, "MUSR": 11.507291666666667, "MMLU-PRO Raw": 0.3126662234042553, "MMLU-PRO": 23.62958037825059, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-29T00:00:00", "Submission Date": "2024-10-03T00:00:00", "Generation": 1, "Base Model": "icefog72/Ice0.7-29.09-RP (Merge)"}, {"eval_name": "icefog72_IceCocoaRP-7b_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/icefog72/IceCocoaRP-7b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">icefog72/IceCocoaRP-7b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/icefog72__IceCocoaRP-7b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "icefog72/IceCocoaRP-7b", "Model sha": "001beaf88932f7e010af21bbdeff0079bda73b1d", "Average \u2b06\ufe0f": 20.871501813377407, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 3, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4962421929369628, "IFEval": 49.62421929369628, "BBH Raw": 0.4937902147076245, "BBH": 29.63689549472275, "MATH Lvl 5 Raw": 0.0543806646525679, "MATH Lvl 5": 5.438066465256798, "GPQA Raw": 0.2953020134228188, "GPQA": 6.040268456375841, "MUSR Raw": 0.4197916666666666, "MUSR": 11.17395833333333, "MMLU-PRO Raw": 0.3098404255319149, "MMLU-PRO": 23.315602836879428, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-07T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "icefog72/IceCocoaRP-7b (Merge)"}, {"eval_name": "icefog72_IceCoffeeRP-7b_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/icefog72/IceCoffeeRP-7b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">icefog72/IceCoffeeRP-7b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/icefog72__IceCoffeeRP-7b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "icefog72/IceCoffeeRP-7b", "Model sha": "131c0f7c0809a9d23b05b63cb550a586c3c7b372", "Average \u2b06\ufe0f": 20.24311983103429, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 6, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4959174989029109, "IFEval": 49.59174989029109, "BBH Raw": 0.4888721624432721, "BBH": 29.39810739240589, "MATH Lvl 5 Raw": 0.0483383685800604, "MATH Lvl 5": 4.833836858006042, "GPQA Raw": 0.285234899328859, "GPQA": 4.697986577181204, "MUSR Raw": 0.4159791666666666, "MUSR": 10.997395833333329, "MMLU-PRO Raw": 0.2974567819148936, "MMLU-PRO": 21.939642434988176, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-26T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "icefog72/IceCoffeeRP-7b"}, {"eval_name": "icefog72_IceDrinkByFrankensteinV3RP_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/icefog72/IceDrinkByFrankensteinV3RP\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">icefog72/IceDrinkByFrankensteinV3RP</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/icefog72__IceDrinkByFrankensteinV3RP-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "icefog72/IceDrinkByFrankensteinV3RP", "Model sha": "a4d2eb422867ea28860ad3b983b93bc97ca91719", "Average \u2b06\ufe0f": 19.780169462753747, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4974911013887596, "IFEval": 49.74911013887596, "BBH Raw": 0.4832523723413275, "BBH": 28.84588139816073, "MATH Lvl 5 Raw": 0.0490936555891238, "MATH Lvl 5": 4.909365558912387, "GPQA Raw": 0.261744966442953, "GPQA": 1.5659955257270708, "MUSR Raw": 0.4253125, "MUSR": 12.19739583333333, "MMLU-PRO Raw": 0.292719414893617, "MMLU-PRO": 21.413268321513, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-23T00:00:00", "Submission Date": "2024-10-03T00:00:00", "Generation": 0, "Base Model": "icefog72/IceDrinkByFrankensteinV3RP"}, {"eval_name": "icefog72_IceDrinkNameGoesHereRP-7b-Model_Stock_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/icefog72/IceDrinkNameGoesHereRP-7b-Model_Stock\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">icefog72/IceDrinkNameGoesHereRP-7b-Model_Stock</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/icefog72__IceDrinkNameGoesHereRP-7b-Model_Stock-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "icefog72/IceDrinkNameGoesHereRP-7b-Model_Stock", "Model sha": "78f7625f85c3cb150565ebb68c3f8d47d48325c8", "Average \u2b06\ufe0f": 18.568950180486038, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 2, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4968417133206558, "IFEval": 49.68417133206558, "BBH Raw": 0.4657864693892725, "BBH": 26.22465405632467, "MATH Lvl 5 Raw": 0.0354984894259818, "MATH Lvl 5": 3.5498489425981874, "GPQA Raw": 0.2684563758389262, "GPQA": 2.460850111856823, "MUSR Raw": 0.4067395833333334, "MUSR": 9.309114583333338, "MMLU-PRO Raw": 0.2816655585106383, "MMLU-PRO": 20.18506205673759, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-14T00:00:00", "Submission Date": "2024-09-24T00:00:00", "Generation": 0, "Base Model": "icefog72/IceDrinkNameGoesHereRP-7b-Model_Stock"}, {"eval_name": "icefog72_IceDrinkNameNotFoundRP-7b-Model_Stock_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/icefog72/IceDrinkNameNotFoundRP-7b-Model_Stock\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">icefog72/IceDrinkNameNotFoundRP-7b-Model_Stock</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/icefog72__IceDrinkNameNotFoundRP-7b-Model_Stock-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "icefog72/IceDrinkNameNotFoundRP-7b-Model_Stock", "Model sha": "35db2bf9e6812c5819378be68f94159e962fd1cb", "Average \u2b06\ufe0f": 21.318321186242603, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.5130032757527804, "IFEval": 51.30032757527805, "BBH Raw": 0.502625425089929, "BBH": 30.6682514458964, "MATH Lvl 5 Raw": 0.0566465256797583, "MATH Lvl 5": 5.664652567975831, "GPQA Raw": 0.2776845637583892, "GPQA": 3.691275167785232, "MUSR Raw": 0.4371875, "MUSR": 13.648437500000004, "MMLU-PRO Raw": 0.3064328457446808, "MMLU-PRO": 22.936982860520093, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-15T00:00:00", "Submission Date": "2024-09-15T00:00:00", "Generation": 0, "Base Model": "icefog72/IceDrinkNameNotFoundRP-7b-Model_Stock"}, {"eval_name": "icefog72_IceDrunkCherryRP-7b_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/icefog72/IceDrunkCherryRP-7b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">icefog72/IceDrunkCherryRP-7b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/icefog72__IceDrunkCherryRP-7b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "icefog72/IceDrunkCherryRP-7b", "Model sha": "160b01e50d9c9441886f6cf987a3495bd8fa1c49", "Average \u2b06\ufe0f": 20.22129039391333, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.489822559697159, "IFEval": 48.98225596971591, "BBH Raw": 0.4846629039263151, "BBH": 28.241090201205957, "MATH Lvl 5 Raw": 0.0581570996978852, "MATH Lvl 5": 5.81570996978852, "GPQA Raw": 0.2768456375838926, "GPQA": 3.5794183445190177, "MUSR Raw": 0.4291875, "MUSR": 12.381770833333336, "MMLU-PRO Raw": 0.3009474734042553, "MMLU-PRO": 22.32749704491725, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-24T00:00:00", "Submission Date": "2024-09-24T00:00:00", "Generation": 0, "Base Model": "icefog72/IceDrunkCherryRP-7b"}, {"eval_name": "icefog72_IceEspressoRPv2-7b_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/icefog72/IceEspressoRPv2-7b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">icefog72/IceEspressoRPv2-7b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/icefog72__IceEspressoRPv2-7b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "icefog72/IceEspressoRPv2-7b", "Model sha": "d71a4c2ae25c063fd4c3d3df039908c648a8bab4", "Average \u2b06\ufe0f": 21.25198343051117, "Hub License": null, "Hub \u2764\ufe0f": 1, "#Params (B)": 7, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4977160600539901, "IFEval": 49.77160600539901, "BBH Raw": 0.5054890156350785, "BBH": 31.303238558418094, "MATH Lvl 5 Raw": 0.0551359516616314, "MATH Lvl 5": 5.5135951661631415, "GPQA Raw": 0.2894295302013422, "GPQA": 5.257270693512303, "MUSR Raw": 0.4330624999999999, "MUSR": 12.766145833333336, "MMLU-PRO Raw": 0.3061003989361702, "MMLU-PRO": 22.90004432624113, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-11T00:00:00", "Submission Date": "2024-09-11T00:00:00", "Generation": 1, "Base Model": "icefog72/IceEspressoRPv2-7b (Merge)"}, {"eval_name": "icefog72_IceLemonTeaRP-32k-7b_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/icefog72/IceLemonTeaRP-32k-7b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">icefog72/IceLemonTeaRP-32k-7b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/icefog72__IceLemonTeaRP-32k-7b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "icefog72/IceLemonTeaRP-32k-7b", "Model sha": "7ea0bdf873c535b73ca20db46db0799bac433662", "Average \u2b06\ufe0f": 21.271730890439965, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 22, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.5212214701436633, "IFEval": 52.12214701436632, "BBH Raw": 0.499738524183793, "BBH": 30.135779642023177, "MATH Lvl 5 Raw": 0.0483383685800604, "MATH Lvl 5": 4.833836858006041, "GPQA Raw": 0.2902684563758389, "GPQA": 5.369127516778524, "MUSR Raw": 0.42903125, "MUSR": 12.195572916666668, "MMLU-PRO Raw": 0.3067652925531915, "MMLU-PRO": 22.973921394799056, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-03T00:00:00", "Submission Date": "2024-07-27T00:00:00", "Generation": 1, "Base Model": "icefog72/IceLemonTeaRP-32k-7b (Merge)"}, {"eval_name": "icefog72_IceMartiniRP-7b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/icefog72/IceMartiniRP-7b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">icefog72/IceMartiniRP-7b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/icefog72__IceMartiniRP-7b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "icefog72/IceMartiniRP-7b", "Model sha": "e5be38a55d2d9877fbb61cffc7f48402ac0193fc", "Average \u2b06\ufe0f": 21.10823835339298, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 2, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.5044603873278457, "IFEval": 50.446038732784565, "BBH Raw": 0.4972421837639585, "BBH": 29.685367916429147, "MATH Lvl 5 Raw": 0.0641993957703927, "MATH Lvl 5": 6.419939577039275, "GPQA Raw": 0.2793624161073825, "GPQA": 3.9149888143176734, "MUSR Raw": 0.4344895833333333, "MUSR": 13.144531250000004, "MMLU-PRO Raw": 0.3073470744680851, "MMLU-PRO": 23.038563829787236, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-24T00:00:00", "Submission Date": "2024-09-24T00:00:00", "Generation": 0, "Base Model": "icefog72/IceMartiniRP-7b"}, {"eval_name": "icefog72_IceSakeRP-7b_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/icefog72/IceSakeRP-7b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">icefog72/IceSakeRP-7b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/icefog72__IceSakeRP-7b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "icefog72/IceSakeRP-7b", "Model sha": "3b6b00bc48cd99e9b28e5aa8293dc987a0cf069a", "Average \u2b06\ufe0f": 21.47551954575211, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 13, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.5227950726295119, "IFEval": 52.27950726295119, "BBH Raw": 0.5119287057484642, "BBH": 31.6512550721568, "MATH Lvl 5 Raw": 0.0581570996978852, "MATH Lvl 5": 5.81570996978852, "GPQA Raw": 0.285234899328859, "GPQA": 4.697986577181204, "MUSR Raw": 0.413, "MUSR": 10.225, "MMLU-PRO Raw": 0.3176529255319149, "MMLU-PRO": 24.183658392434985, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-07T00:00:00", "Submission Date": "2024-08-22T00:00:00", "Generation": 1, "Base Model": "icefog72/IceSakeRP-7b (Merge)"}, {"eval_name": "icefog72_IceSakeV4RP-7b_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/icefog72/IceSakeV4RP-7b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">icefog72/IceSakeV4RP-7b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/icefog72__IceSakeV4RP-7b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "icefog72/IceSakeV4RP-7b", "Model sha": "e8cb50b78918149c7d1bf663bcb807e7bfac3eed", "Average \u2b06\ufe0f": 19.98931040665065, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4634192830578421, "IFEval": 46.34192830578421, "BBH Raw": 0.4929557826908731, "BBH": 29.234193217077536, "MATH Lvl 5 Raw": 0.0521148036253776, "MATH Lvl 5": 5.211480362537765, "GPQA Raw": 0.2944630872483221, "GPQA": 5.92841163310962, "MUSR Raw": 0.4081979166666666, "MUSR": 9.858072916666664, "MMLU-PRO Raw": 0.3102559840425531, "MMLU-PRO": 23.361776004728128, "Maintainer's Highlight": false, "Upload To Hub Date": "", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "Removed"}, {"eval_name": "icefog72_IceSakeV6RP-7b_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/icefog72/IceSakeV6RP-7b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">icefog72/IceSakeV6RP-7b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/icefog72__IceSakeV6RP-7b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "icefog72/IceSakeV6RP-7b", "Model sha": "6838e68d35d037b0ef9b04a9de1ebc8ab508cd45", "Average \u2b06\ufe0f": 21.1263494556244, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.5032613465604596, "IFEval": 50.32613465604596, "BBH Raw": 0.4976033636256635, "BBH": 30.391494717552195, "MATH Lvl 5 Raw": 0.0566465256797583, "MATH Lvl 5": 5.664652567975831, "GPQA Raw": 0.2911073825503356, "GPQA": 5.480984340044745, "MUSR Raw": 0.4200104166666666, "MUSR": 11.634635416666663, "MMLU-PRO Raw": 0.3093417553191489, "MMLU-PRO": 23.26019503546099, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-26T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "icefog72/IceSakeV6RP-7b"}, {"eval_name": "icefog72_IceSakeV8RP-7b_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/icefog72/IceSakeV8RP-7b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">icefog72/IceSakeV8RP-7b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/icefog72__IceSakeV8RP-7b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "icefog72/IceSakeV8RP-7b", "Model sha": "0f8f73fe356583e561479c689aa6597435327f4e", "Average \u2b06\ufe0f": 21.63913423083868, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6085741388404988, "IFEval": 60.85741388404988, "BBH Raw": 0.4884714133796017, "BBH": 28.966258233266576, "MATH Lvl 5 Raw": 0.0566465256797583, "MATH Lvl 5": 5.664652567975831, "GPQA Raw": 0.276006711409396, "GPQA": 3.467561521252797, "MUSR Raw": 0.3992708333333333, "MUSR": 8.542187500000004, "MMLU-PRO Raw": 0.301030585106383, "MMLU-PRO": 22.336731678486995, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-26T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "icefog72/IceSakeV8RP-7b"}, {"eval_name": "icefog72_IceTea21EnergyDrinkRPV13-DPOv3_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/icefog72/IceTea21EnergyDrinkRPV13-DPOv3\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">icefog72/IceTea21EnergyDrinkRPV13-DPOv3</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/icefog72__IceTea21EnergyDrinkRPV13-DPOv3-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "icefog72/IceTea21EnergyDrinkRPV13-DPOv3", "Model sha": "2d4b4fd596ff0f6706a5752198e59da6ffc08067", "Average \u2b06\ufe0f": 21.59614191020839, "Hub License": null, "Hub \u2764\ufe0f": 2, "#Params (B)": 7, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.5263423272472595, "IFEval": 52.63423272472595, "BBH Raw": 0.5019587584232624, "BBH": 30.6127340167025, "MATH Lvl 5 Raw": 0.0536253776435045, "MATH Lvl 5": 5.362537764350453, "GPQA Raw": 0.2835570469798658, "GPQA": 4.4742729306487705, "MUSR Raw": 0.4371875, "MUSR": 13.648437500000004, "MMLU-PRO Raw": 0.3056017287234042, "MMLU-PRO": 22.844636524822693, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-05T00:00:00", "Submission Date": "2024-09-06T00:00:00", "Generation": 1, "Base Model": "icefog72/IceTea21EnergyDrinkRPV13-DPOv3 (Merge)"}, {"eval_name": "icefog72_IceTea21EnergyDrinkRPV13-DPOv3.5_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/icefog72/IceTea21EnergyDrinkRPV13-DPOv3.5\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">icefog72/IceTea21EnergyDrinkRPV13-DPOv3.5</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/icefog72__IceTea21EnergyDrinkRPV13-DPOv3.5-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "icefog72/IceTea21EnergyDrinkRPV13-DPOv3.5", "Model sha": "0b0b0864347c3fad2b4d3e102f2f9839d20e296c", "Average \u2b06\ufe0f": 17.25844702519197, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.487099784128335, "IFEval": 48.70997841283351, "BBH Raw": 0.4399660013109026, "BBH": 22.57322577923665, "MATH Lvl 5 Raw": 0.0324773413897281, "MATH Lvl 5": 3.2477341389728096, "GPQA Raw": 0.2843959731543624, "GPQA": 4.586129753914992, "MUSR Raw": 0.3964166666666666, "MUSR": 7.78541666666667, "MMLU-PRO Raw": 0.2498337765957446, "MMLU-PRO": 16.648197399527188, "Maintainer's Highlight": false, "Upload To Hub Date": "", "Submission Date": "2024-09-25T00:00:00", "Generation": 0, "Base Model": "Removed"}, {"eval_name": "ifable_gemma-2-Ifable-9B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/ifable/gemma-2-Ifable-9B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">ifable/gemma-2-Ifable-9B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/ifable__gemma-2-Ifable-9B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "ifable/gemma-2-Ifable-9B", "Model sha": "d3dbde4efb93ea0a4f247de82541479de6b03160", "Average \u2b06\ufe0f": 22.725045037121493, "Hub License": "gemma", "Hub \u2764\ufe0f": 29, "#Params (B)": 9, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2984292787581395, "IFEval": 29.842927875813952, "BBH Raw": 0.5866115556693244, "BBH": 41.03264464626528, "MATH Lvl 5 Raw": 0.0891238670694864, "MATH Lvl 5": 8.91238670694864, "GPQA Raw": 0.3414429530201342, "GPQA": 12.192393736017896, "MUSR Raw": 0.40525, "MUSR": 8.522916666666669, "MMLU-PRO Raw": 0.4226230053191489, "MMLU-PRO": 35.847000591016545, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-10T00:00:00", "Submission Date": "2024-09-25T00:00:00", "Generation": 0, "Base Model": "ifable/gemma-2-Ifable-9B"}, {"eval_name": "informatiker_Qwen2-7B-Instruct-abliterated_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/informatiker/Qwen2-7B-Instruct-abliterated\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">informatiker/Qwen2-7B-Instruct-abliterated</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/informatiker__Qwen2-7B-Instruct-abliterated-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "informatiker/Qwen2-7B-Instruct-abliterated", "Model sha": "7577d60acfe4544d5ab303f0a4d69a9fcb9cf1aa", "Average \u2b06\ufe0f": 24.9957224453119, "Hub License": null, "Hub \u2764\ufe0f": 4, "#Params (B)": 7, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5821708622011817, "IFEval": 58.217086220118176, "BBH Raw": 0.5534265515936739, "BBH": 37.79572344136589, "MATH Lvl 5 Raw": 0.0838368580060422, "MATH Lvl 5": 8.38368580060423, "GPQA Raw": 0.3011744966442953, "GPQA": 6.823266219239373, "MUSR Raw": 0.3887916666666666, "MUSR": 6.83229166666667, "MMLU-PRO Raw": 0.3873005319148936, "MMLU-PRO": 31.922281323877066, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-10T00:00:00", "Submission Date": "2024-09-15T00:00:00", "Generation": 0, "Base Model": "informatiker/Qwen2-7B-Instruct-abliterated"}, {"eval_name": "instruction-pretrain_InstructLM-500M_float16", "Precision": "float16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/instruction-pretrain/InstructLM-500M\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">instruction-pretrain/InstructLM-500M</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/instruction-pretrain__InstructLM-500M-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "instruction-pretrain/InstructLM-500M", "Model sha": "e9d33823c76303dfaff6a8397a8b70d0118ea350", "Average \u2b06\ufe0f": 2.8543503197666724, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 34, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1027662158627996, "IFEval": 10.27662158627996, "BBH Raw": 0.2940871787252967, "BBH": 2.317053716048478, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2567114093959731, "GPQA": 0.8948545861297527, "MUSR Raw": 0.3528229166666667, "MUSR": 2.0695312500000003, "MMLU-PRO Raw": 0.1141123670212766, "MMLU-PRO": 1.5680407801418434, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-18T00:00:00", "Submission Date": "2024-06-27T00:00:00", "Generation": 0, "Base Model": "instruction-pretrain/InstructLM-500M"}, {"eval_name": "internlm_internlm2-1_8b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "InternLM2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/internlm/internlm2-1_8b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">internlm/internlm2-1_8b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/internlm__internlm2-1_8b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "internlm/internlm2-1_8b", "Model sha": "c24f301c7374ad9f9b58d1ea80f68b5f57cbca13", "Average \u2b06\ufe0f": 8.58448433464234, "Hub License": "other", "Hub \u2764\ufe0f": 28, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2197702097102355, "IFEval": 21.97702097102355, "BBH Raw": 0.3879732800028095, "BBH": 13.63385796590672, "MATH Lvl 5 Raw": 0.0113293051359516, "MATH Lvl 5": 1.1329305135951662, "GPQA Raw": 0.2483221476510067, "GPQA": 0.0, "MUSR Raw": 0.38128125, "MUSR": 8.226822916666668, "MMLU-PRO Raw": 0.1588264627659574, "MMLU-PRO": 6.536273640661936, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-01-30T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "internlm/internlm2-1_8b"}, {"eval_name": "internlm_internlm2-chat-1_8b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "InternLM2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/internlm/internlm2-chat-1_8b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">internlm/internlm2-chat-1_8b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/internlm__internlm2-chat-1_8b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "internlm/internlm2-chat-1_8b", "Model sha": "4e226eeb354499f4d34ef4c27f6939f377475cc1", "Average \u2b06\ufe0f": 10.50333116724414, "Hub License": "other", "Hub \u2764\ufe0f": 29, "#Params (B)": 1, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2386545477111841, "IFEval": 23.865454771118408, "BBH Raw": 0.4452271664119214, "BBH": 20.67235743256185, "MATH Lvl 5 Raw": 0.0241691842900302, "MATH Lvl 5": 2.416918429003021, "GPQA Raw": 0.2659395973154362, "GPQA": 2.1252796420581683, "MUSR Raw": 0.3630520833333333, "MUSR": 4.61484375, "MMLU-PRO Raw": 0.1839261968085106, "MMLU-PRO": 9.325132978723405, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-01-30T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "internlm/internlm2-chat-1_8b"}, {"eval_name": "internlm_internlm2_5-1_8b-chat_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "InternLM2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/internlm/internlm2_5-1_8b-chat\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">internlm/internlm2_5-1_8b-chat</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/internlm__internlm2_5-1_8b-chat-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "internlm/internlm2_5-1_8b-chat", "Model sha": "4426f00b854561fa60d555d2b628064b56bcb758", "Average \u2b06\ufe0f": 12.106337611274624, "Hub License": "other", "Hub \u2764\ufe0f": 21, "#Params (B)": 1, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3849087088924054, "IFEval": 38.49087088924056, "BBH Raw": 0.4488926786996439, "BBH": 21.03092693656956, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2902684563758389, "GPQA": 5.369127516778524, "MUSR Raw": 0.3593958333333333, "MUSR": 4.424479166666669, "MMLU-PRO Raw": 0.1299035904255319, "MMLU-PRO": 3.322621158392436, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-07-30T00:00:00", "Submission Date": "2024-08-07T00:00:00", "Generation": 0, "Base Model": "internlm/internlm2_5-1_8b-chat"}, {"eval_name": "internlm_internlm2_5-20b-chat_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "InternLM2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/internlm/internlm2_5-20b-chat\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">internlm/internlm2_5-20b-chat</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/internlm__internlm2_5-20b-chat-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "internlm/internlm2_5-20b-chat", "Model sha": "ef17bde929761255fee76d95e2c25969ccd93b0d", "Average \u2b06\ufe0f": 32.08201273924976, "Hub License": "other", "Hub \u2764\ufe0f": 82, "#Params (B)": 19, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7009977969565198, "IFEval": 70.09977969565199, "BBH Raw": 0.7473580533672884, "BBH": 62.83245915287989, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.3213087248322148, "GPQA": 9.50782997762864, "MUSR Raw": 0.4558229166666667, "MUSR": 16.744531249999994, "MMLU-PRO Raw": 0.3997672872340425, "MMLU-PRO": 33.30747635933806, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-07-30T00:00:00", "Submission Date": "2024-08-12T00:00:00", "Generation": 0, "Base Model": "internlm/internlm2_5-20b-chat"}, {"eval_name": "internlm_internlm2_5-7b-chat_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "InternLM2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/internlm/internlm2_5-7b-chat\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">internlm/internlm2_5-7b-chat</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/internlm__internlm2_5-7b-chat-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "internlm/internlm2_5-7b-chat", "Model sha": "bebb00121ee105b823647c3ba2b1e152652edc33", "Average \u2b06\ufe0f": 30.463562511466677, "Hub License": "other", "Hub \u2764\ufe0f": 164, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6140196899781469, "IFEval": 61.40196899781469, "BBH Raw": 0.710773697280275, "BBH": 57.67364804232054, "MATH Lvl 5 Raw": 0.0830815709969788, "MATH Lvl 5": 8.308157099697885, "GPQA Raw": 0.3296979865771812, "GPQA": 10.626398210290828, "MUSR Raw": 0.4415, "MUSR": 14.35416666666667, "MMLU-PRO Raw": 0.3737533244680851, "MMLU-PRO": 30.41703605200945, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-06-27T00:00:00", "Submission Date": "2024-07-03T00:00:00", "Generation": 0, "Base Model": "internlm/internlm2_5-7b-chat"}, {"eval_name": "intervitens_mini-magnum-12b-v1.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/intervitens/mini-magnum-12b-v1.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">intervitens/mini-magnum-12b-v1.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/intervitens__mini-magnum-12b-v1.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "intervitens/mini-magnum-12b-v1.1", "Model sha": "3b19e12711d3f4d9b81fdeb73860e9019ebe2404", "Average \u2b06\ufe0f": 20.61332730985801, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 70, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5155509603407846, "IFEval": 51.55509603407847, "BBH Raw": 0.506180035650624, "BBH": 29.731186868686876, "MATH Lvl 5 Raw": 0.0370090634441087, "MATH Lvl 5": 3.700906344410876, "GPQA Raw": 0.2885906040268456, "GPQA": 5.145413870246088, "MUSR Raw": 0.4004479166666666, "MUSR": 8.089322916666669, "MMLU-PRO Raw": 0.3291223404255319, "MMLU-PRO": 25.458037825059098, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-24T00:00:00", "Submission Date": "2024-07-25T00:00:00", "Generation": 0, "Base Model": "intervitens/mini-magnum-12b-v1.1"}, {"eval_name": "invalid-coder_Sakura-SOLAR-Instruct-CarbonVillain-en-10.7B-v2-slerp_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/invalid-coder/Sakura-SOLAR-Instruct-CarbonVillain-en-10.7B-v2-slerp\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">invalid-coder/Sakura-SOLAR-Instruct-CarbonVillain-en-10.7B-v2-slerp</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/invalid-coder__Sakura-SOLAR-Instruct-CarbonVillain-en-10.7B-v2-slerp-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "invalid-coder/Sakura-SOLAR-Instruct-CarbonVillain-en-10.7B-v2-slerp", "Model sha": "39a1c76ddb5fa3a82c5b4071121d2e4866a25300", "Average \u2b06\ufe0f": 19.52985136315749, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 10, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4554759150166003, "IFEval": 45.54759150166004, "BBH Raw": 0.5158439010792586, "BBH": 31.635374808026484, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.3053691275167785, "GPQA": 7.38255033557047, "MUSR Raw": 0.3992395833333333, "MUSR": 8.77161458333333, "MMLU-PRO Raw": 0.3145777925531915, "MMLU-PRO": 23.841976950354614, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-01-10T00:00:00", "Submission Date": "2024-07-25T00:00:00", "Generation": 0, "Base Model": "invalid-coder/Sakura-SOLAR-Instruct-CarbonVillain-en-10.7B-v2-slerp"}, {"eval_name": "invisietch_EtherealRainbow-v0.2-8B_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/invisietch/EtherealRainbow-v0.2-8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">invisietch/EtherealRainbow-v0.2-8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/invisietch__EtherealRainbow-v0.2-8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "invisietch/EtherealRainbow-v0.2-8B", "Model sha": "46611fbb6aac0f33478c8401488d3ec7763c04d0", "Average \u2b06\ufe0f": 19.993283588027733, "Hub License": "llama3", "Hub \u2764\ufe0f": 5, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3903298802732305, "IFEval": 39.03298802732306, "BBH Raw": 0.5102035205059678, "BBH": 30.28379136654109, "MATH Lvl 5 Raw": 0.0755287009063444, "MATH Lvl 5": 7.552870090634441, "GPQA Raw": 0.3028523489932886, "GPQA": 7.046979865771815, "MUSR Raw": 0.3826770833333333, "MUSR": 6.56796875, "MMLU-PRO Raw": 0.3652759308510638, "MMLU-PRO": 29.47510342789598, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-12T00:00:00", "Submission Date": "2024-07-01T00:00:00", "Generation": 0, "Base Model": "invisietch/EtherealRainbow-v0.2-8B"}, {"eval_name": "invisietch_EtherealRainbow-v0.3-8B_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/invisietch/EtherealRainbow-v0.3-8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">invisietch/EtherealRainbow-v0.3-8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/invisietch__EtherealRainbow-v0.3-8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "invisietch/EtherealRainbow-v0.3-8B", "Model sha": "c986c4ca5a5b8474820a59d3e911a431cf26938d", "Average \u2b06\ufe0f": 19.61499802035235, "Hub License": "llama3", "Hub \u2764\ufe0f": 10, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3682229816885862, "IFEval": 36.82229816885863, "BBH Raw": 0.5096758454539693, "BBH": 30.080258475101616, "MATH Lvl 5 Raw": 0.0657099697885196, "MATH Lvl 5": 6.570996978851963, "GPQA Raw": 0.3045302013422818, "GPQA": 7.270693512304249, "MUSR Raw": 0.3903958333333333, "MUSR": 7.766145833333333, "MMLU-PRO Raw": 0.3626163563829787, "MMLU-PRO": 29.179595153664305, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-19T00:00:00", "Submission Date": "2024-07-01T00:00:00", "Generation": 0, "Base Model": "invisietch/EtherealRainbow-v0.3-8B"}, {"eval_name": "invisietch_Nimbus-Miqu-v0.1-70B_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/invisietch/Nimbus-Miqu-v0.1-70B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">invisietch/Nimbus-Miqu-v0.1-70B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/invisietch__Nimbus-Miqu-v0.1-70B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "invisietch/Nimbus-Miqu-v0.1-70B", "Model sha": "3209583a0849383daf8faa7b819f29726b8806cf", "Average \u2b06\ufe0f": 24.70734722039385, "Hub License": "unknown", "Hub \u2764\ufe0f": 19, "#Params (B)": 68, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4646681915096388, "IFEval": 46.466819150963886, "BBH Raw": 0.601030667794844, "BBH": 43.4509951550532, "MATH Lvl 5 Raw": 0.0543806646525679, "MATH Lvl 5": 5.438066465256798, "GPQA Raw": 0.3389261744966443, "GPQA": 11.85682326621924, "MUSR Raw": 0.4133124999999999, "MUSR": 9.330729166666666, "MMLU-PRO Raw": 0.3853058510638298, "MMLU-PRO": 31.700650118203303, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-30T00:00:00", "Submission Date": "2024-07-03T00:00:00", "Generation": 0, "Base Model": "invisietch/Nimbus-Miqu-v0.1-70B"}, {"eval_name": "jaredjoss_pythia-410m-roberta-lr_8e7-kl_01-steps_12000-rlhf-model_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "GPTNeoXForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/jaredjoss/pythia-410m-roberta-lr_8e7-kl_01-steps_12000-rlhf-model\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">jaredjoss/pythia-410m-roberta-lr_8e7-kl_01-steps_12000-rlhf-model</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/jaredjoss__pythia-410m-roberta-lr_8e7-kl_01-steps_12000-rlhf-model-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "jaredjoss/pythia-410m-roberta-lr_8e7-kl_01-steps_12000-rlhf-model", "Model sha": "048bc8edfc32fdcf6d957332d5f4c0d4e5950746", "Average \u2b06\ufe0f": 3.81661033477558, "Hub License": "mit", "Hub \u2764\ufe0f": 0, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.1572217272392806, "IFEval": 15.722172723928066, "BBH Raw": 0.2863444769655102, "BBH": 1.8203742908537424, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.259228187919463, "GPQA": 1.230425055928408, "MUSR Raw": 0.3606979166666667, "MUSR": 2.2539062500000013, "MMLU-PRO Raw": 0.1168550531914893, "MMLU-PRO": 1.8727836879432624, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-23T00:00:00", "Submission Date": "2024-08-06T00:00:00", "Generation": 0, "Base Model": "jaredjoss/pythia-410m-roberta-lr_8e7-kl_01-steps_12000-rlhf-model"}, {"eval_name": "jebcarter_psyonic-cetacean-20B_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/jebcarter/psyonic-cetacean-20B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">jebcarter/psyonic-cetacean-20B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/jebcarter__psyonic-cetacean-20B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "jebcarter/psyonic-cetacean-20B", "Model sha": "298d2086a949d53af06096d229f64f4719261698", "Average \u2b06\ufe0f": 15.87378945287145, "Hub License": "other", "Hub \u2764\ufe0f": 38, "#Params (B)": 19, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2543661928128476, "IFEval": 25.43661928128477, "BBH Raw": 0.4907386156835858, "BBH": 27.843060379681305, "MATH Lvl 5 Raw": 0.0098187311178247, "MATH Lvl 5": 0.9818731117824772, "GPQA Raw": 0.273489932885906, "GPQA": 3.1319910514541416, "MUSR Raw": 0.4661145833333333, "MUSR": 16.897656249999997, "MMLU-PRO Raw": 0.288563829787234, "MMLU-PRO": 20.951536643026003, "Maintainer's Highlight": false, "Upload To Hub Date": "2023-11-28T00:00:00", "Submission Date": "2024-06-30T00:00:00", "Generation": 0, "Base Model": "jebcarter/psyonic-cetacean-20B"}, {"eval_name": "jeonsworld_CarbonVillain-en-10.7B-v4_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/jeonsworld/CarbonVillain-en-10.7B-v4\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">jeonsworld/CarbonVillain-en-10.7B-v4</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/jeonsworld__CarbonVillain-en-10.7B-v4-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "jeonsworld/CarbonVillain-en-10.7B-v4", "Model sha": "57d6ad4d705d336aba228356683d9f221507440a", "Average \u2b06\ufe0f": 19.548213143143965, "Hub License": "cc-by-nc-sa-4.0", "Hub \u2764\ufe0f": 6, "#Params (B)": 10, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4579238642357832, "IFEval": 45.79238642357833, "BBH Raw": 0.516795955873779, "BBH": 31.80563982727619, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.3062080536912752, "GPQA": 7.494407158836691, "MUSR Raw": 0.3965416666666666, "MUSR": 8.401041666666663, "MMLU-PRO Raw": 0.3141622340425531, "MMLU-PRO": 23.795803782505907, "Maintainer's Highlight": false, "Upload To Hub Date": "2023-12-30T00:00:00", "Submission Date": "2024-07-25T00:00:00", "Generation": 0, "Base Model": "jeonsworld/CarbonVillain-en-10.7B-v4"}, {"eval_name": "jieliu_Storm-7B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/jieliu/Storm-7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">jieliu/Storm-7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/jieliu__Storm-7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "jieliu/Storm-7B", "Model sha": "71edab8ee6c2578e428b0359158fb0d43133e989", "Average \u2b06\ufe0f": 19.738701601480617, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 40, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3424192254329623, "IFEval": 34.24192254329623, "BBH Raw": 0.5187285371254579, "BBH": 32.33028437916087, "MATH Lvl 5 Raw": 0.059667673716012, "MATH Lvl 5": 5.966767371601208, "GPQA Raw": 0.3078859060402684, "GPQA": 7.718120805369126, "MUSR Raw": 0.4428958333333333, "MUSR": 14.628645833333332, "MMLU-PRO Raw": 0.3119182180851064, "MMLU-PRO": 23.54646867612293, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-25T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 2, "Base Model": "mistralai/Mistral-7B-v0.1"}, {"eval_name": "johnsutor_Llama-3-8B-Instruct_breadcrumbs-density-0.1-gamma-0.01_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.1-gamma-0.01\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.1-gamma-0.01</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/johnsutor__Llama-3-8B-Instruct_breadcrumbs-density-0.1-gamma-0.01-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.1-gamma-0.01", "Model sha": "f4ebbf27d586e94c63f0a7293f565cbd947b824f", "Average \u2b06\ufe0f": 22.303657517146046, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4271244741729721, "IFEval": 42.71244741729721, "BBH Raw": 0.5035519809362171, "BBH": 29.55001380445773, "MATH Lvl 5 Raw": 0.0370090634441087, "MATH Lvl 5": 3.700906344410876, "GPQA Raw": 0.3221476510067114, "GPQA": 9.61968680089485, "MUSR Raw": 0.4637604166666667, "MUSR": 17.80338541666666, "MMLU-PRO Raw": 0.3739195478723404, "MMLU-PRO": 30.43550531914893, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-07T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.1-gamma-0.01 (Merge)"}, {"eval_name": "johnsutor_Llama-3-8B-Instruct_breadcrumbs-density-0.1-gamma-0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.1-gamma-0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.1-gamma-0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/johnsutor__Llama-3-8B-Instruct_breadcrumbs-density-0.1-gamma-0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.1-gamma-0.1", "Model sha": "66c7330e9d04b13a68ea7dcf25bc0a71d144221a", "Average \u2b06\ufe0f": 21.257534199974774, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.425325913021893, "IFEval": 42.5325913021893, "BBH Raw": 0.5018845446835877, "BBH": 28.607718394442788, "MATH Lvl 5 Raw": 0.0853474320241691, "MATH Lvl 5": 8.534743202416918, "GPQA Raw": 0.3011744966442953, "GPQA": 6.823266219239373, "MUSR Raw": 0.4150208333333333, "MUSR": 10.777604166666672, "MMLU-PRO Raw": 0.3724235372340425, "MMLU-PRO": 30.26928191489361, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-07T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.1-gamma-0.1 (Merge)"}, {"eval_name": "johnsutor_Llama-3-8B-Instruct_breadcrumbs-density-0.3-gamma-0.01_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.3-gamma-0.01\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.3-gamma-0.01</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/johnsutor__Llama-3-8B-Instruct_breadcrumbs-density-0.3-gamma-0.01-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.3-gamma-0.01", "Model sha": "4a432be239528ffc654955338982f1f32eb12901", "Average \u2b06\ufe0f": 20.10354213601356, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.337748285659827, "IFEval": 33.7748285659827, "BBH Raw": 0.4917135045463188, "BBH": 28.135682301211705, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.3120805369127516, "GPQA": 8.277404921700223, "MUSR Raw": 0.5017708333333334, "MUSR": 22.28802083333333, "MMLU-PRO Raw": 0.3533078457446808, "MMLU-PRO": 28.14531619385342, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-07T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.3-gamma-0.01 (Merge)"}, {"eval_name": "johnsutor_Llama-3-8B-Instruct_breadcrumbs-density-0.3-gamma-0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.3-gamma-0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.3-gamma-0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/johnsutor__Llama-3-8B-Instruct_breadcrumbs-density-0.3-gamma-0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.3-gamma-0.1", "Model sha": "d6f8ed8dc4b7f74b4312bc0d24aaac275c61958d", "Average \u2b06\ufe0f": 21.656986893569663, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4273993005226133, "IFEval": 42.73993005226133, "BBH Raw": 0.5125777877188348, "BBH": 30.51494334374904, "MATH Lvl 5 Raw": 0.0702416918429003, "MATH Lvl 5": 7.02416918429003, "GPQA Raw": 0.3087248322147651, "GPQA": 7.829977628635347, "MUSR Raw": 0.4226458333333333, "MUSR": 11.397395833333336, "MMLU-PRO Raw": 0.3739195478723404, "MMLU-PRO": 30.43550531914893, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-07T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.3-gamma-0.1 (Merge)"}, {"eval_name": "johnsutor_Llama-3-8B-Instruct_breadcrumbs-density-0.5-gamma-0.01_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.5-gamma-0.01\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.5-gamma-0.01</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/johnsutor__Llama-3-8B-Instruct_breadcrumbs-density-0.5-gamma-0.01-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.5-gamma-0.01", "Model sha": "6ab1392c825907b08eff8fbed4c97a3e6e0d6dd9", "Average \u2b06\ufe0f": 19.38459094574601, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3203621945327287, "IFEval": 32.03621945327288, "BBH Raw": 0.4883576392175519, "BBH": 27.665794638508448, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.3020134228187919, "GPQA": 6.935123042505594, "MUSR Raw": 0.5097708333333334, "MUSR": 23.621354166666677, "MMLU-PRO Raw": 0.3344414893617021, "MMLU-PRO": 26.049054373522463, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-07T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.5-gamma-0.01 (Merge)"}, {"eval_name": "johnsutor_Llama-3-8B-Instruct_breadcrumbs-density-0.5-gamma-0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.5-gamma-0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.5-gamma-0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/johnsutor__Llama-3-8B-Instruct_breadcrumbs-density-0.5-gamma-0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.5-gamma-0.1", "Model sha": "a481edaceeaab34f4dc0e90c4d8ec0f72658bbdd", "Average \u2b06\ufe0f": 22.18232353793985, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4396390466185277, "IFEval": 43.96390466185278, "BBH Raw": 0.5140041302485145, "BBH": 30.854731427683628, "MATH Lvl 5 Raw": 0.0687311178247734, "MATH Lvl 5": 6.873111782477341, "GPQA Raw": 0.3070469798657718, "GPQA": 7.606263982102905, "MUSR Raw": 0.4397916666666666, "MUSR": 13.840625, "MMLU-PRO Raw": 0.3695977393617021, "MMLU-PRO": 29.955304373522463, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-08T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.5-gamma-0.1 (Merge)"}, {"eval_name": "johnsutor_Llama-3-8B-Instruct_breadcrumbs-density-0.7-gamma-0.01_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.7-gamma-0.01\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.7-gamma-0.01</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/johnsutor__Llama-3-8B-Instruct_breadcrumbs-density-0.7-gamma-0.01-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.7-gamma-0.01", "Model sha": "61f4b44fb917cdb46f0ade9f8fc2a382e0cf67af", "Average \u2b06\ufe0f": 18.442433340954477, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2814443454478561, "IFEval": 28.14443454478561, "BBH Raw": 0.4854325756272537, "BBH": 27.16443115792157, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2902684563758389, "GPQA": 5.369127516778524, "MUSR Raw": 0.5163125000000001, "MUSR": 24.472395833333337, "MMLU-PRO Raw": 0.3295378989361702, "MMLU-PRO": 25.5042109929078, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-08T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.7-gamma-0.01 (Merge)"}, {"eval_name": "johnsutor_Llama-3-8B-Instruct_breadcrumbs-density-0.7-gamma-0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.7-gamma-0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.7-gamma-0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/johnsutor__Llama-3-8B-Instruct_breadcrumbs-density-0.7-gamma-0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.7-gamma-0.1", "Model sha": "139a9bccd0ffb284e670a181a5986a01b1420c6c", "Average \u2b06\ufe0f": 21.73498155878561, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4302218114602588, "IFEval": 43.02218114602588, "BBH Raw": 0.5157097379648965, "BBH": 31.163507714744892, "MATH Lvl 5 Raw": 0.0604229607250755, "MATH Lvl 5": 6.042296072507553, "GPQA Raw": 0.3078859060402684, "GPQA": 7.718120805369126, "MUSR Raw": 0.4331562499999999, "MUSR": 12.877864583333336, "MMLU-PRO Raw": 0.3662732712765957, "MMLU-PRO": 29.58591903073286, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-08T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.7-gamma-0.1 (Merge)"}, {"eval_name": "johnsutor_Llama-3-8B-Instruct_breadcrumbs-density-0.9-gamma-0.01_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.9-gamma-0.01\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.9-gamma-0.01</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/johnsutor__Llama-3-8B-Instruct_breadcrumbs-density-0.9-gamma-0.01-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.9-gamma-0.01", "Model sha": "c88c6b65f751156e7bc04c738947387eb55747e9", "Average \u2b06\ufe0f": 18.48361346373348, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2789963962286732, "IFEval": 27.899639622867326, "BBH Raw": 0.4861153522934073, "BBH": 27.22486881424896, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2944630872483221, "GPQA": 5.92841163310962, "MUSR Raw": 0.5150104166666667, "MUSR": 24.242968750000003, "MMLU-PRO Raw": 0.3304521276595745, "MMLU-PRO": 25.60579196217494, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-08T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.9-gamma-0.01 (Merge)"}, {"eval_name": "johnsutor_Llama-3-8B-Instruct_breadcrumbs-density-0.9-gamma-0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.9-gamma-0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.9-gamma-0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/johnsutor__Llama-3-8B-Instruct_breadcrumbs-density-0.9-gamma-0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.9-gamma-0.1", "Model sha": "818f7e586444b551200862fb234c39bd48d69ae8", "Average \u2b06\ufe0f": 21.818372837189184, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4222784434190171, "IFEval": 42.22784434190171, "BBH Raw": 0.5153764046315631, "BBH": 31.124765884679533, "MATH Lvl 5 Raw": 0.0672205438066465, "MATH Lvl 5": 6.722054380664652, "GPQA Raw": 0.3078859060402684, "GPQA": 7.718120805369126, "MUSR Raw": 0.4384270833333333, "MUSR": 13.670052083333337, "MMLU-PRO Raw": 0.3650265957446808, "MMLU-PRO": 29.44739952718675, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-08T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "johnsutor/Llama-3-8B-Instruct_breadcrumbs-density-0.9-gamma-0.1 (Merge)"}, {"eval_name": "johnsutor_Llama-3-8B-Instruct_breadcrumbs_ties-density-0.1-gamma-0.01_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.1-gamma-0.01\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.1-gamma-0.01</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/johnsutor__Llama-3-8B-Instruct_breadcrumbs_ties-density-0.1-gamma-0.01-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.1-gamma-0.01", "Model sha": "861347cd643d396877d8e560367cf0717c671228", "Average \u2b06\ufe0f": 22.086113080493604, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4358923212631374, "IFEval": 43.58923212631373, "BBH Raw": 0.5040935986635269, "BBH": 29.53001282071684, "MATH Lvl 5 Raw": 0.0430513595166163, "MATH Lvl 5": 4.305135951661631, "GPQA Raw": 0.3104026845637584, "GPQA": 8.05369127516779, "MUSR Raw": 0.45315625, "MUSR": 16.344531249999992, "MMLU-PRO Raw": 0.3762466755319149, "MMLU-PRO": 30.69407505910165, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-07T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.1-gamma-0.01 (Merge)"}, {"eval_name": "johnsutor_Llama-3-8B-Instruct_breadcrumbs_ties-density-0.1-gamma-0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.1-gamma-0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.1-gamma-0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/johnsutor__Llama-3-8B-Instruct_breadcrumbs_ties-density-0.1-gamma-0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.1-gamma-0.1", "Model sha": "2647bc863e6ee686e7174366107eecbd4b37f62e", "Average \u2b06\ufe0f": 21.139756611660303, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4201551882338861, "IFEval": 42.01551882338861, "BBH Raw": 0.501124270710985, "BBH": 28.504906370089667, "MATH Lvl 5 Raw": 0.0883685800604229, "MATH Lvl 5": 8.836858006042297, "GPQA Raw": 0.3003355704697986, "GPQA": 6.711409395973152, "MUSR Raw": 0.4150208333333333, "MUSR": 10.777604166666672, "MMLU-PRO Raw": 0.3699301861702128, "MMLU-PRO": 29.99224290780142, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-07T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.1-gamma-0.1 (Merge)"}, {"eval_name": "johnsutor_Llama-3-8B-Instruct_breadcrumbs_ties-density-0.3-gamma-0.01_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.3-gamma-0.01\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.3-gamma-0.01</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/johnsutor__Llama-3-8B-Instruct_breadcrumbs_ties-density-0.3-gamma-0.01-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.3-gamma-0.01", "Model sha": "fa77530fe3723d7b15b06b88c3ca6110a8421742", "Average \u2b06\ufe0f": 20.385162516827837, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3517865929068205, "IFEval": 35.178659290682056, "BBH Raw": 0.4998521758431218, "BBH": 29.136918888444114, "MATH Lvl 5 Raw": 0.0113293051359516, "MATH Lvl 5": 1.1329305135951662, "GPQA Raw": 0.3062080536912752, "GPQA": 7.494407158836691, "MUSR Raw": 0.4871041666666666, "MUSR": 20.3546875, "MMLU-PRO Raw": 0.3611203457446808, "MMLU-PRO": 29.01337174940898, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-07T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.3-gamma-0.01 (Merge)"}, {"eval_name": "johnsutor_Llama-3-8B-Instruct_breadcrumbs_ties-density-0.3-gamma-0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.3-gamma-0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.3-gamma-0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/johnsutor__Llama-3-8B-Instruct_breadcrumbs_ties-density-0.3-gamma-0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.3-gamma-0.1", "Model sha": "6fe73aa7f9c5b59297739166e9557089d39e5fc7", "Average \u2b06\ufe0f": 21.59772062138564, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4203801468991165, "IFEval": 42.03801468991166, "BBH Raw": 0.5107301269172088, "BBH": 30.244175919150702, "MATH Lvl 5 Raw": 0.080060422960725, "MATH Lvl 5": 8.006042296072508, "GPQA Raw": 0.3045302013422818, "GPQA": 7.270693512304249, "MUSR Raw": 0.4278541666666666, "MUSR": 11.915104166666673, "MMLU-PRO Raw": 0.3710106382978723, "MMLU-PRO": 30.112293144208035, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-07T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.3-gamma-0.1 (Merge)"}, {"eval_name": "johnsutor_Llama-3-8B-Instruct_breadcrumbs_ties-density-0.5-gamma-0.01_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.5-gamma-0.01\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.5-gamma-0.01</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/johnsutor__Llama-3-8B-Instruct_breadcrumbs_ties-density-0.5-gamma-0.01-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.5-gamma-0.01", "Model sha": "a31f86b538ba8b2983620cc27a741bc9a81a7e2f", "Average \u2b06\ufe0f": 20.06151914018542, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3454168273514275, "IFEval": 34.54168273514276, "BBH Raw": 0.4983827321097329, "BBH": 29.32060751365874, "MATH Lvl 5 Raw": 0.0105740181268882, "MATH Lvl 5": 1.0574018126888218, "GPQA Raw": 0.296979865771812, "GPQA": 6.263982102908276, "MUSR Raw": 0.4911354166666666, "MUSR": 21.05859375, "MMLU-PRO Raw": 0.3531416223404255, "MMLU-PRO": 28.126846926713934, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-07T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.5-gamma-0.01 (Merge)"}, {"eval_name": "johnsutor_Llama-3-8B-Instruct_breadcrumbs_ties-density-0.5-gamma-0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.5-gamma-0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.5-gamma-0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/johnsutor__Llama-3-8B-Instruct_breadcrumbs_ties-density-0.5-gamma-0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.5-gamma-0.1", "Model sha": "f9d5bab1c1d0d6890e89b513225d13f68a1c6d75", "Average \u2b06\ufe0f": 21.24082140874051, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4091643505897684, "IFEval": 40.916435058976845, "BBH Raw": 0.513665952913411, "BBH": 30.69307747198892, "MATH Lvl 5 Raw": 0.0687311178247734, "MATH Lvl 5": 6.873111782477341, "GPQA Raw": 0.2953020134228188, "GPQA": 6.040268456375841, "MUSR Raw": 0.4356979166666666, "MUSR": 13.262239583333336, "MMLU-PRO Raw": 0.366938164893617, "MMLU-PRO": 29.659796099290777, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-07T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.5-gamma-0.1 (Merge)"}, {"eval_name": "johnsutor_Llama-3-8B-Instruct_breadcrumbs_ties-density-0.7-gamma-0.01_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.7-gamma-0.01\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.7-gamma-0.01</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/johnsutor__Llama-3-8B-Instruct_breadcrumbs_ties-density-0.7-gamma-0.01-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.7-gamma-0.01", "Model sha": "d30c75506feaec957dc73bc5c040159c310ecf4c", "Average \u2b06\ufe0f": 19.137024064405164, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2903872835188411, "IFEval": 29.03872835188411, "BBH Raw": 0.4967337534367295, "BBH": 28.739266057268598, "MATH Lvl 5 Raw": 0.0052870090634441, "MATH Lvl 5": 0.5287009063444109, "GPQA Raw": 0.299496644295302, "GPQA": 6.599552572706939, "MUSR Raw": 0.4990729166666667, "MUSR": 22.250781249999992, "MMLU-PRO Raw": 0.3489860372340425, "MMLU-PRO": 27.665115248226947, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-07T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.7-gamma-0.01 (Merge)"}, {"eval_name": "johnsutor_Llama-3-8B-Instruct_breadcrumbs_ties-density-0.7-gamma-0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.7-gamma-0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.7-gamma-0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/johnsutor__Llama-3-8B-Instruct_breadcrumbs_ties-density-0.7-gamma-0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.7-gamma-0.1", "Model sha": "cd52bafe64e82d466d0bc590da5399f2299d24e1", "Average \u2b06\ufe0f": 21.463241989676813, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4198803618842449, "IFEval": 41.98803618842449, "BBH Raw": 0.5146905664948336, "BBH": 31.007758447741608, "MATH Lvl 5 Raw": 0.0709969788519637, "MATH Lvl 5": 7.099697885196375, "GPQA Raw": 0.2986577181208054, "GPQA": 6.487695749440718, "MUSR Raw": 0.4357604166666666, "MUSR": 13.136718750000002, "MMLU-PRO Raw": 0.3615359042553192, "MMLU-PRO": 29.05954491725768, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-07T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.7-gamma-0.1 (Merge)"}, {"eval_name": "johnsutor_Llama-3-8B-Instruct_breadcrumbs_ties-density-0.9-gamma-0.01_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.9-gamma-0.01\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.9-gamma-0.01</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/johnsutor__Llama-3-8B-Instruct_breadcrumbs_ties-density-0.9-gamma-0.01-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.9-gamma-0.01", "Model sha": "4c30fdbe0708afefe50788ea640c3dfab294c77f", "Average \u2b06\ufe0f": 18.884376758560723, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.291311497936586, "IFEval": 29.131149793658604, "BBH Raw": 0.4918296438476883, "BBH": 28.219373273671145, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.3003355704697986, "GPQA": 6.711409395973152, "MUSR Raw": 0.4976770833333333, "MUSR": 21.976302083333326, "MMLU-PRO Raw": 0.3454122340425531, "MMLU-PRO": 27.268026004728128, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-07T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.9-gamma-0.01 (Merge)"}, {"eval_name": "johnsutor_Llama-3-8B-Instruct_breadcrumbs_ties-density-0.9-gamma-0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.9-gamma-0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.9-gamma-0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/johnsutor__Llama-3-8B-Instruct_breadcrumbs_ties-density-0.9-gamma-0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.9-gamma-0.1", "Model sha": "378a7cad3e34a1a8b11e77edd95b02ff0d228da2", "Average \u2b06\ufe0f": 21.223027873839133, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4162333718976759, "IFEval": 41.6233371897676, "BBH Raw": 0.5138610942606995, "BBH": 30.841602413783743, "MATH Lvl 5 Raw": 0.0694864048338368, "MATH Lvl 5": 6.948640483383686, "GPQA Raw": 0.296979865771812, "GPQA": 6.263982102908276, "MUSR Raw": 0.4317291666666666, "MUSR": 12.499479166666667, "MMLU-PRO Raw": 0.3624501329787234, "MMLU-PRO": 29.161125886524825, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-07T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "johnsutor/Llama-3-8B-Instruct_breadcrumbs_ties-density-0.9-gamma-0.1 (Merge)"}, {"eval_name": "johnsutor_Llama-3-8B-Instruct_dare_linear_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/johnsutor/Llama-3-8B-Instruct_dare_linear\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">johnsutor/Llama-3-8B-Instruct_dare_linear</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/johnsutor__Llama-3-8B-Instruct_dare_linear-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "johnsutor/Llama-3-8B-Instruct_dare_linear", "Model sha": "abb81fd8fdc2ad32f65befcb7ae369c9837cd563", "Average \u2b06\ufe0f": 14.123522915539402, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2145496172378178, "IFEval": 21.454961723781786, "BBH Raw": 0.4282807940700452, "BBH": 19.610998997495773, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2961409395973154, "GPQA": 6.152125279642054, "MUSR Raw": 0.4979270833333333, "MUSR": 21.80755208333333, "MMLU-PRO Raw": 0.241439494680851, "MMLU-PRO": 15.715499408983453, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-07T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "johnsutor/Llama-3-8B-Instruct_dare_linear (Merge)"}, {"eval_name": "johnsutor_Llama-3-8B-Instruct_dare_ties-density-0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/johnsutor/Llama-3-8B-Instruct_dare_ties-density-0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">johnsutor/Llama-3-8B-Instruct_dare_ties-density-0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/johnsutor__Llama-3-8B-Instruct_dare_ties-density-0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "johnsutor/Llama-3-8B-Instruct_dare_ties-density-0.1", "Model sha": "e7a3a3b955d945f53da8301b958f0b90a28a62d3", "Average \u2b06\ufe0f": 11.619907050970184, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1890705550162457, "IFEval": 18.907055501624576, "BBH Raw": 0.411873601747358, "BBH": 16.85891694951123, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2718120805369127, "GPQA": 2.9082774049217, "MUSR Raw": 0.4658020833333333, "MUSR": 16.991927083333334, "MMLU-PRO Raw": 0.2264793882978723, "MMLU-PRO": 14.05326536643026, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-07T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "johnsutor/Llama-3-8B-Instruct_dare_ties-density-0.1 (Merge)"}, {"eval_name": "johnsutor_Llama-3-8B-Instruct_dare_ties-density-0.3_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/johnsutor/Llama-3-8B-Instruct_dare_ties-density-0.3\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">johnsutor/Llama-3-8B-Instruct_dare_ties-density-0.3</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/johnsutor__Llama-3-8B-Instruct_dare_ties-density-0.3-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "johnsutor/Llama-3-8B-Instruct_dare_ties-density-0.3", "Model sha": "6f966d14d7236f3da6d1ea9ce3bd9b20808e02a9", "Average \u2b06\ufe0f": 15.9437708061195, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2113270566541221, "IFEval": 21.132705665412217, "BBH Raw": 0.4558569854124363, "BBH": 23.0949356647322, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.296979865771812, "GPQA": 6.263982102908276, "MUSR Raw": 0.5069479166666667, "MUSR": 22.50182291666667, "MMLU-PRO Raw": 0.3040226063829787, "MMLU-PRO": 22.669178486997637, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-07T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "johnsutor/Llama-3-8B-Instruct_dare_ties-density-0.3 (Merge)"}, {"eval_name": "johnsutor_Llama-3-8B-Instruct_dare_ties-density-0.7_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/johnsutor/Llama-3-8B-Instruct_dare_ties-density-0.7\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">johnsutor/Llama-3-8B-Instruct_dare_ties-density-0.7</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/johnsutor__Llama-3-8B-Instruct_dare_ties-density-0.7-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "johnsutor/Llama-3-8B-Instruct_dare_ties-density-0.7", "Model sha": "b14b5cd07feb749e42b0567b1e387b390bed033e", "Average \u2b06\ufe0f": 16.721677967899154, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2033836886128804, "IFEval": 20.33836886128805, "BBH Raw": 0.4722858888388635, "BBH": 25.253545989338345, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.3036912751677852, "GPQA": 7.158836689038028, "MUSR Raw": 0.5110104166666667, "MUSR": 23.709635416666668, "MMLU-PRO Raw": 0.3148271276595745, "MMLU-PRO": 23.869680851063837, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-07T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "johnsutor/Llama-3-8B-Instruct_dare_ties-density-0.7 (Merge)"}, {"eval_name": "johnsutor_Llama-3-8B-Instruct_dare_ties-density-0.9_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/johnsutor/Llama-3-8B-Instruct_dare_ties-density-0.9\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">johnsutor/Llama-3-8B-Instruct_dare_ties-density-0.9</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/johnsutor__Llama-3-8B-Instruct_dare_ties-density-0.9-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "johnsutor/Llama-3-8B-Instruct_dare_ties-density-0.9", "Model sha": null, "Average \u2b06\ufe0f": 17.28459343949862, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2160733520392558, "IFEval": 21.607335203925583, "BBH Raw": 0.466396106718115, "BBH": 24.68762324471831, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.3078859060402684, "GPQA": 7.718120805369126, "MUSR Raw": 0.5230416666666667, "MUSR": 25.88020833333333, "MMLU-PRO Raw": 0.3143284574468085, "MMLU-PRO": 23.814273049645383, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-07T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "johnsutor/Llama-3-8B-Instruct_dare_ties-density-0.9 (Merge)"}, {"eval_name": "johnsutor_Llama-3-8B-Instruct_linear_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/johnsutor/Llama-3-8B-Instruct_linear\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">johnsutor/Llama-3-8B-Instruct_linear</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/johnsutor__Llama-3-8B-Instruct_linear-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "johnsutor/Llama-3-8B-Instruct_linear", "Model sha": "7449157fbc2e8b02e5b6e8ad56b4b2bd7ea82e9d", "Average \u2b06\ufe0f": 21.20722707696028, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4308213318439518, "IFEval": 43.08213318439518, "BBH Raw": 0.5031496839210309, "BBH": 28.778577217548463, "MATH Lvl 5 Raw": 0.0906344410876132, "MATH Lvl 5": 9.06344410876133, "GPQA Raw": 0.2953020134228188, "GPQA": 6.040268456375841, "MUSR Raw": 0.4097187499999999, "MUSR": 10.14817708333333, "MMLU-PRO Raw": 0.3711768617021276, "MMLU-PRO": 30.13076241134751, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-07T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "johnsutor/Llama-3-8B-Instruct_linear (Merge)"}, {"eval_name": "johnsutor_Llama-3-8B-Instruct_ties-density-0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/johnsutor/Llama-3-8B-Instruct_ties-density-0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">johnsutor/Llama-3-8B-Instruct_ties-density-0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/johnsutor__Llama-3-8B-Instruct_ties-density-0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "johnsutor/Llama-3-8B-Instruct_ties-density-0.1", "Model sha": "84793f89ebe3be5b5bd9a797d4bbdf374c07419d", "Average \u2b06\ufe0f": 20.29004285560941, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4116122998089513, "IFEval": 41.161229980895136, "BBH Raw": 0.5021445196013956, "BBH": 28.768718884316492, "MATH Lvl 5 Raw": 0.0709969788519637, "MATH Lvl 5": 7.099697885196375, "GPQA Raw": 0.2885906040268456, "GPQA": 5.145413870246088, "MUSR Raw": 0.417375, "MUSR": 10.671875000000002, "MMLU-PRO Raw": 0.3600398936170212, "MMLU-PRO": 28.893321513002363, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-07T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "johnsutor/Llama-3-8B-Instruct_ties-density-0.1 (Merge)"}, {"eval_name": "johnsutor_Llama-3-8B-Instruct_ties-density-0.3_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/johnsutor/Llama-3-8B-Instruct_ties-density-0.3\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">johnsutor/Llama-3-8B-Instruct_ties-density-0.3</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/johnsutor__Llama-3-8B-Instruct_ties-density-0.3-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "johnsutor/Llama-3-8B-Instruct_ties-density-0.3", "Model sha": "8d051f3eec3fc93a4521073c2d290c4ff9144fc1", "Average \u2b06\ufe0f": 18.691324195364174, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3626278274977061, "IFEval": 36.26278274977061, "BBH Raw": 0.490611225200058, "BBH": 27.724506656987163, "MATH Lvl 5 Raw": 0.0574018126888217, "MATH Lvl 5": 5.740181268882175, "GPQA Raw": 0.2961409395973154, "GPQA": 6.152125279642054, "MUSR Raw": 0.4024895833333333, "MUSR": 10.477864583333336, "MMLU-PRO Raw": 0.3321143617021276, "MMLU-PRO": 25.790484633569736, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-07T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "johnsutor/Llama-3-8B-Instruct_ties-density-0.3 (Merge)"}, {"eval_name": "johnsutor_Llama-3-8B-Instruct_ties-density-0.5_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/johnsutor/Llama-3-8B-Instruct_ties-density-0.5\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">johnsutor/Llama-3-8B-Instruct_ties-density-0.5</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/johnsutor__Llama-3-8B-Instruct_ties-density-0.5-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "johnsutor/Llama-3-8B-Instruct_ties-density-0.5", "Model sha": "c857e33c30016960f114e3a049f5dae41d68bfe7", "Average \u2b06\ufe0f": 18.108302614739227, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3796637366631648, "IFEval": 37.966373666316485, "BBH Raw": 0.4793124894884983, "BBH": 26.01209708592899, "MATH Lvl 5 Raw": 0.0543806646525679, "MATH Lvl 5": 5.438066465256798, "GPQA Raw": 0.3045302013422818, "GPQA": 7.270693512304249, "MUSR Raw": 0.3879791666666667, "MUSR": 7.797395833333334, "MMLU-PRO Raw": 0.3174867021276595, "MMLU-PRO": 24.165189125295505, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-07T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "johnsutor/Llama-3-8B-Instruct_ties-density-0.5 (Merge)"}, {"eval_name": "johnsutor_Llama-3-8B-Instruct_ties-density-0.7_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/johnsutor/Llama-3-8B-Instruct_ties-density-0.7\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">johnsutor/Llama-3-8B-Instruct_ties-density-0.7</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/johnsutor__Llama-3-8B-Instruct_ties-density-0.7-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "johnsutor/Llama-3-8B-Instruct_ties-density-0.7", "Model sha": "8d7d8bbb1e8cba5e51337f97bc3d6d8ae40544d5", "Average \u2b06\ufe0f": 17.89289721546466, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3681232463197649, "IFEval": 36.81232463197649, "BBH Raw": 0.4738186124296502, "BBH": 25.371407671115207, "MATH Lvl 5 Raw": 0.0574018126888217, "MATH Lvl 5": 5.740181268882175, "GPQA Raw": 0.3095637583892617, "GPQA": 7.941834451901568, "MUSR Raw": 0.3880729166666667, "MUSR": 7.575781250000001, "MMLU-PRO Raw": 0.3152426861702128, "MMLU-PRO": 23.91585401891253, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-07T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "johnsutor/Llama-3-8B-Instruct_ties-density-0.7 (Merge)"}, {"eval_name": "johnsutor_Llama-3-8B-Instruct_ties-density-0.9_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/johnsutor/Llama-3-8B-Instruct_ties-density-0.9\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">johnsutor/Llama-3-8B-Instruct_ties-density-0.9</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/johnsutor__Llama-3-8B-Instruct_ties-density-0.9-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "johnsutor/Llama-3-8B-Instruct_ties-density-0.9", "Model sha": "57c280ce43fe81a23c966b48de6db7f4a85383a3", "Average \u2b06\ufe0f": 18.03514558670802, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3858085435533274, "IFEval": 38.58085435533274, "BBH Raw": 0.4735432113601314, "BBH": 25.46373486461887, "MATH Lvl 5 Raw": 0.0558912386706948, "MATH Lvl 5": 5.589123867069486, "GPQA Raw": 0.299496644295302, "GPQA": 6.599552572706939, "MUSR Raw": 0.3880416666666667, "MUSR": 7.738541666666667, "MMLU-PRO Raw": 0.3181515957446808, "MMLU-PRO": 24.23906619385342, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-07T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "johnsutor/Llama-3-8B-Instruct_ties-density-0.9 (Merge)"}, {"eval_name": "jpacifico_Chocolatine-14B-Instruct-4k-DPO_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Phi3ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/jpacifico/Chocolatine-14B-Instruct-4k-DPO\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">jpacifico/Chocolatine-14B-Instruct-4k-DPO</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/jpacifico__Chocolatine-14B-Instruct-4k-DPO-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "jpacifico/Chocolatine-14B-Instruct-4k-DPO", "Model sha": "30677e58010979af26b70240846fdf7ff38cbbf2", "Average \u2b06\ufe0f": 29.825484182093238, "Hub License": "mit", "Hub \u2764\ufe0f": 1, "#Params (B)": 13, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4688648341954902, "IFEval": 46.886483419549016, "BBH Raw": 0.6299582409761587, "BBH": 48.02072159780435, "MATH Lvl 5 Raw": 0.1487915407854985, "MATH Lvl 5": 14.879154078549847, "GPQA Raw": 0.3414429530201342, "GPQA": 12.192393736017896, "MUSR Raw": 0.4438854166666666, "MUSR": 15.15234375, "MMLU-PRO Raw": 0.4763962765957447, "MMLU-PRO": 41.8218085106383, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-01T00:00:00", "Submission Date": "2024-08-08T00:00:00", "Generation": 0, "Base Model": "jpacifico/Chocolatine-14B-Instruct-4k-DPO"}, {"eval_name": "jpacifico_Chocolatine-14B-Instruct-DPO-v1.2_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Phi3ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/jpacifico/Chocolatine-14B-Instruct-DPO-v1.2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">jpacifico/Chocolatine-14B-Instruct-DPO-v1.2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/jpacifico__Chocolatine-14B-Instruct-DPO-v1.2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "jpacifico/Chocolatine-14B-Instruct-DPO-v1.2", "Model sha": "d34bbd55b48e553f28579d86f3ccae19726c6b39", "Average \u2b06\ufe0f": 33.30487439463958, "Hub License": "mit", "Hub \u2764\ufe0f": 8, "#Params (B)": 13, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6852107962428579, "IFEval": 68.52107962428579, "BBH Raw": 0.6438408959901142, "BBH": 49.845064475726, "MATH Lvl 5 Raw": 0.1797583081570997, "MATH Lvl 5": 17.97583081570997, "GPQA Raw": 0.3255033557046979, "GPQA": 10.067114093959727, "MUSR Raw": 0.4267708333333333, "MUSR": 12.346354166666671, "MMLU-PRO Raw": 0.4696642287234042, "MMLU-PRO": 41.07380319148936, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-12T00:00:00", "Submission Date": "2024-08-28T00:00:00", "Generation": 0, "Base Model": "jpacifico/Chocolatine-14B-Instruct-DPO-v1.2"}, {"eval_name": "jpacifico_Chocolatine-3B-Instruct-DPO-Revised_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Phi3ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/jpacifico/Chocolatine-3B-Instruct-DPO-Revised\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">jpacifico/Chocolatine-3B-Instruct-DPO-Revised</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/jpacifico__Chocolatine-3B-Instruct-DPO-Revised-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "jpacifico/Chocolatine-3B-Instruct-DPO-Revised", "Model sha": "c403df6c0f78148cfb477972455cbd859149311a", "Average \u2b06\ufe0f": 27.634989730055235, "Hub License": "mit", "Hub \u2764\ufe0f": 18, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5622625744136669, "IFEval": 56.22625744136669, "BBH Raw": 0.5539982344792619, "BBH": 37.1552860906475, "MATH Lvl 5 Raw": 0.1450151057401812, "MATH Lvl 5": 14.501510574018129, "GPQA Raw": 0.3221476510067114, "GPQA": 9.61968680089485, "MUSR Raw": 0.44534375, "MUSR": 15.101302083333328, "MMLU-PRO Raw": 0.3988530585106383, "MMLU-PRO": 33.205895390070914, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-17T00:00:00", "Submission Date": "2024-07-19T00:00:00", "Generation": 0, "Base Model": "jpacifico/Chocolatine-3B-Instruct-DPO-Revised"}, {"eval_name": "jpacifico_Chocolatine-3B-Instruct-DPO-v1.0_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Phi3ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/jpacifico/Chocolatine-3B-Instruct-DPO-v1.0\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">jpacifico/Chocolatine-3B-Instruct-DPO-v1.0</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/jpacifico__Chocolatine-3B-Instruct-DPO-v1.0-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "jpacifico/Chocolatine-3B-Instruct-DPO-v1.0", "Model sha": "98d049b8f8c305cfba81adae498a95e6b5647d4a", "Average \u2b06\ufe0f": 25.00159453013012, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 2, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3737184005106451, "IFEval": 37.37184005106451, "BBH Raw": 0.5471398082537478, "BBH": 36.55452005645581, "MATH Lvl 5 Raw": 0.1525679758308157, "MATH Lvl 5": 15.256797583081571, "GPQA Raw": 0.3154362416107382, "GPQA": 8.7248322147651, "MUSR Raw": 0.4754791666666667, "MUSR": 19.468229166666664, "MMLU-PRO Raw": 0.3937001329787234, "MMLU-PRO": 32.63334810874704, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-11T00:00:00", "Submission Date": "2024-07-11T00:00:00", "Generation": 0, "Base Model": "jpacifico/Chocolatine-3B-Instruct-DPO-v1.0"}, {"eval_name": "jpacifico_Chocolatine-3B-Instruct-DPO-v1.2_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Phi3ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/jpacifico/Chocolatine-3B-Instruct-DPO-v1.2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">jpacifico/Chocolatine-3B-Instruct-DPO-v1.2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/jpacifico__Chocolatine-3B-Instruct-DPO-v1.2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "jpacifico/Chocolatine-3B-Instruct-DPO-v1.2", "Model sha": "ebc9de6c266586adb1ec0db31bf050d1cd8fdffe", "Average \u2b06\ufe0f": 26.590513223320727, "Hub License": "mit", "Hub \u2764\ufe0f": 2, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5455014915978493, "IFEval": 54.55014915978493, "BBH Raw": 0.5487182027245813, "BBH": 35.99938785144921, "MATH Lvl 5 Raw": 0.1283987915407855, "MATH Lvl 5": 12.83987915407855, "GPQA Raw": 0.3389261744966443, "GPQA": 11.85682326621924, "MUSR Raw": 0.4154270833333333, "MUSR": 12.328385416666668, "MMLU-PRO Raw": 0.3877160904255319, "MMLU-PRO": 31.96845449172577, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-22T00:00:00", "Submission Date": "2024-08-28T00:00:00", "Generation": 0, "Base Model": "jpacifico/Chocolatine-3B-Instruct-DPO-v1.2"}, {"eval_name": "jsfs11_MixtureofMerges-MoE-4x7b-v4_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/jsfs11/MixtureofMerges-MoE-4x7b-v4\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">jsfs11/MixtureofMerges-MoE-4x7b-v4</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/jsfs11__MixtureofMerges-MoE-4x7b-v4-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "jsfs11/MixtureofMerges-MoE-4x7b-v4", "Model sha": "2b98406f20a874184dbffb5ed24e1f4b5063ec4b", "Average \u2b06\ufe0f": 19.921656279416982, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 4, "#Params (B)": 24, "Available on the hub": true, "Not_Merged": false, "MoE": false, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4029940557720182, "IFEval": 40.299405577201824, "BBH Raw": 0.5169007103786006, "BBH": 32.21799819533692, "MATH Lvl 5 Raw": 0.0574018126888217, "MATH Lvl 5": 5.740181268882175, "GPQA Raw": 0.2860738255033557, "GPQA": 4.809843400447425, "MUSR Raw": 0.4385520833333333, "MUSR": 13.885677083333334, "MMLU-PRO Raw": 0.3031914893617021, "MMLU-PRO": 22.57683215130024, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-02-11T00:00:00", "Submission Date": "2024-08-05T00:00:00", "Generation": 1, "Base Model": "jsfs11/MixtureofMerges-MoE-4x7b-v4 (Merge)"}, {"eval_name": "jsfs11_MixtureofMerges-MoE-4x7b-v5_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/jsfs11/MixtureofMerges-MoE-4x7b-v5\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">jsfs11/MixtureofMerges-MoE-4x7b-v5</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/jsfs11__MixtureofMerges-MoE-4x7b-v5-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "jsfs11/MixtureofMerges-MoE-4x7b-v5", "Model sha": "c1b5ce7144b966062df7627d2482a59e0df3757c", "Average \u2b06\ufe0f": 20.359412371661197, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 24, "Available on the hub": true, "Not_Merged": false, "MoE": false, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4199302295686556, "IFEval": 41.99302295686556, "BBH Raw": 0.5198481257083689, "BBH": 32.82672418068055, "MATH Lvl 5 Raw": 0.0709969788519637, "MATH Lvl 5": 7.099697885196375, "GPQA Raw": 0.2843959731543624, "GPQA": 4.586129753914992, "MUSR Raw": 0.4304895833333333, "MUSR": 12.344531250000005, "MMLU-PRO Raw": 0.3097573138297872, "MMLU-PRO": 23.30636820330969, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-02-25T00:00:00", "Submission Date": "2024-08-05T00:00:00", "Generation": 1, "Base Model": "jsfs11/MixtureofMerges-MoE-4x7b-v5 (Merge)"}, {"eval_name": "kaist-ai_mistral-orpo-capybara-7k_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/kaist-ai/mistral-orpo-capybara-7k\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">kaist-ai/mistral-orpo-capybara-7k</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/kaist-ai__mistral-orpo-capybara-7k-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "kaist-ai/mistral-orpo-capybara-7k", "Model sha": "24c1172060658a1923c9b454796857e2cc59fbeb", "Average \u2b06\ufe0f": 19.1201896457913, "Hub License": "mit", "Hub \u2764\ufe0f": 26, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.536733644507684, "IFEval": 53.6733644507684, "BBH Raw": 0.4488995185492166, "BBH": 23.434359116276923, "MATH Lvl 5 Raw": 0.0332326283987915, "MATH Lvl 5": 3.3232628398791544, "GPQA Raw": 0.2860738255033557, "GPQA": 4.809843400447425, "MUSR Raw": 0.3963541666666666, "MUSR": 7.57760416666667, "MMLU-PRO Raw": 0.297124335106383, "MMLU-PRO": 21.90270390070922, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-03-23T00:00:00", "Submission Date": "2024-10-09T00:00:00", "Generation": 1, "Base Model": "kaist-ai/mistral-orpo-capybara-7k (Merge)"}, {"eval_name": "keeeeenw_MicroLlama_float16", "Precision": "float16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/keeeeenw/MicroLlama\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">keeeeenw/MicroLlama</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/keeeeenw__MicroLlama-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "keeeeenw/MicroLlama", "Model sha": "8d5874ca07b86ea1ea2e71eea96212278506ba65", "Average \u2b06\ufe0f": 5.077266589541096, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 39, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1985376578589254, "IFEval": 19.85376578589254, "BBH Raw": 0.3007313991347165, "BBH": 2.831363636363637, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2609060402684564, "GPQA": 1.45413870246085, "MUSR Raw": 0.3698124999999999, "MUSR": 4.793229166666666, "MMLU-PRO Raw": 0.1137799202127659, "MMLU-PRO": 1.5311022458628842, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-03-29T00:00:00", "Submission Date": "2024-09-15T00:00:00", "Generation": 0, "Base Model": "keeeeenw/MicroLlama"}, {"eval_name": "kekmodel_StopCarbon-10.7B-v5_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/kekmodel/StopCarbon-10.7B-v5\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">kekmodel/StopCarbon-10.7B-v5</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/kekmodel__StopCarbon-10.7B-v5-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "kekmodel/StopCarbon-10.7B-v5", "Model sha": "7d59819dce2439f6c83b4f5c21a68aa882ff5ac9", "Average \u2b06\ufe0f": 20.00147157604368, "Hub License": "cc-by-nc-sa-4.0", "Hub \u2764\ufe0f": 2, "#Params (B)": 10, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.472836518216111, "IFEval": 47.2836518216111, "BBH Raw": 0.5177716413471513, "BBH": 31.9932224557197, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.3062080536912752, "GPQA": 7.494407158836691, "MUSR Raw": 0.4019375, "MUSR": 9.27552083333333, "MMLU-PRO Raw": 0.3156582446808511, "MMLU-PRO": 23.96202718676123, "Maintainer's Highlight": false, "Upload To Hub Date": "2023-12-30T00:00:00", "Submission Date": "2024-07-25T00:00:00", "Generation": 0, "Base Model": "kekmodel/StopCarbon-10.7B-v5"}, {"eval_name": "kevin009_llamaRAGdrama_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/kevin009/llamaRAGdrama\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">kevin009/llamaRAGdrama</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/kevin009__llamaRAGdrama-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "kevin009/llamaRAGdrama", "Model sha": "8c103ca8fa6dd9a8d3dab81b319408095e9a1ad8", "Average \u2b06\ufe0f": 13.197659794199703, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 7, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2598372318780835, "IFEval": 25.98372318780835, "BBH Raw": 0.4007385667099335, "BBH": 16.637813694151937, "MATH Lvl 5 Raw": 0.0339879154078549, "MATH Lvl 5": 3.3987915407854987, "GPQA Raw": 0.2642617449664429, "GPQA": 1.9015659955257265, "MUSR Raw": 0.4315729166666666, "MUSR": 12.113281250000002, "MMLU-PRO Raw": 0.2723570478723404, "MMLU-PRO": 19.15078309692672, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-02-04T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "kevin009/llamaRAGdrama"}, {"eval_name": "kms7530_chemeng_llama-3-8b-Instruct-bnb-4bit_24_1_100_1_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Adapter", "Architecture": "?", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/kms7530/chemeng_llama-3-8b-Instruct-bnb-4bit_24_1_100_1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">kms7530/chemeng_llama-3-8b-Instruct-bnb-4bit_24_1_100_1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/kms7530__chemeng_llama-3-8b-Instruct-bnb-4bit_24_1_100_1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "kms7530/chemeng_llama-3-8b-Instruct-bnb-4bit_24_1_100_1", "Model sha": "f296897830363557c84cc4a942c2cd1f91818ae4", "Average \u2b06\ufe0f": 17.480604343494793, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 9, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5455014915978493, "IFEval": 54.55014915978493, "BBH Raw": 0.4289039446973606, "BBH": 19.079190454097787, "MATH Lvl 5 Raw": 0.0309667673716012, "MATH Lvl 5": 3.096676737160121, "GPQA Raw": 0.2701342281879195, "GPQA": 2.684563758389265, "MUSR Raw": 0.3820624999999999, "MUSR": 5.491145833333334, "MMLU-PRO Raw": 0.2798371010638298, "MMLU-PRO": 19.98190011820331, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-10T00:00:00", "Submission Date": "2024-10-14T00:00:00", "Generation": 1, "Base Model": "unsloth/llama-3-8b-Instruct-bnb-4bit"}, {"eval_name": "kno10_ende-chat-0.0.5_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/kno10/ende-chat-0.0.5\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">kno10/ende-chat-0.0.5</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/kno10__ende-chat-0.0.5-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "kno10/ende-chat-0.0.5", "Model sha": "fff913e8ce204bab72b02582b663db669cb61412", "Average \u2b06\ufe0f": 10.610910904235965, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3404455733010634, "IFEval": 34.04455733010634, "BBH Raw": 0.3604365707523862, "BBH": 11.125830654491324, "MATH Lvl 5 Raw": 0.0060422960725075, "MATH Lvl 5": 0.6042296072507553, "GPQA Raw": 0.2651006711409396, "GPQA": 2.0134228187919474, "MUSR Raw": 0.39384375, "MUSR": 7.097135416666668, "MMLU-PRO Raw": 0.1790226063829787, "MMLU-PRO": 8.780289598108746, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-27T00:00:00", "Submission Date": "2024-06-27T00:00:00", "Generation": 0, "Base Model": "kno10/ende-chat-0.0.5"}, {"eval_name": "kno10_ende-chat-0.0.7_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/kno10/ende-chat-0.0.7\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">kno10/ende-chat-0.0.7</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/kno10__ende-chat-0.0.7-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "kno10/ende-chat-0.0.7", "Model sha": "1d45f51e5a3387378cea1036b0c65f2893466dd6", "Average \u2b06\ufe0f": 13.082387129788158, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.440063476021401, "IFEval": 44.006347602140096, "BBH Raw": 0.3791874557762433, "BBH": 13.57894913417845, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2810402684563758, "GPQA": 4.138702460850116, "MUSR Raw": 0.386125, "MUSR": 6.032291666666666, "MMLU-PRO Raw": 0.1966422872340425, "MMLU-PRO": 10.738031914893616, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-30T00:00:00", "Submission Date": "2024-07-30T00:00:00", "Generation": 0, "Base Model": "kno10/ende-chat-0.0.7"}, {"eval_name": "laislemke_LLaMA-2-vicuna-7b-slerp_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/laislemke/LLaMA-2-vicuna-7b-slerp\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">laislemke/LLaMA-2-vicuna-7b-slerp</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/laislemke__LLaMA-2-vicuna-7b-slerp-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "laislemke/LLaMA-2-vicuna-7b-slerp", "Model sha": "84a64f0ac8ff7db632a9d012fd5f4dcdf1eff950", "Average \u2b06\ufe0f": 7.669226122472586, "Hub License": "llama2", "Hub \u2764\ufe0f": 0, "#Params (B)": 6, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2932097944564865, "IFEval": 29.320979445648653, "BBH Raw": 0.2986216305235626, "BBH": 2.598263938597983, "MATH Lvl 5 Raw": 0.0098187311178247, "MATH Lvl 5": 0.9818731117824772, "GPQA Raw": 0.273489932885906, "GPQA": 3.1319910514541416, "MUSR Raw": 0.3833020833333333, "MUSR": 6.179427083333336, "MMLU-PRO Raw": 0.1342253989361702, "MMLU-PRO": 3.802822104018913, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-03T00:00:00", "Submission Date": "2024-07-03T00:00:00", "Generation": 1, "Base Model": "laislemke/LLaMA-2-vicuna-7b-slerp (Merge)"}, {"eval_name": "langgptai_Qwen-las-v0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Adapter", "Architecture": "?", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/langgptai/Qwen-las-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">langgptai/Qwen-las-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/langgptai__Qwen-las-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "langgptai/Qwen-las-v0.1", "Model sha": "a7a4d4945d28bac955554c9abd2f74a71ebbf22f", "Average \u2b06\ufe0f": 11.343651810199756, "Hub License": "other", "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3301041237250495, "IFEval": 33.01041237250495, "BBH Raw": 0.3892552562995618, "BBH": 14.698639898107368, "MATH Lvl 5 Raw": 0.0196374622356495, "MATH Lvl 5": 1.9637462235649543, "GPQA Raw": 0.2466442953020134, "GPQA": 0.0, "MUSR Raw": 0.3700937499999999, "MUSR": 3.66171875, "MMLU-PRO Raw": 0.2325465425531915, "MMLU-PRO": 14.727393617021276, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-26T00:00:00", "Submission Date": "2024-06-27T00:00:00", "Generation": 1, "Base Model": "Qwen/Qwen1.5-4B-Chat"}, {"eval_name": "langgptai_qwen1.5-7b-chat-sa-v0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Adapter", "Architecture": "?", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/langgptai/qwen1.5-7b-chat-sa-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">langgptai/qwen1.5-7b-chat-sa-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/langgptai__qwen1.5-7b-chat-sa-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "langgptai/qwen1.5-7b-chat-sa-v0.1", "Model sha": "5f4f5e69ac7f1d508f8369e977de208b4803444b", "Average \u2b06\ufe0f": 16.580170752646193, "Hub License": "other", "Hub \u2764\ufe0f": 0, "#Params (B)": 15, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4267742922113325, "IFEval": 42.67742922113326, "BBH Raw": 0.4325267992878656, "BBH": 20.302342129934097, "MATH Lvl 5 Raw": 0.0302114803625377, "MATH Lvl 5": 3.0211480362537766, "GPQA Raw": 0.3120805369127516, "GPQA": 8.277404921700223, "MUSR Raw": 0.3551458333333333, "MUSR": 3.0598958333333326, "MMLU-PRO Raw": 0.2992852393617021, "MMLU-PRO": 22.14280437352246, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-30T00:00:00", "Submission Date": "2024-06-27T00:00:00", "Generation": 1, "Base Model": "Qwen/Qwen1.5-7B-Chat"}, {"eval_name": "leafspark_Llama-3.1-8B-MultiReflection-Instruct_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/leafspark/Llama-3.1-8B-MultiReflection-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">leafspark/Llama-3.1-8B-MultiReflection-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/leafspark__Llama-3.1-8B-MultiReflection-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "leafspark/Llama-3.1-8B-MultiReflection-Instruct", "Model sha": "b748441154efdbd7690d773b0194197bfc136ed0", "Average \u2b06\ufe0f": 26.123059600394644, "Hub License": "llama3.1", "Hub \u2764\ufe0f": 3, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7125382872999197, "IFEval": 71.25382872999197, "BBH Raw": 0.5009088261495708, "BBH": 28.448045037118614, "MATH Lvl 5 Raw": 0.1253776435045317, "MATH Lvl 5": 12.537764350453172, "GPQA Raw": 0.2927852348993288, "GPQA": 5.7046979865771785, "MUSR Raw": 0.3681979166666667, "MUSR": 8.524739583333336, "MMLU-PRO Raw": 0.3724235372340425, "MMLU-PRO": 30.26928191489361, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-15T00:00:00", "Submission Date": "2024-09-15T00:00:00", "Generation": 1, "Base Model": "leafspark/Llama-3.1-8B-MultiReflection-Instruct (Merge)"}, {"eval_name": "lemon07r_Gemma-2-Ataraxy-9B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/lemon07r/Gemma-2-Ataraxy-9B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">lemon07r/Gemma-2-Ataraxy-9B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/lemon07r__Gemma-2-Ataraxy-9B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "lemon07r/Gemma-2-Ataraxy-9B", "Model sha": "fb22193268c7a6c3b4598255999ce2de3af8c256", "Average \u2b06\ufe0f": 22.42752014348775, "Hub License": "gemma", "Hub \u2764\ufe0f": 58, "#Params (B)": 10, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3008772279773224, "IFEval": 30.08772279773224, "BBH Raw": 0.5931298417725773, "BBH": 42.03199052898647, "MATH Lvl 5 Raw": 0.0083081570996978, "MATH Lvl 5": 0.8308157099697886, "GPQA Raw": 0.3347315436241611, "GPQA": 11.297539149888143, "MUSR Raw": 0.4424270833333333, "MUSR": 14.47005208333333, "MMLU-PRO Raw": 0.4226230053191489, "MMLU-PRO": 35.847000591016545, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-14T00:00:00", "Submission Date": "2024-08-27T00:00:00", "Generation": 1, "Base Model": "lemon07r/Gemma-2-Ataraxy-9B (Merge)"}, {"eval_name": "lemon07r_Gemma-2-Ataraxy-Advanced-9B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/lemon07r/Gemma-2-Ataraxy-Advanced-9B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">lemon07r/Gemma-2-Ataraxy-Advanced-9B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/lemon07r__Gemma-2-Ataraxy-Advanced-9B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "lemon07r/Gemma-2-Ataraxy-Advanced-9B", "Model sha": "960654f5780f0b458367a6b591ad8440892c2aad", "Average \u2b06\ufe0f": 25.0719295148964, "Hub License": null, "Hub \u2764\ufe0f": 2, "#Params (B)": 10, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.5515964308036011, "IFEval": 55.15964308036011, "BBH Raw": 0.5889067263184956, "BBH": 41.16143815473681, "MATH Lvl 5 Raw": 0.0015105740181268, "MATH Lvl 5": 0.1510574018126888, "GPQA Raw": 0.3355704697986577, "GPQA": 11.409395973154364, "MUSR Raw": 0.3760729166666667, "MUSR": 6.509114583333333, "MMLU-PRO Raw": 0.4243683510638298, "MMLU-PRO": 36.040927895981085, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-30T00:00:00", "Submission Date": "2024-09-30T00:00:00", "Generation": 1, "Base Model": "lemon07r/Gemma-2-Ataraxy-Advanced-9B (Merge)"}, {"eval_name": "lemon07r_Gemma-2-Ataraxy-Remix-9B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/lemon07r/Gemma-2-Ataraxy-Remix-9B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">lemon07r/Gemma-2-Ataraxy-Remix-9B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/lemon07r__Gemma-2-Ataraxy-Remix-9B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "lemon07r/Gemma-2-Ataraxy-Remix-9B", "Model sha": "f917a9be9f86d58fe122d58ba84cf4b08e4a975e", "Average \u2b06\ufe0f": 29.211318786699504, "Hub License": null, "Hub \u2764\ufe0f": 2, "#Params (B)": 10, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.7083416446140685, "IFEval": 70.83416446140684, "BBH Raw": 0.5892021015046846, "BBH": 41.59231281593379, "MATH Lvl 5 Raw": 0.0128398791540785, "MATH Lvl 5": 1.283987915407855, "GPQA Raw": 0.3389261744966443, "GPQA": 11.85682326621924, "MUSR Raw": 0.4371875, "MUSR": 13.715104166666665, "MMLU-PRO Raw": 0.4238696808510638, "MMLU-PRO": 35.985520094562645, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-30T00:00:00", "Submission Date": "2024-09-30T00:00:00", "Generation": 1, "Base Model": "lemon07r/Gemma-2-Ataraxy-Remix-9B (Merge)"}, {"eval_name": "lemon07r_Gemma-2-Ataraxy-v2-9B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/lemon07r/Gemma-2-Ataraxy-v2-9B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">lemon07r/Gemma-2-Ataraxy-v2-9B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/lemon07r__Gemma-2-Ataraxy-v2-9B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "lemon07r/Gemma-2-Ataraxy-v2-9B", "Model sha": "77aca48ac25eb2cbe8c0751a4ef77e5face34d80", "Average \u2b06\ufe0f": 19.161242089617037, "Hub License": null, "Hub \u2764\ufe0f": 10, "#Params (B)": 10, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2136242946493082, "IFEval": 21.362429464930827, "BBH Raw": 0.5765835815625312, "BBH": 39.79685359725269, "MATH Lvl 5 Raw": 0.0083081570996978, "MATH Lvl 5": 0.8308157099697886, "GPQA Raw": 0.3422818791946309, "GPQA": 12.304250559284116, "MUSR Raw": 0.3483854166666666, "MUSR": 4.881510416666667, "MMLU-PRO Raw": 0.422124335106383, "MMLU-PRO": 35.791592789598106, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-28T00:00:00", "Submission Date": "2024-09-28T00:00:00", "Generation": 1, "Base Model": "lemon07r/Gemma-2-Ataraxy-v2-9B (Merge)"}, {"eval_name": "lemon07r_Gemma-2-Ataraxy-v2a-9B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/lemon07r/Gemma-2-Ataraxy-v2a-9B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">lemon07r/Gemma-2-Ataraxy-v2a-9B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/lemon07r__Gemma-2-Ataraxy-v2a-9B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "lemon07r/Gemma-2-Ataraxy-v2a-9B", "Model sha": "899fb093d80569fc919f53217e3acf031dde89a5", "Average \u2b06\ufe0f": 15.01936138376009, "Hub License": null, "Hub \u2764\ufe0f": 1, "#Params (B)": 10, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.159469097550056, "IFEval": 15.946909755005606, "BBH Raw": 0.518248966271832, "BBH": 31.19852836941699, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.3397651006711409, "GPQA": 11.968680089485462, "MUSR Raw": 0.3164791666666666, "MUSR": 3.0598958333333326, "MMLU-PRO Raw": 0.3514793882978723, "MMLU-PRO": 27.942154255319146, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-29T00:00:00", "Submission Date": "2024-09-29T00:00:00", "Generation": 1, "Base Model": "lemon07r/Gemma-2-Ataraxy-v2a-9B (Merge)"}, {"eval_name": "lemon07r_Gemma-2-Ataraxy-v2f-9B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/lemon07r/Gemma-2-Ataraxy-v2f-9B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">lemon07r/Gemma-2-Ataraxy-v2f-9B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/lemon07r__Gemma-2-Ataraxy-v2f-9B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "lemon07r/Gemma-2-Ataraxy-v2f-9B", "Model sha": "44da9d6a9bc7be5a9af24fb0951047849d5f717d", "Average \u2b06\ufe0f": 18.765944401672623, "Hub License": null, "Hub \u2764\ufe0f": 1, "#Params (B)": 10, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3791140839638824, "IFEval": 37.911408396388246, "BBH Raw": 0.5192845467961766, "BBH": 31.421336195418803, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.3389261744966443, "GPQA": 11.85682326621924, "MUSR Raw": 0.3231458333333333, "MUSR": 3.5932291666666667, "MMLU-PRO Raw": 0.3503158244680851, "MMLU-PRO": 27.812869385342783, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-30T00:00:00", "Submission Date": "2024-09-30T00:00:00", "Generation": 1, "Base Model": "lemon07r/Gemma-2-Ataraxy-v2f-9B (Merge)"}, {"eval_name": "lemon07r_Gemma-2-Ataraxy-v3-Advanced-9B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/lemon07r/Gemma-2-Ataraxy-v3-Advanced-9B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">lemon07r/Gemma-2-Ataraxy-v3-Advanced-9B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/lemon07r__Gemma-2-Ataraxy-v3-Advanced-9B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "lemon07r/Gemma-2-Ataraxy-v3-Advanced-9B", "Model sha": "318afe2b44a150780e44483a0f90a499e81f946f", "Average \u2b06\ufe0f": 28.333876970643036, "Hub License": null, "Hub \u2764\ufe0f": 3, "#Params (B)": 10, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.6601816513517467, "IFEval": 66.01816513517468, "BBH Raw": 0.5935146853737787, "BBH": 42.21047229127766, "MATH Lvl 5 Raw": 0.0015105740181268, "MATH Lvl 5": 0.1510574018126888, "GPQA Raw": 0.3364093959731543, "GPQA": 11.521252796420578, "MUSR Raw": 0.4449687499999999, "MUSR": 14.58776041666667, "MMLU-PRO Raw": 0.4196309840425531, "MMLU-PRO": 35.51455378250591, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-09T00:00:00", "Submission Date": "2024-10-09T00:00:00", "Generation": 1, "Base Model": "lemon07r/Gemma-2-Ataraxy-v3-Advanced-9B (Merge)"}, {"eval_name": "lemon07r_Gemma-2-Ataraxy-v3b-9B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/lemon07r/Gemma-2-Ataraxy-v3b-9B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">lemon07r/Gemma-2-Ataraxy-v3b-9B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/lemon07r__Gemma-2-Ataraxy-v3b-9B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "lemon07r/Gemma-2-Ataraxy-v3b-9B", "Model sha": "de8bbacddabf22dad89658d3b3d358b3eccbd59c", "Average \u2b06\ufe0f": 28.95338859297975, "Hub License": null, "Hub \u2764\ufe0f": 1, "#Params (B)": 9, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.6809144181881852, "IFEval": 68.09144181881851, "BBH Raw": 0.5907698162898164, "BBH": 41.62398549212332, "MATH Lvl 5 Raw": 0.0211480362537764, "MATH Lvl 5": 2.114803625377644, "GPQA Raw": 0.3330536912751677, "GPQA": 11.0738255033557, "MUSR Raw": 0.4488749999999999, "MUSR": 15.209374999999996, "MMLU-PRO Raw": 0.4204621010638298, "MMLU-PRO": 35.606900118203306, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-08T00:00:00", "Submission Date": "2024-10-08T00:00:00", "Generation": 1, "Base Model": "lemon07r/Gemma-2-Ataraxy-v3b-9B (Merge)"}, {"eval_name": "lemon07r_Gemma-2-Ataraxy-v3i-9B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/lemon07r/Gemma-2-Ataraxy-v3i-9B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">lemon07r/Gemma-2-Ataraxy-v3i-9B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/lemon07r__Gemma-2-Ataraxy-v3i-9B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "lemon07r/Gemma-2-Ataraxy-v3i-9B", "Model sha": "8bd1ce81b6f42ebeebd9957b605c7313eedbe0a8", "Average \u2b06\ufe0f": 21.293827573842577, "Hub License": null, "Hub \u2764\ufe0f": 3, "#Params (B)": 9, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4203047912871182, "IFEval": 42.03047912871182, "BBH Raw": 0.5625750779805955, "BBH": 38.238824874777286, "MATH Lvl 5 Raw": 0.0015105740181268, "MATH Lvl 5": 0.1510574018126888, "GPQA Raw": 0.3280201342281879, "GPQA": 10.402684563758392, "MUSR Raw": 0.3180624999999999, "MUSR": 1.7578124999999991, "MMLU-PRO Raw": 0.4166389627659574, "MMLU-PRO": 35.182106973995275, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-06T00:00:00", "Submission Date": "2024-10-06T00:00:00", "Generation": 1, "Base Model": "lemon07r/Gemma-2-Ataraxy-v3i-9B (Merge)"}, {"eval_name": "lemon07r_Gemma-2-Ataraxy-v3j-9B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/lemon07r/Gemma-2-Ataraxy-v3j-9B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">lemon07r/Gemma-2-Ataraxy-v3j-9B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/lemon07r__Gemma-2-Ataraxy-v3j-9B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "lemon07r/Gemma-2-Ataraxy-v3j-9B", "Model sha": "7ad4a1bf604f37bd82f3470dbc24870896d7287d", "Average \u2b06\ufe0f": 21.180095735103663, "Hub License": null, "Hub \u2764\ufe0f": 1, "#Params (B)": 9, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4169326276501904, "IFEval": 41.69326276501904, "BBH Raw": 0.5632286961183511, "BBH": 38.16656919949616, "MATH Lvl 5 Raw": 0.0007552870090634, "MATH Lvl 5": 0.0755287009063444, "GPQA Raw": 0.3280201342281879, "GPQA": 10.402684563758392, "MUSR Raw": 0.31803125, "MUSR": 1.920572916666666, "MMLU-PRO Raw": 0.4133976063829787, "MMLU-PRO": 34.821956264775416, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-09T00:00:00", "Submission Date": "2024-10-09T00:00:00", "Generation": 1, "Base Model": "lemon07r/Gemma-2-Ataraxy-v3j-9B (Merge)"}, {"eval_name": "lemon07r_Llama-3-RedMagic4-8B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/lemon07r/Llama-3-RedMagic4-8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">lemon07r/Llama-3-RedMagic4-8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/lemon07r__Llama-3-RedMagic4-8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "lemon07r/Llama-3-RedMagic4-8B", "Model sha": "65ee08a0434f1903a8971640fc3cca6c8ae8590e", "Average \u2b06\ufe0f": 19.317697446594423, "Hub License": "llama3", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4864005283758206, "IFEval": 48.64005283758206, "BBH Raw": 0.4256048947039041, "BBH": 19.475746974326068, "MATH Lvl 5 Raw": 0.0830815709969788, "MATH Lvl 5": 8.308157099697885, "GPQA Raw": 0.2902684563758389, "GPQA": 5.369127516778524, "MUSR Raw": 0.3766354166666666, "MUSR": 4.379427083333333, "MMLU-PRO Raw": 0.3676030585106383, "MMLU-PRO": 29.733673167848696, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-19T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "lemon07r/Llama-3-RedMagic4-8B (Merge)"}, {"eval_name": "lemon07r_llama-3-NeuralMahou-8b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/lemon07r/llama-3-NeuralMahou-8b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">lemon07r/llama-3-NeuralMahou-8b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/lemon07r__llama-3-NeuralMahou-8b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "lemon07r/llama-3-NeuralMahou-8b", "Model sha": "59a0937df85f9d6d65d15dbb4a7c06b6ad8a0305", "Average \u2b06\ufe0f": 19.73278116247831, "Hub License": "llama3", "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4900973860468002, "IFEval": 49.00973860468002, "BBH Raw": 0.4184112368330152, "BBH": 18.69206874721008, "MATH Lvl 5 Raw": 0.0951661631419939, "MATH Lvl 5": 9.516616314199396, "GPQA Raw": 0.2885906040268456, "GPQA": 5.145413870246088, "MUSR Raw": 0.3872708333333333, "MUSR": 6.142187500000001, "MMLU-PRO Raw": 0.3690159574468085, "MMLU-PRO": 29.89066193853428, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-30T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "lemon07r/llama-3-NeuralMahou-8b (Merge)"}, {"eval_name": "lesubra_ECE-EIFFEL-3B_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "Phi3ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/lesubra/ECE-EIFFEL-3B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">lesubra/ECE-EIFFEL-3B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/lesubra__ECE-EIFFEL-3B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "lesubra/ECE-EIFFEL-3B", "Model sha": "aa56433ac824d245ac82d5e55ce8e589df0711ec", "Average \u2b06\ufe0f": 21.95054619555363, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3469405621528655, "IFEval": 34.69405621528655, "BBH Raw": 0.5101583259186949, "BBH": 31.286439186186243, "MATH Lvl 5 Raw": 0.0883685800604229, "MATH Lvl 5": 8.836858006042297, "GPQA Raw": 0.3313758389261745, "GPQA": 10.850111856823268, "MUSR Raw": 0.4362291666666666, "MUSR": 14.6953125, "MMLU-PRO Raw": 0.3820644946808511, "MMLU-PRO": 31.340499408983447, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-01T00:00:00", "Submission Date": "2024-10-01T00:00:00", "Generation": 0, "Base Model": "lesubra/ECE-EIFFEL-3B"}, {"eval_name": "lesubra_ECE-EIFFEL-3Bv2_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "Phi3ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/lesubra/ECE-EIFFEL-3Bv2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">lesubra/ECE-EIFFEL-3Bv2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/lesubra__ECE-EIFFEL-3Bv2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "lesubra/ECE-EIFFEL-3Bv2", "Model sha": "b059d1a0d49f09d6df34d93f133d24f6641bc535", "Average \u2b06\ufe0f": 21.94522037378076, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3013027655509603, "IFEval": 30.13027655509603, "BBH Raw": 0.5424007873371969, "BBH": 36.35313296509659, "MATH Lvl 5 Raw": 0.0468277945619335, "MATH Lvl 5": 4.682779456193353, "GPQA Raw": 0.3355704697986577, "GPQA": 11.409395973154364, "MUSR Raw": 0.4442916666666667, "MUSR": 15.769791666666665, "MMLU-PRO Raw": 0.3999335106382978, "MMLU-PRO": 33.32594562647754, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-03T00:00:00", "Submission Date": "2024-10-03T00:00:00", "Generation": 0, "Base Model": "lesubra/ECE-EIFFEL-3Bv2"}, {"eval_name": "lesubra_ECE-EIFFEL-3Bv3_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "Phi3ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/lesubra/ECE-EIFFEL-3Bv3\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">lesubra/ECE-EIFFEL-3Bv3</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/lesubra__ECE-EIFFEL-3Bv3-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "lesubra/ECE-EIFFEL-3Bv3", "Model sha": "2cd31e58d38b96626a8a83192b5d2eec6669f5e2", "Average \u2b06\ufe0f": 25.136172005353373, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3786142989490109, "IFEval": 37.861429894901086, "BBH Raw": 0.5469446669064592, "BBH": 36.46408334995511, "MATH Lvl 5 Raw": 0.1450151057401812, "MATH Lvl 5": 14.501510574018129, "GPQA Raw": 0.3296979865771812, "GPQA": 10.626398210290828, "MUSR Raw": 0.4675104166666666, "MUSR": 18.30546875, "MMLU-PRO Raw": 0.3975232712765957, "MMLU-PRO": 33.05814125295508, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-07T00:00:00", "Submission Date": "2024-10-07T00:00:00", "Generation": 0, "Base Model": "lesubra/ECE-EIFFEL-3Bv3"}, {"eval_name": "lesubra_merge-test_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Phi3ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/lesubra/merge-test\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">lesubra/merge-test</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/lesubra__merge-test-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "lesubra/merge-test", "Model sha": "39895c64dd646443719873a2ab2b19d3afe4f86c", "Average \u2b06\ufe0f": 25.584584365111088, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.538257379309122, "IFEval": 53.8257379309122, "BBH Raw": 0.5240434385320306, "BBH": 33.353311441745, "MATH Lvl 5 Raw": 0.0913897280966767, "MATH Lvl 5": 9.138972809667674, "GPQA Raw": 0.3221476510067114, "GPQA": 9.61968680089485, "MUSR Raw": 0.44190625, "MUSR": 15.638281249999997, "MMLU-PRO Raw": 0.3873836436170212, "MMLU-PRO": 31.93151595744681, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-27T00:00:00", "Submission Date": "2024-09-27T00:00:00", "Generation": 0, "Base Model": "lesubra/merge-test"}, {"eval_name": "lightblue_suzume-llama-3-8B-multilingual_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/lightblue/suzume-llama-3-8B-multilingual\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">lightblue/suzume-llama-3-8B-multilingual</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/lightblue__suzume-llama-3-8B-multilingual-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "lightblue/suzume-llama-3-8B-multilingual", "Model sha": "0cb15aa9ec685eef494f9a15f65aefcfe3c04c66", "Average \u2b06\ufe0f": 23.721955897112263, "Hub License": "other", "Hub \u2764\ufe0f": 105, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6678003253589365, "IFEval": 66.78003253589365, "BBH Raw": 0.4949952418735974, "BBH": 28.895092037237777, "MATH Lvl 5 Raw": 0.0785498489425981, "MATH Lvl 5": 7.854984894259818, "GPQA Raw": 0.2835570469798658, "GPQA": 4.4742729306487705, "MUSR Raw": 0.3976874999999999, "MUSR": 7.844270833333335, "MMLU-PRO Raw": 0.3383477393617021, "MMLU-PRO": 26.483082151300238, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-23T00:00:00", "Submission Date": "2024-07-30T00:00:00", "Generation": 1, "Base Model": "meta-llama/Meta-Llama-3-8B-Instruct"}, {"eval_name": "lightblue_suzume-llama-3-8B-multilingual-orpo-borda-full_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/lightblue/suzume-llama-3-8B-multilingual-orpo-borda-full\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">lightblue/suzume-llama-3-8B-multilingual-orpo-borda-full</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/lightblue__suzume-llama-3-8B-multilingual-orpo-borda-full-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "lightblue/suzume-llama-3-8B-multilingual-orpo-borda-full", "Model sha": "ac04e23fb8861c188f8ecddfecc4250b40aee04d", "Average \u2b06\ufe0f": 19.533832531795, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5817464327983085, "IFEval": 58.174643279830846, "BBH Raw": 0.4714219934773132, "BBH": 25.07547488849692, "MATH Lvl 5 Raw": 0.0302114803625377, "MATH Lvl 5": 3.0211480362537766, "GPQA Raw": 0.259228187919463, "GPQA": 1.230425055928408, "MUSR Raw": 0.3221875, "MUSR": 4.040104166666668, "MMLU-PRO Raw": 0.3309507978723404, "MMLU-PRO": 25.66119976359338, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-25T00:00:00", "Submission Date": "2024-07-29T00:00:00", "Generation": 2, "Base Model": "meta-llama/Meta-Llama-3-8B-Instruct"}, {"eval_name": "lightblue_suzume-llama-3-8B-multilingual-orpo-borda-half_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/lightblue/suzume-llama-3-8B-multilingual-orpo-borda-half\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">lightblue/suzume-llama-3-8B-multilingual-orpo-borda-half</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/lightblue__suzume-llama-3-8B-multilingual-orpo-borda-half-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "lightblue/suzume-llama-3-8B-multilingual-orpo-borda-half", "Model sha": "b82150a9840ba5ba93918c745adc70afc6ad2ce1", "Average \u2b06\ufe0f": 21.283210604494027, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 13, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6249107922534431, "IFEval": 62.49107922534431, "BBH Raw": 0.4707458491057301, "BBH": 26.34859792572119, "MATH Lvl 5 Raw": 0.0770392749244713, "MATH Lvl 5": 7.7039274924471295, "GPQA Raw": 0.2449664429530201, "GPQA": 0.0, "MUSR Raw": 0.3515833333333333, "MUSR": 2.114583333333334, "MMLU-PRO Raw": 0.3613696808510638, "MMLU-PRO": 29.0410756501182, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-25T00:00:00", "Submission Date": "2024-06-29T00:00:00", "Generation": 2, "Base Model": "meta-llama/Meta-Llama-3-8B-Instruct"}, {"eval_name": "lightblue_suzume-llama-3-8B-multilingual-orpo-borda-top25_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/lightblue/suzume-llama-3-8B-multilingual-orpo-borda-top25\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">lightblue/suzume-llama-3-8B-multilingual-orpo-borda-top25</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/lightblue__suzume-llama-3-8B-multilingual-orpo-borda-top25-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "lightblue/suzume-llama-3-8B-multilingual-orpo-borda-top25", "Model sha": "5a2f17238cc83932e00613d285f8bf6b8f4a0c3a", "Average \u2b06\ufe0f": 23.370065191977883, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 2, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6636535503574958, "IFEval": 66.36535503574959, "BBH Raw": 0.4864641205580417, "BBH": 27.665285015300118, "MATH Lvl 5 Raw": 0.0853474320241691, "MATH Lvl 5": 8.534743202416918, "GPQA Raw": 0.2726510067114094, "GPQA": 3.0201342281879207, "MUSR Raw": 0.3566041666666666, "MUSR": 4.808854166666668, "MMLU-PRO Raw": 0.3684341755319149, "MMLU-PRO": 29.82601950354609, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-26T00:00:00", "Submission Date": "2024-06-29T00:00:00", "Generation": 2, "Base Model": "meta-llama/Meta-Llama-3-8B-Instruct"}, {"eval_name": "lightblue_suzume-llama-3-8B-multilingual-orpo-borda-top75_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/lightblue/suzume-llama-3-8B-multilingual-orpo-borda-top75\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">lightblue/suzume-llama-3-8B-multilingual-orpo-borda-top75</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/lightblue__suzume-llama-3-8B-multilingual-orpo-borda-top75-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "lightblue/suzume-llama-3-8B-multilingual-orpo-borda-top75", "Model sha": "555f4a0092f239557e1aa34f9d489e8156b907bb", "Average \u2b06\ufe0f": 23.43312179189275, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6687245397766814, "IFEval": 66.87245397766813, "BBH Raw": 0.4833316609585611, "BBH": 28.05625593898892, "MATH Lvl 5 Raw": 0.0657099697885196, "MATH Lvl 5": 6.570996978851963, "GPQA Raw": 0.2726510067114094, "GPQA": 3.0201342281879207, "MUSR Raw": 0.3816875, "MUSR": 5.3109375000000005, "MMLU-PRO Raw": 0.3769115691489361, "MMLU-PRO": 30.76795212765957, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-26T00:00:00", "Submission Date": "2024-06-29T00:00:00", "Generation": 2, "Base Model": "meta-llama/Meta-Llama-3-8B-Instruct"}, {"eval_name": "llmat_Mistral-v0.3-7B-ORPO_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/llmat/Mistral-v0.3-7B-ORPO\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">llmat/Mistral-v0.3-7B-ORPO</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/llmat__Mistral-v0.3-7B-ORPO-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "llmat/Mistral-v0.3-7B-ORPO", "Model sha": "868d8a51e8deb6fd948eabe5bc296c53bcf41073", "Average \u2b06\ufe0f": 12.084587090107751, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3770406964631622, "IFEval": 37.70406964631621, "BBH Raw": 0.3977660730291809, "BBH": 14.86315851911541, "MATH Lvl 5 Raw": 0.0052870090634441, "MATH Lvl 5": 0.5287009063444109, "GPQA Raw": 0.2667785234899328, "GPQA": 2.2371364653243813, "MUSR Raw": 0.3555208333333333, "MUSR": 2.973437500000001, "MMLU-PRO Raw": 0.2278091755319149, "MMLU-PRO": 14.2010195035461, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-04T00:00:00", "Submission Date": "2024-09-02T00:00:00", "Generation": 1, "Base Model": "unsloth/mistral-7b-v0.3-bnb-4bit"}, {"eval_name": "llmat_Mistral-v0.3-7B-ORPO_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/llmat/Mistral-v0.3-7B-ORPO\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">llmat/Mistral-v0.3-7B-ORPO</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/llmat__Mistral-v0.3-7B-ORPO-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "llmat/Mistral-v0.3-7B-ORPO", "Model sha": "868d8a51e8deb6fd948eabe5bc296c53bcf41073", "Average \u2b06\ufe0f": 12.024321589275658, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3639764713183243, "IFEval": 36.39764713183243, "BBH Raw": 0.400465557804411, "BBH": 15.59149132338697, "MATH Lvl 5 Raw": 0.0015105740181268, "MATH Lvl 5": 0.1510574018126888, "GPQA Raw": 0.2692953020134228, "GPQA": 2.572706935123044, "MUSR Raw": 0.3528541666666667, "MUSR": 2.973437500000001, "MMLU-PRO Raw": 0.2301363031914893, "MMLU-PRO": 14.45958924349882, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-04T00:00:00", "Submission Date": "2024-08-06T00:00:00", "Generation": 1, "Base Model": "unsloth/mistral-7b-v0.3-bnb-4bit"}, {"eval_name": "lmsys_vicuna-13b-v1.3_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/lmsys/vicuna-13b-v1.3\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">lmsys/vicuna-13b-v1.3</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/lmsys__vicuna-13b-v1.3-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "lmsys/vicuna-13b-v1.3", "Model sha": "6566e9cb1787585d1147dcf4f9bc48f29e1328d2", "Average \u2b06\ufe0f": 10.271888157023232, "Hub License": null, "Hub \u2764\ufe0f": 194, "#Params (B)": 13, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3343506340953115, "IFEval": 33.43506340953115, "BBH Raw": 0.3384399312777569, "BBH": 7.48978931162921, "MATH Lvl 5 Raw": 0.0045317220543806, "MATH Lvl 5": 0.4531722054380665, "GPQA Raw": 0.2676174496644295, "GPQA": 2.348993288590602, "MUSR Raw": 0.3727291666666666, "MUSR": 4.091145833333333, "MMLU-PRO Raw": 0.2243184840425532, "MMLU-PRO": 13.813164893617024, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-06-18T00:00:00", "Submission Date": "2024-06-28T00:00:00", "Generation": 0, "Base Model": "lmsys/vicuna-13b-v1.3"}, {"eval_name": "lmsys_vicuna-7b-v1.3_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/lmsys/vicuna-7b-v1.3\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">lmsys/vicuna-7b-v1.3</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/lmsys__vicuna-7b-v1.3-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "lmsys/vicuna-7b-v1.3", "Model sha": "236eeeab96f0dc2e463f2bebb7bb49809279c6d6", "Average \u2b06\ufe0f": 8.31181120581355, "Hub License": null, "Hub \u2764\ufe0f": 128, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.290861580606125, "IFEval": 29.086158060612505, "BBH Raw": 0.3298410006592924, "BBH": 6.461378796018201, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2424496644295302, "GPQA": 0.0, "MUSR Raw": 0.3793333333333333, "MUSR": 5.016666666666668, "MMLU-PRO Raw": 0.1837599734042553, "MMLU-PRO": 9.306663711583925, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-06-18T00:00:00", "Submission Date": "2024-06-28T00:00:00", "Generation": 0, "Base Model": "lmsys/vicuna-7b-v1.3"}, {"eval_name": "lmsys_vicuna-7b-v1.5_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/lmsys/vicuna-7b-v1.5\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">lmsys/vicuna-7b-v1.5</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/lmsys__vicuna-7b-v1.5-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "lmsys/vicuna-7b-v1.5", "Model sha": "3321f76e3f527bd14065daf69dad9344000a201d", "Average \u2b06\ufe0f": 10.784447380313544, "Hub License": "llama2", "Hub \u2764\ufe0f": 296, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2351571607778472, "IFEval": 23.515716077784724, "BBH Raw": 0.3947043684223377, "BBH": 15.15250931284372, "MATH Lvl 5 Raw": 0.0075528700906344, "MATH Lvl 5": 0.7552870090634441, "GPQA Raw": 0.2583892617449664, "GPQA": 1.1185682326621946, "MUSR Raw": 0.4231145833333333, "MUSR": 11.42265625, "MMLU-PRO Raw": 0.2146775265957446, "MMLU-PRO": 12.741947399527188, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-07-29T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "lmsys/vicuna-7b-v1.5"}, {"eval_name": "lodrick-the-lafted_llama-3.1-8b-instruct-ortho-v7_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/lodrick-the-lafted/llama-3.1-8b-instruct-ortho-v7\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">lodrick-the-lafted/llama-3.1-8b-instruct-ortho-v7</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/lodrick-the-lafted__llama-3.1-8b-instruct-ortho-v7-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "lodrick-the-lafted/llama-3.1-8b-instruct-ortho-v7", "Model sha": "6b7673cd78398c3a8c92f8e759aaae6409e96978", "Average \u2b06\ufe0f": 11.649173836014825, "Hub License": "wtfpl", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3514618988727687, "IFEval": 35.14618988727687, "BBH Raw": 0.3906914026136291, "BBH": 14.43786307942362, "MATH Lvl 5 Raw": 0.0173716012084592, "MATH Lvl 5": 1.7371601208459215, "GPQA Raw": 0.2726510067114094, "GPQA": 3.0201342281879207, "MUSR Raw": 0.36159375, "MUSR": 4.732552083333332, "MMLU-PRO Raw": 0.1973902925531915, "MMLU-PRO": 10.821143617021276, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-25T00:00:00", "Submission Date": "2024-07-30T00:00:00", "Generation": 0, "Base Model": "lodrick-the-lafted/llama-3.1-8b-instruct-ortho-v7"}, {"eval_name": "lordjia_Llama-3-Cantonese-8B-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/lordjia/Llama-3-Cantonese-8B-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">lordjia/Llama-3-Cantonese-8B-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/lordjia__Llama-3-Cantonese-8B-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "lordjia/Llama-3-Cantonese-8B-Instruct", "Model sha": "ea98e9b1ab3ea0d66e5270816e43d7a70aaaa151", "Average \u2b06\ufe0f": 24.158415833357576, "Hub License": "llama3", "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6669259786256023, "IFEval": 66.69259786256023, "BBH Raw": 0.4814148018954038, "BBH": 26.79103884029782, "MATH Lvl 5 Raw": 0.0823262839879154, "MATH Lvl 5": 8.23262839879154, "GPQA Raw": 0.2936241610738255, "GPQA": 5.8165548098434, "MUSR Raw": 0.4046041666666666, "MUSR": 9.47552083333334, "MMLU-PRO Raw": 0.3514793882978723, "MMLU-PRO": 27.942154255319146, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-16T00:00:00", "Submission Date": "2024-08-03T00:00:00", "Generation": 0, "Base Model": "lordjia/Llama-3-Cantonese-8B-Instruct"}, {"eval_name": "lordjia_Qwen2-Cantonese-7B-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/lordjia/Qwen2-Cantonese-7B-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">lordjia/Qwen2-Cantonese-7B-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/lordjia__Qwen2-Cantonese-7B-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "lordjia/Qwen2-Cantonese-7B-Instruct", "Model sha": "eb8b0faee749d167fd70e74f5e579094c4cfe7fb", "Average \u2b06\ufe0f": 23.50204610523104, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5435278394659503, "IFEval": 54.35278394659503, "BBH Raw": 0.5215311346221223, "BBH": 32.45321665791298, "MATH Lvl 5 Raw": 0.0876132930513595, "MATH Lvl 5": 8.761329305135952, "GPQA Raw": 0.2953020134228188, "GPQA": 6.040268456375841, "MUSR Raw": 0.4003854166666666, "MUSR": 7.814843749999999, "MMLU-PRO Raw": 0.3843085106382978, "MMLU-PRO": 31.589834515366427, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-13T00:00:00", "Submission Date": "2024-08-03T00:00:00", "Generation": 0, "Base Model": "lordjia/Qwen2-Cantonese-7B-Instruct"}, {"eval_name": "macadeliccc_Samantha-Qwen-2-7B_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/macadeliccc/Samantha-Qwen-2-7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">macadeliccc/Samantha-Qwen-2-7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/macadeliccc__Samantha-Qwen-2-7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "macadeliccc/Samantha-Qwen-2-7B", "Model sha": "59058972fa9b56d132d04589eb17cbba277c2826", "Average \u2b06\ufe0f": 24.700030376790338, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 2, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4377152621710395, "IFEval": 43.771526217103954, "BBH Raw": 0.5082341412476951, "BBH": 31.41189390746123, "MATH Lvl 5 Raw": 0.1895770392749244, "MATH Lvl 5": 18.95770392749245, "GPQA Raw": 0.2726510067114094, "GPQA": 3.0201342281879207, "MUSR Raw": 0.4799479166666667, "MUSR": 20.160156250000004, "MMLU-PRO Raw": 0.3779089095744681, "MMLU-PRO": 30.87876773049646, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-15T00:00:00", "Submission Date": "2024-08-05T00:00:00", "Generation": 1, "Base Model": "Qwen/Qwen2-7B"}, {"eval_name": "macadeliccc_magistrate-3.2-3b-base_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe9 continuously pretrained", "T": "\ud83d\udfe9", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/macadeliccc/magistrate-3.2-3b-base\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">macadeliccc/magistrate-3.2-3b-base</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/macadeliccc__magistrate-3.2-3b-base-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "macadeliccc/magistrate-3.2-3b-base", "Model sha": "2a40ac9ca1904fca2c1e69573e27f0ff8039b738", "Average \u2b06\ufe0f": 5.957980545401248, "Hub License": "llama3.2", "Hub \u2764\ufe0f": 1, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1159301763764589, "IFEval": 11.59301763764589, "BBH Raw": 0.3342701056047533, "BBH": 6.910280939116192, "MATH Lvl 5 Raw": 0.0060422960725075, "MATH Lvl 5": 0.6042296072507553, "GPQA Raw": 0.2609060402684564, "GPQA": 1.45413870246085, "MUSR Raw": 0.3975937499999999, "MUSR": 7.532552083333333, "MMLU-PRO Raw": 0.1688829787234042, "MMLU-PRO": 7.65366430260047, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-28T00:00:00", "Submission Date": "2024-10-01T00:00:00", "Generation": 1, "Base Model": "meta-llama/Llama-3.2-3B"}, {"eval_name": "macadeliccc_magistrate-3.2-3b-it_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/macadeliccc/magistrate-3.2-3b-it\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">macadeliccc/magistrate-3.2-3b-it</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/macadeliccc__magistrate-3.2-3b-it-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "macadeliccc/magistrate-3.2-3b-it", "Model sha": "122961278c97195dd59d67b244907359013e4de5", "Average \u2b06\ufe0f": 7.0251356695901634, "Hub License": "llama3.2", "Hub \u2764\ufe0f": 0, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2291874448685044, "IFEval": 22.918744486850443, "BBH Raw": 0.3256506790327196, "BBH": 5.323155419813335, "MATH Lvl 5 Raw": 0.0158610271903323, "MATH Lvl 5": 1.5861027190332326, "GPQA Raw": 0.24748322147651, "GPQA": 0.0, "MUSR Raw": 0.3763229166666667, "MUSR": 5.740364583333334, "MMLU-PRO Raw": 0.1592420212765957, "MMLU-PRO": 6.582446808510639, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-01T00:00:00", "Submission Date": "2024-10-01T00:00:00", "Generation": 2, "Base Model": "meta-llama/Llama-3.2-3B"}, {"eval_name": "maldv_badger-kappa-llama-3-8b_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/maldv/badger-kappa-llama-3-8b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">maldv/badger-kappa-llama-3-8b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/maldv__badger-kappa-llama-3-8b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "maldv/badger-kappa-llama-3-8b", "Model sha": "aa6863eb816ca6ad29453b8aaf846962c4328998", "Average \u2b06\ufe0f": 21.00304297937068, "Hub License": "llama3", "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4694643545791832, "IFEval": 46.94643545791833, "BBH Raw": 0.5084927997756815, "BBH": 30.153238604373765, "MATH Lvl 5 Raw": 0.0762839879154078, "MATH Lvl 5": 7.628398791540786, "GPQA Raw": 0.3028523489932886, "GPQA": 7.046979865771815, "MUSR Raw": 0.3765104166666666, "MUSR": 4.297135416666666, "MMLU-PRO Raw": 0.3695146276595745, "MMLU-PRO": 29.94606973995272, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-02T00:00:00", "Submission Date": "2024-06-27T00:00:00", "Generation": 0, "Base Model": "maldv/badger-kappa-llama-3-8b"}, {"eval_name": "maldv_badger-lambda-llama-3-8b_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/maldv/badger-lambda-llama-3-8b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">maldv/badger-lambda-llama-3-8b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/maldv__badger-lambda-llama-3-8b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "maldv/badger-lambda-llama-3-8b", "Model sha": "8ef157d0d3c12212ca5e70d354869aed90e03f22", "Average \u2b06\ufe0f": 20.75502849599364, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 10, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4860758343417687, "IFEval": 48.60758343417688, "BBH Raw": 0.4963486651044483, "BBH": 28.10305001435372, "MATH Lvl 5 Raw": 0.0830815709969788, "MATH Lvl 5": 8.308157099697885, "GPQA Raw": 0.2818791946308724, "GPQA": 4.250559284116329, "MUSR Raw": 0.3753645833333333, "MUSR": 4.520572916666667, "MMLU-PRO Raw": 0.3766622340425531, "MMLU-PRO": 30.74024822695036, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-10T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "maldv/badger-lambda-llama-3-8b"}, {"eval_name": "maldv_badger-mu-llama-3-8b_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/maldv/badger-mu-llama-3-8b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">maldv/badger-mu-llama-3-8b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/maldv__badger-mu-llama-3-8b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "maldv/badger-mu-llama-3-8b", "Model sha": "952a269bb1e6c18ee772c6d088e74d305df4425d", "Average \u2b06\ufe0f": 19.768293385661035, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.49194581488229, "IFEval": 49.194581488229005, "BBH Raw": 0.514287576852281, "BBH": 30.51396514214568, "MATH Lvl 5 Raw": 0.0226586102719033, "MATH Lvl 5": 2.2658610271903323, "GPQA Raw": 0.259228187919463, "GPQA": 1.230425055928408, "MUSR Raw": 0.3554583333333332, "MUSR": 5.69895833333333, "MMLU-PRO Raw": 0.3673537234042553, "MMLU-PRO": 29.70596926713948, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-27T00:00:00", "Submission Date": "2024-06-27T00:00:00", "Generation": 0, "Base Model": "maldv/badger-mu-llama-3-8b"}, {"eval_name": "maldv_badger-writer-llama-3-8b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/maldv/badger-writer-llama-3-8b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">maldv/badger-writer-llama-3-8b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/maldv__badger-writer-llama-3-8b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "maldv/badger-writer-llama-3-8b", "Model sha": "1d8134d01af87e994571ae16ccd7b31cce42418f", "Average \u2b06\ufe0f": 20.93324210923608, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 9, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5303140112678804, "IFEval": 53.03140112678803, "BBH Raw": 0.4863893856673737, "BBH": 26.8783606145384, "MATH Lvl 5 Raw": 0.0657099697885196, "MATH Lvl 5": 6.570996978851963, "GPQA Raw": 0.2894295302013422, "GPQA": 5.257270693512303, "MUSR Raw": 0.35809375, "MUSR": 3.195052083333334, "MMLU-PRO Raw": 0.3759973404255319, "MMLU-PRO": 30.66637115839244, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-17T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "maldv/badger-writer-llama-3-8b (Merge)"}, {"eval_name": "mattshumer_Reflection-Llama-3.1-70B_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/mattshumer/Reflection-Llama-3.1-70B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">mattshumer/Reflection-Llama-3.1-70B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/mattshumer__Reflection-Llama-3.1-70B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "mattshumer/Reflection-Llama-3.1-70B", "Model sha": "458962ed801fac4eadd01a91a2029a3a82f4cd84", "Average \u2b06\ufe0f": 26.561461535316194, "Hub License": "llama3.1", "Hub \u2764\ufe0f": 1677, "#Params (B)": 70, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6562598350155366, "IFEval": 65.62598350155366, "BBH Raw": 0.5998839958220125, "BBH": 42.38944488022307, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2609060402684564, "GPQA": 1.45413870246085, "MUSR Raw": 0.4126666666666667, "MUSR": 10.016666666666666, "MMLU-PRO Raw": 0.4589428191489361, "MMLU-PRO": 39.882535460992905, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-05T00:00:00", "Submission Date": "2024-09-09T00:00:00", "Generation": 2, "Base Model": "meta-llama/Meta-Llama-3.1-70B"}, {"eval_name": "mattshumer_ref_70_e3_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/mattshumer/ref_70_e3\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">mattshumer/ref_70_e3</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/mattshumer__ref_70_e3-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "mattshumer/ref_70_e3", "Model sha": "5d2d9dbb9e0bf61879255f63f1b787296fe524cc", "Average \u2b06\ufe0f": 30.737996436280383, "Hub License": "llama3.1", "Hub \u2764\ufe0f": 51, "#Params (B)": 70, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6294321289733462, "IFEval": 62.94321289733463, "BBH Raw": 0.6500839481104265, "BBH": 49.27446660003019, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.3355704697986577, "GPQA": 11.409395973154364, "MUSR Raw": 0.4327604166666667, "MUSR": 12.995052083333334, "MMLU-PRO Raw": 0.5302526595744681, "MMLU-PRO": 47.80585106382979, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-08T00:00:00", "Submission Date": "2024-09-08T00:00:00", "Generation": 2, "Base Model": "meta-llama/Meta-Llama-3.1-70B"}, {"eval_name": "maywell_Qwen2-7B-Multilingual-RP_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/maywell/Qwen2-7B-Multilingual-RP\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">maywell/Qwen2-7B-Multilingual-RP</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/maywell__Qwen2-7B-Multilingual-RP-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "maywell/Qwen2-7B-Multilingual-RP", "Model sha": "487e8f0498419e4d1188f661dbb63bd629be4638", "Average \u2b06\ufe0f": 23.148763889766204, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 36, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4347176602525743, "IFEval": 43.47176602525742, "BBH Raw": 0.5062058680861069, "BBH": 30.54356147647468, "MATH Lvl 5 Raw": 0.2061933534743202, "MATH Lvl 5": 20.619335347432024, "GPQA Raw": 0.296979865771812, "GPQA": 6.263982102908276, "MUSR Raw": 0.3695625, "MUSR": 6.228645833333334, "MMLU-PRO Raw": 0.3858876329787234, "MMLU-PRO": 31.765292553191493, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-24T00:00:00", "Submission Date": "2024-09-05T00:00:00", "Generation": 0, "Base Model": "maywell/Qwen2-7B-Multilingual-RP"}, {"eval_name": "meditsolutions_Llama-3.2-SUN-2.4B-checkpoint-26000_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/meditsolutions/Llama-3.2-SUN-2.4B-checkpoint-26000\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">meditsolutions/Llama-3.2-SUN-2.4B-checkpoint-26000</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/meditsolutions__Llama-3.2-SUN-2.4B-checkpoint-26000-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "meditsolutions/Llama-3.2-SUN-2.4B-checkpoint-26000", "Model sha": "1300885555ca8bbed20a57cf0ec9f7ae014200c3", "Average \u2b06\ufe0f": 7.942075095506563, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 2, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2813944777634454, "IFEval": 28.139447776344547, "BBH Raw": 0.3017752699243885, "BBH": 2.8953053502640427, "MATH Lvl 5 Raw": 0.0060422960725075, "MATH Lvl 5": 0.6042296072507553, "GPQA Raw": 0.2776845637583892, "GPQA": 3.691275167785232, "MUSR Raw": 0.4103333333333332, "MUSR": 8.491666666666665, "MMLU-PRO Raw": 0.1344747340425532, "MMLU-PRO": 3.830526004728132, "Maintainer's Highlight": false, "Upload To Hub Date": "", "Submission Date": "2024-10-04T00:00:00", "Generation": 0, "Base Model": "Removed"}, {"eval_name": "meditsolutions_Llama-3.2-SUN-2.4B-checkpoint-34800_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/meditsolutions/Llama-3.2-SUN-2.4B-checkpoint-34800\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">meditsolutions/Llama-3.2-SUN-2.4B-checkpoint-34800</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/meditsolutions__Llama-3.2-SUN-2.4B-checkpoint-34800-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "meditsolutions/Llama-3.2-SUN-2.4B-checkpoint-34800", "Model sha": "ef65f05f577a69a1992349c8d33c96cd099844f7", "Average \u2b06\ufe0f": 8.042045147015047, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 2, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2500953026857626, "IFEval": 25.009530268576263, "BBH Raw": 0.3161124673749052, "BBH": 5.466179719646344, "MATH Lvl 5 Raw": 0.0015105740181268, "MATH Lvl 5": 0.1510574018126888, "GPQA Raw": 0.2860738255033557, "GPQA": 4.809843400447425, "MUSR Raw": 0.4022395833333334, "MUSR": 8.846614583333333, "MMLU-PRO Raw": 0.135721409574468, "MMLU-PRO": 3.969045508274229, "Maintainer's Highlight": false, "Upload To Hub Date": "", "Submission Date": "2024-10-05T00:00:00", "Generation": 0, "Base Model": "Removed"}, {"eval_name": "meraGPT_mera-mix-4x7B_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/meraGPT/mera-mix-4x7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">meraGPT/mera-mix-4x7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/meraGPT__mera-mix-4x7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "meraGPT/mera-mix-4x7B", "Model sha": "09d965c5ef9b66ce419986027e03a915cb869e43", "Average \u2b06\ufe0f": 17.77943003203333, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 18, "#Params (B)": 24, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4831779677921249, "IFEval": 48.317796779212486, "BBH Raw": 0.4018989916366171, "BBH": 17.48643895465503, "MATH Lvl 5 Raw": 0.0490936555891238, "MATH Lvl 5": 4.909365558912387, "GPQA Raw": 0.3045302013422818, "GPQA": 7.270693512304249, "MUSR Raw": 0.40565625, "MUSR": 9.273697916666668, "MMLU-PRO Raw": 0.2747672872340425, "MMLU-PRO": 19.418587470449168, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-13T00:00:00", "Submission Date": "2024-06-27T00:00:00", "Generation": 0, "Base Model": "meraGPT/mera-mix-4x7B"}, {"eval_name": "meta-llama_Llama-2-13b-chat-hf_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/meta-llama/Llama-2-13b-chat-hf\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">meta-llama/Llama-2-13b-chat-hf</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/meta-llama__Llama-2-13b-chat-hf-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "meta-llama/Llama-2-13b-chat-hf", "Model sha": "a2cb7a712bb6e5e736ca7f8cd98167f81a0b5bd8", "Average \u2b06\ufe0f": 11.00375415839273, "Hub License": "llama2", "Hub \u2764\ufe0f": 1020, "#Params (B)": 13, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.398472719052115, "IFEval": 39.8472719052115, "BBH Raw": 0.3342736706671418, "BBH": 7.155379968626988, "MATH Lvl 5 Raw": 0.0060422960725075, "MATH Lvl 5": 0.6042296072507553, "GPQA Raw": 0.2315436241610738, "GPQA": 0.0, "MUSR Raw": 0.4007291666666666, "MUSR": 8.1578125, "MMLU-PRO Raw": 0.1923204787234042, "MMLU-PRO": 10.257830969267138, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-07-13T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "meta-llama/Llama-2-13b-chat-hf"}, {"eval_name": "meta-llama_Llama-2-13b-hf_float16", "Precision": "float16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/meta-llama/Llama-2-13b-hf\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">meta-llama/Llama-2-13b-hf</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/meta-llama__Llama-2-13b-hf-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "meta-llama/Llama-2-13b-hf", "Model sha": "5c31dfb671ce7cfe2d7bb7c04375e44c55e815b1", "Average \u2b06\ufe0f": 10.989657280367652, "Hub License": "llama2", "Hub \u2764\ufe0f": 572, "#Params (B)": 13, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2482468738502728, "IFEval": 24.82468738502728, "BBH Raw": 0.4125624223383505, "BBH": 17.222559825058127, "MATH Lvl 5 Raw": 0.0105740181268882, "MATH Lvl 5": 1.0574018126888218, "GPQA Raw": 0.2810402684563758, "GPQA": 4.138702460850116, "MUSR Raw": 0.35375, "MUSR": 3.385416666666666, "MMLU-PRO Raw": 0.237782579787234, "MMLU-PRO": 15.309175531914892, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-07-13T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "meta-llama/Llama-2-13b-hf"}, {"eval_name": "meta-llama_Llama-2-70b-chat-hf_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/meta-llama/Llama-2-70b-chat-hf\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">meta-llama/Llama-2-70b-chat-hf</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/meta-llama__Llama-2-70b-chat-hf-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "meta-llama/Llama-2-70b-chat-hf", "Model sha": "e9149a12809580e8602995856f8098ce973d1080", "Average \u2b06\ufe0f": 12.733816621748955, "Hub License": "llama2", "Hub \u2764\ufe0f": 2150, "#Params (B)": 68, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4957922756065018, "IFEval": 49.57922756065019, "BBH Raw": 0.3042474146164265, "BBH": 4.613767082590614, "MATH Lvl 5 Raw": 0.0090634441087613, "MATH Lvl 5": 0.906344410876133, "GPQA Raw": 0.2642617449664429, "GPQA": 1.9015659955257265, "MUSR Raw": 0.3686666666666667, "MUSR": 3.483333333333336, "MMLU-PRO Raw": 0.2432679521276596, "MMLU-PRO": 15.918661347517732, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-07-14T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "meta-llama/Llama-2-70b-chat-hf"}, {"eval_name": "meta-llama_Llama-2-70b-hf_float16", "Precision": "float16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/meta-llama/Llama-2-70b-hf\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">meta-llama/Llama-2-70b-hf</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/meta-llama__Llama-2-70b-hf-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "meta-llama/Llama-2-70b-hf", "Model sha": "3aba440b59558f995867ba6e1f58f21d0336b5bb", "Average \u2b06\ufe0f": 18.246717437525763, "Hub License": "llama2", "Hub \u2764\ufe0f": 827, "#Params (B)": 68, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2406780675274937, "IFEval": 24.06780675274937, "BBH Raw": 0.5472591190449342, "BBH": 35.900061863721675, "MATH Lvl 5 Raw": 0.0249244712990936, "MATH Lvl 5": 2.492447129909366, "GPQA Raw": 0.3028523489932886, "GPQA": 7.046979865771815, "MUSR Raw": 0.4123541666666666, "MUSR": 9.777604166666668, "MMLU-PRO Raw": 0.3717586436170212, "MMLU-PRO": 30.1954048463357, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-07-11T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "meta-llama/Llama-2-70b-hf"}, {"eval_name": "meta-llama_Llama-2-7b-chat-hf_float16", "Precision": "float16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/meta-llama/Llama-2-7b-chat-hf\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">meta-llama/Llama-2-7b-chat-hf</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/meta-llama__Llama-2-7b-chat-hf-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "meta-llama/Llama-2-7b-chat-hf", "Model sha": "f5db02db724555f92da89c216ac04704f23d4590", "Average \u2b06\ufe0f": 9.395485278250948, "Hub License": "llama2", "Hub \u2764\ufe0f": 3903, "#Params (B)": 6, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3986478100329348, "IFEval": 39.86478100329349, "BBH Raw": 0.3113546355002185, "BBH": 4.459171645959485, "MATH Lvl 5 Raw": 0.0067975830815709, "MATH Lvl 5": 0.6797583081570997, "GPQA Raw": 0.2533557046979866, "GPQA": 0.4474272930648763, "MUSR Raw": 0.3675520833333333, "MUSR": 3.27734375, "MMLU-PRO Raw": 0.1687998670212765, "MMLU-PRO": 7.644429669030731, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-07-13T00:00:00", "Submission Date": "2024-08-30T00:00:00", "Generation": 0, "Base Model": "meta-llama/Llama-2-7b-chat-hf"}, {"eval_name": "meta-llama_Llama-2-7b-hf_float16", "Precision": "float16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/meta-llama/Llama-2-7b-hf\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">meta-llama/Llama-2-7b-hf</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/meta-llama__Llama-2-7b-hf-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "meta-llama/Llama-2-7b-hf", "Model sha": "01c7f73d771dfac7d292323805ebc428287df4f9", "Average \u2b06\ufe0f": 8.718240778815948, "Hub License": "llama2", "Hub \u2764\ufe0f": 1729, "#Params (B)": 6, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2518938638368418, "IFEval": 25.18938638368418, "BBH Raw": 0.3496195819982183, "BBH": 10.35141665784897, "MATH Lvl 5 Raw": 0.0120845921450151, "MATH Lvl 5": 1.2084592145015105, "GPQA Raw": 0.2667785234899328, "GPQA": 2.2371364653243813, "MUSR Raw": 0.3700624999999999, "MUSR": 3.7578125, "MMLU-PRO Raw": 0.1860871010638297, "MMLU-PRO": 9.56523345153664, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-07-13T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "meta-llama/Llama-2-7b-hf"}, {"eval_name": "meta-llama_Llama-3.2-1B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/meta-llama/Llama-3.2-1B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">meta-llama/Llama-3.2-1B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/meta-llama__Llama-3.2-1B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "meta-llama/Llama-3.2-1B", "Model sha": "a7c18587d7f473bfea02aa5639aa349403307b54", "Average \u2b06\ufe0f": 4.031494495415088, "Hub License": "llama3.2", "Hub \u2764\ufe0f": 497, "#Params (B)": 1, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.147779004153424, "IFEval": 14.7779004153424, "BBH Raw": 0.3114954096460809, "BBH": 4.366029656556756, "MATH Lvl 5 Raw": 0.0022658610271903, "MATH Lvl 5": 0.2265861027190332, "GPQA Raw": 0.2281879194630872, "GPQA": 0.0, "MUSR Raw": 0.3447291666666667, "MUSR": 2.5578125000000003, "MMLU-PRO Raw": 0.120345744680851, "MMLU-PRO": 2.2606382978723394, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-09-18T00:00:00", "Submission Date": "2024-09-23T00:00:00", "Generation": 0, "Base Model": "meta-llama/Llama-3.2-1B"}, {"eval_name": "meta-llama_Llama-3.2-1B-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">meta-llama/Llama-3.2-1B-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/meta-llama__Llama-3.2-1B-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "meta-llama/Llama-3.2-1B-Instruct", "Model sha": "d0a2081ed47e20ce524e8bc5d132f3fad2f69ff0", "Average \u2b06\ufe0f": 13.763368025554035, "Hub License": "llama3.2", "Hub \u2764\ufe0f": 350, "#Params (B)": 1, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5698313807364459, "IFEval": 56.9831380736446, "BBH Raw": 0.3496849806176826, "BBH": 8.742521312303046, "MATH Lvl 5 Raw": 0.0294561933534743, "MATH Lvl 5": 2.9456193353474323, "GPQA Raw": 0.2751677852348993, "GPQA": 3.355704697986576, "MUSR Raw": 0.3328541666666667, "MUSR": 2.973437500000001, "MMLU-PRO Raw": 0.1682180851063829, "MMLU-PRO": 7.579787234042552, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-09-18T00:00:00", "Submission Date": "2024-09-23T00:00:00", "Generation": 0, "Base Model": "meta-llama/Llama-3.2-1B-Instruct"}, {"eval_name": "meta-llama_Llama-3.2-3B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/meta-llama/Llama-3.2-3B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">meta-llama/Llama-3.2-3B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/meta-llama__Llama-3.2-3B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "meta-llama/Llama-3.2-3B", "Model sha": "95c102307f55fbd6d18ddf28bfbcb537ffdc2806", "Average \u2b06\ufe0f": 8.584529665203304, "Hub License": "llama3.2", "Hub \u2764\ufe0f": 200, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1337406969064304, "IFEval": 13.374069690643047, "BBH Raw": 0.3905117116991059, "BBH": 14.232664884364109, "MATH Lvl 5 Raw": 0.0120845921450151, "MATH Lvl 5": 1.2084592145015105, "GPQA Raw": 0.2676174496644295, "GPQA": 2.348993288590602, "MUSR Raw": 0.35771875, "MUSR": 3.81484375, "MMLU-PRO Raw": 0.2487533244680851, "MMLU-PRO": 16.528147163120565, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-09-18T00:00:00", "Submission Date": "2024-09-27T00:00:00", "Generation": 0, "Base Model": "meta-llama/Llama-3.2-3B"}, {"eval_name": "meta-llama_Llama-3.2-3B-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">meta-llama/Llama-3.2-3B-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/meta-llama__Llama-3.2-3B-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "meta-llama/Llama-3.2-3B-Instruct", "Model sha": "276b29ce8303c9b88966a9b32fc75692dce4d8e1", "Average \u2b06\ufe0f": 23.852183536897183, "Hub License": "llama3.2", "Hub \u2764\ufe0f": 336, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7393161256576994, "IFEval": 73.93161256576994, "BBH Raw": 0.4610070239466069, "BBH": 24.059186446885477, "MATH Lvl 5 Raw": 0.1555891238670695, "MATH Lvl 5": 15.55891238670695, "GPQA Raw": 0.2785234899328859, "GPQA": 3.803131991051453, "MUSR Raw": 0.3528541666666667, "MUSR": 1.3734374999999996, "MMLU-PRO Raw": 0.3194813829787234, "MMLU-PRO": 24.386820330969268, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-09-18T00:00:00", "Submission Date": "2024-09-27T00:00:00", "Generation": 0, "Base Model": "meta-llama/Llama-3.2-3B-Instruct"}, {"eval_name": "meta-llama_Meta-Llama-3-70B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/meta-llama/Meta-Llama-3-70B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">meta-llama/Meta-Llama-3-70B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/meta-llama__Meta-Llama-3-70B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "meta-llama/Meta-Llama-3-70B", "Model sha": "b4d08b7db49d488da3ac49adf25a6b9ac01ae338", "Average \u2b06\ufe0f": 26.36547101753479, "Hub License": "llama3", "Hub \u2764\ufe0f": 807, "#Params (B)": 70, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1603190645265673, "IFEval": 16.031906452656727, "BBH Raw": 0.6461074599904467, "BBH": 48.709812647505885, "MATH Lvl 5 Raw": 0.1654078549848942, "MATH Lvl 5": 16.540785498489427, "GPQA Raw": 0.3976510067114094, "GPQA": 19.686800894854585, "MUSR Raw": 0.4518229166666667, "MUSR": 16.011197916666664, "MMLU-PRO Raw": 0.4709109042553192, "MMLU-PRO": 41.21232269503546, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-04-17T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "meta-llama/Meta-Llama-3-70B"}, {"eval_name": "meta-llama_Meta-Llama-3-70B-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/meta-llama/Meta-Llama-3-70B-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">meta-llama/Meta-Llama-3-70B-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/meta-llama__Meta-Llama-3-70B-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "meta-llama/Meta-Llama-3-70B-Instruct", "Model sha": "7129260dd854a80eb10ace5f61c20324b472b31c", "Average \u2b06\ufe0f": 36.18340237700426, "Hub License": "llama3", "Hub \u2764\ufe0f": 1407, "#Params (B)": 70, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.8099077115387172, "IFEval": 80.99077115387172, "BBH Raw": 0.6546699432372051, "BBH": 50.18513318440344, "MATH Lvl 5 Raw": 0.2333836858006042, "MATH Lvl 5": 23.338368580060425, "GPQA Raw": 0.2869127516778523, "GPQA": 4.921700223713646, "MUSR Raw": 0.4153645833333333, "MUSR": 10.92057291666667, "MMLU-PRO Raw": 0.5206948138297872, "MMLU-PRO": 46.74386820330969, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-04-17T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 1, "Base Model": "meta-llama/Meta-Llama-3-70B"}, {"eval_name": "meta-llama_Meta-Llama-3-8B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/meta-llama/Meta-Llama-3-8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">meta-llama/Meta-Llama-3-8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/meta-llama__Meta-Llama-3-8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "meta-llama/Meta-Llama-3-8B", "Model sha": "62bd457b6fe961a42a631306577e622c83876cb6", "Average \u2b06\ufe0f": 13.412859085784763, "Hub License": "llama3", "Hub \u2764\ufe0f": 5741, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1455061459150609, "IFEval": 14.550614591506092, "BBH Raw": 0.4597905195240255, "BBH": 24.50076379676797, "MATH Lvl 5 Raw": 0.0324773413897281, "MATH Lvl 5": 3.2477341389728096, "GPQA Raw": 0.3053691275167785, "GPQA": 7.38255033557047, "MUSR Raw": 0.36140625, "MUSR": 6.242447916666666, "MMLU-PRO Raw": 0.3209773936170212, "MMLU-PRO": 24.553043735224584, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-04-17T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "meta-llama/Meta-Llama-3-8B"}, {"eval_name": "meta-llama_Meta-Llama-3-8B-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">meta-llama/Meta-Llama-3-8B-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/meta-llama__Meta-Llama-3-8B-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "meta-llama/Meta-Llama-3-8B-Instruct", "Model sha": "e1945c40cd546c78e41f1151f4db032b271faeaa", "Average \u2b06\ufe0f": 23.90873569393684, "Hub License": "llama3", "Hub \u2764\ufe0f": 3511, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7408398604591373, "IFEval": 74.08398604591373, "BBH Raw": 0.4988711113616952, "BBH": 28.24494957634361, "MATH Lvl 5 Raw": 0.086858006042296, "MATH Lvl 5": 8.685800604229607, "GPQA Raw": 0.259228187919463, "GPQA": 1.230425055928408, "MUSR Raw": 0.3568229166666667, "MUSR": 1.602864583333335, "MMLU-PRO Raw": 0.3664394946808511, "MMLU-PRO": 29.604388297872337, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-04-17T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "meta-llama/Meta-Llama-3-8B-Instruct"}, {"eval_name": "meta-llama_Meta-Llama-3-8B-Instruct_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">meta-llama/Meta-Llama-3-8B-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/meta-llama__Meta-Llama-3-8B-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "meta-llama/Meta-Llama-3-8B-Instruct", "Model sha": "e1945c40cd546c78e41f1151f4db032b271faeaa", "Average \u2b06\ufe0f": 20.48327827784863, "Hub License": "llama3", "Hub \u2764\ufe0f": 3511, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4782322016693484, "IFEval": 47.823220166934846, "BBH Raw": 0.4910264175128683, "BBH": 26.795283502573653, "MATH Lvl 5 Raw": 0.0838368580060422, "MATH Lvl 5": 8.38368580060423, "GPQA Raw": 0.2927852348993288, "GPQA": 5.7046979865771785, "MUSR Raw": 0.3805416666666666, "MUSR": 5.401041666666668, "MMLU-PRO Raw": 0.359125664893617, "MMLU-PRO": 28.791740543735223, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-04-17T00:00:00", "Submission Date": "2024-07-08T00:00:00", "Generation": 0, "Base Model": "meta-llama/Meta-Llama-3-8B-Instruct"}, {"eval_name": "meta-llama_Meta-Llama-3.1-70B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/meta-llama/Meta-Llama-3.1-70B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">meta-llama/Meta-Llama-3.1-70B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/meta-llama__Meta-Llama-3.1-70B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "meta-llama/Meta-Llama-3.1-70B", "Model sha": "f7d3cc45ed4ff669a354baf2e0f05e65799a0bee", "Average \u2b06\ufe0f": 25.91068915656829, "Hub License": "llama3.1", "Hub \u2764\ufe0f": 282, "#Params (B)": 70, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.1684375235486287, "IFEval": 16.843752354862875, "BBH Raw": 0.626006918317161, "BBH": 46.39941295581887, "MATH Lvl 5 Raw": 0.1669184290030211, "MATH Lvl 5": 16.691842900302113, "GPQA Raw": 0.3875838926174497, "GPQA": 18.34451901565996, "MUSR Raw": 0.4571875, "MUSR": 16.581770833333337, "MMLU-PRO Raw": 0.4654255319148936, "MMLU-PRO": 40.602836879432616, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-07-14T00:00:00", "Submission Date": "2024-07-23T00:00:00", "Generation": 0, "Base Model": "meta-llama/Meta-Llama-3.1-70B"}, {"eval_name": "meta-llama_Meta-Llama-3.1-70B-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/meta-llama/Meta-Llama-3.1-70B-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">meta-llama/Meta-Llama-3.1-70B-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/meta-llama__Meta-Llama-3.1-70B-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "meta-llama/Meta-Llama-3.1-70B-Instruct", "Model sha": "b9461463b511ed3c0762467538ea32cf7c9669f2", "Average \u2b06\ufe0f": 41.73572870888848, "Hub License": "llama3.1", "Hub \u2764\ufe0f": 578, "#Params (B)": 70, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.8668854195756149, "IFEval": 86.6885419575615, "BBH Raw": 0.6917287453663654, "BBH": 55.92799173898473, "MATH Lvl 5 Raw": 0.2802114803625378, "MATH Lvl 5": 28.02114803625378, "GPQA Raw": 0.3565436241610738, "GPQA": 14.205816554809845, "MUSR Raw": 0.4580625, "MUSR": 17.691145833333334, "MMLU-PRO Raw": 0.5309175531914894, "MMLU-PRO": 47.87972813238771, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-07-16T00:00:00", "Submission Date": "2024-08-15T00:00:00", "Generation": 1, "Base Model": "meta-llama/Meta-Llama-3.1-70B"}, {"eval_name": "meta-llama_Meta-Llama-3.1-8B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/meta-llama/Meta-Llama-3.1-8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">meta-llama/Meta-Llama-3.1-8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/meta-llama__Meta-Llama-3.1-8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "meta-llama/Meta-Llama-3.1-8B", "Model sha": "e5c39e551424c763dbc3e58e32ef2999d33a6d8d", "Average \u2b06\ufe0f": 13.78094944355508, "Hub License": "llama3.1", "Hub \u2764\ufe0f": 945, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.1269963696325749, "IFEval": 12.69963696325749, "BBH Raw": 0.4666136555003996, "BBH": 25.29477985108717, "MATH Lvl 5 Raw": 0.04607250755287, "MATH Lvl 5": 4.607250755287009, "GPQA Raw": 0.2961409395973154, "GPQA": 6.152125279642054, "MUSR Raw": 0.3825208333333333, "MUSR": 8.981770833333334, "MMLU-PRO Raw": 0.3245511968085106, "MMLU-PRO": 24.950132978723403, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-07-14T00:00:00", "Submission Date": "2024-07-23T00:00:00", "Generation": 0, "Base Model": "meta-llama/Meta-Llama-3.1-8B"}, {"eval_name": "meta-llama_Meta-Llama-3.1-8B-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">meta-llama/Meta-Llama-3.1-8B-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/meta-llama__Meta-Llama-3.1-8B-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "meta-llama/Meta-Llama-3.1-8B-Instruct", "Model sha": "df34336b42332c6d360959e259cd6271c6a09fd4", "Average \u2b06\ufe0f": 27.914931811294263, "Hub License": "llama3.1", "Hub \u2764\ufe0f": 2785, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7855778224001206, "IFEval": 78.55778224001206, "BBH Raw": 0.5073267838961463, "BBH": 29.89275635245275, "MATH Lvl 5 Raw": 0.1759818731117824, "MATH Lvl 5": 17.598187311178247, "GPQA Raw": 0.2676174496644295, "GPQA": 2.348993288590602, "MUSR Raw": 0.3869895833333333, "MUSR": 8.407031249999996, "MMLU-PRO Raw": 0.3761635638297872, "MMLU-PRO": 30.68484042553192, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-07-18T00:00:00", "Submission Date": "2024-08-15T00:00:00", "Generation": 1, "Base Model": "meta-llama/Meta-Llama-3.1-8B"}, {"eval_name": "microsoft_DialoGPT-medium_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "GPT2LMHeadModel", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/microsoft/DialoGPT-medium\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">microsoft/DialoGPT-medium</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/microsoft__DialoGPT-medium-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "microsoft/DialoGPT-medium", "Model sha": "7b40bb0f92c45fefa957d088000d8648e5c7fa33", "Average \u2b06\ufe0f": 5.251433606790305, "Hub License": "mit", "Hub \u2764\ufe0f": 324, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.1479042274498331, "IFEval": 14.79042274498331, "BBH Raw": 0.3014156380141994, "BBH": 2.5568557723352243, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2541946308724832, "GPQA": 0.5592841163310973, "MUSR Raw": 0.4286666666666667, "MUSR": 12.283333333333331, "MMLU-PRO Raw": 0.1118683510638298, "MMLU-PRO": 1.3187056737588652, "Maintainer's Highlight": true, "Upload To Hub Date": "2022-03-02T00:00:00", "Submission Date": "2024-06-13T00:00:00", "Generation": 0, "Base Model": "microsoft/DialoGPT-medium"}, {"eval_name": "microsoft_Orca-2-13b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/microsoft/Orca-2-13b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">microsoft/Orca-2-13b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/microsoft__Orca-2-13b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "microsoft/Orca-2-13b", "Model sha": "2539ff53e6baa4cc603774ad5a2d646f4041ea4e", "Average \u2b06\ufe0f": 18.136815704093205, "Hub License": "other", "Hub \u2764\ufe0f": 662, "#Params (B)": 13, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3127933882099496, "IFEval": 31.27933882099496, "BBH Raw": 0.4884489728839609, "BBH": 27.308019499942574, "MATH Lvl 5 Raw": 0.0098187311178247, "MATH Lvl 5": 0.9818731117824772, "GPQA Raw": 0.2802013422818792, "GPQA": 4.026845637583895, "MUSR Raw": 0.5129687500000001, "MUSR": 25.787760416666668, "MMLU-PRO Raw": 0.2749335106382978, "MMLU-PRO": 19.437056737588648, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-11-14T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "microsoft/Orca-2-13b"}, {"eval_name": "microsoft_Orca-2-7b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/microsoft/Orca-2-7b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">microsoft/Orca-2-7b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/microsoft__Orca-2-7b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "microsoft/Orca-2-7b", "Model sha": "60e31e6bdcf582ad103b807cb74b73ee1d2c4b17", "Average \u2b06\ufe0f": 14.216008329134612, "Hub License": "other", "Hub \u2764\ufe0f": 213, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2183462102776189, "IFEval": 21.83462102776189, "BBH Raw": 0.4452132267545943, "BBH": 22.429468402818458, "MATH Lvl 5 Raw": 0.0083081570996978, "MATH Lvl 5": 0.8308157099697886, "GPQA Raw": 0.2609060402684564, "GPQA": 1.45413870246085, "MUSR Raw": 0.5026145833333333, "MUSR": 24.093489583333326, "MMLU-PRO Raw": 0.2318816489361702, "MMLU-PRO": 14.653516548463358, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-11-14T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "microsoft/Orca-2-7b"}, {"eval_name": "microsoft_Phi-3-medium-128k-instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Phi3ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/microsoft/Phi-3-medium-128k-instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">microsoft/Phi-3-medium-128k-instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/microsoft__Phi-3-medium-128k-instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "microsoft/Phi-3-medium-128k-instruct", "Model sha": "fa7d2aa4f5ea69b2e36b20d050cdae79c9bfbb3f", "Average \u2b06\ufe0f": 31.522831503399715, "Hub License": "mit", "Hub \u2764\ufe0f": 366, "#Params (B)": 13, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6040029344361849, "IFEval": 60.400293443618494, "BBH Raw": 0.6382322530870549, "BBH": 48.46045127399018, "MATH Lvl 5 Raw": 0.161631419939577, "MATH Lvl 5": 16.1631419939577, "GPQA Raw": 0.3364093959731543, "GPQA": 11.521252796420578, "MUSR Raw": 0.4129479166666667, "MUSR": 11.351822916666665, "MMLU-PRO Raw": 0.4711602393617021, "MMLU-PRO": 41.24002659574468, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-05-07T00:00:00", "Submission Date": "2024-08-21T00:00:00", "Generation": 0, "Base Model": "microsoft/Phi-3-medium-128k-instruct"}, {"eval_name": "microsoft_Phi-3-medium-4k-instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Phi3ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/microsoft/Phi-3-medium-4k-instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">microsoft/Phi-3-medium-4k-instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/microsoft__Phi-3-medium-4k-instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "microsoft/Phi-3-medium-4k-instruct", "Model sha": "d194e4e74ffad5a5e193e26af25bcfc80c7f1ffc", "Average \u2b06\ufe0f": 32.6696634675738, "Hub License": "mit", "Hub \u2764\ufe0f": 210, "#Params (B)": 13, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6422713954529538, "IFEval": 64.22713954529537, "BBH Raw": 0.6412464890555547, "BBH": 49.38061007422016, "MATH Lvl 5 Raw": 0.1699395770392749, "MATH Lvl 5": 16.993957703927492, "GPQA Raw": 0.3364093959731543, "GPQA": 11.521252796420578, "MUSR Raw": 0.42575, "MUSR": 13.052083333333334, "MMLU-PRO Raw": 0.4675864361702128, "MMLU-PRO": 40.84293735224587, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-05-07T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "microsoft/Phi-3-medium-4k-instruct"}, {"eval_name": "microsoft_Phi-3-mini-128k-instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Phi3ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/microsoft/Phi-3-mini-128k-instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">microsoft/Phi-3-mini-128k-instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/microsoft__Phi-3-mini-128k-instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "microsoft/Phi-3-mini-128k-instruct", "Model sha": "5be6479b4bc06a081e8f4c6ece294241ccd32dec", "Average \u2b06\ufe0f": 25.4878179882604, "Hub License": "mit", "Hub \u2764\ufe0f": 1585, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5976331688807919, "IFEval": 59.76331688807919, "BBH Raw": 0.5574531792679852, "BBH": 37.09976663224031, "MATH Lvl 5 Raw": 0.0891238670694864, "MATH Lvl 5": 8.91238670694864, "GPQA Raw": 0.3179530201342282, "GPQA": 9.060402684563762, "MUSR Raw": 0.3936875, "MUSR": 7.710937500000003, "MMLU-PRO Raw": 0.3734208776595745, "MMLU-PRO": 30.38009751773049, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-04-22T00:00:00", "Submission Date": "2024-08-21T00:00:00", "Generation": 0, "Base Model": "microsoft/Phi-3-mini-128k-instruct"}, {"eval_name": "microsoft_Phi-3-mini-4k-instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Phi3ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/microsoft/Phi-3-mini-4k-instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">microsoft/Phi-3-mini-4k-instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/microsoft__Phi-3-mini-4k-instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "microsoft/Phi-3-mini-4k-instruct", "Model sha": "ff07dc01615f8113924aed013115ab2abd32115b", "Average \u2b06\ufe0f": 25.967732638041607, "Hub License": "mit", "Hub \u2764\ufe0f": 1042, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5612884923115112, "IFEval": 56.12884923115112, "BBH Raw": 0.5675972626334875, "BBH": 39.2693352377728, "MATH Lvl 5 Raw": 0.1163141993957704, "MATH Lvl 5": 11.63141993957704, "GPQA Raw": 0.3196308724832215, "GPQA": 9.284116331096197, "MUSR Raw": 0.3950208333333333, "MUSR": 7.644270833333336, "MMLU-PRO Raw": 0.3866356382978723, "MMLU-PRO": 31.848404255319146, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-04-22T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "microsoft/Phi-3-mini-4k-instruct"}, {"eval_name": "microsoft_Phi-3-mini-4k-instruct_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Phi3ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/microsoft/Phi-3-mini-4k-instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">microsoft/Phi-3-mini-4k-instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/microsoft__Phi-3-mini-4k-instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "microsoft/Phi-3-mini-4k-instruct", "Model sha": "c1358f8a35e6d2af81890deffbbfa575b978c62f", "Average \u2b06\ufe0f": 27.197118655878285, "Hub License": "mit", "Hub \u2764\ufe0f": 1042, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.547674614467391, "IFEval": 54.76746144673909, "BBH Raw": 0.5490718919495822, "BBH": 36.55985530518785, "MATH Lvl 5 Raw": 0.1419939577039275, "MATH Lvl 5": 14.19939577039275, "GPQA Raw": 0.3322147651006711, "GPQA": 10.96196868008949, "MUSR Raw": 0.4284166666666666, "MUSR": 13.118749999999997, "MMLU-PRO Raw": 0.4021775265957447, "MMLU-PRO": 33.57528073286053, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-04-22T00:00:00", "Submission Date": "2024-07-02T00:00:00", "Generation": 0, "Base Model": "microsoft/Phi-3-mini-4k-instruct"}, {"eval_name": "microsoft_Phi-3-small-128k-instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Phi3SmallForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/microsoft/Phi-3-small-128k-instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">microsoft/Phi-3-small-128k-instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/microsoft__Phi-3-small-128k-instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "microsoft/Phi-3-small-128k-instruct", "Model sha": "f80aaa30bfc64c2b8ab214b541d9050e97163bc4", "Average \u2b06\ufe0f": 28.59099156952276, "Hub License": "mit", "Hub \u2764\ufe0f": 168, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6368258443153056, "IFEval": 63.68258443153056, "BBH Raw": 0.6202176778696983, "BBH": 45.63406964144793, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.3171140939597315, "GPQA": 8.948545861297541, "MUSR Raw": 0.43784375, "MUSR": 14.49713541666666, "MMLU-PRO Raw": 0.4490525265957447, "MMLU-PRO": 38.783614066193856, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-05-07T00:00:00", "Submission Date": "2024-06-13T00:00:00", "Generation": 0, "Base Model": "microsoft/Phi-3-small-128k-instruct"}, {"eval_name": "microsoft_Phi-3-small-8k-instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Phi3SmallForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/microsoft/Phi-3-small-8k-instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">microsoft/Phi-3-small-8k-instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/microsoft__Phi-3-small-8k-instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "microsoft/Phi-3-small-8k-instruct", "Model sha": "1535ae26fb4faada95c6950e8bc6e867cdad6b00", "Average \u2b06\ufe0f": 29.63767022277582, "Hub License": "mit", "Hub \u2764\ufe0f": 157, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6496651107949131, "IFEval": 64.96651107949131, "BBH Raw": 0.6208364880870563, "BBH": 46.20557036638908, "MATH Lvl 5 Raw": 0.0264350453172205, "MATH Lvl 5": 2.643504531722054, "GPQA Raw": 0.3120805369127516, "GPQA": 8.277404921700223, "MUSR Raw": 0.4557916666666666, "MUSR": 16.77395833333333, "MMLU-PRO Raw": 0.4506316489361702, "MMLU-PRO": 38.95907210401891, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-05-07T00:00:00", "Submission Date": "2024-06-13T00:00:00", "Generation": 0, "Base Model": "microsoft/Phi-3-small-8k-instruct"}, {"eval_name": "microsoft_Phi-3.5-MoE-instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Phi3ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/microsoft/Phi-3.5-MoE-instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">microsoft/Phi-3.5-MoE-instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/microsoft__Phi-3.5-MoE-instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "microsoft/Phi-3.5-MoE-instruct", "Model sha": "482a9ba0eb0e1fa1671e3560e009d7cec2e5147c", "Average \u2b06\ufe0f": 35.104040250710206, "Hub License": "mit", "Hub \u2764\ufe0f": 497, "#Params (B)": 42, "Available on the hub": true, "Not_Merged": true, "MoE": false, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.692454908531585, "IFEval": 69.2454908531585, "BBH Raw": 0.640762564622586, "BBH": 48.77464635932187, "MATH Lvl 5 Raw": 0.2054380664652568, "MATH Lvl 5": 20.54380664652568, "GPQA Raw": 0.3557046979865771, "GPQA": 14.093959731543624, "MUSR Raw": 0.4564791666666667, "MUSR": 17.326562499999998, "MMLU-PRO Raw": 0.4657579787234042, "MMLU-PRO": 40.639775413711575, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-08-17T00:00:00", "Submission Date": "2024-08-21T00:00:00", "Generation": 0, "Base Model": "microsoft/Phi-3.5-MoE-instruct"}, {"eval_name": "microsoft_Phi-3.5-mini-instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Phi3ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/microsoft/Phi-3.5-mini-instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">microsoft/Phi-3.5-mini-instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/microsoft__Phi-3.5-mini-instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "microsoft/Phi-3.5-mini-instruct", "Model sha": "64963004ad95869fa73a30279371c8778509ac84", "Average \u2b06\ufe0f": 27.40392795016573, "Hub License": "mit", "Hub \u2764\ufe0f": 554, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5774500547436359, "IFEval": 57.74500547436358, "BBH Raw": 0.5517785126111956, "BBH": 36.74585390851661, "MATH Lvl 5 Raw": 0.1495468277945619, "MATH Lvl 5": 14.954682779456194, "GPQA Raw": 0.3397651006711409, "GPQA": 11.968680089485462, "MUSR Raw": 0.402125, "MUSR": 10.098958333333334, "MMLU-PRO Raw": 0.3961934840425531, "MMLU-PRO": 32.91038711583924, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-08-16T00:00:00", "Submission Date": "2024-08-21T00:00:00", "Generation": 0, "Base Model": "microsoft/Phi-3.5-mini-instruct"}, {"eval_name": "microsoft_phi-1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "PhiForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/microsoft/phi-1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">microsoft/phi-1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/microsoft__phi-1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "microsoft/phi-1", "Model sha": "b9ac0e6d78d43970ecf88e9e0154b3a7da20ed89", "Average \u2b06\ufe0f": 5.523965728106273, "Hub License": "mit", "Hub \u2764\ufe0f": 202, "#Params (B)": 1, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2068057199342189, "IFEval": 20.6805719934219, "BBH Raw": 0.3139475589583784, "BBH": 4.273999212214679, "MATH Lvl 5 Raw": 0.0067975830815709, "MATH Lvl 5": 0.6797583081570997, "GPQA Raw": 0.2651006711409396, "GPQA": 2.0134228187919474, "MUSR Raw": 0.3525104166666666, "MUSR": 3.697135416666667, "MMLU-PRO Raw": 0.116190159574468, "MMLU-PRO": 1.798906619385342, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-09-10T00:00:00", "Submission Date": "2024-06-13T00:00:00", "Generation": 0, "Base Model": "microsoft/phi-1"}, {"eval_name": "microsoft_phi-1_5_float16", "Precision": "float16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "PhiForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/microsoft/phi-1_5\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">microsoft/phi-1_5</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/microsoft__phi-1_5-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "microsoft/phi-1_5", "Model sha": "675aa382d814580b22651a30acb1a585d7c25963", "Average \u2b06\ufe0f": 7.057673794439714, "Hub License": "mit", "Hub \u2764\ufe0f": 1313, "#Params (B)": 1, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2032839532440591, "IFEval": 20.32839532440591, "BBH Raw": 0.3359758321199665, "BBH": 7.468938770070243, "MATH Lvl 5 Raw": 0.0113293051359516, "MATH Lvl 5": 1.1329305135951662, "GPQA Raw": 0.2676174496644295, "GPQA": 2.348993288590602, "MUSR Raw": 0.3404166666666666, "MUSR": 3.385416666666666, "MMLU-PRO Raw": 0.1691323138297872, "MMLU-PRO": 7.681368203309693, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-09-10T00:00:00", "Submission Date": "2024-06-09T00:00:00", "Generation": 0, "Base Model": "microsoft/phi-1_5"}, {"eval_name": "microsoft_phi-2_float16", "Precision": "float16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "PhiForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/microsoft/phi-2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">microsoft/phi-2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/microsoft__phi-2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "microsoft/phi-2", "Model sha": "ef382358ec9e382308935a992d908de099b64c23", "Average \u2b06\ufe0f": 15.446174740490832, "Hub License": "mit", "Hub \u2764\ufe0f": 3238, "#Params (B)": 2, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.273875539125077, "IFEval": 27.3875539125077, "BBH Raw": 0.4881208771249696, "BBH": 28.038519293439304, "MATH Lvl 5 Raw": 0.0241691842900302, "MATH Lvl 5": 2.416918429003021, "GPQA Raw": 0.2718120805369127, "GPQA": 2.9082774049217, "MUSR Raw": 0.4098958333333333, "MUSR": 13.83697916666666, "MMLU-PRO Raw": 0.2627992021276595, "MMLU-PRO": 18.088800236406616, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-12-13T00:00:00", "Submission Date": "2024-06-09T00:00:00", "Generation": 0, "Base Model": "microsoft/phi-2"}, {"eval_name": "migtissera_Llama-3-70B-Synthia-v3.5_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/migtissera/Llama-3-70B-Synthia-v3.5\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">migtissera/Llama-3-70B-Synthia-v3.5</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/migtissera__Llama-3-70B-Synthia-v3.5-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "migtissera/Llama-3-70B-Synthia-v3.5", "Model sha": "8744db0bccfc18f1847633da9d29fc89b35b4190", "Average \u2b06\ufe0f": 35.20429856307621, "Hub License": "llama3", "Hub \u2764\ufe0f": 5, "#Params (B)": 70, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6076499244227538, "IFEval": 60.764992442275386, "BBH Raw": 0.6488638026271278, "BBH": 49.118159695748176, "MATH Lvl 5 Raw": 0.1895770392749244, "MATH Lvl 5": 18.95770392749245, "GPQA Raw": 0.3875838926174497, "GPQA": 18.34451901565996, "MUSR Raw": 0.4921979166666667, "MUSR": 23.39140625, "MMLU-PRO Raw": 0.4658410904255319, "MMLU-PRO": 40.64901004728132, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-26T00:00:00", "Submission Date": "2024-08-28T00:00:00", "Generation": 0, "Base Model": "migtissera/Llama-3-70B-Synthia-v3.5"}, {"eval_name": "migtissera_Llama-3-8B-Synthia-v3.5_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/migtissera/Llama-3-8B-Synthia-v3.5\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">migtissera/Llama-3-8B-Synthia-v3.5</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/migtissera__Llama-3-8B-Synthia-v3.5-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "migtissera/Llama-3-8B-Synthia-v3.5", "Model sha": "af4990801a24fee7acf16370cb5aa5643b5e9d6c", "Average \u2b06\ufe0f": 19.696677808834853, "Hub License": "llama3", "Hub \u2764\ufe0f": 14, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5069582042314393, "IFEval": 50.69582042314393, "BBH Raw": 0.4887940933660044, "BBH": 27.54233943005765, "MATH Lvl 5 Raw": 0.0506042296072507, "MATH Lvl 5": 5.060422960725076, "GPQA Raw": 0.2718120805369127, "GPQA": 2.9082774049217, "MUSR Raw": 0.4043854166666666, "MUSR": 9.414843749999996, "MMLU-PRO Raw": 0.3030252659574468, "MMLU-PRO": 22.55836288416076, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-17T00:00:00", "Submission Date": "2024-08-28T00:00:00", "Generation": 0, "Base Model": "migtissera/Llama-3-8B-Synthia-v3.5"}, {"eval_name": "migtissera_Tess-3-7B-SFT_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/migtissera/Tess-3-7B-SFT\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">migtissera/Tess-3-7B-SFT</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/migtissera__Tess-3-7B-SFT-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "migtissera/Tess-3-7B-SFT", "Model sha": "404de3b56564dbd43cd64d97f8574b43189462f3", "Average \u2b06\ufe0f": 17.096163150722504, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 3, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3946262583279033, "IFEval": 39.46262583279033, "BBH Raw": 0.4607348389507621, "BBH": 24.123847398237004, "MATH Lvl 5 Raw": 0.0332326283987915, "MATH Lvl 5": 3.3232628398791544, "GPQA Raw": 0.2709731543624161, "GPQA": 2.796420581655479, "MUSR Raw": 0.4112708333333333, "MUSR": 10.275520833333331, "MMLU-PRO Raw": 0.3033577127659574, "MMLU-PRO": 22.59530141843972, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-09T00:00:00", "Submission Date": "2024-07-20T00:00:00", "Generation": 1, "Base Model": "mistralai/Mistral-7B-v0.3"}, {"eval_name": "migtissera_Tess-3-Mistral-Nemo-12B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/migtissera/Tess-3-Mistral-Nemo-12B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">migtissera/Tess-3-Mistral-Nemo-12B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/migtissera__Tess-3-Mistral-Nemo-12B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "migtissera/Tess-3-Mistral-Nemo-12B", "Model sha": "0b82dea6e8f4aed4a1c2e10198d68991c30d171b", "Average \u2b06\ufe0f": 16.543939390579638, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 12, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.335499807178287, "IFEval": 33.549980717828696, "BBH Raw": 0.489942302453045, "BBH": 28.042728344416503, "MATH Lvl 5 Raw": 0.0468277945619335, "MATH Lvl 5": 4.682779456193353, "GPQA Raw": 0.2508389261744966, "GPQA": 0.1118568232662209, "MUSR Raw": 0.44578125, "MUSR": 15.489322916666673, "MMLU-PRO Raw": 0.2564827127659574, "MMLU-PRO": 17.386968085106382, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-13T00:00:00", "Submission Date": "2024-09-16T00:00:00", "Generation": 0, "Base Model": "migtissera/Tess-3-Mistral-Nemo-12B"}, {"eval_name": "migtissera_Tess-v2.5-Phi-3-medium-128k-14B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Phi3ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/migtissera/Tess-v2.5-Phi-3-medium-128k-14B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">migtissera/Tess-v2.5-Phi-3-medium-128k-14B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/migtissera__Tess-v2.5-Phi-3-medium-128k-14B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "migtissera/Tess-v2.5-Phi-3-medium-128k-14B", "Model sha": "3a4dbce32e765f659d418c57f0040d290b8b480d", "Average \u2b06\ufe0f": 23.738381656622384, "Hub License": "mit", "Hub \u2764\ufe0f": 3, "#Params (B)": 13, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.453876824603164, "IFEval": 45.3876824603164, "BBH Raw": 0.6206613823135703, "BBH": 46.21582810863877, "MATH Lvl 5 Raw": 0.0264350453172205, "MATH Lvl 5": 2.643504531722054, "GPQA Raw": 0.3078859060402684, "GPQA": 7.718120805369126, "MUSR Raw": 0.4113020833333333, "MUSR": 10.112760416666667, "MMLU-PRO Raw": 0.3731715425531915, "MMLU-PRO": 30.352393617021285, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-05T00:00:00", "Submission Date": "2024-08-30T00:00:00", "Generation": 1, "Base Model": "microsoft/Phi-3-medium-128k-instruct"}, {"eval_name": "migtissera_Tess-v2.5.2-Qwen2-72B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/migtissera/Tess-v2.5.2-Qwen2-72B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">migtissera/Tess-v2.5.2-Qwen2-72B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/migtissera__Tess-v2.5.2-Qwen2-72B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "migtissera/Tess-v2.5.2-Qwen2-72B", "Model sha": "0435e634ad9bc8b1172395a535b78e6f25f3594f", "Average \u2b06\ufe0f": 33.27604657472896, "Hub License": "other", "Hub \u2764\ufe0f": 11, "#Params (B)": 72, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4494308434952592, "IFEval": 44.943084349525925, "BBH Raw": 0.6646791891060648, "BBH": 52.30813577387958, "MATH Lvl 5 Raw": 0.2741691842900302, "MATH Lvl 5": 27.416918429003022, "GPQA Raw": 0.3506711409395973, "GPQA": 13.422818791946312, "MUSR Raw": 0.4188333333333333, "MUSR": 10.887500000000005, "MMLU-PRO Raw": 0.5561003989361702, "MMLU-PRO": 50.67782210401892, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-13T00:00:00", "Submission Date": "2024-08-10T00:00:00", "Generation": 0, "Base Model": "migtissera/Tess-v2.5.2-Qwen2-72B"}, {"eval_name": "migtissera_Trinity-2-Codestral-22B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/migtissera/Trinity-2-Codestral-22B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">migtissera/Trinity-2-Codestral-22B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/migtissera__Trinity-2-Codestral-22B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "migtissera/Trinity-2-Codestral-22B", "Model sha": "5f20b9d8af1a75c135c70bd7295e58301cce63fc", "Average \u2b06\ufe0f": 21.81901085635334, "Hub License": "other", "Hub \u2764\ufe0f": 11, "#Params (B)": 22, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4202050559182968, "IFEval": 42.02050559182968, "BBH Raw": 0.5593244825460373, "BBH": 36.41273800501431, "MATH Lvl 5 Raw": 0.0861027190332326, "MATH Lvl 5": 8.610271903323262, "GPQA Raw": 0.3145973154362416, "GPQA": 8.612975391498878, "MUSR Raw": 0.4110520833333333, "MUSR": 9.61484375, "MMLU-PRO Raw": 0.3307845744680851, "MMLU-PRO": 25.642730496453904, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-07T00:00:00", "Submission Date": "2024-09-16T00:00:00", "Generation": 1, "Base Model": "mistralai/Codestral-22B-v0.1"}, {"eval_name": "migtissera_Trinity-2-Codestral-22B-v0.2_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/migtissera/Trinity-2-Codestral-22B-v0.2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">migtissera/Trinity-2-Codestral-22B-v0.2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/migtissera__Trinity-2-Codestral-22B-v0.2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "migtissera/Trinity-2-Codestral-22B-v0.2", "Model sha": "63513c3eb9b7c552fc163f58a2e7dc1fa09573b5", "Average \u2b06\ufe0f": 21.869825084599302, "Hub License": "other", "Hub \u2764\ufe0f": 4, "#Params (B)": 22, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4344683218305207, "IFEval": 43.44683218305208, "BBH Raw": 0.5686364683055418, "BBH": 37.61424608895926, "MATH Lvl 5 Raw": 0.0838368580060422, "MATH Lvl 5": 8.38368580060423, "GPQA Raw": 0.3003355704697986, "GPQA": 6.711409395973152, "MUSR Raw": 0.4044791666666666, "MUSR": 9.059895833333336, "MMLU-PRO Raw": 0.3340259308510638, "MMLU-PRO": 26.002881205673763, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-13T00:00:00", "Submission Date": "2024-08-28T00:00:00", "Generation": 1, "Base Model": "mistralai/Codestral-22B-v0.1"}, {"eval_name": "migtissera_Trinity-2-Codestral-22B-v0.2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/migtissera/Trinity-2-Codestral-22B-v0.2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">migtissera/Trinity-2-Codestral-22B-v0.2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/migtissera__Trinity-2-Codestral-22B-v0.2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "migtissera/Trinity-2-Codestral-22B-v0.2", "Model sha": "9452a82ac7bfa9092a061ec913e9078ef3525a03", "Average \u2b06\ufe0f": 22.1117998201449, "Hub License": "other", "Hub \u2764\ufe0f": 4, "#Params (B)": 22, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4430112102554555, "IFEval": 44.30112102554556, "BBH Raw": 0.5706466356198404, "BBH": 37.78604101957199, "MATH Lvl 5 Raw": 0.0785498489425981, "MATH Lvl 5": 7.854984894259818, "GPQA Raw": 0.3078859060402684, "GPQA": 7.718120805369126, "MUSR Raw": 0.4031458333333333, "MUSR": 8.859895833333338, "MMLU-PRO Raw": 0.3353557180851064, "MMLU-PRO": 26.150635342789595, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-13T00:00:00", "Submission Date": "2024-09-16T00:00:00", "Generation": 1, "Base Model": "mistralai/Codestral-22B-v0.1"}, {"eval_name": "minghaowu_Qwen1.5-1.8B-OpenHermes-2.5_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/minghaowu/Qwen1.5-1.8B-OpenHermes-2.5\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">minghaowu/Qwen1.5-1.8B-OpenHermes-2.5</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/minghaowu__Qwen1.5-1.8B-OpenHermes-2.5-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "minghaowu/Qwen1.5-1.8B-OpenHermes-2.5", "Model sha": "40700de82968350c192318877fe522630d0ef76d", "Average \u2b06\ufe0f": 8.319695788165424, "Hub License": "other", "Hub \u2764\ufe0f": 8, "#Params (B)": 1, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2777973554612871, "IFEval": 27.779735546128716, "BBH Raw": 0.3374639680126601, "BBH": 7.561477534247794, "MATH Lvl 5 Raw": 0.0022658610271903, "MATH Lvl 5": 0.2265861027190332, "GPQA Raw": 0.2835570469798658, "GPQA": 4.4742729306487705, "MUSR Raw": 0.3528854166666667, "MUSR": 1.0773437500000014, "MMLU-PRO Raw": 0.179188829787234, "MMLU-PRO": 8.798758865248226, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-02-10T00:00:00", "Submission Date": "2024-09-12T00:00:00", "Generation": 1, "Base Model": "Qwen/Qwen1.5-1.8B"}, {"eval_name": "mistral-community_Mistral-7B-v0.2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/mistral-community/Mistral-7B-v0.2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">mistral-community/Mistral-7B-v0.2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/mistral-community__Mistral-7B-v0.2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "mistral-community/Mistral-7B-v0.2", "Model sha": "2c3e624962b1a3f3fbf52e15969565caa7bc064a", "Average \u2b06\ufe0f": 14.152421858603484, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 230, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2266397602805001, "IFEval": 22.663976028050016, "BBH Raw": 0.4510187962797583, "BBH": 23.950865383029598, "MATH Lvl 5 Raw": 0.0264350453172205, "MATH Lvl 5": 2.643504531722054, "GPQA Raw": 0.2919463087248322, "GPQA": 5.592841163310966, "MUSR Raw": 0.4031770833333333, "MUSR": 8.363802083333333, "MMLU-PRO Raw": 0.2952958776595745, "MMLU-PRO": 21.699541962174944, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-03-23T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "mistral-community/Mistral-7B-v0.2"}, {"eval_name": "mistral-community_mixtral-8x22B-v0.3_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/mistral-community/mixtral-8x22B-v0.3\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">mistral-community/mixtral-8x22B-v0.3</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/mistral-community__mixtral-8x22B-v0.3-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "mistral-community/mixtral-8x22B-v0.3", "Model sha": "211b177b79ab5ef245ee334d106c27623e786882", "Average \u2b06\ufe0f": 25.550232388991247, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 3, "#Params (B)": 140, "Available on the hub": true, "Not_Merged": true, "MoE": false, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2582636293922348, "IFEval": 25.82636293922349, "BBH Raw": 0.6250002178435845, "BBH": 45.73104089763324, "MATH Lvl 5 Raw": 0.168429003021148, "MATH Lvl 5": 16.842900302114806, "GPQA Raw": 0.3775167785234899, "GPQA": 17.00223713646532, "MUSR Raw": 0.4036979166666667, "MUSR": 7.462239583333335, "MMLU-PRO Raw": 0.4639295212765957, "MMLU-PRO": 40.4366134751773, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-05-25T00:00:00", "Submission Date": "2024-06-13T00:00:00", "Generation": 0, "Base Model": "mistral-community/mixtral-8x22B-v0.3"}, {"eval_name": "mistralai_Codestral-22B-v0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/mistralai/Codestral-22B-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">mistralai/Codestral-22B-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/mistralai__Codestral-22B-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "mistralai/Codestral-22B-v0.1", "Model sha": "8f5fe23af91885222a1563283c87416745a5e212", "Average \u2b06\ufe0f": 23.06591942096332, "Hub License": "other", "Hub \u2764\ufe0f": 1128, "#Params (B)": 22, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5771752283939946, "IFEval": 57.71752283939946, "BBH Raw": 0.5139136921003167, "BBH": 30.737634411945635, "MATH Lvl 5 Raw": 0.0876132930513595, "MATH Lvl 5": 8.761329305135952, "GPQA Raw": 0.2986577181208054, "GPQA": 6.487695749440718, "MUSR Raw": 0.4187083333333333, "MUSR": 10.738541666666668, "MMLU-PRO Raw": 0.3155751329787234, "MMLU-PRO": 23.95279255319149, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-05-29T00:00:00", "Submission Date": "2024-09-28T00:00:00", "Generation": 0, "Base Model": "mistralai/Codestral-22B-v0.1"}, {"eval_name": "mistralai_Mistral-7B-Instruct-v0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">mistralai/Mistral-7B-Instruct-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/mistralai__Mistral-7B-Instruct-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "mistralai/Mistral-7B-Instruct-v0.1", "Model sha": "73068f3702d050a2fd5aa2ca1e612e5036429398", "Average \u2b06\ufe0f": 12.670524460488826, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1514, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4487060998151571, "IFEval": 44.87060998151571, "BBH Raw": 0.3354808475981098, "BBH": 7.647020535827543, "MATH Lvl 5 Raw": 0.0166163141993957, "MATH Lvl 5": 1.6616314199395772, "GPQA Raw": 0.25, "GPQA": 0.0, "MUSR Raw": 0.3847604166666666, "MUSR": 6.12838541666667, "MMLU-PRO Raw": 0.241439494680851, "MMLU-PRO": 15.715499408983453, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-09-27T00:00:00", "Submission Date": "2024-06-27T00:00:00", "Generation": 1, "Base Model": "mistralai/Mistral-7B-v0.1"}, {"eval_name": "mistralai_Mistral-7B-Instruct-v0.2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">mistralai/Mistral-7B-Instruct-v0.2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/mistralai__Mistral-7B-Instruct-v0.2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "mistralai/Mistral-7B-Instruct-v0.2", "Model sha": "41b61a33a2483885c981aa79e0df6b32407ed873", "Average \u2b06\ufe0f": 18.444951008649024, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 2546, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5496227786717023, "IFEval": 54.96227786717022, "BBH Raw": 0.4459735520329279, "BBH": 22.910601936713604, "MATH Lvl 5 Raw": 0.0264350453172205, "MATH Lvl 5": 2.643504531722054, "GPQA Raw": 0.276006711409396, "GPQA": 3.467561521252797, "MUSR Raw": 0.3966041666666666, "MUSR": 7.608854166666667, "MMLU-PRO Raw": 0.2716921542553192, "MMLU-PRO": 19.0769060283688, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-12-11T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "mistralai/Mistral-7B-Instruct-v0.2"}, {"eval_name": "mistralai_Mistral-7B-Instruct-v0.3_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">mistralai/Mistral-7B-Instruct-v0.3</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/mistralai__Mistral-7B-Instruct-v0.3-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "mistralai/Mistral-7B-Instruct-v0.3", "Model sha": "83e9aa141f2e28c82232fea5325f54edf17c43de", "Average \u2b06\ufe0f": 19.11180572554635, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1049, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5465254413844156, "IFEval": 54.65254413844156, "BBH Raw": 0.4721963171264839, "BBH": 25.56911494885904, "MATH Lvl 5 Raw": 0.0317220543806646, "MATH Lvl 5": 3.1722054380664653, "GPQA Raw": 0.2793624161073825, "GPQA": 3.9149888143176734, "MUSR Raw": 0.37390625, "MUSR": 4.304947916666669, "MMLU-PRO Raw": 0.3075132978723404, "MMLU-PRO": 23.05703309692672, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-05-22T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 1, "Base Model": "mistralai/Mistral-7B-v0.3"}, {"eval_name": "mistralai_Mistral-7B-v0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/mistralai/Mistral-7B-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">mistralai/Mistral-7B-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/mistralai__Mistral-7B-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "mistralai/Mistral-7B-v0.1", "Model sha": "26bca36bde8333b5d7f72e9ed20ccda6a618af24", "Average \u2b06\ufe0f": 14.524854732980714, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 3407, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2385548123423627, "IFEval": 23.855481234236272, "BBH Raw": 0.4431067812183711, "BBH": 22.16840245789813, "MATH Lvl 5 Raw": 0.0249244712990936, "MATH Lvl 5": 2.492447129909366, "GPQA Raw": 0.2919463087248322, "GPQA": 5.592841163310966, "MUSR Raw": 0.4139375, "MUSR": 10.675520833333335, "MMLU-PRO Raw": 0.3012799202127659, "MMLU-PRO": 22.36443557919621, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-09-20T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "mistralai/Mistral-7B-v0.1"}, {"eval_name": "mistralai_Mistral-7B-v0.3_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/mistralai/Mistral-7B-v0.3\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">mistralai/Mistral-7B-v0.3</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/mistralai__Mistral-7B-v0.3-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "mistralai/Mistral-7B-v0.3", "Model sha": "b67d6a03ca097c5122fa65904fce0413500bf8c8", "Average \u2b06\ufe0f": 14.152421858603484, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 371, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2266397602805001, "IFEval": 22.663976028050016, "BBH Raw": 0.4510187962797583, "BBH": 23.950865383029598, "MATH Lvl 5 Raw": 0.0264350453172205, "MATH Lvl 5": 2.643504531722054, "GPQA Raw": 0.2919463087248322, "GPQA": 5.592841163310966, "MUSR Raw": 0.4031770833333333, "MUSR": 8.363802083333333, "MMLU-PRO Raw": 0.2952958776595745, "MMLU-PRO": 21.699541962174944, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-05-22T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "mistralai/Mistral-7B-v0.3"}, {"eval_name": "mistralai_Mistral-Nemo-Base-2407_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/mistralai/Mistral-Nemo-Base-2407\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">mistralai/Mistral-Nemo-Base-2407</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/mistralai__Mistral-Nemo-Base-2407-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "mistralai/Mistral-Nemo-Base-2407", "Model sha": "d2efb15544d5401f761235bef327babb850887d0", "Average \u2b06\ufe0f": 15.075710524125512, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 246, "#Params (B)": 11, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1629919724109806, "IFEval": 16.299197241098064, "BBH Raw": 0.5035062000369291, "BBH": 29.374736440966878, "MATH Lvl 5 Raw": 0.0498489425981873, "MATH Lvl 5": 4.984894259818732, "GPQA Raw": 0.2936241610738255, "GPQA": 5.8165548098434, "MUSR Raw": 0.3921354166666667, "MUSR": 6.516927083333336, "MMLU-PRO Raw": 0.347157579787234, "MMLU-PRO": 27.46195330969267, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-07-18T00:00:00", "Submission Date": "2024-07-19T00:00:00", "Generation": 0, "Base Model": "mistralai/Mistral-Nemo-Base-2407"}, {"eval_name": "mistralai_Mistral-Nemo-Instruct-2407_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/mistralai/Mistral-Nemo-Instruct-2407\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">mistralai/Mistral-Nemo-Instruct-2407</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/mistralai__Mistral-Nemo-Instruct-2407-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "mistralai/Mistral-Nemo-Instruct-2407", "Model sha": "4d14c1db68fe20dbf80b8eca85d39b909c5fe1d5", "Average \u2b06\ufe0f": 23.53266942770951, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1116, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6380248850826917, "IFEval": 63.80248850826917, "BBH Raw": 0.5036523950310812, "BBH": 29.679970381152803, "MATH Lvl 5 Raw": 0.0589123867069486, "MATH Lvl 5": 5.8912386706948645, "GPQA Raw": 0.2902684563758389, "GPQA": 5.369127516778524, "MUSR Raw": 0.3899999999999999, "MUSR": 8.483333333333333, "MMLU-PRO Raw": 0.3517287234042553, "MMLU-PRO": 27.969858156028373, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-07-17T00:00:00", "Submission Date": "2024-08-29T00:00:00", "Generation": 1, "Base Model": "mistralai/Mistral-Nemo-Base-2407"}, {"eval_name": "mistralai_Mistral-Small-Instruct-2409_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/mistralai/Mistral-Small-Instruct-2409\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">mistralai/Mistral-Small-Instruct-2409</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/mistralai__Mistral-Small-Instruct-2409-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "mistralai/Mistral-Small-Instruct-2409", "Model sha": "63e53df6575e7085d62113f4383835ff979b3795", "Average \u2b06\ufe0f": 26.26274897641828, "Hub License": "other", "Hub \u2764\ufe0f": 306, "#Params (B)": 22, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.666975846310013, "IFEval": 66.69758463100129, "BBH Raw": 0.5213075098146217, "BBH": 30.7920960925092, "MATH Lvl 5 Raw": 0.1435045317220543, "MATH Lvl 5": 14.350453172205436, "GPQA Raw": 0.3238255033557047, "GPQA": 9.843400447427292, "MUSR Raw": 0.3632083333333333, "MUSR": 3.001041666666666, "MMLU-PRO Raw": 0.3960272606382978, "MMLU-PRO": 32.89191784869976, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-09-17T00:00:00", "Submission Date": "2024-09-19T00:00:00", "Generation": 0, "Base Model": "mistralai/Mistral-Small-Instruct-2409"}, {"eval_name": "mistralai_Mistral-Small-Instruct-2409_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/mistralai/Mistral-Small-Instruct-2409\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">mistralai/Mistral-Small-Instruct-2409</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/mistralai__Mistral-Small-Instruct-2409-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "mistralai/Mistral-Small-Instruct-2409", "Model sha": "63e53df6575e7085d62113f4383835ff979b3795", "Average \u2b06\ufe0f": 29.54130399994349, "Hub License": "other", "Hub \u2764\ufe0f": 306, "#Params (B)": 22, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.6282829558903709, "IFEval": 62.82829558903709, "BBH Raw": 0.5830283846898211, "BBH": 40.5597130348992, "MATH Lvl 5 Raw": 0.1812688821752265, "MATH Lvl 5": 18.12688821752266, "GPQA Raw": 0.3330536912751677, "GPQA": 11.0738255033557, "MUSR Raw": 0.4063333333333334, "MUSR": 10.225, "MMLU-PRO Raw": 0.409906914893617, "MMLU-PRO": 34.43410165484633, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-09-17T00:00:00", "Submission Date": "2024-09-25T00:00:00", "Generation": 0, "Base Model": "mistralai/Mistral-Small-Instruct-2409"}, {"eval_name": "mistralai_Mixtral-8x22B-Instruct-v0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/mistralai/Mixtral-8x22B-Instruct-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">mistralai/Mixtral-8x22B-Instruct-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/mistralai__Mixtral-8x22B-Instruct-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "mistralai/Mixtral-8x22B-Instruct-v0.1", "Model sha": "b0c3516041d014f640267b14feb4e9a84c8e8c71", "Average \u2b06\ufe0f": 33.88568028808198, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 678, "#Params (B)": 140, "Available on the hub": true, "Not_Merged": true, "MoE": false, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7183584001560305, "IFEval": 71.83584001560305, "BBH Raw": 0.6124924926272018, "BBH": 44.11434558724835, "MATH Lvl 5 Raw": 0.1873111782477341, "MATH Lvl 5": 18.731117824773413, "GPQA Raw": 0.3733221476510067, "GPQA": 16.442953020134222, "MUSR Raw": 0.4311145833333333, "MUSR": 13.489322916666664, "MMLU-PRO Raw": 0.4483045212765957, "MMLU-PRO": 38.70050236406619, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-04-16T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 1, "Base Model": "mistralai/Mixtral-8x22B-v0.1"}, {"eval_name": "mistralai_Mixtral-8x22B-v0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/mistralai/Mixtral-8x22B-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">mistralai/Mixtral-8x22B-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/mistralai__Mixtral-8x22B-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "mistralai/Mixtral-8x22B-v0.1", "Model sha": "b03e260818710044a2f088d88fab12bb220884fb", "Average \u2b06\ufe0f": 25.489173938868174, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 192, "#Params (B)": 140, "Available on the hub": true, "Not_Merged": true, "MoE": false, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2582636293922348, "IFEval": 25.82636293922349, "BBH Raw": 0.6239807473187268, "BBH": 45.58840384342722, "MATH Lvl 5 Raw": 0.168429003021148, "MATH Lvl 5": 16.842900302114806, "GPQA Raw": 0.3758389261744966, "GPQA": 16.778523489932887, "MUSR Raw": 0.4036979166666667, "MUSR": 7.462239583333335, "MMLU-PRO Raw": 0.4639295212765957, "MMLU-PRO": 40.4366134751773, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-04-16T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "mistralai/Mixtral-8x22B-v0.1"}, {"eval_name": "mistralai_Mixtral-8x7B-Instruct-v0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">mistralai/Mixtral-8x7B-Instruct-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/mistralai__Mixtral-8x7B-Instruct-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "mistralai/Mixtral-8x7B-Instruct-v0.1", "Model sha": "1e637f2d7cb0a9d6fb1922f305cb784995190a83", "Average \u2b06\ufe0f": 23.65345718721589, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 4160, "#Params (B)": 46, "Available on the hub": true, "Not_Merged": true, "MoE": false, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5599143605633053, "IFEval": 55.991436056330535, "BBH Raw": 0.4962365401335649, "BBH": 29.74239838096733, "MATH Lvl 5 Raw": 0.0815709969788519, "MATH Lvl 5": 8.157099697885197, "GPQA Raw": 0.3028523489932886, "GPQA": 7.046979865771815, "MUSR Raw": 0.4203229166666666, "MUSR": 11.073697916666667, "MMLU-PRO Raw": 0.3691821808510638, "MMLU-PRO": 29.90913120567376, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-12-10T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 1, "Base Model": "mistralai/Mixtral-8x7B-v0.1"}, {"eval_name": "mistralai_Mixtral-8x7B-v0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/mistralai/Mixtral-8x7B-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">mistralai/Mixtral-8x7B-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/mistralai__Mixtral-8x7B-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "mistralai/Mixtral-8x7B-v0.1", "Model sha": "985aa055896a8f943d4a9f2572e6ea1341823841", "Average \u2b06\ufe0f": 19.32610679326308, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1637, "#Params (B)": 46, "Available on the hub": true, "Not_Merged": true, "MoE": false, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2415269263332402, "IFEval": 24.152692633324023, "BBH Raw": 0.508666743762444, "BBH": 30.294194918961484, "MATH Lvl 5 Raw": 0.0876132930513595, "MATH Lvl 5": 8.761329305135952, "GPQA Raw": 0.313758389261745, "GPQA": 8.501118568232664, "MUSR Raw": 0.4321354166666666, "MUSR": 12.58359375, "MMLU-PRO Raw": 0.3849734042553192, "MMLU-PRO": 31.663711583924343, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-12-01T00:00:00", "Submission Date": "2024-08-20T00:00:00", "Generation": 0, "Base Model": "mistralai/Mixtral-8x7B-v0.1"}, {"eval_name": "mistralai_Mixtral-8x7B-v0.1_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/mistralai/Mixtral-8x7B-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">mistralai/Mixtral-8x7B-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/mistralai__Mixtral-8x7B-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "mistralai/Mixtral-8x7B-v0.1", "Model sha": "985aa055896a8f943d4a9f2572e6ea1341823841", "Average \u2b06\ufe0f": 19.665108918316083, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1637, "#Params (B)": 46, "Available on the hub": true, "Not_Merged": true, "MoE": false, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2326094761898429, "IFEval": 23.260947618984297, "BBH Raw": 0.5097711377553386, "BBH": 30.4002992674255, "MATH Lvl 5 Raw": 0.093655589123867, "MATH Lvl 5": 9.365558912386708, "GPQA Raw": 0.3204697986577181, "GPQA": 9.395973154362418, "MUSR Raw": 0.4413125, "MUSR": 13.6640625, "MMLU-PRO Raw": 0.3871343085106383, "MMLU-PRO": 31.903812056737586, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-12-01T00:00:00", "Submission Date": "2024-06-27T00:00:00", "Generation": 0, "Base Model": "mistralai/Mixtral-8x7B-v0.1"}, {"eval_name": "mixtao_MixTAO-7Bx2-MoE-v8.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/mixtao/MixTAO-7Bx2-MoE-v8.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">mixtao/MixTAO-7Bx2-MoE-v8.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/mixtao__MixTAO-7Bx2-MoE-v8.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "mixtao/MixTAO-7Bx2-MoE-v8.1", "Model sha": "339130b87b6ef2484fea9fbfacba8a714ac03347", "Average \u2b06\ufe0f": 20.90169334834877, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 53, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": false, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4162333718976759, "IFEval": 41.6233371897676, "BBH Raw": 0.5189059391733521, "BBH": 32.31034233969924, "MATH Lvl 5 Raw": 0.080060422960725, "MATH Lvl 5": 8.006042296072508, "GPQA Raw": 0.2843959731543624, "GPQA": 4.586129753914992, "MUSR Raw": 0.4463333333333333, "MUSR": 15.291666666666664, "MMLU-PRO Raw": 0.3123337765957447, "MMLU-PRO": 23.592641843971627, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-02-26T00:00:00", "Submission Date": "2024-10-04T00:00:00", "Generation": 0, "Base Model": "mixtao/MixTAO-7Bx2-MoE-v8.1"}, {"eval_name": "mlabonne_AlphaMonarch-7B_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/mlabonne/AlphaMonarch-7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">mlabonne/AlphaMonarch-7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/mlabonne__AlphaMonarch-7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "mlabonne/AlphaMonarch-7B", "Model sha": "3de065d84411d74e5b3590f67f52b0b71faf6161", "Average \u2b06\ufe0f": 17.592856841556475, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 148, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.493943846771012, "IFEval": 49.39438467710121, "BBH Raw": 0.4625522037183211, "BBH": 23.947378025426246, "MATH Lvl 5 Raw": 0.0385196374622356, "MATH Lvl 5": 3.8519637462235647, "GPQA Raw": 0.2701342281879195, "GPQA": 2.684563758389265, "MUSR Raw": 0.4121354166666666, "MUSR": 9.316927083333333, "MMLU-PRO Raw": 0.2472573138297872, "MMLU-PRO": 16.36192375886525, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-02-14T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 1, "Base Model": "mlabonne/AlphaMonarch-7B (Merge)"}, {"eval_name": "mlabonne_Beyonder-4x7B-v3_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/mlabonne/Beyonder-4x7B-v3\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">mlabonne/Beyonder-4x7B-v3</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/mlabonne__Beyonder-4x7B-v3-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "mlabonne/Beyonder-4x7B-v3", "Model sha": "8e923fa480f511ab54d79b44b0487768bdd3de4e", "Average \u2b06\ufe0f": 19.30615376378484, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 58, "#Params (B)": 24, "Available on the hub": true, "Not_Merged": false, "MoE": false, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5608385749810503, "IFEval": 56.08385749810503, "BBH Raw": 0.4670522037183211, "BBH": 24.55720918011033, "MATH Lvl 5 Raw": 0.0475830815709969, "MATH Lvl 5": 4.758308157099698, "GPQA Raw": 0.285234899328859, "GPQA": 4.697986577181204, "MUSR Raw": 0.4045416666666666, "MUSR": 8.934375000000001, "MMLU-PRO Raw": 0.2512466755319149, "MMLU-PRO": 16.805186170212764, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-03-21T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 1, "Base Model": "mlabonne/Beyonder-4x7B-v3 (Merge)"}, {"eval_name": "mlabonne_BigQwen2.5-52B-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/mlabonne/BigQwen2.5-52B-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">mlabonne/BigQwen2.5-52B-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/mlabonne__BigQwen2.5-52B-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "mlabonne/BigQwen2.5-52B-Instruct", "Model sha": "425b9bffc9871085cc0d42c34138ce776f96ba02", "Average \u2b06\ufe0f": 37.419811304749054, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 2, "#Params (B)": 52, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7928718023732585, "IFEval": 79.28718023732586, "BBH Raw": 0.7121004678698547, "BBH": 59.80960695923371, "MATH Lvl 5 Raw": 0.1782477341389728, "MATH Lvl 5": 17.82477341389728, "GPQA Raw": 0.3020134228187919, "GPQA": 6.935123042505594, "MUSR Raw": 0.4113020833333333, "MUSR": 10.44609375, "MMLU-PRO Raw": 0.5519448138297872, "MMLU-PRO": 50.21609042553191, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-09-23T00:00:00", "Submission Date": "2024-09-25T00:00:00", "Generation": 1, "Base Model": "mlabonne/BigQwen2.5-52B-Instruct (Merge)"}, {"eval_name": "mlabonne_BigQwen2.5-Echo-47B-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/mlabonne/BigQwen2.5-Echo-47B-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">mlabonne/BigQwen2.5-Echo-47B-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/mlabonne__BigQwen2.5-Echo-47B-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "mlabonne/BigQwen2.5-Echo-47B-Instruct", "Model sha": "f95fcf22f8ab87c2dbb1893b87c8a132820acb5e", "Average \u2b06\ufe0f": 30.309840637122004, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 3, "#Params (B)": 47, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7356691356711305, "IFEval": 73.56691356711303, "BBH Raw": 0.6125111878044905, "BBH": 44.52224375363397, "MATH Lvl 5 Raw": 0.0347432024169184, "MATH Lvl 5": 3.474320241691843, "GPQA Raw": 0.3145973154362416, "GPQA": 8.612975391498878, "MUSR Raw": 0.4124791666666667, "MUSR": 10.193229166666669, "MMLU-PRO Raw": 0.4734042553191489, "MMLU-PRO": 41.48936170212765, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-09-23T00:00:00", "Submission Date": "2024-09-24T00:00:00", "Generation": 1, "Base Model": "mlabonne/BigQwen2.5-Echo-47B-Instruct (Merge)"}, {"eval_name": "mlabonne_ChimeraLlama-3-8B-v2_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/mlabonne/ChimeraLlama-3-8B-v2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">mlabonne/ChimeraLlama-3-8B-v2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/mlabonne__ChimeraLlama-3-8B-v2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "mlabonne/ChimeraLlama-3-8B-v2", "Model sha": "d90a12b1574d7be084e53e0ad610282638ab29cf", "Average \u2b06\ufe0f": 19.994624011947774, "Hub License": "other", "Hub \u2764\ufe0f": 14, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4468831589072549, "IFEval": 44.6883158907255, "BBH Raw": 0.5045597361952603, "BBH": 28.47879573339652, "MATH Lvl 5 Raw": 0.0830815709969788, "MATH Lvl 5": 8.308157099697885, "GPQA Raw": 0.285234899328859, "GPQA": 4.697986577181204, "MUSR Raw": 0.3790833333333334, "MUSR": 5.252083333333334, "MMLU-PRO Raw": 0.3568816489361702, "MMLU-PRO": 28.54240543735224, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-04-22T00:00:00", "Submission Date": "2024-08-25T00:00:00", "Generation": 1, "Base Model": "mlabonne/ChimeraLlama-3-8B-v2 (Merge)"}, {"eval_name": "mlabonne_ChimeraLlama-3-8B-v3_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/mlabonne/ChimeraLlama-3-8B-v3\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">mlabonne/ChimeraLlama-3-8B-v3</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/mlabonne__ChimeraLlama-3-8B-v3-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "mlabonne/ChimeraLlama-3-8B-v3", "Model sha": "c8c1787e1426e3979ae82134f4eb7fa332f58ae0", "Average \u2b06\ufe0f": 20.533484535073143, "Hub License": "other", "Hub \u2764\ufe0f": 15, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4407882197015031, "IFEval": 44.07882197015032, "BBH Raw": 0.497819027265292, "BBH": 27.64609355033005, "MATH Lvl 5 Raw": 0.0785498489425981, "MATH Lvl 5": 7.854984894259818, "GPQA Raw": 0.2919463087248322, "GPQA": 5.592841163310966, "MUSR Raw": 0.4003541666666666, "MUSR": 8.37760416666667, "MMLU-PRO Raw": 0.3668550531914893, "MMLU-PRO": 29.650561465721044, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-05-01T00:00:00", "Submission Date": "2024-08-25T00:00:00", "Generation": 1, "Base Model": "mlabonne/ChimeraLlama-3-8B-v3 (Merge)"}, {"eval_name": "mlabonne_Daredevil-8B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/mlabonne/Daredevil-8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">mlabonne/Daredevil-8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/mlabonne__Daredevil-8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "mlabonne/Daredevil-8B", "Model sha": "717953c83631cc9adf2dddccfff06739308f10f7", "Average \u2b06\ufe0f": 22.13270781899716, "Hub License": "other", "Hub \u2764\ufe0f": 33, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4547766592640859, "IFEval": 45.4776659264086, "BBH Raw": 0.5194408746721715, "BBH": 31.62685476252992, "MATH Lvl 5 Raw": 0.0898791540785498, "MATH Lvl 5": 8.987915407854985, "GPQA Raw": 0.3078859060402684, "GPQA": 7.718120805369126, "MUSR Raw": 0.393875, "MUSR": 7.534375000000003, "MMLU-PRO Raw": 0.383061835106383, "MMLU-PRO": 31.451315011820324, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-05-25T00:00:00", "Submission Date": "2024-07-02T00:00:00", "Generation": 1, "Base Model": "mlabonne/Daredevil-8B (Merge)"}, {"eval_name": "mlabonne_Daredevil-8B-abliterated_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/mlabonne/Daredevil-8B-abliterated\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">mlabonne/Daredevil-8B-abliterated</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/mlabonne__Daredevil-8B-abliterated-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "mlabonne/Daredevil-8B-abliterated", "Model sha": "034c0ce8ceeba075d1dff2bac1b113a017c79390", "Average \u2b06\ufe0f": 19.5495262877528, "Hub License": "other", "Hub \u2764\ufe0f": 30, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4426366485369929, "IFEval": 44.2636648536993, "BBH Raw": 0.4254272523147253, "BBH": 19.865777111108127, "MATH Lvl 5 Raw": 0.0861027190332326, "MATH Lvl 5": 8.610271903323262, "GPQA Raw": 0.2902684563758389, "GPQA": 5.369127516778524, "MUSR Raw": 0.4070208333333333, "MUSR": 9.17760416666667, "MMLU-PRO Raw": 0.3700964095744681, "MMLU-PRO": 30.010712174940902, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-05-26T00:00:00", "Submission Date": "2024-07-02T00:00:00", "Generation": 0, "Base Model": "mlabonne/Daredevil-8B-abliterated"}, {"eval_name": "mlabonne_Meta-Llama-3.1-8B-Instruct-abliterated_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/mlabonne/Meta-Llama-3.1-8B-Instruct-abliterated\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">mlabonne/Meta-Llama-3.1-8B-Instruct-abliterated</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/mlabonne__Meta-Llama-3.1-8B-Instruct-abliterated-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "mlabonne/Meta-Llama-3.1-8B-Instruct-abliterated", "Model sha": "aef878bdf42c119d007322967006fcdef5ae6ee1", "Average \u2b06\ufe0f": 23.12702357053137, "Hub License": "llama3.1", "Hub \u2764\ufe0f": 119, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7329463601023063, "IFEval": 73.29463601023062, "BBH Raw": 0.4874064873490218, "BBH": 27.12916478111247, "MATH Lvl 5 Raw": 0.0641993957703927, "MATH Lvl 5": 6.419939577039275, "GPQA Raw": 0.2567114093959731, "GPQA": 0.8948545861297527, "MUSR Raw": 0.3648854166666666, "MUSR": 3.2106770833333336, "MMLU-PRO Raw": 0.3503158244680851, "MMLU-PRO": 27.812869385342783, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-07-24T00:00:00", "Submission Date": "2024-10-13T00:00:00", "Generation": 2, "Base Model": "meta-llama/Meta-Llama-3.1-8B"}, {"eval_name": "mlabonne_NeuralBeagle14-7B_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/mlabonne/NeuralBeagle14-7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">mlabonne/NeuralBeagle14-7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/mlabonne__NeuralBeagle14-7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "mlabonne/NeuralBeagle14-7B", "Model sha": "1567ad618a0998139654cb355738bb9bc018ca64", "Average \u2b06\ufe0f": 18.834547644838565, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 157, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4935194173681387, "IFEval": 49.35194173681387, "BBH Raw": 0.4627870945235384, "BBH": 23.959695145493203, "MATH Lvl 5 Raw": 0.0475830815709969, "MATH Lvl 5": 4.758308157099698, "GPQA Raw": 0.2818791946308724, "GPQA": 4.250559284116329, "MUSR Raw": 0.4319479166666666, "MUSR": 12.893489583333336, "MMLU-PRO Raw": 0.2601396276595745, "MMLU-PRO": 17.793291962174944, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-01-15T00:00:00", "Submission Date": "2024-06-27T00:00:00", "Generation": 2, "Base Model": "mlabonne/Beagle14-7B (Merge)"}, {"eval_name": "mlabonne_NeuralDaredevil-8B-abliterated_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/mlabonne/NeuralDaredevil-8B-abliterated\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">mlabonne/NeuralDaredevil-8B-abliterated</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/mlabonne__NeuralDaredevil-8B-abliterated-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "mlabonne/NeuralDaredevil-8B-abliterated", "Model sha": "2f4a5e8a8522f19dff345c7189b7891468763061", "Average \u2b06\ufe0f": 27.010507040994607, "Hub License": "llama3", "Hub \u2764\ufe0f": 140, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.756077208473517, "IFEval": 75.60772084735169, "BBH Raw": 0.5110566504436299, "BBH": 30.30798586214647, "MATH Lvl 5 Raw": 0.080060422960725, "MATH Lvl 5": 8.006042296072508, "GPQA Raw": 0.3062080536912752, "GPQA": 7.494407158836691, "MUSR Raw": 0.4019375, "MUSR": 9.075520833333336, "MMLU-PRO Raw": 0.3841422872340425, "MMLU-PRO": 31.57136524822695, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-05-27T00:00:00", "Submission Date": "2024-07-25T00:00:00", "Generation": 0, "Base Model": "mlabonne/NeuralDaredevil-8B-abliterated"}, {"eval_name": "mlabonne_NeuralDaredevil-8B-abliterated_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/mlabonne/NeuralDaredevil-8B-abliterated\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">mlabonne/NeuralDaredevil-8B-abliterated</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/mlabonne__NeuralDaredevil-8B-abliterated-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "mlabonne/NeuralDaredevil-8B-abliterated", "Model sha": "89b01e3292e031ed85ad21545849182f5627021e", "Average \u2b06\ufe0f": 21.499914415098534, "Hub License": "llama3", "Hub \u2764\ufe0f": 140, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4162333718976759, "IFEval": 41.6233371897676, "BBH Raw": 0.5123964057729099, "BBH": 29.763198395755456, "MATH Lvl 5 Raw": 0.0853474320241691, "MATH Lvl 5": 8.534743202416918, "GPQA Raw": 0.3028523489932886, "GPQA": 7.046979865771815, "MUSR Raw": 0.4149583333333333, "MUSR": 10.903124999999996, "MMLU-PRO Raw": 0.3801529255319149, "MMLU-PRO": 31.128102836879428, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-05-27T00:00:00", "Submission Date": "2024-06-27T00:00:00", "Generation": 0, "Base Model": "mlabonne/NeuralDaredevil-8B-abliterated"}, {"eval_name": "mlabonne_OrpoLlama-3-8B_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/mlabonne/OrpoLlama-3-8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">mlabonne/OrpoLlama-3-8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/mlabonne__OrpoLlama-3-8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "mlabonne/OrpoLlama-3-8B", "Model sha": "7f200e4c84ad0daa3ff6bc414012d8d0bacbf90e", "Average \u2b06\ufe0f": 14.86751004330882, "Hub License": "other", "Hub \u2764\ufe0f": 53, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3652752474545317, "IFEval": 36.52752474545318, "BBH Raw": 0.4424079063503051, "BBH": 21.95410762879941, "MATH Lvl 5 Raw": 0.0385196374622356, "MATH Lvl 5": 3.8519637462235647, "GPQA Raw": 0.2793624161073825, "GPQA": 3.9149888143176734, "MUSR Raw": 0.3579375, "MUSR": 4.008854166666668, "MMLU-PRO Raw": 0.2705285904255319, "MMLU-PRO": 18.947621158392437, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-04-18T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 1, "Base Model": "meta-llama/Meta-Llama-3-8B"}, {"eval_name": "mlabonne_phixtral-2x2_8_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "PhiForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/mlabonne/phixtral-2x2_8\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">mlabonne/phixtral-2x2_8</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/mlabonne__phixtral-2x2_8-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "mlabonne/phixtral-2x2_8", "Model sha": "7744a977d83f132ae5808d8c3b70157031f7de44", "Average \u2b06\ufe0f": 15.389468073057904, "Hub License": "mit", "Hub \u2764\ufe0f": 146, "#Params (B)": 4, "Available on the hub": true, "Not_Merged": true, "MoE": false, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3431184811854767, "IFEval": 34.31184811854767, "BBH Raw": 0.488859418730762, "BBH": 28.502644855771297, "MATH Lvl 5 Raw": 0.0256797583081571, "MATH Lvl 5": 2.56797583081571, "GPQA Raw": 0.2651006711409396, "GPQA": 2.0134228187919474, "MUSR Raw": 0.3643541666666667, "MUSR": 7.710937500000003, "MMLU-PRO Raw": 0.2550698138297872, "MMLU-PRO": 17.229979314420802, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-01-07T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "mlabonne/phixtral-2x2_8"}, {"eval_name": "mmnga_Llama-3-70B-japanese-suzume-vector-v0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/mmnga/Llama-3-70B-japanese-suzume-vector-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">mmnga/Llama-3-70B-japanese-suzume-vector-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/mmnga__Llama-3-70B-japanese-suzume-vector-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "mmnga/Llama-3-70B-japanese-suzume-vector-v0.1", "Model sha": "16f98b2d45684af2c4a9ff5da75b00ef13cca808", "Average \u2b06\ufe0f": 30.543689991662063, "Hub License": "llama3", "Hub \u2764\ufe0f": 4, "#Params (B)": 70, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4648931501748693, "IFEval": 46.48931501748693, "BBH Raw": 0.6541763652331517, "BBH": 50.02266053282724, "MATH Lvl 5 Raw": 0.2424471299093655, "MATH Lvl 5": 24.24471299093656, "GPQA Raw": 0.2860738255033557, "GPQA": 4.809843400447425, "MUSR Raw": 0.4140625, "MUSR": 10.757812500000002, "MMLU-PRO Raw": 0.5224401595744681, "MMLU-PRO": 46.93779550827424, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-28T00:00:00", "Submission Date": "2024-09-19T00:00:00", "Generation": 0, "Base Model": "mmnga/Llama-3-70B-japanese-suzume-vector-v0.1"}, {"eval_name": "monsterapi_Llama-3_1-8B-Instruct-orca-ORPO_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Adapter", "Architecture": "?", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/monsterapi/Llama-3_1-8B-Instruct-orca-ORPO\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">monsterapi/Llama-3_1-8B-Instruct-orca-ORPO</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/monsterapi__Llama-3_1-8B-Instruct-orca-ORPO-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "monsterapi/Llama-3_1-8B-Instruct-orca-ORPO", "Model sha": "5206a32e0bd3067aef1ce90f5528ade7d866253f", "Average \u2b06\ufe0f": 4.832138103419669, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 16, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2272891483486039, "IFEval": 22.728914834860397, "BBH Raw": 0.286536257787428, "BBH": 1.3404688979507675, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2491610738255033, "GPQA": 0.0, "MUSR Raw": 0.3444791666666666, "MUSR": 3.0598958333333326, "MMLU-PRO Raw": 0.1167719414893617, "MMLU-PRO": 1.8635490543735225, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-01T00:00:00", "Submission Date": "2024-08-30T00:00:00", "Generation": 2, "Base Model": "meta-llama/Meta-Llama-3.1-8B"}, {"eval_name": "monsterapi_gemma-2-2b-LoRA-MonsterInstruct_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/monsterapi/gemma-2-2b-LoRA-MonsterInstruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">monsterapi/gemma-2-2b-LoRA-MonsterInstruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/monsterapi__gemma-2-2b-LoRA-MonsterInstruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "monsterapi/gemma-2-2b-LoRA-MonsterInstruct", "Model sha": "6422e27e96e15cf93b966c973aacc15f8a27a458", "Average \u2b06\ufe0f": 11.840114683532404, "Hub License": "gemma", "Hub \u2764\ufe0f": 0, "#Params (B)": 2, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3902545246612322, "IFEval": 39.02545246612322, "BBH Raw": 0.3649686192749869, "BBH": 11.965057260762338, "MATH Lvl 5 Raw": 0.0098187311178247, "MATH Lvl 5": 0.9818731117824772, "GPQA Raw": 0.2701342281879195, "GPQA": 2.684563758389265, "MUSR Raw": 0.3643854166666667, "MUSR": 5.41484375, "MMLU-PRO Raw": 0.198720079787234, "MMLU-PRO": 10.968897754137116, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-03T00:00:00", "Submission Date": "2024-08-05T00:00:00", "Generation": 0, "Base Model": "monsterapi/gemma-2-2b-LoRA-MonsterInstruct"}, {"eval_name": "mosaicml_mpt-7b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "MPTForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/mosaicml/mpt-7b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">mosaicml/mpt-7b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/mosaicml__mpt-7b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "mosaicml/mpt-7b", "Model sha": "039e37745f00858f0e01e988383a8c4393b1a4f5", "Average \u2b06\ufe0f": 5.981676871872839, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1158, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2151990053059216, "IFEval": 21.51990053059216, "BBH Raw": 0.3299741596080132, "BBH": 6.550600790794161, "MATH Lvl 5 Raw": 0.0128398791540785, "MATH Lvl 5": 1.283987915407855, "GPQA Raw": 0.2600671140939597, "GPQA": 1.342281879194629, "MUSR Raw": 0.3672395833333333, "MUSR": 2.904947916666668, "MMLU-PRO Raw": 0.120595079787234, "MMLU-PRO": 2.288342198581559, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-05-05T00:00:00", "Submission Date": "2024-06-08T00:00:00", "Generation": 0, "Base Model": "mosaicml/mpt-7b"}, {"eval_name": "natong19_Mistral-Nemo-Instruct-2407-abliterated_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/natong19/Mistral-Nemo-Instruct-2407-abliterated\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">natong19/Mistral-Nemo-Instruct-2407-abliterated</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/natong19__Mistral-Nemo-Instruct-2407-abliterated-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "natong19/Mistral-Nemo-Instruct-2407-abliterated", "Model sha": "9c7087f62e6ab10ec4aeeb268e25cb3d4000696b", "Average \u2b06\ufe0f": 23.758813738775725, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 6, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6392239258500778, "IFEval": 63.92239258500778, "BBH Raw": 0.5048447739625885, "BBH": 29.915044266358997, "MATH Lvl 5 Raw": 0.0566465256797583, "MATH Lvl 5": 5.664652567975831, "GPQA Raw": 0.2869127516778523, "GPQA": 4.921700223713646, "MUSR Raw": 0.4033333333333333, "MUSR": 10.15, "MMLU-PRO Raw": 0.351811835106383, "MMLU-PRO": 27.979092789598106, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-15T00:00:00", "Submission Date": "2024-09-21T00:00:00", "Generation": 0, "Base Model": "natong19/Mistral-Nemo-Instruct-2407-abliterated"}, {"eval_name": "natong19_Qwen2-7B-Instruct-abliterated_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/natong19/Qwen2-7B-Instruct-abliterated\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">natong19/Qwen2-7B-Instruct-abliterated</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/natong19__Qwen2-7B-Instruct-abliterated-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "natong19/Qwen2-7B-Instruct-abliterated", "Model sha": "127962453ae87879719a82a97384ac1859787a25", "Average \u2b06\ufe0f": 25.62007473244844, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 5, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5836945970026197, "IFEval": 58.36945970026197, "BBH Raw": 0.5553035842403061, "BBH": 37.74683385346309, "MATH Lvl 5 Raw": 0.1027190332326284, "MATH Lvl 5": 10.27190332326284, "GPQA Raw": 0.3011744966442953, "GPQA": 6.823266219239373, "MUSR Raw": 0.4034270833333333, "MUSR": 8.92838541666667, "MMLU-PRO Raw": 0.3842253989361702, "MMLU-PRO": 31.580599881796683, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-14T00:00:00", "Submission Date": "2024-07-29T00:00:00", "Generation": 0, "Base Model": "natong19/Qwen2-7B-Instruct-abliterated"}, {"eval_name": "nbeerbower_Flammades-Mistral-Nemo-12B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/nbeerbower/Flammades-Mistral-Nemo-12B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">nbeerbower/Flammades-Mistral-Nemo-12B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/nbeerbower__Flammades-Mistral-Nemo-12B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "nbeerbower/Flammades-Mistral-Nemo-12B", "Model sha": "ddc76d1976af06aedc7f06bbffcaa34166c1cbdd", "Average \u2b06\ufe0f": 22.34013811309316, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3841595854554803, "IFEval": 38.41595854554804, "BBH Raw": 0.5299609345270283, "BBH": 32.39377187272594, "MATH Lvl 5 Raw": 0.0619335347432024, "MATH Lvl 5": 6.193353474320242, "GPQA Raw": 0.3036912751677852, "GPQA": 7.158836689038028, "MUSR Raw": 0.480625, "MUSR": 20.31145833333333, "MMLU-PRO Raw": 0.3661070478723404, "MMLU-PRO": 29.56744976359338, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-05T00:00:00", "Submission Date": "2024-10-06T00:00:00", "Generation": 1, "Base Model": "nbeerbower/Flammades-Mistral-Nemo-12B (Merge)"}, {"eval_name": "nbeerbower_Gemma2-Gutenberg-Doppel-9B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/nbeerbower/Gemma2-Gutenberg-Doppel-9B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">nbeerbower/Gemma2-Gutenberg-Doppel-9B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/nbeerbower__Gemma2-Gutenberg-Doppel-9B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "nbeerbower/Gemma2-Gutenberg-Doppel-9B", "Model sha": "f425bc69783891088e89e0afe44ec62b730567ba", "Average \u2b06\ufe0f": 29.823411042771763, "Hub License": "gemma", "Hub \u2764\ufe0f": 2, "#Params (B)": 9, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.7171094917042337, "IFEval": 71.71094917042336, "BBH Raw": 0.5870114193661848, "BBH": 41.08306318800703, "MATH Lvl 5 Raw": 0.0347432024169184, "MATH Lvl 5": 3.474320241691843, "GPQA Raw": 0.3296979865771812, "GPQA": 10.626398210290828, "MUSR Raw": 0.46078125, "MUSR": 17.29765625, "MMLU-PRO Raw": 0.4127327127659574, "MMLU-PRO": 34.748079196217496, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-29T00:00:00", "Submission Date": "2024-10-01T00:00:00", "Generation": 1, "Base Model": "nbeerbower/Gemma2-Gutenberg-Doppel-9B (Merge)"}, {"eval_name": "nbeerbower_Gutensuppe-mistral-nemo-12B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/nbeerbower/Gutensuppe-mistral-nemo-12B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">nbeerbower/Gutensuppe-mistral-nemo-12B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/nbeerbower__Gutensuppe-mistral-nemo-12B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "nbeerbower/Gutensuppe-mistral-nemo-12B", "Model sha": "6ee13f347071bc3c4ee95c9dc3488a4093927143", "Average \u2b06\ufe0f": 21.91657848609934, "Hub License": null, "Hub \u2764\ufe0f": 5, "#Params (B)": 12, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2916107040430502, "IFEval": 29.161070404305026, "BBH Raw": 0.5486832203098263, "BBH": 35.56934797458052, "MATH Lvl 5 Raw": 0.1102719033232628, "MATH Lvl 5": 11.027190332326285, "GPQA Raw": 0.337248322147651, "GPQA": 11.6331096196868, "MUSR Raw": 0.42903125, "MUSR": 14.328906249999998, "MMLU-PRO Raw": 0.3680186170212766, "MMLU-PRO": 29.779846335697403, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-23T00:00:00", "Submission Date": "2024-09-03T00:00:00", "Generation": 1, "Base Model": "nbeerbower/Gutensuppe-mistral-nemo-12B (Merge)"}, {"eval_name": "nbeerbower_Hermes2-Gutenberg2-Mistral-7B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/nbeerbower/Hermes2-Gutenberg2-Mistral-7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">nbeerbower/Hermes2-Gutenberg2-Mistral-7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/nbeerbower__Hermes2-Gutenberg2-Mistral-7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "nbeerbower/Hermes2-Gutenberg2-Mistral-7B", "Model sha": "5eec0dfd29999ef1d7775010b7e9c7be9ed89bfd", "Average \u2b06\ufe0f": 19.35127264204293, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 2, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3721447980247964, "IFEval": 37.21447980247965, "BBH Raw": 0.4981450458280896, "BBH": 28.907334664767347, "MATH Lvl 5 Raw": 0.0566465256797583, "MATH Lvl 5": 5.664652567975831, "GPQA Raw": 0.2894295302013422, "GPQA": 5.257270693512303, "MUSR Raw": 0.4623020833333333, "MUSR": 16.92109375, "MMLU-PRO Raw": 0.2992852393617021, "MMLU-PRO": 22.14280437352246, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-30T00:00:00", "Submission Date": "2024-10-01T00:00:00", "Generation": 1, "Base Model": "nbeerbower/Hermes2-Gutenberg2-Mistral-7B (Merge)"}, {"eval_name": "nbeerbower_Lyra-Gutenberg-mistral-nemo-12B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/nbeerbower/Lyra-Gutenberg-mistral-nemo-12B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">nbeerbower/Lyra-Gutenberg-mistral-nemo-12B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/nbeerbower__Lyra-Gutenberg-mistral-nemo-12B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "nbeerbower/Lyra-Gutenberg-mistral-nemo-12B", "Model sha": "5c506391eb02075e02f4cf5953b443505d646bce", "Average \u2b06\ufe0f": 22.56524904898664, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 15, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3494882467408697, "IFEval": 34.94882467408698, "BBH Raw": 0.5586245741555749, "BBH": 36.99243243937594, "MATH Lvl 5 Raw": 0.0830815709969788, "MATH Lvl 5": 8.308157099697885, "GPQA Raw": 0.3338926174496644, "GPQA": 11.185682326621922, "MUSR Raw": 0.4356666666666666, "MUSR": 14.758333333333333, "MMLU-PRO Raw": 0.362782579787234, "MMLU-PRO": 29.19806442080379, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-23T00:00:00", "Submission Date": "2024-09-03T00:00:00", "Generation": 1, "Base Model": "nbeerbower/Lyra-Gutenberg-mistral-nemo-12B (Merge)"}, {"eval_name": "nbeerbower_Lyra4-Gutenberg-12B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/nbeerbower/Lyra4-Gutenberg-12B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">nbeerbower/Lyra4-Gutenberg-12B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/nbeerbower__Lyra4-Gutenberg-12B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "nbeerbower/Lyra4-Gutenberg-12B", "Model sha": "cb6911be3475da99a810071c04803d6edfb5965b", "Average \u2b06\ufe0f": 19.630121244079547, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 17, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2212185888996751, "IFEval": 22.12185888996751, "BBH Raw": 0.538669487933139, "BBH": 34.23559275480162, "MATH Lvl 5 Raw": 0.1170694864048338, "MATH Lvl 5": 11.706948640483382, "GPQA Raw": 0.3187919463087248, "GPQA": 9.172259507829976, "MUSR Raw": 0.4037916666666666, "MUSR": 11.973958333333329, "MMLU-PRO Raw": 0.3571309840425531, "MMLU-PRO": 28.570109338061467, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-09T00:00:00", "Submission Date": "2024-09-12T00:00:00", "Generation": 1, "Base Model": "nbeerbower/Lyra4-Gutenberg-12B (Merge)"}, {"eval_name": "nbeerbower_Lyra4-Gutenberg2-12B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/nbeerbower/Lyra4-Gutenberg2-12B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">nbeerbower/Lyra4-Gutenberg2-12B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/nbeerbower__Lyra4-Gutenberg2-12B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "nbeerbower/Lyra4-Gutenberg2-12B", "Model sha": "6a5f117695cc729de16da87654b979e6df72ed2f", "Average \u2b06\ufe0f": 19.743471927197398, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 7, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2585129678142883, "IFEval": 25.851296781428832, "BBH Raw": 0.5344527944750038, "BBH": 33.73063962440059, "MATH Lvl 5 Raw": 0.1049848942598187, "MATH Lvl 5": 10.498489425981871, "GPQA Raw": 0.3129194630872483, "GPQA": 8.389261744966444, "MUSR Raw": 0.3972187499999999, "MUSR": 11.485677083333329, "MMLU-PRO Raw": 0.3565492021276595, "MMLU-PRO": 28.50546690307328, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-29T00:00:00", "Submission Date": "2024-10-01T00:00:00", "Generation": 1, "Base Model": "nbeerbower/Lyra4-Gutenberg2-12B (Merge)"}, {"eval_name": "nbeerbower_Mistral-Nemo-Gutenberg-Doppel-12B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/nbeerbower/Mistral-Nemo-Gutenberg-Doppel-12B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">nbeerbower/Mistral-Nemo-Gutenberg-Doppel-12B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/nbeerbower__Mistral-Nemo-Gutenberg-Doppel-12B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "nbeerbower/Mistral-Nemo-Gutenberg-Doppel-12B", "Model sha": "0eaaac89d4b53e94d5b78220b24439a026ee29e6", "Average \u2b06\ufe0f": 21.28622464315799, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 2, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3567068711020093, "IFEval": 35.67068711020093, "BBH Raw": 0.5274606999473499, "BBH": 32.42152675939865, "MATH Lvl 5 Raw": 0.1064954682779456, "MATH Lvl 5": 10.649546827794564, "GPQA Raw": 0.3162751677852349, "GPQA": 8.83668903803132, "MUSR Raw": 0.4132187499999999, "MUSR": 11.485677083333329, "MMLU-PRO Raw": 0.3578789893617021, "MMLU-PRO": 28.65322104018913, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-26T00:00:00", "Submission Date": "2024-09-26T00:00:00", "Generation": 1, "Base Model": "nbeerbower/Mistral-Nemo-Gutenberg-Doppel-12B (Merge)"}, {"eval_name": "nbeerbower_Mistral-Nemo-Gutenberg-Doppel-12B-v2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/nbeerbower/Mistral-Nemo-Gutenberg-Doppel-12B-v2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">nbeerbower/Mistral-Nemo-Gutenberg-Doppel-12B-v2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/nbeerbower__Mistral-Nemo-Gutenberg-Doppel-12B-v2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "nbeerbower/Mistral-Nemo-Gutenberg-Doppel-12B-v2", "Model sha": "adc1ccd9d83d24e41bed895f989803af87ea2d2c", "Average \u2b06\ufe0f": 24.65504001243245, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 4, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6535869271311232, "IFEval": 65.35869271311232, "BBH Raw": 0.5374496172235809, "BBH": 34.35741284991507, "MATH Lvl 5 Raw": 0.0407854984894259, "MATH Lvl 5": 4.078549848942599, "GPQA Raw": 0.2709731543624161, "GPQA": 2.796420581655479, "MUSR Raw": 0.4233020833333333, "MUSR": 13.046093749999995, "MMLU-PRO Raw": 0.3546376329787234, "MMLU-PRO": 28.29307033096927, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-04T00:00:00", "Submission Date": "2024-10-09T00:00:00", "Generation": 1, "Base Model": "nbeerbower/Mistral-Nemo-Gutenberg-Doppel-12B-v2 (Merge)"}, {"eval_name": "nbeerbower_Mistral-Small-Drummer-22B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/nbeerbower/Mistral-Small-Drummer-22B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">nbeerbower/Mistral-Small-Drummer-22B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/nbeerbower__Mistral-Small-Drummer-22B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "nbeerbower/Mistral-Small-Drummer-22B", "Model sha": "53b21ece0c64ffc8aba81f294ad19e2c06e9852c", "Average \u2b06\ufe0f": 29.454353409900733, "Hub License": "other", "Hub \u2764\ufe0f": 6, "#Params (B)": 22, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.6331289866443259, "IFEval": 63.3128986644326, "BBH Raw": 0.5793201948136216, "BBH": 40.12177010845507, "MATH Lvl 5 Raw": 0.1669184290030211, "MATH Lvl 5": 16.691842900302113, "GPQA Raw": 0.3431208053691275, "GPQA": 12.416107382550338, "MUSR Raw": 0.4063645833333333, "MUSR": 9.795572916666668, "MMLU-PRO Raw": 0.4094913563829787, "MMLU-PRO": 34.38792848699764, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-26T00:00:00", "Submission Date": "2024-10-01T00:00:00", "Generation": 1, "Base Model": "nbeerbower/Mistral-Small-Drummer-22B (Merge)"}, {"eval_name": "nbeerbower_Mistral-Small-Gutenberg-Doppel-22B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/nbeerbower/Mistral-Small-Gutenberg-Doppel-22B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">nbeerbower/Mistral-Small-Gutenberg-Doppel-22B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/nbeerbower__Mistral-Small-Gutenberg-Doppel-22B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "nbeerbower/Mistral-Small-Gutenberg-Doppel-22B", "Model sha": "d8091aad5f882b714321e4d51f504cc61996ee67", "Average \u2b06\ufe0f": 27.581808111737303, "Hub License": "other", "Hub \u2764\ufe0f": 7, "#Params (B)": 22, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4893227746822874, "IFEval": 48.93227746822875, "BBH Raw": 0.5858932329112819, "BBH": 40.93134519747112, "MATH Lvl 5 Raw": 0.1948640483383685, "MATH Lvl 5": 19.486404833836858, "GPQA Raw": 0.3464765100671141, "GPQA": 12.863534675615217, "MUSR Raw": 0.3970625, "MUSR": 8.566145833333334, "MMLU-PRO Raw": 0.4124002659574468, "MMLU-PRO": 34.711140661938536, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-25T00:00:00", "Submission Date": "2024-09-25T00:00:00", "Generation": 1, "Base Model": "nbeerbower/Mistral-Small-Gutenberg-Doppel-22B (Merge)"}, {"eval_name": "nbeerbower_Stella-mistral-nemo-12B-v2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/nbeerbower/Stella-mistral-nemo-12B-v2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">nbeerbower/Stella-mistral-nemo-12B-v2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/nbeerbower__Stella-mistral-nemo-12B-v2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "nbeerbower/Stella-mistral-nemo-12B-v2", "Model sha": "b81bab28f7dcb25a0aa0fe4dcf957f3083ee6b43", "Average \u2b06\ufe0f": 22.29189984891019, "Hub License": null, "Hub \u2764\ufe0f": 3, "#Params (B)": 12, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3274312158406361, "IFEval": 32.743121584063616, "BBH Raw": 0.5483750956495209, "BBH": 35.364516100686416, "MATH Lvl 5 Raw": 0.1042296072507553, "MATH Lvl 5": 10.42296072507553, "GPQA Raw": 0.3322147651006711, "GPQA": 10.96196868008949, "MUSR Raw": 0.4303958333333333, "MUSR": 14.432812499999995, "MMLU-PRO Raw": 0.3684341755319149, "MMLU-PRO": 29.82601950354609, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-07T00:00:00", "Submission Date": "2024-09-14T00:00:00", "Generation": 1, "Base Model": "nbeerbower/Stella-mistral-nemo-12B-v2 (Merge)"}, {"eval_name": "nbeerbower_gemma2-gutenberg-27B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/nbeerbower/gemma2-gutenberg-27B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">nbeerbower/gemma2-gutenberg-27B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/nbeerbower__gemma2-gutenberg-27B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "nbeerbower/gemma2-gutenberg-27B", "Model sha": "d4febe52e8b7b13a98126dbf1716ed1329f48922", "Average \u2b06\ufe0f": 10.1089609543278, "Hub License": "gemma", "Hub \u2764\ufe0f": 4, "#Params (B)": 27, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2947080413303368, "IFEval": 29.47080413303368, "BBH Raw": 0.3796568350345161, "BBH": 13.091524912026523, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2726510067114094, "GPQA": 3.0201342281879207, "MUSR Raw": 0.3727291666666666, "MUSR": 4.1578125, "MMLU-PRO Raw": 0.198221409574468, "MMLU-PRO": 10.913489952718674, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-09T00:00:00", "Submission Date": "2024-09-23T00:00:00", "Generation": 1, "Base Model": "nbeerbower/gemma2-gutenberg-27B (Merge)"}, {"eval_name": "nbeerbower_gemma2-gutenberg-9B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/nbeerbower/gemma2-gutenberg-9B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">nbeerbower/gemma2-gutenberg-9B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/nbeerbower__gemma2-gutenberg-9B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "nbeerbower/gemma2-gutenberg-9B", "Model sha": "ebdab2d41f257fc9e7c858498653644d13386ce5", "Average \u2b06\ufe0f": 22.61149217284802, "Hub License": "gemma", "Hub \u2764\ufe0f": 9, "#Params (B)": 9, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2795948084416016, "IFEval": 27.95948084416016, "BBH Raw": 0.5950904001490335, "BBH": 42.35561106809721, "MATH Lvl 5 Raw": 0.0143504531722054, "MATH Lvl 5": 1.4350453172205435, "GPQA Raw": 0.3380872483221476, "GPQA": 11.74496644295302, "MUSR Raw": 0.4595104166666666, "MUSR": 16.705468749999994, "MMLU-PRO Raw": 0.4192154255319149, "MMLU-PRO": 35.4683806146572, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-14T00:00:00", "Submission Date": "2024-08-03T00:00:00", "Generation": 1, "Base Model": "nbeerbower/gemma2-gutenberg-9B (Merge)"}, {"eval_name": "nbeerbower_llama-3-gutenberg-8B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/nbeerbower/llama-3-gutenberg-8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">nbeerbower/llama-3-gutenberg-8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/nbeerbower__llama-3-gutenberg-8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "nbeerbower/llama-3-gutenberg-8B", "Model sha": "4ed3aac5e30c078bee79ae193c2d301d38860b20", "Average \u2b06\ufe0f": 21.17034777157925, "Hub License": "other", "Hub \u2764\ufe0f": 7, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4371910973993448, "IFEval": 43.71910973993448, "BBH Raw": 0.4993600256199419, "BBH": 27.958132724191334, "MATH Lvl 5 Raw": 0.0702416918429003, "MATH Lvl 5": 7.02416918429003, "GPQA Raw": 0.3011744966442953, "GPQA": 6.823266219239373, "MUSR Raw": 0.4073020833333333, "MUSR": 10.04609375, "MMLU-PRO Raw": 0.383061835106383, "MMLU-PRO": 31.451315011820324, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-05T00:00:00", "Submission Date": "2024-07-10T00:00:00", "Generation": 1, "Base Model": "nbeerbower/llama-3-gutenberg-8B (Merge)"}, {"eval_name": "nbeerbower_llama3.1-cc-8B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/nbeerbower/llama3.1-cc-8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">nbeerbower/llama3.1-cc-8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/nbeerbower__llama3.1-cc-8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "nbeerbower/llama3.1-cc-8B", "Model sha": "5269bb26f1afe005f144564f484e7554f185239f", "Average \u2b06\ufe0f": 20.13016049257663, "Hub License": "llama3", "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.5068086011782071, "IFEval": 50.68086011782072, "BBH Raw": 0.4871187428614386, "BBH": 26.48381169342659, "MATH Lvl 5 Raw": 0.0634441087613293, "MATH Lvl 5": 6.3444108761329305, "GPQA Raw": 0.285234899328859, "GPQA": 4.697986577181204, "MUSR Raw": 0.3885104166666666, "MUSR": 6.497135416666668, "MMLU-PRO Raw": 0.3346908244680851, "MMLU-PRO": 26.076758274231683, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-18T00:00:00", "Submission Date": "2024-09-14T00:00:00", "Generation": 1, "Base Model": "nbeerbower/llama3.1-cc-8B (Merge)"}, {"eval_name": "nbeerbower_mistral-nemo-bophades-12B_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/nbeerbower/mistral-nemo-bophades-12B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">nbeerbower/mistral-nemo-bophades-12B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/nbeerbower__mistral-nemo-bophades-12B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "nbeerbower/mistral-nemo-bophades-12B", "Model sha": "252a358e099f77a0a28125e00a57aa3a107b3910", "Average \u2b06\ufe0f": 24.7215529354948, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 7, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6794405510711579, "IFEval": 67.94405510711579, "BBH Raw": 0.4988471515853883, "BBH": 29.543905352144947, "MATH Lvl 5 Raw": 0.0626888217522658, "MATH Lvl 5": 6.268882175226587, "GPQA Raw": 0.285234899328859, "GPQA": 4.697986577181204, "MUSR Raw": 0.41778125, "MUSR": 12.089322916666667, "MMLU-PRO Raw": 0.3500664893617021, "MMLU-PRO": 27.785165484633573, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-13T00:00:00", "Submission Date": "2024-09-03T00:00:00", "Generation": 1, "Base Model": "nbeerbower/mistral-nemo-bophades-12B (Merge)"}, {"eval_name": "nbeerbower_mistral-nemo-cc-12B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/nbeerbower/mistral-nemo-cc-12B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">nbeerbower/mistral-nemo-cc-12B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/nbeerbower__mistral-nemo-cc-12B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "nbeerbower/mistral-nemo-cc-12B", "Model sha": "fc32293e0b022d6daef9bfdb0c54d57a5226bf9a", "Average \u2b06\ufe0f": 17.07752910499712, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.143532493783162, "IFEval": 14.3532493783162, "BBH Raw": 0.5399409546487519, "BBH": 34.44654701952267, "MATH Lvl 5 Raw": 0.0181268882175226, "MATH Lvl 5": 1.812688821752266, "GPQA Raw": 0.3154362416107382, "GPQA": 8.7248322147651, "MUSR Raw": 0.4423645833333333, "MUSR": 14.262239583333338, "MMLU-PRO Raw": 0.3597905585106383, "MMLU-PRO": 28.865617612293136, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-18T00:00:00", "Submission Date": "2024-09-14T00:00:00", "Generation": 1, "Base Model": "nbeerbower/mistral-nemo-cc-12B (Merge)"}, {"eval_name": "nbeerbower_mistral-nemo-gutades-12B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/nbeerbower/mistral-nemo-gutades-12B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">nbeerbower/mistral-nemo-gutades-12B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/nbeerbower__mistral-nemo-gutades-12B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "nbeerbower/mistral-nemo-gutades-12B", "Model sha": "5689f929808a6165f94ba43f872b944a4bdaaea3", "Average \u2b06\ufe0f": 20.76122173900939, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 2, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3425189608017837, "IFEval": 34.25189608017837, "BBH Raw": 0.5407194259684368, "BBH": 34.57440821872691, "MATH Lvl 5 Raw": 0.0989425981873111, "MATH Lvl 5": 9.894259818731117, "GPQA Raw": 0.3154362416107382, "GPQA": 8.7248322147651, "MUSR Raw": 0.4040416666666667, "MUSR": 8.671875000000004, "MMLU-PRO Raw": 0.3560505319148936, "MMLU-PRO": 28.45005910165484, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-17T00:00:00", "Submission Date": "2024-09-23T00:00:00", "Generation": 1, "Base Model": "nbeerbower/mistral-nemo-gutades-12B (Merge)"}, {"eval_name": "nbeerbower_mistral-nemo-gutenberg-12B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/nbeerbower/mistral-nemo-gutenberg-12B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">nbeerbower/mistral-nemo-gutenberg-12B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/nbeerbower__mistral-nemo-gutenberg-12B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "nbeerbower/mistral-nemo-gutenberg-12B", "Model sha": "6aeb6f769a53eb111839db8f439b614730e39593", "Average \u2b06\ufe0f": 20.82274509573089, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 6, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.350386973231027, "IFEval": 35.0386973231027, "BBH Raw": 0.5281363707697807, "BBH": 32.43387434197657, "MATH Lvl 5 Raw": 0.1042296072507553, "MATH Lvl 5": 10.42296072507553, "GPQA Raw": 0.3070469798657718, "GPQA": 7.606263982102905, "MUSR Raw": 0.4170625, "MUSR": 10.966145833333336, "MMLU-PRO Raw": 0.3562167553191489, "MMLU-PRO": 28.46852836879432, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-12T00:00:00", "Submission Date": "2024-09-03T00:00:00", "Generation": 1, "Base Model": "nbeerbower/mistral-nemo-gutenberg-12B (Merge)"}, {"eval_name": "nbeerbower_mistral-nemo-gutenberg-12B-v2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/nbeerbower/mistral-nemo-gutenberg-12B-v2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">nbeerbower/mistral-nemo-gutenberg-12B-v2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/nbeerbower__mistral-nemo-gutenberg-12B-v2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "nbeerbower/mistral-nemo-gutenberg-12B-v2", "Model sha": "86bf9c105ff40835132e41699ac1a76ee0e5b683", "Average \u2b06\ufe0f": 24.054098286364027, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 20, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6203395878491292, "IFEval": 62.033958784912926, "BBH Raw": 0.5397203788283472, "BBH": 34.73061633928093, "MATH Lvl 5 Raw": 0.0211480362537764, "MATH Lvl 5": 2.114803625377644, "GPQA Raw": 0.2776845637583892, "GPQA": 3.691275167785232, "MUSR Raw": 0.4286979166666667, "MUSR": 13.987239583333333, "MMLU-PRO Raw": 0.3499002659574468, "MMLU-PRO": 27.76669621749409, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-13T00:00:00", "Submission Date": "2024-09-03T00:00:00", "Generation": 1, "Base Model": "nbeerbower/mistral-nemo-gutenberg-12B-v2 (Merge)"}, {"eval_name": "nbeerbower_mistral-nemo-gutenberg-12B-v3_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/nbeerbower/mistral-nemo-gutenberg-12B-v3\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">nbeerbower/mistral-nemo-gutenberg-12B-v3</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/nbeerbower__mistral-nemo-gutenberg-12B-v3-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "nbeerbower/mistral-nemo-gutenberg-12B-v3", "Model sha": "3e1a716281f23280abd72e402139c578faca175a", "Average \u2b06\ufe0f": 19.0639260308616, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 10, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2182708546656205, "IFEval": 21.827085466562057, "BBH Raw": 0.544065799051091, "BBH": 34.95791456295642, "MATH Lvl 5 Raw": 0.04607250755287, "MATH Lvl 5": 4.607250755287009, "GPQA Raw": 0.3145973154362416, "GPQA": 8.612975391498878, "MUSR Raw": 0.44503125, "MUSR": 14.995572916666662, "MMLU-PRO Raw": 0.3644448138297872, "MMLU-PRO": 29.38275709219858, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-15T00:00:00", "Submission Date": "2024-09-03T00:00:00", "Generation": 1, "Base Model": "nbeerbower/mistral-nemo-gutenberg-12B-v3 (Merge)"}, {"eval_name": "nbeerbower_mistral-nemo-gutenberg-12B-v4_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/nbeerbower/mistral-nemo-gutenberg-12B-v4\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">nbeerbower/mistral-nemo-gutenberg-12B-v4</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/nbeerbower__mistral-nemo-gutenberg-12B-v4-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "nbeerbower/mistral-nemo-gutenberg-12B-v4", "Model sha": "59409afe585ae6945a588c867f879a9d31e571e6", "Average \u2b06\ufe0f": 19.56204287811981, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 12, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.237929804031082, "IFEval": 23.7929804031082, "BBH Raw": 0.5269028864823667, "BBH": 31.97125827358258, "MATH Lvl 5 Raw": 0.1095166163141994, "MATH Lvl 5": 10.95166163141994, "GPQA Raw": 0.3162751677852349, "GPQA": 8.83668903803132, "MUSR Raw": 0.4104270833333333, "MUSR": 13.203385416666665, "MMLU-PRO Raw": 0.3575465425531915, "MMLU-PRO": 28.616282505910167, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-22T00:00:00", "Submission Date": "2024-09-03T00:00:00", "Generation": 1, "Base Model": "nbeerbower/mistral-nemo-gutenberg-12B-v4 (Merge)"}, {"eval_name": "nbeerbower_mistral-nemo-gutenberg2-12B-test_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/nbeerbower/mistral-nemo-gutenberg2-12B-test\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">nbeerbower/mistral-nemo-gutenberg2-12B-test</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/nbeerbower__mistral-nemo-gutenberg2-12B-test-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "nbeerbower/mistral-nemo-gutenberg2-12B-test", "Model sha": "10da6150b0bedf8fd59206d72c4c0335ac665df3", "Average \u2b06\ufe0f": 20.73140573108906, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3384719211691644, "IFEval": 33.847192116916446, "BBH Raw": 0.525477908630255, "BBH": 32.04475928596384, "MATH Lvl 5 Raw": 0.1019637462235649, "MATH Lvl 5": 10.196374622356496, "GPQA Raw": 0.3171140939597315, "GPQA": 8.948545861297541, "MUSR Raw": 0.4157291666666667, "MUSR": 10.966145833333336, "MMLU-PRO Raw": 0.35546875, "MMLU-PRO": 28.385416666666668, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-24T00:00:00", "Submission Date": "2024-09-25T00:00:00", "Generation": 1, "Base Model": "nbeerbower/mistral-nemo-gutenberg2-12B-test (Merge)"}, {"eval_name": "nbeerbower_mistral-nemo-wissenschaft-12B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/nbeerbower/mistral-nemo-wissenschaft-12B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">nbeerbower/mistral-nemo-wissenschaft-12B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/nbeerbower__mistral-nemo-wissenschaft-12B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "nbeerbower/mistral-nemo-wissenschaft-12B", "Model sha": "2480f9924415c72fe00ae9391bb15a6d05c889eb", "Average \u2b06\ufe0f": 24.57840522043703, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 3, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6520133246452745, "IFEval": 65.20133246452745, "BBH Raw": 0.5040306120993181, "BBH": 29.567999415715217, "MATH Lvl 5 Raw": 0.0657099697885196, "MATH Lvl 5": 6.570996978851963, "GPQA Raw": 0.2927852348993288, "GPQA": 5.7046979865771785, "MUSR Raw": 0.41778125, "MUSR": 12.289322916666665, "MMLU-PRO Raw": 0.3532247340425531, "MMLU-PRO": 28.13608156028369, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-12T00:00:00", "Submission Date": "2024-08-30T00:00:00", "Generation": 1, "Base Model": "nbeerbower/mistral-nemo-wissenschaft-12B (Merge)"}, {"eval_name": "nbrahme_IndusQ_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "GPT2LMHeadModel", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/nbrahme/IndusQ\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">nbrahme/IndusQ</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/nbrahme__IndusQ-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "nbrahme/IndusQ", "Model sha": "d4224f753e6a2d6e7476752fb927c26c55ec9467", "Average \u2b06\ufe0f": 5.623545926817777, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 1, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2439748755524231, "IFEval": 24.39748755524231, "BBH Raw": 0.3062403519847498, "BBH": 3.747096495974056, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2651006711409396, "GPQA": 2.0134228187919545, "MUSR Raw": 0.3366354166666667, "MUSR": 2.24609375, "MMLU-PRO Raw": 0.1120345744680851, "MMLU-PRO": 1.337174940898345, "Maintainer's Highlight": false, "Upload To Hub Date": "", "Submission Date": "2024-09-18T00:00:00", "Generation": 0, "Base Model": "Removed"}, {"eval_name": "netcat420_MFANN-llama3.1-Abliterated-SLERP_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/netcat420/MFANN-llama3.1-Abliterated-SLERP\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">netcat420/MFANN-llama3.1-Abliterated-SLERP</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/netcat420__MFANN-llama3.1-Abliterated-SLERP-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "netcat420/MFANN-llama3.1-Abliterated-SLERP", "Model sha": "0c7b2916727e6c28bbca2aa613b8247b66905915", "Average \u2b06\ufe0f": 13.831281096632956, "Hub License": null, "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2590626205135706, "IFEval": 25.906262051357064, "BBH Raw": 0.4574499946087828, "BBH": 22.28062513418979, "MATH Lvl 5 Raw": 0.0453172205438066, "MATH Lvl 5": 4.531722054380665, "GPQA Raw": 0.273489932885906, "GPQA": 3.1319910514541416, "MUSR Raw": 0.3809166666666666, "MUSR": 5.714583333333336, "MMLU-PRO Raw": 0.2928025265957447, "MMLU-PRO": 21.42250295508274, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-25T00:00:00", "Submission Date": "2024-10-07T00:00:00", "Generation": 1, "Base Model": "netcat420/MFANN-llama3.1-Abliterated-SLERP (Merge)"}, {"eval_name": "netcat420_MFANN-llama3.1-abliterated-SLERP-v3_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/netcat420/MFANN-llama3.1-abliterated-SLERP-v3\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">netcat420/MFANN-llama3.1-abliterated-SLERP-v3</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/netcat420__MFANN-llama3.1-abliterated-SLERP-v3-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "netcat420/MFANN-llama3.1-abliterated-SLERP-v3", "Model sha": "f90a20024060942826302c30860572c227dd4013", "Average \u2b06\ufe0f": 17.941556591410226, "Hub License": "llama3.1", "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.379938563012806, "IFEval": 37.9938563012806, "BBH Raw": 0.4930576546092712, "BBH": 27.1872703942033, "MATH Lvl 5 Raw": 0.0581570996978852, "MATH Lvl 5": 5.81570996978852, "GPQA Raw": 0.2911073825503356, "GPQA": 5.480984340044745, "MUSR Raw": 0.36603125, "MUSR": 3.053906250000002, "MMLU-PRO Raw": 0.3530585106382978, "MMLU-PRO": 28.117612293144205, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-07T00:00:00", "Submission Date": "2024-10-07T00:00:00", "Generation": 1, "Base Model": "netcat420/MFANN-llama3.1-abliterated-SLERP-v3 (Merge)"}, {"eval_name": "netcat420_MFANN-llama3.1-abliterated-SLERP-v3.1_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/netcat420/MFANN-llama3.1-abliterated-SLERP-v3.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">netcat420/MFANN-llama3.1-abliterated-SLERP-v3.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/netcat420__MFANN-llama3.1-abliterated-SLERP-v3.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "netcat420/MFANN-llama3.1-abliterated-SLERP-v3.1", "Model sha": "6d306eb66466cb8e1456a36f3895890a117e91e4", "Average \u2b06\ufe0f": 18.865747473977432, "Hub License": "llama3.1", "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.421678923035324, "IFEval": 42.167892303532405, "BBH Raw": 0.492068920606988, "BBH": 27.026315532744476, "MATH Lvl 5 Raw": 0.0619335347432024, "MATH Lvl 5": 6.193353474320242, "GPQA Raw": 0.2927852348993288, "GPQA": 5.7046979865771785, "MUSR Raw": 0.3686354166666667, "MUSR": 3.846093750000001, "MMLU-PRO Raw": 0.3543051861702128, "MMLU-PRO": 28.25613179669031, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-08T00:00:00", "Submission Date": "2024-10-08T00:00:00", "Generation": 1, "Base Model": "netcat420/MFANN-llama3.1-abliterated-SLERP-v3.1 (Merge)"}, {"eval_name": "netcat420_MFANN-llama3.1-abliterated-v2_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/netcat420/MFANN-llama3.1-abliterated-v2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">netcat420/MFANN-llama3.1-abliterated-v2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/netcat420__MFANN-llama3.1-abliterated-v2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "netcat420/MFANN-llama3.1-abliterated-v2", "Model sha": "3d0a5d3634726e1a63ac84bee561b346960ca1d7", "Average \u2b06\ufe0f": 19.63264204497857, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4429114748866341, "IFEval": 44.29114748866341, "BBH Raw": 0.4940829733015402, "BBH": 27.35361826731554, "MATH Lvl 5 Raw": 0.0657099697885196, "MATH Lvl 5": 6.570996978851963, "GPQA Raw": 0.2927852348993288, "GPQA": 5.7046979865771785, "MUSR Raw": 0.3845416666666666, "MUSR": 6.201041666666668, "MMLU-PRO Raw": 0.3490691489361702, "MMLU-PRO": 27.67434988179669, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-04T00:00:00", "Submission Date": "2024-10-07T00:00:00", "Generation": 1, "Base Model": "netcat420/MFANN-llama3.1-abliterated-v2 (Merge)"}, {"eval_name": "netcat420_MFANN3bv0.15_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "PhiForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/netcat420/MFANN3bv0.15\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">netcat420/MFANN3bv0.15</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/netcat420__MFANN3bv0.15-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "netcat420/MFANN3bv0.15", "Model sha": "20dbdfb9154cc2f6d43651fc8cea63a120220dc7", "Average \u2b06\ufe0f": 11.811262006601297, "Hub License": "mit", "Hub \u2764\ufe0f": 0, "#Params (B)": 2, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2012105657433388, "IFEval": 20.12105657433388, "BBH Raw": 0.453931293669888, "BBH": 23.46934667082661, "MATH Lvl 5 Raw": 0.0196374622356495, "MATH Lvl 5": 1.9637462235649543, "GPQA Raw": 0.2516778523489933, "GPQA": 0.2237136465324418, "MUSR Raw": 0.3957916666666667, "MUSR": 8.773958333333335, "MMLU-PRO Raw": 0.2468417553191489, "MMLU-PRO": 16.315750591016545, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-04T00:00:00", "Submission Date": "2024-07-05T00:00:00", "Generation": 0, "Base Model": "netcat420/MFANN3bv0.15"}, {"eval_name": "netcat420_MFANN3bv0.18_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "PhiForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/netcat420/MFANN3bv0.18\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">netcat420/MFANN3bv0.18</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/netcat420__MFANN3bv0.18-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "netcat420/MFANN3bv0.18", "Model sha": "3e792e3413217b63ea9caa0e8b8595fbeb236a69", "Average \u2b06\ufe0f": 12.54917132124898, "Hub License": "mit", "Hub \u2764\ufe0f": 0, "#Params (B)": 2, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2206445564435697, "IFEval": 22.06445564435697, "BBH Raw": 0.4514366169824164, "BBH": 23.07340376774899, "MATH Lvl 5 Raw": 0.0188821752265861, "MATH Lvl 5": 1.8882175226586104, "GPQA Raw": 0.2575503355704698, "GPQA": 1.0067114093959737, "MUSR Raw": 0.4023645833333333, "MUSR": 10.595572916666669, "MMLU-PRO Raw": 0.25, "MMLU-PRO": 16.666666666666664, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-25T00:00:00", "Submission Date": "2024-07-25T00:00:00", "Generation": 0, "Base Model": "netcat420/MFANN3bv0.18"}, {"eval_name": "netcat420_MFANN3bv0.19_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "PhiForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/netcat420/MFANN3bv0.19\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">netcat420/MFANN3bv0.19</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/netcat420__MFANN3bv0.19-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "netcat420/MFANN3bv0.19", "Model sha": "073d42274686f5cb6ef6ff9f6ade24eab198e1f2", "Average \u2b06\ufe0f": 12.453019429281811, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 2, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2258152812315766, "IFEval": 22.581528123157664, "BBH Raw": 0.4515800678058734, "BBH": 22.9070546869096, "MATH Lvl 5 Raw": 0.0143504531722054, "MATH Lvl 5": 1.4350453172205435, "GPQA Raw": 0.2575503355704698, "GPQA": 1.0067114093959737, "MUSR Raw": 0.4023958333333333, "MUSR": 9.899479166666667, "MMLU-PRO Raw": 0.2519946808510638, "MMLU-PRO": 16.888297872340427, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-04T00:00:00", "Submission Date": "2024-08-08T00:00:00", "Generation": 0, "Base Model": "netcat420/MFANN3bv0.19"}, {"eval_name": "netcat420_MFANN3bv0.20_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "PhiForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/netcat420/MFANN3bv0.20\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">netcat420/MFANN3bv0.20</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/netcat420__MFANN3bv0.20-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "netcat420/MFANN3bv0.20", "Model sha": "ac8ba24559cbdb5704d77b602580d911c265fdee", "Average \u2b06\ufe0f": 12.358007166371488, "Hub License": "mit", "Hub \u2764\ufe0f": 0, "#Params (B)": 2, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2193457803073622, "IFEval": 21.934578030736223, "BBH Raw": 0.4493365019423472, "BBH": 22.790710795250103, "MATH Lvl 5 Raw": 0.0135951661631419, "MATH Lvl 5": 1.3595166163141994, "GPQA Raw": 0.259228187919463, "GPQA": 1.230425055928408, "MUSR Raw": 0.4077291666666667, "MUSR": 10.166145833333337, "MMLU-PRO Raw": 0.25, "MMLU-PRO": 16.666666666666664, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-29T00:00:00", "Submission Date": "2024-08-29T00:00:00", "Generation": 2, "Base Model": "netcat420/MFANN3bv0.19.12 (Merge)"}, {"eval_name": "netcat420_MFANN3bv0.21_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "PhiForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/netcat420/MFANN3bv0.21\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">netcat420/MFANN3bv0.21</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/netcat420__MFANN3bv0.21-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "netcat420/MFANN3bv0.21", "Model sha": "8e78416dce916b69247fa03bd587369d0dade5ed", "Average \u2b06\ufe0f": 11.69125386716322, "Hub License": "mit", "Hub \u2764\ufe0f": 0, "#Params (B)": 2, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1915185042354286, "IFEval": 19.151850423542868, "BBH Raw": 0.4470023689803905, "BBH": 22.58342571657233, "MATH Lvl 5 Raw": 0.0120845921450151, "MATH Lvl 5": 1.2084592145015105, "GPQA Raw": 0.2642617449664429, "GPQA": 1.9015659955257265, "MUSR Raw": 0.3759479166666666, "MUSR": 9.82682291666667, "MMLU-PRO Raw": 0.2392785904255319, "MMLU-PRO": 15.475398936170212, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-23T00:00:00", "Submission Date": "2024-09-24T00:00:00", "Generation": 1, "Base Model": "netcat420/MFANN3bv0.21 (Merge)"}, {"eval_name": "netcat420_MFANNv0.19_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/netcat420/MFANNv0.19\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">netcat420/MFANNv0.19</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/netcat420__MFANNv0.19-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "netcat420/MFANNv0.19", "Model sha": "af26a25549b7ad291766c479bebda58f15fbff42", "Average \u2b06\ufe0f": 14.13730349615228, "Hub License": "llama3.1", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3056744992176314, "IFEval": 30.567449921763146, "BBH Raw": 0.4731383203875531, "BBH": 24.92410586579366, "MATH Lvl 5 Raw": 0.0264350453172205, "MATH Lvl 5": 2.643504531722054, "GPQA Raw": 0.3070469798657718, "GPQA": 7.606263982102905, "MUSR Raw": 0.3526979166666666, "MUSR": 2.720572916666667, "MMLU-PRO Raw": 0.2472573138297872, "MMLU-PRO": 16.36192375886525, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-27T00:00:00", "Submission Date": "2024-07-27T00:00:00", "Generation": 0, "Base Model": "netcat420/MFANNv0.19"}, {"eval_name": "netcat420_MFANNv0.20_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/netcat420/MFANNv0.20\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">netcat420/MFANNv0.20</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/netcat420__MFANNv0.20-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "netcat420/MFANNv0.20", "Model sha": "e612e57c933870b8990ac2bc217c434f3ffc84bd", "Average \u2b06\ufe0f": 16.411304344618586, "Hub License": "llama3.1", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3478647765706104, "IFEval": 34.78647765706104, "BBH Raw": 0.4574431878198548, "BBH": 22.401696904581677, "MATH Lvl 5 Raw": 0.0468277945619335, "MATH Lvl 5": 4.682779456193353, "GPQA Raw": 0.2902684563758389, "GPQA": 5.369127516778524, "MUSR Raw": 0.3873958333333333, "MUSR": 6.757812500000003, "MMLU-PRO Raw": 0.3202293882978723, "MMLU-PRO": 24.469932033096924, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-07T00:00:00", "Submission Date": "2024-08-08T00:00:00", "Generation": 0, "Base Model": "netcat420/MFANNv0.20"}, {"eval_name": "netcat420_MFANNv0.21_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/netcat420/MFANNv0.21\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">netcat420/MFANNv0.21</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/netcat420__MFANNv0.21-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "netcat420/MFANNv0.21", "Model sha": "8c71d0eb419f54c489fa1ddf55d4bd18a1fb27d8", "Average \u2b06\ufe0f": 15.810638316978917, "Hub License": "llama3", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3233099287667832, "IFEval": 32.33099287667832, "BBH Raw": 0.4576372304837252, "BBH": 22.058431786302453, "MATH Lvl 5 Raw": 0.052870090634441, "MATH Lvl 5": 5.287009063444108, "GPQA Raw": 0.2785234899328859, "GPQA": 3.803131991051453, "MUSR Raw": 0.3993333333333333, "MUSR": 8.81666666666667, "MMLU-PRO Raw": 0.3031083776595745, "MMLU-PRO": 22.567597517730498, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-31T00:00:00", "Submission Date": "2024-09-02T00:00:00", "Generation": 2, "Base Model": "netcat420/MFANNv0.20.12 (Merge)"}, {"eval_name": "netcat420_MFANNv0.22.1_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/netcat420/MFANNv0.22.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">netcat420/MFANNv0.22.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/netcat420__MFANNv0.22.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "netcat420/MFANNv0.22.1", "Model sha": "98108142480b802a3e1bb27e3d47075a4ea3a4f1", "Average \u2b06\ufe0f": 15.604436675357816, "Hub License": "llama3.1", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3089469274857378, "IFEval": 30.894692748573785, "BBH Raw": 0.4660892852782458, "BBH": 23.602792666118614, "MATH Lvl 5 Raw": 0.0498489425981873, "MATH Lvl 5": 4.984894259818732, "GPQA Raw": 0.276006711409396, "GPQA": 3.467561521252797, "MUSR Raw": 0.3753020833333333, "MUSR": 4.64609375, "MMLU-PRO Raw": 0.3342752659574468, "MMLU-PRO": 26.03058510638298, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-04T00:00:00", "Submission Date": "2024-10-05T00:00:00", "Generation": 1, "Base Model": "netcat420/MFANNv0.22.1 (Merge)"}, {"eval_name": "nidum_Nidum-Limitless-Gemma-2B_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "GemmaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/nidum/Nidum-Limitless-Gemma-2B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">nidum/Nidum-Limitless-Gemma-2B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/nidum__Nidum-Limitless-Gemma-2B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "nidum/Nidum-Limitless-Gemma-2B", "Model sha": "e209e3513d2b34c0e6c433ede26e17604c25cb1a", "Average \u2b06\ufe0f": 5.939421848563431, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 4, "#Params (B)": 2, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2423514053821637, "IFEval": 24.235140538216378, "BBH Raw": 0.3078801520076317, "BBH": 3.4510601516101125, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2642617449664429, "GPQA": 1.9015659955257265, "MUSR Raw": 0.37403125, "MUSR": 4.120572916666667, "MMLU-PRO Raw": 0.1173537234042553, "MMLU-PRO": 1.9281914893617007, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-02T00:00:00", "Submission Date": "2024-08-07T00:00:00", "Generation": 0, "Base Model": "nidum/Nidum-Limitless-Gemma-2B"}, {"eval_name": "nisten_franqwenstein-35b_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/nisten/franqwenstein-35b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">nisten/franqwenstein-35b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/nisten__franqwenstein-35b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "nisten/franqwenstein-35b", "Model sha": "7180aa73e82945a1d2ae0eb304508e21d57e4c27", "Average \u2b06\ufe0f": 35.94192578741262, "Hub License": "mit", "Hub \u2764\ufe0f": 5, "#Params (B)": 34, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3798632074008076, "IFEval": 37.98632074008077, "BBH Raw": 0.6646579178049268, "BBH": 52.227468077653526, "MATH Lvl 5 Raw": 0.3028700906344411, "MATH Lvl 5": 30.28700906344411, "GPQA Raw": 0.4035234899328859, "GPQA": 20.46979865771812, "MUSR Raw": 0.4940208333333333, "MUSR": 22.119270833333328, "MMLU-PRO Raw": 0.5730551861702128, "MMLU-PRO": 52.56168735224587, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-03T00:00:00", "Submission Date": "2024-10-03T00:00:00", "Generation": 1, "Base Model": "nisten/franqwenstein-35b (Merge)"}, {"eval_name": "nisten_franqwenstein-35b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/nisten/franqwenstein-35b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">nisten/franqwenstein-35b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/nisten__franqwenstein-35b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "nisten/franqwenstein-35b", "Model sha": "901351a987d664a1cd7f483115a167d3ae5694ec", "Average \u2b06\ufe0f": 34.16159014441657, "Hub License": "mit", "Hub \u2764\ufe0f": 5, "#Params (B)": 34, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3913538300597968, "IFEval": 39.13538300597969, "BBH Raw": 0.6591132598701116, "BBH": 51.68027687329707, "MATH Lvl 5 Raw": 0.2870090634441087, "MATH Lvl 5": 28.700906344410875, "GPQA Raw": 0.3590604026845637, "GPQA": 14.5413870246085, "MUSR Raw": 0.4681041666666667, "MUSR": 19.6796875, "MMLU-PRO Raw": 0.5610871010638298, "MMLU-PRO": 51.23190011820331, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-03T00:00:00", "Submission Date": "2024-10-03T00:00:00", "Generation": 1, "Base Model": "nisten/franqwenstein-35b (Merge)"}, {"eval_name": "nlpguy_Mistral-NeMo-Minitron-Upscale-v1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/nlpguy/Mistral-NeMo-Minitron-Upscale-v1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">nlpguy/Mistral-NeMo-Minitron-Upscale-v1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/nlpguy__Mistral-NeMo-Minitron-Upscale-v1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "nlpguy/Mistral-NeMo-Minitron-Upscale-v1", "Model sha": "9e6d747cbb81e1f25915a0f42802cbeb85b61c3e", "Average \u2b06\ufe0f": 10.864341627799732, "Hub License": "other", "Hub \u2764\ufe0f": 0, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1648404012464704, "IFEval": 16.484040124647045, "BBH Raw": 0.4467998409796705, "BBH": 22.06890968577206, "MATH Lvl 5 Raw": 0.0067975830815709, "MATH Lvl 5": 0.6797583081570997, "GPQA Raw": 0.2802013422818792, "GPQA": 4.026845637583895, "MUSR Raw": 0.3803541666666667, "MUSR": 4.844270833333336, "MMLU-PRO Raw": 0.2537400265957447, "MMLU-PRO": 17.082225177304963, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-29T00:00:00", "Submission Date": "2024-09-29T00:00:00", "Generation": 1, "Base Model": "nlpguy/Mistral-NeMo-Minitron-Upscale-v1 (Merge)"}, {"eval_name": "nlpguy_Mistral-NeMo-Minitron-Upscale-v2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/nlpguy/Mistral-NeMo-Minitron-Upscale-v2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">nlpguy/Mistral-NeMo-Minitron-Upscale-v2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/nlpguy__Mistral-NeMo-Minitron-Upscale-v2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "nlpguy/Mistral-NeMo-Minitron-Upscale-v2", "Model sha": "4ac077e496705687fdcbe51f3b915be42e91bf79", "Average \u2b06\ufe0f": 8.219562929187555, "Hub License": "other", "Hub \u2764\ufe0f": 0, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1572715949236913, "IFEval": 15.727159492369136, "BBH Raw": 0.3949668154807224, "BBH": 14.382673288078204, "MATH Lvl 5 Raw": 0.0052870090634441, "MATH Lvl 5": 0.5287009063444109, "GPQA Raw": 0.273489932885906, "GPQA": 3.1319910514541416, "MUSR Raw": 0.3790833333333334, "MUSR": 5.252083333333334, "MMLU-PRO Raw": 0.1926529255319149, "MMLU-PRO": 10.2947695035461, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-29T00:00:00", "Submission Date": "2024-09-29T00:00:00", "Generation": 1, "Base Model": "nlpguy/Mistral-NeMo-Minitron-Upscale-v2 (Merge)"}, {"eval_name": "nlpguy_Mistral-NeMo-Minitron-Upscale-v3_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/nlpguy/Mistral-NeMo-Minitron-Upscale-v3\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">nlpguy/Mistral-NeMo-Minitron-Upscale-v3</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/nlpguy__Mistral-NeMo-Minitron-Upscale-v3-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "nlpguy/Mistral-NeMo-Minitron-Upscale-v3", "Model sha": "6703b09d3d78cc020448ee93c53dc727312bcbaf", "Average \u2b06\ufe0f": 5.013437438056034, "Hub License": "other", "Hub \u2764\ufe0f": 1, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1412097678603882, "IFEval": 14.120976786038822, "BBH Raw": 0.3052452260291806, "BBH": 3.3982664477164874, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.259228187919463, "GPQA": 1.230425055928408, "MUSR Raw": 0.40984375, "MUSR": 9.43046875, "MMLU-PRO Raw": 0.1171043882978723, "MMLU-PRO": 1.9004875886524817, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-04T00:00:00", "Submission Date": "2024-10-04T00:00:00", "Generation": 1, "Base Model": "nlpguy/Mistral-NeMo-Minitron-Upscale-v3 (Merge)"}, {"eval_name": "nlpguy_StableProse_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/nlpguy/StableProse\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">nlpguy/StableProse</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/nlpguy__StableProse-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "nlpguy/StableProse", "Model sha": "4937dc747684705e4b87df27b47eab5429f3a9c1", "Average \u2b06\ufe0f": 16.321789997306105, "Hub License": null, "Hub \u2764\ufe0f": 1, "#Params (B)": 12, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1972388817227179, "IFEval": 19.723888172271792, "BBH Raw": 0.5116558625577087, "BBH": 30.18020271418596, "MATH Lvl 5 Raw": 0.0468277945619335, "MATH Lvl 5": 4.682779456193353, "GPQA Raw": 0.3028523489932886, "GPQA": 7.046979865771815, "MUSR Raw": 0.4067083333333333, "MUSR": 8.871875000000001, "MMLU-PRO Raw": 0.3468251329787234, "MMLU-PRO": 27.425014775413715, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-16T00:00:00", "Submission Date": "2024-08-17T00:00:00", "Generation": 1, "Base Model": "nlpguy/StableProse (Merge)"}, {"eval_name": "nlpguy_StarFusion-alpha1_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/nlpguy/StarFusion-alpha1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">nlpguy/StarFusion-alpha1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/nlpguy__StarFusion-alpha1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "nlpguy/StarFusion-alpha1", "Model sha": "dccad965a710d7bee001b6387c8307e7c320291e", "Average \u2b06\ufe0f": 20.70244238484936, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5660092997690572, "IFEval": 56.60092997690572, "BBH Raw": 0.4428694115507034, "BBH": 21.933181635654744, "MATH Lvl 5 Raw": 0.0641993957703927, "MATH Lvl 5": 6.419939577039275, "GPQA Raw": 0.2953020134228188, "GPQA": 6.040268456375841, "MUSR Raw": 0.4081041666666666, "MUSR": 8.879687500000001, "MMLU-PRO Raw": 0.3190658244680851, "MMLU-PRO": 24.34064716312057, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-13T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "nlpguy/StarFusion-alpha1 (Merge)"}, {"eval_name": "nothingiisreal_MN-12B-Starcannon-v2_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/nothingiisreal/MN-12B-Starcannon-v2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">nothingiisreal/MN-12B-Starcannon-v2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/nothingiisreal__MN-12B-Starcannon-v2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "nothingiisreal/MN-12B-Starcannon-v2", "Model sha": "f2ff756e8c32d9107d4f6a3c18c730e3fe0cae88", "Average \u2b06\ufe0f": 17.92968756835265, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 5, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3925273828995953, "IFEval": 39.25273828995952, "BBH Raw": 0.5004499888471767, "BBH": 28.424782963573875, "MATH Lvl 5 Raw": 0.0445619335347432, "MATH Lvl 5": 4.45619335347432, "GPQA Raw": 0.2785234899328859, "GPQA": 3.803131991051453, "MUSR Raw": 0.3978124999999999, "MUSR": 7.993229166666668, "MMLU-PRO Raw": 0.3128324468085106, "MMLU-PRO": 23.648049645390067, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-13T00:00:00", "Submission Date": "2024-09-03T00:00:00", "Generation": 1, "Base Model": "nothingiisreal/MN-12B-Starcannon-v2 (Merge)"}, {"eval_name": "nothingiisreal_MN-12B-Starcannon-v3_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/nothingiisreal/MN-12B-Starcannon-v3\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">nothingiisreal/MN-12B-Starcannon-v3</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/nothingiisreal__MN-12B-Starcannon-v3-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "nothingiisreal/MN-12B-Starcannon-v3", "Model sha": "169480b62121c4f070e93a05158545c679712644", "Average \u2b06\ufe0f": 18.94306139515605, "Hub License": null, "Hub \u2764\ufe0f": 8, "#Params (B)": 12, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3807375541341418, "IFEval": 38.07375541341418, "BBH Raw": 0.5170553444795719, "BBH": 30.873001626388614, "MATH Lvl 5 Raw": 0.0657099697885196, "MATH Lvl 5": 6.570996978851963, "GPQA Raw": 0.273489932885906, "GPQA": 3.1319910514541416, "MUSR Raw": 0.4046354166666666, "MUSR": 9.846093749999996, "MMLU-PRO Raw": 0.3264627659574468, "MMLU-PRO": 25.162529550827426, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-13T00:00:00", "Submission Date": "2024-09-03T00:00:00", "Generation": 1, "Base Model": "nothingiisreal/MN-12B-Starcannon-v3 (Merge)"}, {"eval_name": "nvidia_Llama-3.1-Minitron-4B-Depth-Base_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/nvidia/Llama-3.1-Minitron-4B-Depth-Base\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">nvidia/Llama-3.1-Minitron-4B-Depth-Base</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/nvidia__Llama-3.1-Minitron-4B-Depth-Base-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "nvidia/Llama-3.1-Minitron-4B-Depth-Base", "Model sha": "40d82bc951b4f39e9c9e11176334250c30975098", "Average \u2b06\ufe0f": 11.519581858455927, "Hub License": "other", "Hub \u2764\ufe0f": 19, "#Params (B)": 4, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1606936262450298, "IFEval": 16.069362624502986, "BBH Raw": 0.4170704193104893, "BBH": 19.44410955550794, "MATH Lvl 5 Raw": 0.0113293051359516, "MATH Lvl 5": 1.1329305135951662, "GPQA Raw": 0.2634228187919463, "GPQA": 1.789709172259505, "MUSR Raw": 0.4010625, "MUSR": 10.699479166666668, "MMLU-PRO Raw": 0.2798371010638298, "MMLU-PRO": 19.98190011820331, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-08-13T00:00:00", "Submission Date": "2024-09-25T00:00:00", "Generation": 0, "Base Model": "nvidia/Llama-3.1-Minitron-4B-Depth-Base"}, {"eval_name": "nvidia_Minitron-4B-Base_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "NemotronForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/nvidia/Minitron-4B-Base\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">nvidia/Minitron-4B-Base</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/nvidia__Minitron-4B-Base-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "nvidia/Minitron-4B-Base", "Model sha": "d6321f64412982046a32d761701167e752fedc02", "Average \u2b06\ufe0f": 11.927384588359018, "Hub License": "other", "Hub \u2764\ufe0f": 127, "#Params (B)": 4, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2217937295265451, "IFEval": 22.17937295265451, "BBH Raw": 0.4083876243992497, "BBH": 17.215600655061085, "MATH Lvl 5 Raw": 0.0166163141993957, "MATH Lvl 5": 1.6616314199395772, "GPQA Raw": 0.2692953020134228, "GPQA": 2.572706935123044, "MUSR Raw": 0.413375, "MUSR": 9.938541666666667, "MMLU-PRO Raw": 0.261968085106383, "MMLU-PRO": 17.99645390070922, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-07-19T00:00:00", "Submission Date": "2024-09-25T00:00:00", "Generation": 0, "Base Model": "nvidia/Minitron-4B-Base"}, {"eval_name": "nvidia_Minitron-8B-Base_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "NemotronForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/nvidia/Minitron-8B-Base\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">nvidia/Minitron-8B-Base</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/nvidia__Minitron-8B-Base-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "nvidia/Minitron-8B-Base", "Model sha": "70fa5997afc42807f41eebd5d481f040556fdf97", "Average \u2b06\ufe0f": 14.166138298613824, "Hub License": "other", "Hub \u2764\ufe0f": 64, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2424267609941621, "IFEval": 24.24267609941621, "BBH Raw": 0.4395063188357604, "BBH": 22.04079297000523, "MATH Lvl 5 Raw": 0.0226586102719033, "MATH Lvl 5": 2.2658610271903323, "GPQA Raw": 0.273489932885906, "GPQA": 3.1319910514541416, "MUSR Raw": 0.4025520833333333, "MUSR": 9.085677083333335, "MMLU-PRO Raw": 0.3180684840425531, "MMLU-PRO": 24.229831560283685, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-07-19T00:00:00", "Submission Date": "2024-09-25T00:00:00", "Generation": 0, "Base Model": "nvidia/Minitron-8B-Base"}, {"eval_name": "nvidia_Mistral-NeMo-Minitron-8B-Base_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/nvidia/Mistral-NeMo-Minitron-8B-Base\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">nvidia/Mistral-NeMo-Minitron-8B-Base</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/nvidia__Mistral-NeMo-Minitron-8B-Base-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "nvidia/Mistral-NeMo-Minitron-8B-Base", "Model sha": "cc94637b669b62c4829b1e0c3b9074fecd883b74", "Average \u2b06\ufe0f": 17.597220922987812, "Hub License": "other", "Hub \u2764\ufe0f": 152, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1945659738383045, "IFEval": 19.456597383830456, "BBH Raw": 0.5219098090521418, "BBH": 31.822015157490156, "MATH Lvl 5 Raw": 0.0422960725075528, "MATH Lvl 5": 4.229607250755287, "GPQA Raw": 0.3255033557046979, "GPQA": 10.067114093959727, "MUSR Raw": 0.40915625, "MUSR": 8.944531250000002, "MMLU-PRO Raw": 0.3795711436170212, "MMLU-PRO": 31.06346040189125, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-08-19T00:00:00", "Submission Date": "2024-08-22T00:00:00", "Generation": 0, "Base Model": "nvidia/Mistral-NeMo-Minitron-8B-Base"}, {"eval_name": "nvidia_Mistral-NeMo-Minitron-8B-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/nvidia/Mistral-NeMo-Minitron-8B-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">nvidia/Mistral-NeMo-Minitron-8B-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/nvidia__Mistral-NeMo-Minitron-8B-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "Model sha": "27964e305f862f9947f577332a943d7013abc30f", "Average \u2b06\ufe0f": 21.709555194286317, "Hub License": "other", "Hub \u2764\ufe0f": 44, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5003889679384035, "IFEval": 50.03889679384034, "BBH Raw": 0.5320919605840294, "BBH": 34.126491245346166, "MATH Lvl 5 Raw": 0.0045317220543806, "MATH Lvl 5": 0.4531722054380665, "GPQA Raw": 0.287751677852349, "GPQA": 5.033557046979867, "MUSR Raw": 0.3885729166666666, "MUSR": 7.37161458333333, "MMLU-PRO Raw": 0.3991023936170212, "MMLU-PRO": 33.23359929078014, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-10-02T00:00:00", "Submission Date": "2024-10-04T00:00:00", "Generation": 1, "Base Model": "nvidia/Mistral-NeMo-Minitron-8B-Instruct (Merge)"}, {"eval_name": "nvidia_Nemotron-Mini-4B-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "NemotronForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/nvidia/Nemotron-Mini-4B-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">nvidia/Nemotron-Mini-4B-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/nvidia__Nemotron-Mini-4B-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "nvidia/Nemotron-Mini-4B-Instruct", "Model sha": "6a417790c444fd65a3da6a5c8821de6afc9654a6", "Average \u2b06\ufe0f": 17.93551534108315, "Hub License": "other", "Hub \u2764\ufe0f": 106, "#Params (B)": 4, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6668761109411916, "IFEval": 66.68761109411916, "BBH Raw": 0.3864840798591535, "BBH": 14.203825178862052, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2802013422818792, "GPQA": 4.026845637583895, "MUSR Raw": 0.3767291666666666, "MUSR": 4.624479166666667, "MMLU-PRO Raw": 0.2626329787234042, "MMLU-PRO": 18.070330969267136, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-09-10T00:00:00", "Submission Date": "2024-09-25T00:00:00", "Generation": 1, "Base Model": "nvidia/Minitron-4B-Base"}, {"eval_name": "nxmwxm_Beast-Soul-new_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/nxmwxm/Beast-Soul-new\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">nxmwxm/Beast-Soul-new</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/nxmwxm__Beast-Soul-new-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "nxmwxm/Beast-Soul-new", "Model sha": "dd2ae8a96b7d088eb94a1cfa6ff84c3489e8c010", "Average \u2b06\ufe0f": 21.74214471169793, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4868748254631045, "IFEval": 48.68748254631046, "BBH Raw": 0.5227143628884523, "BBH": 33.07275916855207, "MATH Lvl 5 Raw": 0.0694864048338368, "MATH Lvl 5": 6.948640483383686, "GPQA Raw": 0.2818791946308724, "GPQA": 4.250559284116329, "MUSR Raw": 0.4459270833333333, "MUSR": 14.140885416666668, "MMLU-PRO Raw": 0.3101728723404255, "MMLU-PRO": 23.352541371158388, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-07T00:00:00", "Submission Date": "2024-08-07T00:00:00", "Generation": 1, "Base Model": "nxmwxm/Beast-Soul-new (Merge)"}, {"eval_name": "occiglot_occiglot-7b-es-en-instruct_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/occiglot/occiglot-7b-es-en-instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">occiglot/occiglot-7b-es-en-instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/occiglot__occiglot-7b-es-en-instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "occiglot/occiglot-7b-es-en-instruct", "Model sha": "5858f6ee118eef70896f1870fd61052348ff571e", "Average \u2b06\ufe0f": 12.36978715736164, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 2, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3485141646387142, "IFEval": 34.851416463871416, "BBH Raw": 0.4110970229781084, "BBH": 17.23541035561212, "MATH Lvl 5 Raw": 0.0188821752265861, "MATH Lvl 5": 1.8882175226586104, "GPQA Raw": 0.259228187919463, "GPQA": 1.230425055928408, "MUSR Raw": 0.37375, "MUSR": 4.452083333333333, "MMLU-PRO Raw": 0.2310505319148936, "MMLU-PRO": 14.561170212765957, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-03-05T00:00:00", "Submission Date": "2024-09-02T00:00:00", "Generation": 0, "Base Model": "occiglot/occiglot-7b-es-en-instruct"}, {"eval_name": "olabs-ai_reflection_model_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Adapter", "Architecture": "?", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/olabs-ai/reflection_model\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">olabs-ai/reflection_model</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/olabs-ai__reflection_model-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "olabs-ai/reflection_model", "Model sha": "a8b0fc584b10e0110e04f9d21c7f10d24391c1d5", "Average \u2b06\ufe0f": 13.940696250576138, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 9, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1598691471961063, "IFEval": 15.986914719610631, "BBH Raw": 0.4712508645838735, "BBH": 25.206881738811884, "MATH Lvl 5 Raw": 0.0430513595166163, "MATH Lvl 5": 4.305135951661631, "GPQA Raw": 0.3003355704697986, "GPQA": 6.711409395973152, "MUSR Raw": 0.3508333333333333, "MUSR": 5.754166666666666, "MMLU-PRO Raw": 0.3311170212765957, "MMLU-PRO": 25.67966903073286, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-08T00:00:00", "Submission Date": "2024-09-08T00:00:00", "Generation": 0, "Base Model": "olabs-ai/reflection_model"}, {"eval_name": "oobabooga_CodeBooga-34B-v0.1_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/oobabooga/CodeBooga-34B-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">oobabooga/CodeBooga-34B-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/oobabooga__CodeBooga-34B-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "oobabooga/CodeBooga-34B-v0.1", "Model sha": "8a4e1e16ac46333cbd0c17d733d3d70a956071a6", "Average \u2b06\ufe0f": 15.095240905583989, "Hub License": "llama2", "Hub \u2764\ufe0f": 141, "#Params (B)": 33, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5250180631834643, "IFEval": 52.50180631834643, "BBH Raw": 0.3427441185661722, "BBH": 8.562465862636055, "MATH Lvl 5 Raw": 0.0052870090634441, "MATH Lvl 5": 0.5287009063444109, "GPQA Raw": 0.2567114093959731, "GPQA": 0.8948545861297527, "MUSR Raw": 0.4310208333333333, "MUSR": 12.977604166666673, "MMLU-PRO Raw": 0.2359541223404255, "MMLU-PRO": 15.106013593380617, "Maintainer's Highlight": false, "Upload To Hub Date": "2023-10-19T00:00:00", "Submission Date": "2024-07-29T00:00:00", "Generation": 0, "Base Model": "oobabooga/CodeBooga-34B-v0.1"}, {"eval_name": "openai-community_gpt2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "GPT2LMHeadModel", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/openai-community/gpt2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">openai-community/gpt2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/openai-community__gpt2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "openai-community/gpt2", "Model sha": "607a30d783dfa663caf39e06633721c8d4cfcd7e", "Average \u2b06\ufe0f": 6.510807087761722, "Hub License": "mit", "Hub \u2764\ufe0f": 2293, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1792532702119265, "IFEval": 17.925327021192658, "BBH Raw": 0.3035711244213359, "BBH": 2.674981367986987, "MATH Lvl 5 Raw": 0.0022658610271903, "MATH Lvl 5": 0.2265861027190332, "GPQA Raw": 0.2583892617449664, "GPQA": 1.1185682326621946, "MUSR Raw": 0.4470520833333333, "MUSR": 15.348177083333336, "MMLU-PRO Raw": 0.1159408244680851, "MMLU-PRO": 1.7712027186761226, "Maintainer's Highlight": true, "Upload To Hub Date": "2022-03-02T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "openai-community/gpt2"}, {"eval_name": "openai-community_gpt2_float16", "Precision": "float16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "GPT2LMHeadModel", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/openai-community/gpt2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">openai-community/gpt2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/openai-community__gpt2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "openai-community/gpt2", "Model sha": "607a30d783dfa663caf39e06633721c8d4cfcd7e", "Average \u2b06\ufe0f": 6.296471067838717, "Hub License": "mit", "Hub \u2764\ufe0f": 2293, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1779544940757191, "IFEval": 17.795449407571912, "BBH Raw": 0.3016580106765305, "BBH": 2.8159113095085133, "MATH Lvl 5 Raw": 0.0030211480362537, "MATH Lvl 5": 0.3021148036253776, "GPQA Raw": 0.2583892617449664, "GPQA": 1.1185682326621946, "MUSR Raw": 0.4390208333333333, "MUSR": 13.9109375, "MMLU-PRO Raw": 0.1165226063829787, "MMLU-PRO": 1.8358451536643017, "Maintainer's Highlight": true, "Upload To Hub Date": "2022-03-02T00:00:00", "Submission Date": "2024-08-12T00:00:00", "Generation": 0, "Base Model": "openai-community/gpt2"}, {"eval_name": "openai-community_gpt2-large_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "GPT2LMHeadModel", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/openai-community/gpt2-large\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">openai-community/gpt2-large</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/openai-community__gpt2-large-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "openai-community/gpt2-large", "Model sha": "32b71b12589c2f8d625668d2335a01cac3249519", "Average \u2b06\ufe0f": 5.479590375205572, "Hub License": "mit", "Hub \u2764\ufe0f": 262, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2047822001179093, "IFEval": 20.47822001179094, "BBH Raw": 0.3068841876011882, "BBH": 3.2537905449787403, "MATH Lvl 5 Raw": 0.0067975830815709, "MATH Lvl 5": 0.6797583081570997, "GPQA Raw": 0.259228187919463, "GPQA": 1.230425055928408, "MUSR Raw": 0.3788645833333333, "MUSR": 5.658072916666665, "MMLU-PRO Raw": 0.1141954787234042, "MMLU-PRO": 1.5772754137115832, "Maintainer's Highlight": true, "Upload To Hub Date": "2022-03-02T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "openai-community/gpt2-large"}, {"eval_name": "openai-community_gpt2-medium_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "GPT2LMHeadModel", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/openai-community/gpt2-medium\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">openai-community/gpt2-medium</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/openai-community__gpt2-medium-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "openai-community/gpt2-medium", "Model sha": "6dcaa7a952f72f9298047fd5137cd6e4f05f41da", "Average \u2b06\ufe0f": 5.8142234694303765, "Hub License": "mit", "Hub \u2764\ufe0f": 153, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2208440271812125, "IFEval": 22.08440271812125, "BBH Raw": 0.3050280232176266, "BBH": 2.719972238356244, "MATH Lvl 5 Raw": 0.0022658610271903, "MATH Lvl 5": 0.2265861027190332, "GPQA Raw": 0.2625838926174497, "GPQA": 1.6778523489932915, "MUSR Raw": 0.3884479166666666, "MUSR": 6.155989583333335, "MMLU-PRO Raw": 0.1181848404255319, "MMLU-PRO": 2.020537825059101, "Maintainer's Highlight": true, "Upload To Hub Date": "2022-03-02T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "openai-community/gpt2-medium"}, {"eval_name": "openai-community_gpt2-xl_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "GPT2LMHeadModel", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/openai-community/gpt2-xl\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">openai-community/gpt2-xl</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/openai-community__gpt2-xl-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "openai-community/gpt2-xl", "Model sha": "15ea56dee5df4983c59b2538573817e1667135e2", "Average \u2b06\ufe0f": 4.980187627399172, "Hub License": "mit", "Hub \u2764\ufe0f": 308, "#Params (B)": 1, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2038579857001644, "IFEval": 20.385798570016444, "BBH Raw": 0.3008576112326078, "BBH": 2.580960647452716, "MATH Lvl 5 Raw": 0.0030211480362537, "MATH Lvl 5": 0.3021148036253776, "GPQA Raw": 0.2583892617449664, "GPQA": 1.1185682326621946, "MUSR Raw": 0.3709583333333333, "MUSR": 4.036458333333333, "MMLU-PRO Raw": 0.1131150265957446, "MMLU-PRO": 1.457225177304964, "Maintainer's Highlight": true, "Upload To Hub Date": "2022-03-02T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "openai-community/gpt2-xl"}, {"eval_name": "openchat_openchat-3.5-0106_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/openchat/openchat-3.5-0106\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">openchat/openchat-3.5-0106</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/openchat__openchat-3.5-0106-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "openchat/openchat-3.5-0106", "Model sha": "ff058fda49726ecf4ea53dc1635f917cdb8ba36b", "Average \u2b06\ufe0f": 22.49503791444532, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 342, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5951353519771982, "IFEval": 59.51353519771983, "BBH Raw": 0.4616978708396059, "BBH": 24.03871121391158, "MATH Lvl 5 Raw": 0.0649546827794562, "MATH Lvl 5": 6.495468277945619, "GPQA Raw": 0.3078859060402684, "GPQA": 7.718120805369126, "MUSR Raw": 0.4254374999999999, "MUSR": 11.746354166666668, "MMLU-PRO Raw": 0.3291223404255319, "MMLU-PRO": 25.458037825059098, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-01-07T00:00:00", "Submission Date": "2024-06-27T00:00:00", "Generation": 1, "Base Model": "mistralai/Mistral-7B-v0.1"}, {"eval_name": "openchat_openchat-3.5-1210_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/openchat/openchat-3.5-1210\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">openchat/openchat-3.5-1210</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/openchat__openchat-3.5-1210-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "openchat/openchat-3.5-1210", "Model sha": "801f5459b7577241500785f11c2b026912badd6e", "Average \u2b06\ufe0f": 22.56420409002869, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 276, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.603678240402133, "IFEval": 60.3678240402133, "BBH Raw": 0.4535356846447984, "BBH": 23.236296582166464, "MATH Lvl 5 Raw": 0.0687311178247734, "MATH Lvl 5": 6.873111782477341, "GPQA Raw": 0.3011744966442953, "GPQA": 6.823266219239373, "MUSR Raw": 0.4414375, "MUSR": 14.279687500000003, "MMLU-PRO Raw": 0.3142453457446808, "MMLU-PRO": 23.805038416075647, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-12-12T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 1, "Base Model": "mistralai/Mistral-7B-v0.1"}, {"eval_name": "openchat_openchat-3.6-8b-20240522_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/openchat/openchat-3.6-8b-20240522\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">openchat/openchat-3.6-8b-20240522</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/openchat__openchat-3.6-8b-20240522-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "openchat/openchat-3.6-8b-20240522", "Model sha": "2264eb98558978f708e88ae52afb78e43b832801", "Average \u2b06\ufe0f": 22.6667318381336, "Hub License": "llama3", "Hub \u2764\ufe0f": 148, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5343355629729118, "IFEval": 53.43355629729119, "BBH Raw": 0.5338412089001999, "BBH": 33.23293691836929, "MATH Lvl 5 Raw": 0.073262839879154, "MATH Lvl 5": 7.326283987915408, "GPQA Raw": 0.3179530201342282, "GPQA": 9.060402684563762, "MUSR Raw": 0.3998541666666667, "MUSR": 8.181770833333333, "MMLU-PRO Raw": 0.3228889627659574, "MMLU-PRO": 24.765440307328607, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-05-07T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "meta-llama/Meta-Llama-3-8B"}, {"eval_name": "openchat_openchat_3.5_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/openchat/openchat_3.5\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">openchat/openchat_3.5</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/openchat__openchat_3.5-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "openchat/openchat_3.5", "Model sha": "0fc98e324280bc4bf5d2c30ecf7b97b84fb8a19b", "Average \u2b06\ufe0f": 21.52253406020508, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1115, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5931118321608887, "IFEval": 59.31118321608887, "BBH Raw": 0.4426319686283289, "BBH": 21.58216684769999, "MATH Lvl 5 Raw": 0.0657099697885196, "MATH Lvl 5": 6.570996978851963, "GPQA Raw": 0.2986577181208054, "GPQA": 6.487695749440718, "MUSR Raw": 0.4228645833333333, "MUSR": 11.258072916666668, "MMLU-PRO Raw": 0.3153257978723404, "MMLU-PRO": 23.92508865248227, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-10-30T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "openchat/openchat_3.5"}, {"eval_name": "openchat_openchat_v3.2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/openchat/openchat_v3.2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">openchat/openchat_v3.2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/openchat__openchat_v3.2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "openchat/openchat_v3.2", "Model sha": "acc7ce92558681e749678648189812f15c1465fe", "Average \u2b06\ufe0f": 13.807969316891429, "Hub License": "llama2", "Hub \u2764\ufe0f": 42, "#Params (B)": 13, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2980558252104416, "IFEval": 29.805582521044165, "BBH Raw": 0.4330564283474314, "BBH": 20.32300299720885, "MATH Lvl 5 Raw": 0.0113293051359516, "MATH Lvl 5": 1.1329305135951662, "GPQA Raw": 0.2701342281879195, "GPQA": 2.684563758389265, "MUSR Raw": 0.433625, "MUSR": 13.103125, "MMLU-PRO Raw": 0.2421875, "MMLU-PRO": 15.79861111111111, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-07-30T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "openchat/openchat_v3.2"}, {"eval_name": "openchat_openchat_v3.2_super_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/openchat/openchat_v3.2_super\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">openchat/openchat_v3.2_super</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/openchat__openchat_v3.2_super-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "openchat/openchat_v3.2_super", "Model sha": "9479cc37d43234a57a33628637d1aca0293d745a", "Average \u2b06\ufe0f": 12.83545818567648, "Hub License": "llama2", "Hub \u2764\ufe0f": 36, "#Params (B)": 13, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2861906408329898, "IFEval": 28.61906408329898, "BBH Raw": 0.4221208983880397, "BBH": 19.153539587477532, "MATH Lvl 5 Raw": 0.0158610271903323, "MATH Lvl 5": 1.5861027190332326, "GPQA Raw": 0.2642617449664429, "GPQA": 1.9015659955257265, "MUSR Raw": 0.4161354166666666, "MUSR": 9.916927083333333, "MMLU-PRO Raw": 0.2425199468085106, "MMLU-PRO": 15.83554964539007, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-09-04T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "openchat/openchat_v3.2_super"}, {"eval_name": "orai-nlp_Llama-eus-8B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe9 continuously pretrained", "T": "\ud83d\udfe9", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/orai-nlp/Llama-eus-8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">orai-nlp/Llama-eus-8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/orai-nlp__Llama-eus-8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "orai-nlp/Llama-eus-8B", "Model sha": "75b5645d222047b517a7a9190922ea1b5382c71f", "Average \u2b06\ufe0f": 13.880813774174548, "Hub License": null, "Hub \u2764\ufe0f": 4, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2161232197236665, "IFEval": 21.61232197236665, "BBH Raw": 0.4418245490788701, "BBH": 20.96137115221118, "MATH Lvl 5 Raw": 0.0430513595166163, "MATH Lvl 5": 4.305135951661631, "GPQA Raw": 0.2894295302013422, "GPQA": 5.257270693512303, "MUSR Raw": 0.3918854166666667, "MUSR": 8.285677083333335, "MMLU-PRO Raw": 0.3057679521276595, "MMLU-PRO": 22.86310579196217, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-04T00:00:00", "Submission Date": "2024-09-30T00:00:00", "Generation": 1, "Base Model": "meta-llama/Meta-Llama-3.1-8B"}, {"eval_name": "paloalma_ECE-TW3-JRGL-V1_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/paloalma/ECE-TW3-JRGL-V1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">paloalma/ECE-TW3-JRGL-V1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/paloalma__ECE-TW3-JRGL-V1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "paloalma/ECE-TW3-JRGL-V1", "Model sha": "2f08c7ab9db03b1b9f455c7beee6a41e99aa910e", "Average \u2b06\ufe0f": 30.02200313062725, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 68, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.5534947273235016, "IFEval": 55.349472732350165, "BBH Raw": 0.6283667540784627, "BBH": 46.69713905397109, "MATH Lvl 5 Raw": 0.1185800604229607, "MATH Lvl 5": 11.858006042296072, "GPQA Raw": 0.3473154362416107, "GPQA": 12.975391498881436, "MUSR Raw": 0.4620833333333333, "MUSR": 17.460416666666664, "MMLU-PRO Raw": 0.422124335106383, "MMLU-PRO": 35.791592789598106, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-03T00:00:00", "Submission Date": "2024-08-04T00:00:00", "Generation": 0, "Base Model": "paloalma/ECE-TW3-JRGL-V1"}, {"eval_name": "paloalma_ECE-TW3-JRGL-V2_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/paloalma/ECE-TW3-JRGL-V2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">paloalma/ECE-TW3-JRGL-V2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/paloalma__ECE-TW3-JRGL-V2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "paloalma/ECE-TW3-JRGL-V2", "Model sha": "f2c15045f1a7a7a34540ab18abcee8a566a74ca6", "Average \u2b06\ufe0f": 25.427659611155264, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 72, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2254894790267601, "IFEval": 22.54894790267601, "BBH Raw": 0.6030988136029874, "BBH": 43.17326773447519, "MATH Lvl 5 Raw": 0.1631419939577039, "MATH Lvl 5": 16.314199395770395, "GPQA Raw": 0.3313758389261745, "GPQA": 10.850111856823268, "MUSR Raw": 0.4793229166666666, "MUSR": 19.815364583333327, "MMLU-PRO Raw": 0.4587765957446808, "MMLU-PRO": 39.86406619385342, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-04T00:00:00", "Submission Date": "2024-09-19T00:00:00", "Generation": 0, "Base Model": "paloalma/ECE-TW3-JRGL-V2"}, {"eval_name": "paloalma_ECE-TW3-JRGL-V5_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/paloalma/ECE-TW3-JRGL-V5\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">paloalma/ECE-TW3-JRGL-V5</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/paloalma__ECE-TW3-JRGL-V5-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "paloalma/ECE-TW3-JRGL-V5", "Model sha": "4061fa10de22945790cad825f7f4dec96d55b204", "Average \u2b06\ufe0f": 29.189932013682675, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 72, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4552509563513699, "IFEval": 45.52509563513699, "BBH Raw": 0.6024712037668832, "BBH": 43.46251365157702, "MATH Lvl 5 Raw": 0.1654078549848942, "MATH Lvl 5": 16.540785498489424, "GPQA Raw": 0.3414429530201342, "GPQA": 12.192393736017896, "MUSR Raw": 0.4620520833333333, "MUSR": 16.88984375, "MMLU-PRO Raw": 0.4647606382978723, "MMLU-PRO": 40.528959810874696, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-11T00:00:00", "Submission Date": "2024-08-30T00:00:00", "Generation": 0, "Base Model": "paloalma/ECE-TW3-JRGL-V5"}, {"eval_name": "paloalma_Le_Triomphant-ECE-TW3_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/paloalma/Le_Triomphant-ECE-TW3\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">paloalma/Le_Triomphant-ECE-TW3</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/paloalma__Le_Triomphant-ECE-TW3-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "paloalma/Le_Triomphant-ECE-TW3", "Model sha": "f72399253bb3e65c0f55e50461488c098f658a49", "Average \u2b06\ufe0f": 31.656415040134583, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 3, "#Params (B)": 72, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.5402055435134332, "IFEval": 54.02055435134332, "BBH Raw": 0.6112057897556996, "BBH": 44.96329362428286, "MATH Lvl 5 Raw": 0.1744712990936555, "MATH Lvl 5": 17.447129909365557, "GPQA Raw": 0.348993288590604, "GPQA": 13.19910514541387, "MUSR Raw": 0.4725, "MUSR": 18.495833333333334, "MMLU-PRO Raw": 0.476313164893617, "MMLU-PRO": 41.81257387706855, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-01T00:00:00", "Submission Date": "2024-07-25T00:00:00", "Generation": 0, "Base Model": "paloalma/Le_Triomphant-ECE-TW3"}, {"eval_name": "paloalma_TW3-JRGL-v2_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/paloalma/TW3-JRGL-v2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">paloalma/TW3-JRGL-v2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/paloalma__TW3-JRGL-v2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "paloalma/TW3-JRGL-v2", "Model sha": "aca3f0ba2bfb90038a9e2cd5b486821d4c181b46", "Average \u2b06\ufe0f": 32.12265972921163, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 72, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.5316127874040878, "IFEval": 53.16127874040878, "BBH Raw": 0.6137525505395743, "BBH": 45.61110998256794, "MATH Lvl 5 Raw": 0.1586102719033232, "MATH Lvl 5": 15.861027190332328, "GPQA Raw": 0.3590604026845637, "GPQA": 14.5413870246085, "MUSR Raw": 0.4858333333333333, "MUSR": 20.69583333333333, "MMLU-PRO Raw": 0.4857878989361702, "MMLU-PRO": 42.86532210401891, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-01T00:00:00", "Submission Date": "2024-08-29T00:00:00", "Generation": 0, "Base Model": "paloalma/TW3-JRGL-v2"}, {"eval_name": "pankajmathur_Al_Dente_v1_8b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/pankajmathur/Al_Dente_v1_8b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">pankajmathur/Al_Dente_v1_8b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/pankajmathur__Al_Dente_v1_8b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "pankajmathur/Al_Dente_v1_8b", "Model sha": "149d70e04085ecd90510a60f916efc55da1294e7", "Average \u2b06\ufe0f": 17.12382543018816, "Hub License": "llama3", "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3693721547715617, "IFEval": 36.93721547715617, "BBH Raw": 0.4834737140438052, "BBH": 27.247898492647995, "MATH Lvl 5 Raw": 0.0302114803625377, "MATH Lvl 5": 3.0211480362537766, "GPQA Raw": 0.299496644295302, "GPQA": 6.599552572706939, "MUSR Raw": 0.3987083333333334, "MUSR": 8.271875000000001, "MMLU-PRO Raw": 0.2859873670212766, "MMLU-PRO": 20.665263002364064, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-02T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "pankajmathur/Al_Dente_v1_8b"}, {"eval_name": "pankajmathur_model_007_13b_v2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/pankajmathur/model_007_13b_v2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">pankajmathur/model_007_13b_v2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/pankajmathur__model_007_13b_v2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "pankajmathur/model_007_13b_v2", "Model sha": "2c6ddf25cdb134f22e2543121b5a36b41342a9e2", "Average \u2b06\ufe0f": 15.856346294263778, "Hub License": "llama2", "Hub \u2764\ufe0f": 4, "#Params (B)": 13, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3056490112900437, "IFEval": 30.564901129004376, "BBH Raw": 0.4702292766687601, "BBH": 25.454420185872465, "MATH Lvl 5 Raw": 0.0120845921450151, "MATH Lvl 5": 1.2084592145015105, "GPQA Raw": 0.2835570469798658, "GPQA": 4.4742729306487705, "MUSR Raw": 0.46109375, "MUSR": 17.203385416666663, "MMLU-PRO Raw": 0.24609375, "MMLU-PRO": 16.232638888888886, "Maintainer's Highlight": false, "Upload To Hub Date": "2023-08-12T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "pankajmathur/model_007_13b_v2"}, {"eval_name": "pankajmathur_orca_mini_3b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/pankajmathur/orca_mini_3b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">pankajmathur/orca_mini_3b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/pankajmathur__orca_mini_3b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "pankajmathur/orca_mini_3b", "Model sha": "31e1a7bc3f7ea2f247b432d60036d975b8d590e9", "Average \u2b06\ufe0f": 3.0749229598669547, "Hub License": "cc-by-nc-sa-4.0", "Hub \u2764\ufe0f": 158, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.0742141961107638, "IFEval": 7.421419611076388, "BBH Raw": 0.3196070040004752, "BBH": 4.6859845437903855, "MATH Lvl 5 Raw": 0.0052870090634441, "MATH Lvl 5": 0.5287009063444109, "GPQA Raw": 0.2458053691275167, "GPQA": 0.0, "MUSR Raw": 0.3349270833333333, "MUSR": 4.199218749999999, "MMLU-PRO Raw": 0.1145279255319148, "MMLU-PRO": 1.6142139479905429, "Maintainer's Highlight": false, "Upload To Hub Date": "2023-06-22T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "pankajmathur/orca_mini_3b"}, {"eval_name": "pankajmathur_orca_mini_v2_7b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/pankajmathur/orca_mini_v2_7b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">pankajmathur/orca_mini_v2_7b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/pankajmathur__orca_mini_v2_7b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "pankajmathur/orca_mini_v2_7b", "Model sha": "66d3f32a4a6bca0a2a261f1bdb54d2582028f75f", "Average \u2b06\ufe0f": 5.502368522121576, "Hub License": "cc-by-nc-sa-4.0", "Hub \u2764\ufe0f": 36, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1357885964795631, "IFEval": 13.57885964795631, "BBH Raw": 0.3536341784786451, "BBH": 10.199953477088153, "MATH Lvl 5 Raw": 0.0113293051359516, "MATH Lvl 5": 1.1329305135951662, "GPQA Raw": 0.2491610738255033, "GPQA": 0.0, "MUSR Raw": 0.3593333333333333, "MUSR": 2.0833333333333326, "MMLU-PRO Raw": 0.1541722074468085, "MMLU-PRO": 6.019134160756501, "Maintainer's Highlight": false, "Upload To Hub Date": "2023-07-03T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "pankajmathur/orca_mini_v2_7b"}, {"eval_name": "pankajmathur_orca_mini_v3_13b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/pankajmathur/orca_mini_v3_13b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">pankajmathur/orca_mini_v3_13b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/pankajmathur__orca_mini_v3_13b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "pankajmathur/orca_mini_v3_13b", "Model sha": "7d6e567d24ce2f228beaf54e89c17b0e750bfe99", "Average \u2b06\ufe0f": 15.003532639062788, "Hub License": "other", "Hub \u2764\ufe0f": 31, "#Params (B)": 13, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2896625398387389, "IFEval": 28.966253983873894, "BBH Raw": 0.4710970361474938, "BBH": 25.549482064607844, "MATH Lvl 5 Raw": 0.0188821752265861, "MATH Lvl 5": 1.8882175226586104, "GPQA Raw": 0.2651006711409396, "GPQA": 2.0134228187919474, "MUSR Raw": 0.4597916666666666, "MUSR": 17.107291666666665, "MMLU-PRO Raw": 0.23046875, "MMLU-PRO": 14.496527777777777, "Maintainer's Highlight": false, "Upload To Hub Date": "2023-08-09T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "pankajmathur/orca_mini_v3_13b"}, {"eval_name": "pankajmathur_orca_mini_v3_70b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/pankajmathur/orca_mini_v3_70b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">pankajmathur/orca_mini_v3_70b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/pankajmathur__orca_mini_v3_70b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "pankajmathur/orca_mini_v3_70b", "Model sha": "e8e856dfb5c737d1906b50f9e65fd3a4f8d77422", "Average \u2b06\ufe0f": 25.260395142233207, "Hub License": "other", "Hub \u2764\ufe0f": 23, "#Params (B)": 70, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4014703209705803, "IFEval": 40.14703209705803, "BBH Raw": 0.5949312065598904, "BBH": 42.975787003923045, "MATH Lvl 5 Raw": 0.0362537764350453, "MATH Lvl 5": 3.625377643504532, "GPQA Raw": 0.3179530201342282, "GPQA": 9.060402684563762, "MUSR Raw": 0.5078541666666667, "MUSR": 25.11510416666667, "MMLU-PRO Raw": 0.3757480053191489, "MMLU-PRO": 30.63866725768321, "Maintainer's Highlight": false, "Upload To Hub Date": "2023-08-10T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "pankajmathur/orca_mini_v3_70b"}, {"eval_name": "pankajmathur_orca_mini_v3_7b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/pankajmathur/orca_mini_v3_7b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">pankajmathur/orca_mini_v3_7b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/pankajmathur__orca_mini_v3_7b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "pankajmathur/orca_mini_v3_7b", "Model sha": "6252eb7ca29da8d951ae7d2bca948bf84e04a2b9", "Average \u2b06\ufe0f": 13.51814003742416, "Hub License": "other", "Hub \u2764\ufe0f": 40, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2820937335159599, "IFEval": 28.20937335159599, "BBH Raw": 0.4095332668279368, "BBH": 17.843955571096647, "MATH Lvl 5 Raw": 0.0030211480362537, "MATH Lvl 5": 0.3021148036253776, "GPQA Raw": 0.2466442953020134, "GPQA": 0.0, "MUSR Raw": 0.4982395833333333, "MUSR": 22.71328125, "MMLU-PRO Raw": 0.2083610372340425, "MMLU-PRO": 12.04011524822695, "Maintainer's Highlight": false, "Upload To Hub Date": "2023-08-07T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "pankajmathur/orca_mini_v3_7b"}, {"eval_name": "pankajmathur_orca_mini_v5_8b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/pankajmathur/orca_mini_v5_8b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">pankajmathur/orca_mini_v5_8b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/pankajmathur__orca_mini_v5_8b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "pankajmathur/orca_mini_v5_8b", "Model sha": "f57c84d4cc0b3b74549458c0d38e868bd7fffad1", "Average \u2b06\ufe0f": 20.15842157836384, "Hub License": "llama3", "Hub \u2764\ufe0f": 2, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4806047952765329, "IFEval": 48.06047952765329, "BBH Raw": 0.5064242853619262, "BBH": 29.34579501072649, "MATH Lvl 5 Raw": 0.0785498489425981, "MATH Lvl 5": 7.854984894259818, "GPQA Raw": 0.2869127516778523, "GPQA": 4.921700223713646, "MUSR Raw": 0.4000104166666667, "MUSR": 7.701302083333336, "MMLU-PRO Raw": 0.3075964095744681, "MMLU-PRO": 23.066267730496453, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-26T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "pankajmathur/orca_mini_v5_8b"}, {"eval_name": "pankajmathur_orca_mini_v5_8b_dpo_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/pankajmathur/orca_mini_v5_8b_dpo\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">pankajmathur/orca_mini_v5_8b_dpo</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/pankajmathur__orca_mini_v5_8b_dpo-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "pankajmathur/orca_mini_v5_8b_dpo", "Model sha": "fdc0d0aaa85a58f1abaf2c24ce0ddca10c08f0f1", "Average \u2b06\ufe0f": 19.95656348897113, "Hub License": "llama3", "Hub \u2764\ufe0f": 2, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4896474687163393, "IFEval": 48.964746871633935, "BBH Raw": 0.5074598658862709, "BBH": 29.605372989233757, "MATH Lvl 5 Raw": 0.0747734138972809, "MATH Lvl 5": 7.477341389728097, "GPQA Raw": 0.2743288590604026, "GPQA": 3.243847874720355, "MUSR Raw": 0.389375, "MUSR": 6.938541666666667, "MMLU-PRO Raw": 0.3115857712765957, "MMLU-PRO": 23.50953014184397, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-30T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "pankajmathur/orca_mini_v5_8b_dpo"}, {"eval_name": "pankajmathur_orca_mini_v5_8b_orpo_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/pankajmathur/orca_mini_v5_8b_orpo\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">pankajmathur/orca_mini_v5_8b_orpo</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/pankajmathur__orca_mini_v5_8b_orpo-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "pankajmathur/orca_mini_v5_8b_orpo", "Model sha": "4cdc018043ef439f15bd8a09c4f09c6bc528dfc7", "Average \u2b06\ufe0f": 12.880437048843222, "Hub License": "llama3", "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.0824323905016467, "IFEval": 8.243239050164673, "BBH Raw": 0.496374377369289, "BBH": 27.87762825685837, "MATH Lvl 5 Raw": 0.059667673716012, "MATH Lvl 5": 5.966767371601208, "GPQA Raw": 0.2843959731543624, "GPQA": 4.586129753914992, "MUSR Raw": 0.4131249999999999, "MUSR": 8.973958333333334, "MMLU-PRO Raw": 0.2947140957446808, "MMLU-PRO": 21.63489952718676, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-31T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "pankajmathur/orca_mini_v5_8b_orpo"}, {"eval_name": "pankajmathur_orca_mini_v6_8b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/pankajmathur/orca_mini_v6_8b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">pankajmathur/orca_mini_v6_8b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/pankajmathur__orca_mini_v6_8b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "pankajmathur/orca_mini_v6_8b", "Model sha": "e95dc8e4c6b6ca5957b657cc2d905683142eaf3e", "Average \u2b06\ufe0f": 1.4133981765593575, "Hub License": "llama3", "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.0111160609405266, "IFEval": 1.1116060940526693, "BBH Raw": 0.3028695911207613, "BBH": 3.219809856556432, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2382550335570469, "GPQA": 0.0, "MUSR Raw": 0.3554583333333334, "MUSR": 2.7656250000000004, "MMLU-PRO Raw": 0.1124501329787234, "MMLU-PRO": 1.383348108747044, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-02T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "pankajmathur/orca_mini_v6_8b"}, {"eval_name": "pankajmathur_orca_mini_v6_8b_dpo_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/pankajmathur/orca_mini_v6_8b_dpo\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">pankajmathur/orca_mini_v6_8b_dpo</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/pankajmathur__orca_mini_v6_8b_dpo-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "pankajmathur/orca_mini_v6_8b_dpo", "Model sha": "ebb11b63839d38e8c03c7ecac012e047fcb2346e", "Average \u2b06\ufe0f": 20.291787427570725, "Hub License": "llama3", "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3882564927725103, "IFEval": 38.82564927725103, "BBH Raw": 0.520280774453148, "BBH": 32.47882597428379, "MATH Lvl 5 Raw": 0.0551359516616314, "MATH Lvl 5": 5.5135951661631415, "GPQA Raw": 0.3011744966442953, "GPQA": 6.823266219239373, "MUSR Raw": 0.40903125, "MUSR": 9.262239583333336, "MMLU-PRO Raw": 0.359624335106383, "MMLU-PRO": 28.847148345153663, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-21T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "pankajmathur/orca_mini_v6_8b_dpo"}, {"eval_name": "pankajmathur_orca_mini_v7_72b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/pankajmathur/orca_mini_v7_72b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">pankajmathur/orca_mini_v7_72b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/pankajmathur__orca_mini_v7_72b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "pankajmathur/orca_mini_v7_72b", "Model sha": "447f11912cfa496e32e188a55214043a05760d3a", "Average \u2b06\ufe0f": 39.06020531201064, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 11, "#Params (B)": 72, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.5929622291076566, "IFEval": 59.29622291076566, "BBH Raw": 0.6842301988001044, "BBH": 55.05552307693972, "MATH Lvl 5 Raw": 0.2643504531722054, "MATH Lvl 5": 26.435045317220546, "GPQA Raw": 0.3850671140939597, "GPQA": 18.008948545861294, "MUSR Raw": 0.5070416666666667, "MUSR": 24.21354166666666, "MMLU-PRO Raw": 0.5621675531914894, "MMLU-PRO": 51.35195035460993, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-26T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "pankajmathur/orca_mini_v7_72b"}, {"eval_name": "pankajmathur_orca_mini_v7_7b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/pankajmathur/orca_mini_v7_7b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">pankajmathur/orca_mini_v7_7b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/pankajmathur__orca_mini_v7_7b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "pankajmathur/orca_mini_v7_7b", "Model sha": "f5e84ff6ea25fb4585908ea45d1520bac416d803", "Average \u2b06\ufe0f": 22.41298966861666, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 2, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4387646998851935, "IFEval": 43.87646998851935, "BBH Raw": 0.5274909601771501, "BBH": 33.95043410425148, "MATH Lvl 5 Raw": 0.0264350453172205, "MATH Lvl 5": 2.643504531722054, "GPQA Raw": 0.2961409395973154, "GPQA": 6.152125279642054, "MUSR Raw": 0.4359791666666666, "MUSR": 12.6640625, "MMLU-PRO Raw": 0.4167220744680851, "MMLU-PRO": 35.19134160756501, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-20T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "pankajmathur/orca_mini_v7_7b"}, {"eval_name": "paulml_ECE-ILAB-Q1_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/paulml/ECE-ILAB-Q1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">paulml/ECE-ILAB-Q1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/paulml__ECE-ILAB-Q1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "paulml/ECE-ILAB-Q1", "Model sha": "393bea0ee85e4c752acd5fd77ce07f577fc13bd9", "Average \u2b06\ufe0f": 40.92955788594744, "Hub License": "other", "Hub \u2764\ufe0f": 0, "#Params (B)": 72, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.7864521691334547, "IFEval": 78.64521691334548, "BBH Raw": 0.6717755530661759, "BBH": 53.70222770817057, "MATH Lvl 5 Raw": 0.2613293051359516, "MATH Lvl 5": 26.132930513595166, "GPQA Raw": 0.386744966442953, "GPQA": 18.232662192393736, "MUSR Raw": 0.461375, "MUSR": 18.805208333333333, "MMLU-PRO Raw": 0.550531914893617, "MMLU-PRO": 50.05910165484633, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-06T00:00:00", "Submission Date": "2024-09-16T00:00:00", "Generation": 0, "Base Model": "paulml/ECE-ILAB-Q1"}, {"eval_name": "pints-ai_1.5-Pints-16K-v0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/pints-ai/1.5-Pints-16K-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">pints-ai/1.5-Pints-16K-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/pints-ai__1.5-Pints-16K-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "pints-ai/1.5-Pints-16K-v0.1", "Model sha": "7862a52f250be68fad593f3a4030f00d658ede56", "Average \u2b06\ufe0f": 4.150222953923024, "Hub License": "mit", "Hub \u2764\ufe0f": 12, "#Params (B)": 1, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.1635914927946737, "IFEval": 16.35914927946737, "BBH Raw": 0.3133077677150869, "BBH": 3.658292060342125, "MATH Lvl 5 Raw": 0.0083081570996978, "MATH Lvl 5": 0.8308157099697886, "GPQA Raw": 0.235738255033557, "GPQA": 0.0, "MUSR Raw": 0.357875, "MUSR": 2.734375, "MMLU-PRO Raw": 0.1118683510638298, "MMLU-PRO": 1.3187056737588652, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-07T00:00:00", "Submission Date": "2024-09-09T00:00:00", "Generation": 0, "Base Model": "pints-ai/1.5-Pints-16K-v0.1"}, {"eval_name": "pints-ai_1.5-Pints-2K-v0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/pints-ai/1.5-Pints-2K-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">pints-ai/1.5-Pints-2K-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/pints-ai__1.5-Pints-2K-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "pints-ai/1.5-Pints-2K-v0.1", "Model sha": "2e865c18669161ebbf5e9ad79ae0502ee0153df0", "Average \u2b06\ufe0f": 3.8304416986902328, "Hub License": "mit", "Hub \u2764\ufe0f": 15, "#Params (B)": 1, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.1761559329246399, "IFEval": 17.615593292463995, "BBH Raw": 0.2980194338975043, "BBH": 2.3744704635071923, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2483221476510067, "GPQA": 0.0, "MUSR Raw": 0.3501874999999999, "MUSR": 1.8401041666666655, "MMLU-PRO Raw": 0.1103723404255319, "MMLU-PRO": 1.1524822695035457, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-07T00:00:00", "Submission Date": "2024-09-09T00:00:00", "Generation": 0, "Base Model": "pints-ai/1.5-Pints-2K-v0.1"}, {"eval_name": "piotr25691_thea-3b-25r_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/piotr25691/thea-3b-25r\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">piotr25691/thea-3b-25r</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/piotr25691__thea-3b-25r-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "piotr25691/thea-3b-25r", "Model sha": "4661fb3c8b18bdf2059f703c4f69caea24057151", "Average \u2b06\ufe0f": 23.7443086762807, "Hub License": "llama3.2", "Hub \u2764\ufe0f": 0, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7344202272193336, "IFEval": 73.44202272193337, "BBH Raw": 0.4484410029364986, "BBH": 22.54671082396668, "MATH Lvl 5 Raw": 0.1631419939577039, "MATH Lvl 5": 16.314199395770395, "GPQA Raw": 0.2676174496644295, "GPQA": 2.348993288590602, "MUSR Raw": 0.3314583333333333, "MUSR": 3.565625000000001, "MMLU-PRO Raw": 0.3182347074468085, "MMLU-PRO": 24.248300827423165, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-11T00:00:00", "Submission Date": "2024-10-12T00:00:00", "Generation": 1, "Base Model": "chuanli11/Llama-3.2-3B-Instruct-uncensored"}, {"eval_name": "princeton-nlp_Llama-3-8B-ProLong-512k-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/princeton-nlp/Llama-3-8B-ProLong-512k-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">princeton-nlp/Llama-3-8B-ProLong-512k-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/princeton-nlp__Llama-3-8B-ProLong-512k-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "princeton-nlp/Llama-3-8B-ProLong-512k-Instruct", "Model sha": "eae0626e8597575215276c2b248720f731bc50b8", "Average \u2b06\ufe0f": 18.83339420680035, "Hub License": "llama3", "Hub \u2764\ufe0f": 16, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4130108113139802, "IFEval": 41.30108113139802, "BBH Raw": 0.4967586873360171, "BBH": 28.43975489639733, "MATH Lvl 5 Raw": 0.0445619335347432, "MATH Lvl 5": 4.45619335347432, "GPQA Raw": 0.2667785234899328, "GPQA": 2.2371364653243813, "MUSR Raw": 0.4223645833333333, "MUSR": 11.66223958333333, "MMLU-PRO Raw": 0.3241356382978723, "MMLU-PRO": 24.903959810874703, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-22T00:00:00", "Submission Date": "2024-09-17T00:00:00", "Generation": 1, "Base Model": "princeton-nlp/Llama-3-8B-ProLong-512k-Instruct (Merge)"}, {"eval_name": "princeton-nlp_Llama-3-8B-ProLong-64k-Base_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe9 continuously pretrained", "T": "\ud83d\udfe9", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/princeton-nlp/Llama-3-8B-ProLong-64k-Base\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">princeton-nlp/Llama-3-8B-ProLong-64k-Base</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/princeton-nlp__Llama-3-8B-ProLong-64k-Base-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "princeton-nlp/Llama-3-8B-ProLong-64k-Base", "Model sha": "97994d6918f80162a893e22d5e7bba586551f941", "Average \u2b06\ufe0f": 13.773111520841974, "Hub License": "llama3", "Hub \u2764\ufe0f": 5, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1249229821318545, "IFEval": 12.492298213185457, "BBH Raw": 0.4702640288936317, "BBH": 25.018708351323117, "MATH Lvl 5 Raw": 0.0581570996978852, "MATH Lvl 5": 5.81570996978852, "GPQA Raw": 0.2860738255033557, "GPQA": 4.809843400447425, "MUSR Raw": 0.3917291666666667, "MUSR": 9.099479166666669, "MMLU-PRO Raw": 0.3286236702127659, "MMLU-PRO": 25.40263002364066, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-22T00:00:00", "Submission Date": "2024-09-17T00:00:00", "Generation": 1, "Base Model": "princeton-nlp/Llama-3-8B-ProLong-64k-Base (Merge)"}, {"eval_name": "princeton-nlp_Llama-3-8B-ProLong-64k-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/princeton-nlp/Llama-3-8B-ProLong-64k-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">princeton-nlp/Llama-3-8B-ProLong-64k-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/princeton-nlp__Llama-3-8B-ProLong-64k-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "princeton-nlp/Llama-3-8B-ProLong-64k-Instruct", "Model sha": "fe55aed18544c5744239e473bb0d3aa0151776d3", "Average \u2b06\ufe0f": 18.80340131218, "Hub License": "llama3", "Hub \u2764\ufe0f": 12, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3986478100329348, "IFEval": 39.86478100329349, "BBH Raw": 0.4994010394760559, "BBH": 28.710959529198124, "MATH Lvl 5 Raw": 0.0551359516616314, "MATH Lvl 5": 5.5135951661631415, "GPQA Raw": 0.2718120805369127, "GPQA": 2.9082774049217, "MUSR Raw": 0.4157291666666666, "MUSR": 11.232812499999994, "MMLU-PRO Raw": 0.3213098404255319, "MMLU-PRO": 24.589982269503544, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-21T00:00:00", "Submission Date": "2024-09-17T00:00:00", "Generation": 1, "Base Model": "princeton-nlp/Llama-3-8B-ProLong-64k-Instruct (Merge)"}, {"eval_name": "princeton-nlp_Llama-3-Base-8B-SFT_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/princeton-nlp/Llama-3-Base-8B-SFT\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">princeton-nlp/Llama-3-Base-8B-SFT</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/princeton-nlp__Llama-3-Base-8B-SFT-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "princeton-nlp/Llama-3-Base-8B-SFT", "Model sha": "b622b7d814aa03aa722328bf88feaf1ad480b7fb", "Average \u2b06\ufe0f": 15.37426045550471, "Hub License": null, "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3096461832382522, "IFEval": 30.964618323825228, "BBH Raw": 0.4547838615765894, "BBH": 24.388576484696543, "MATH Lvl 5 Raw": 0.0271903323262839, "MATH Lvl 5": 2.719033232628399, "GPQA Raw": 0.2835570469798658, "GPQA": 4.4742729306487705, "MUSR Raw": 0.3949583333333333, "MUSR": 8.036458333333336, "MMLU-PRO Raw": 0.2949634308510638, "MMLU-PRO": 21.66260342789598, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-17T00:00:00", "Submission Date": "2024-10-07T00:00:00", "Generation": 0, "Base Model": "princeton-nlp/Llama-3-Base-8B-SFT"}, {"eval_name": "princeton-nlp_Llama-3-Base-8B-SFT-CPO_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/princeton-nlp/Llama-3-Base-8B-SFT-CPO\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">princeton-nlp/Llama-3-Base-8B-SFT-CPO</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/princeton-nlp__Llama-3-Base-8B-SFT-CPO-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "princeton-nlp/Llama-3-Base-8B-SFT-CPO", "Model sha": "536ce7e7beb35175c48538fe46e7e9e100f228c9", "Average \u2b06\ufe0f": 15.790143791011252, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3703462368737172, "IFEval": 37.03462368737173, "BBH Raw": 0.4594875922440002, "BBH": 25.474648628373444, "MATH Lvl 5 Raw": 0.0445619335347432, "MATH Lvl 5": 4.45619335347432, "GPQA Raw": 0.2743288590604026, "GPQA": 3.243847874720355, "MUSR Raw": 0.3608541666666667, "MUSR": 2.5734375000000025, "MMLU-PRO Raw": 0.2976230053191489, "MMLU-PRO": 21.95811170212766, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-06T00:00:00", "Submission Date": "2024-10-07T00:00:00", "Generation": 0, "Base Model": "princeton-nlp/Llama-3-Base-8B-SFT-CPO"}, {"eval_name": "princeton-nlp_Llama-3-Base-8B-SFT-DPO_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/princeton-nlp/Llama-3-Base-8B-SFT-DPO\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">princeton-nlp/Llama-3-Base-8B-SFT-DPO</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/princeton-nlp__Llama-3-Base-8B-SFT-DPO-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "princeton-nlp/Llama-3-Base-8B-SFT-DPO", "Model sha": "3f5ec47c9beffb37cfbdcd837e76a336a9b1e651", "Average \u2b06\ufe0f": 18.111868659124134, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4111125147940797, "IFEval": 41.11125147940797, "BBH Raw": 0.4665850606491354, "BBH": 26.001873821480995, "MATH Lvl 5 Raw": 0.0256797583081571, "MATH Lvl 5": 2.56797583081571, "GPQA Raw": 0.3104026845637584, "GPQA": 8.05369127516779, "MUSR Raw": 0.3867395833333333, "MUSR": 7.842447916666668, "MMLU-PRO Raw": 0.3078457446808511, "MMLU-PRO": 23.093971631205672, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-17T00:00:00", "Submission Date": "2024-10-07T00:00:00", "Generation": 0, "Base Model": "princeton-nlp/Llama-3-Base-8B-SFT-DPO"}, {"eval_name": "princeton-nlp_Llama-3-Base-8B-SFT-IPO_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/princeton-nlp/Llama-3-Base-8B-SFT-IPO\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">princeton-nlp/Llama-3-Base-8B-SFT-IPO</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/princeton-nlp__Llama-3-Base-8B-SFT-IPO-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "princeton-nlp/Llama-3-Base-8B-SFT-IPO", "Model sha": "85055cc4b9c707e0bd1239d20d1f62927a7a54c3", "Average \u2b06\ufe0f": 18.269301066674803, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4486562321307464, "IFEval": 44.86562321307464, "BBH Raw": 0.4690068582318399, "BBH": 25.705433288023944, "MATH Lvl 5 Raw": 0.0120845921450151, "MATH Lvl 5": 1.2084592145015105, "GPQA Raw": 0.2978187919463087, "GPQA": 6.375838926174497, "MUSR Raw": 0.3919479166666667, "MUSR": 7.960156250000001, "MMLU-PRO Raw": 0.3115026595744681, "MMLU-PRO": 23.50029550827423, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-17T00:00:00", "Submission Date": "2024-10-07T00:00:00", "Generation": 0, "Base Model": "princeton-nlp/Llama-3-Base-8B-SFT-IPO"}, {"eval_name": "princeton-nlp_Llama-3-Base-8B-SFT-KTO_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/princeton-nlp/Llama-3-Base-8B-SFT-KTO\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">princeton-nlp/Llama-3-Base-8B-SFT-KTO</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/princeton-nlp__Llama-3-Base-8B-SFT-KTO-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "princeton-nlp/Llama-3-Base-8B-SFT-KTO", "Model sha": "49a8c2e5ccc7a28ed7bbedf093e352015fc1eb9b", "Average \u2b06\ufe0f": 17.952269968855877, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4522533544329047, "IFEval": 45.22533544329048, "BBH Raw": 0.4692852292721417, "BBH": 25.55523001299593, "MATH Lvl 5 Raw": 0.0113293051359516, "MATH Lvl 5": 1.1329305135951662, "GPQA Raw": 0.3053691275167785, "GPQA": 7.38255033557047, "MUSR Raw": 0.3841979166666667, "MUSR": 5.59140625, "MMLU-PRO Raw": 0.3054355053191489, "MMLU-PRO": 22.826167257683213, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-17T00:00:00", "Submission Date": "2024-10-07T00:00:00", "Generation": 0, "Base Model": "princeton-nlp/Llama-3-Base-8B-SFT-KTO"}, {"eval_name": "princeton-nlp_Llama-3-Base-8B-SFT-ORPO_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/princeton-nlp/Llama-3-Base-8B-SFT-ORPO\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">princeton-nlp/Llama-3-Base-8B-SFT-ORPO</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/princeton-nlp__Llama-3-Base-8B-SFT-ORPO-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "princeton-nlp/Llama-3-Base-8B-SFT-ORPO", "Model sha": "54d58402e0168faff6503e41621ad6c8274a310a", "Average \u2b06\ufe0f": 19.1424447216433, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4516538340492116, "IFEval": 45.16538340492117, "BBH Raw": 0.4734057302465391, "BBH": 26.48589369385502, "MATH Lvl 5 Raw": 0.039274924471299, "MATH Lvl 5": 3.927492447129909, "GPQA Raw": 0.313758389261745, "GPQA": 8.501118568232664, "MUSR Raw": 0.3706770833333333, "MUSR": 7.634635416666668, "MMLU-PRO Raw": 0.3082613031914893, "MMLU-PRO": 23.140144799054376, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-17T00:00:00", "Submission Date": "2024-10-07T00:00:00", "Generation": 0, "Base Model": "princeton-nlp/Llama-3-Base-8B-SFT-ORPO"}, {"eval_name": "princeton-nlp_Llama-3-Base-8B-SFT-RDPO_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/princeton-nlp/Llama-3-Base-8B-SFT-RDPO\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">princeton-nlp/Llama-3-Base-8B-SFT-RDPO</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/princeton-nlp__Llama-3-Base-8B-SFT-RDPO-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "princeton-nlp/Llama-3-Base-8B-SFT-RDPO", "Model sha": "b41a964c2135ba34dcc6fa7edf76b6b9ea656949", "Average \u2b06\ufe0f": 18.802423077730147, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4480068440626427, "IFEval": 44.80068440626427, "BBH Raw": 0.4662014044875229, "BBH": 25.526521127200017, "MATH Lvl 5 Raw": 0.0370090634441087, "MATH Lvl 5": 3.700906344410876, "GPQA Raw": 0.3062080536912752, "GPQA": 7.494407158836691, "MUSR Raw": 0.4027395833333334, "MUSR": 8.909114583333336, "MMLU-PRO Raw": 0.3014461436170212, "MMLU-PRO": 22.38290484633569, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-17T00:00:00", "Submission Date": "2024-10-07T00:00:00", "Generation": 0, "Base Model": "princeton-nlp/Llama-3-Base-8B-SFT-RDPO"}, {"eval_name": "princeton-nlp_Llama-3-Base-8B-SFT-RRHF_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/princeton-nlp/Llama-3-Base-8B-SFT-RRHF\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">princeton-nlp/Llama-3-Base-8B-SFT-RRHF</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/princeton-nlp__Llama-3-Base-8B-SFT-RRHF-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "princeton-nlp/Llama-3-Base-8B-SFT-RRHF", "Model sha": "aea8c04b3940cebd1f8296a2c76914f0ce70c276", "Average \u2b06\ufe0f": 16.00578570356289, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3357247658435174, "IFEval": 33.57247658435174, "BBH Raw": 0.4520360167602379, "BBH": 23.659142323042403, "MATH Lvl 5 Raw": 0.0287009063444108, "MATH Lvl 5": 2.8700906344410875, "GPQA Raw": 0.3053691275167785, "GPQA": 7.38255033557047, "MUSR Raw": 0.3722291666666666, "MUSR": 7.561979166666668, "MMLU-PRO Raw": 0.2888962765957447, "MMLU-PRO": 20.988475177304963, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-06T00:00:00", "Submission Date": "2024-10-07T00:00:00", "Generation": 0, "Base Model": "princeton-nlp/Llama-3-Base-8B-SFT-RRHF"}, {"eval_name": "princeton-nlp_Llama-3-Base-8B-SFT-SLiC-HF_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/princeton-nlp/Llama-3-Base-8B-SFT-SLiC-HF\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">princeton-nlp/Llama-3-Base-8B-SFT-SLiC-HF</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/princeton-nlp__Llama-3-Base-8B-SFT-SLiC-HF-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "princeton-nlp/Llama-3-Base-8B-SFT-SLiC-HF", "Model sha": "325092c1eddffc3ca7157be1ff9958128e5753ef", "Average \u2b06\ufe0f": 19.6424085565218, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4890479483326463, "IFEval": 48.90479483326463, "BBH Raw": 0.4704075127777334, "BBH": 26.37396261839453, "MATH Lvl 5 Raw": 0.0445619335347432, "MATH Lvl 5": 4.45619335347432, "GPQA Raw": 0.2869127516778523, "GPQA": 4.921700223713646, "MUSR Raw": 0.40909375, "MUSR": 10.270052083333336, "MMLU-PRO Raw": 0.3063497340425531, "MMLU-PRO": 22.92774822695035, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-06T00:00:00", "Submission Date": "2024-10-07T00:00:00", "Generation": 0, "Base Model": "princeton-nlp/Llama-3-Base-8B-SFT-SLiC-HF"}, {"eval_name": "princeton-nlp_Llama-3-Base-8B-SFT-SimPO_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/princeton-nlp/Llama-3-Base-8B-SFT-SimPO\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">princeton-nlp/Llama-3-Base-8B-SFT-SimPO</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/princeton-nlp__Llama-3-Base-8B-SFT-SimPO-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "princeton-nlp/Llama-3-Base-8B-SFT-SimPO", "Model sha": "0a6e518b13b67abe8433bce3f7beee9beb74a794", "Average \u2b06\ufe0f": 19.279456083611223, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4685401401614383, "IFEval": 46.85401401614384, "BBH Raw": 0.4741250703396082, "BBH": 26.39594961870209, "MATH Lvl 5 Raw": 0.0203927492447129, "MATH Lvl 5": 2.0392749244712998, "GPQA Raw": 0.2885906040268456, "GPQA": 5.145413870246088, "MUSR Raw": 0.4126875, "MUSR": 11.852604166666666, "MMLU-PRO Raw": 0.3105053191489361, "MMLU-PRO": 23.389479905437348, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-24T00:00:00", "Submission Date": "2024-09-28T00:00:00", "Generation": 0, "Base Model": "princeton-nlp/Llama-3-Base-8B-SFT-SimPO"}, {"eval_name": "princeton-nlp_Llama-3-Instruct-8B-CPO_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/princeton-nlp/Llama-3-Instruct-8B-CPO\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">princeton-nlp/Llama-3-Instruct-8B-CPO</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/princeton-nlp__Llama-3-Instruct-8B-CPO-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "princeton-nlp/Llama-3-Instruct-8B-CPO", "Model sha": "d4645ae4c3b99892f1c59f60a77330be35567835", "Average \u2b06\ufe0f": 23.77249032668833, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7292993701157373, "IFEval": 72.92993701157374, "BBH Raw": 0.4998793158888361, "BBH": 28.604298572618475, "MATH Lvl 5 Raw": 0.0853474320241691, "MATH Lvl 5": 8.534743202416918, "GPQA Raw": 0.2600671140939597, "GPQA": 1.342281879194629, "MUSR Raw": 0.3513958333333333, "MUSR": 1.7578124999999991, "MMLU-PRO Raw": 0.3651928191489361, "MMLU-PRO": 29.465868794326237, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-06T00:00:00", "Submission Date": "2024-09-28T00:00:00", "Generation": 0, "Base Model": "princeton-nlp/Llama-3-Instruct-8B-CPO"}, {"eval_name": "princeton-nlp_Llama-3-Instruct-8B-CPO-v0.2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/princeton-nlp/Llama-3-Instruct-8B-CPO-v0.2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">princeton-nlp/Llama-3-Instruct-8B-CPO-v0.2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/princeton-nlp__Llama-3-Instruct-8B-CPO-v0.2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "princeton-nlp/Llama-3-Instruct-8B-CPO-v0.2", "Model sha": "5ed83728712693437bd547f4cd32923ac4e1172d", "Average \u2b06\ufe0f": 24.73289757114966, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7505817896514582, "IFEval": 75.05817896514581, "BBH Raw": 0.5026669871217129, "BBH": 29.086406714200837, "MATH Lvl 5 Raw": 0.0989425981873111, "MATH Lvl 5": 9.894259818731117, "GPQA Raw": 0.2609060402684564, "GPQA": 1.45413870246085, "MUSR Raw": 0.36190625, "MUSR": 2.83828125, "MMLU-PRO Raw": 0.370595079787234, "MMLU-PRO": 30.06611997635934, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-06T00:00:00", "Submission Date": "2024-09-28T00:00:00", "Generation": 0, "Base Model": "princeton-nlp/Llama-3-Instruct-8B-CPO-v0.2"}, {"eval_name": "princeton-nlp_Llama-3-Instruct-8B-DPO_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/princeton-nlp/Llama-3-Instruct-8B-DPO\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">princeton-nlp/Llama-3-Instruct-8B-DPO</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/princeton-nlp__Llama-3-Instruct-8B-DPO-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "princeton-nlp/Llama-3-Instruct-8B-DPO", "Model sha": "0afbf4c012ec7507f61c554999151b95a3651db3", "Average \u2b06\ufe0f": 22.6422477823758, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6757436934001781, "IFEval": 67.57436934001782, "BBH Raw": 0.4991303079139502, "BBH": 28.50739167799402, "MATH Lvl 5 Raw": 0.0332326283987915, "MATH Lvl 5": 3.3232628398791544, "GPQA Raw": 0.2718120805369127, "GPQA": 2.9082774049217, "MUSR Raw": 0.3738125, "MUSR": 3.9265625000000015, "MMLU-PRO Raw": 0.3665226063829787, "MMLU-PRO": 29.613622931442084, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-17T00:00:00", "Submission Date": "2024-09-28T00:00:00", "Generation": 0, "Base Model": "princeton-nlp/Llama-3-Instruct-8B-DPO"}, {"eval_name": "princeton-nlp_Llama-3-Instruct-8B-DPO-v0.2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/princeton-nlp/Llama-3-Instruct-8B-DPO-v0.2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">princeton-nlp/Llama-3-Instruct-8B-DPO-v0.2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/princeton-nlp__Llama-3-Instruct-8B-DPO-v0.2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "princeton-nlp/Llama-3-Instruct-8B-DPO-v0.2", "Model sha": "d06275e02abbeaf29d911a3c0cf22922dcca6b0b", "Average \u2b06\ufe0f": 24.629909847555165, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7208063493752133, "IFEval": 72.08063493752132, "BBH Raw": 0.505620320855615, "BBH": 28.939587046939987, "MATH Lvl 5 Raw": 0.0551359516616314, "MATH Lvl 5": 5.5135951661631415, "GPQA Raw": 0.2869127516778523, "GPQA": 4.921700223713646, "MUSR Raw": 0.3844479166666666, "MUSR": 5.555989583333333, "MMLU-PRO Raw": 0.3769115691489361, "MMLU-PRO": 30.76795212765957, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-06T00:00:00", "Submission Date": "2024-09-28T00:00:00", "Generation": 0, "Base Model": "princeton-nlp/Llama-3-Instruct-8B-DPO-v0.2"}, {"eval_name": "princeton-nlp_Llama-3-Instruct-8B-KTO_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/princeton-nlp/Llama-3-Instruct-8B-KTO\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">princeton-nlp/Llama-3-Instruct-8B-KTO</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/princeton-nlp__Llama-3-Instruct-8B-KTO-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "princeton-nlp/Llama-3-Instruct-8B-KTO", "Model sha": "e697908201cbab01e0ca54088bb8cd2fd99b4574", "Average \u2b06\ufe0f": 22.751876374011218, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6864098370102439, "IFEval": 68.6409837010244, "BBH Raw": 0.4981903187457697, "BBH": 28.64965788695442, "MATH Lvl 5 Raw": 0.0324773413897281, "MATH Lvl 5": 3.2477341389728096, "GPQA Raw": 0.276006711409396, "GPQA": 3.467561521252797, "MUSR Raw": 0.3698437499999999, "MUSR": 3.630468749999999, "MMLU-PRO Raw": 0.3598736702127659, "MMLU-PRO": 28.874852245862886, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-17T00:00:00", "Submission Date": "2024-09-28T00:00:00", "Generation": 0, "Base Model": "princeton-nlp/Llama-3-Instruct-8B-KTO"}, {"eval_name": "princeton-nlp_Llama-3-Instruct-8B-KTO-v0.2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/princeton-nlp/Llama-3-Instruct-8B-KTO-v0.2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">princeton-nlp/Llama-3-Instruct-8B-KTO-v0.2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/princeton-nlp__Llama-3-Instruct-8B-KTO-v0.2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "princeton-nlp/Llama-3-Instruct-8B-KTO-v0.2", "Model sha": "477d33ea62ed57a0429517170612aa1df21c78d6", "Average \u2b06\ufe0f": 24.193629755100236, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7290245437660962, "IFEval": 72.90245437660963, "BBH Raw": 0.5079766897761946, "BBH": 29.648405523209775, "MATH Lvl 5 Raw": 0.0717522658610271, "MATH Lvl 5": 7.175226586102719, "GPQA Raw": 0.2600671140939597, "GPQA": 1.342281879194629, "MUSR Raw": 0.37775, "MUSR": 4.4520833333333325, "MMLU-PRO Raw": 0.3667719414893617, "MMLU-PRO": 29.6413268321513, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-06T00:00:00", "Submission Date": "2024-09-28T00:00:00", "Generation": 0, "Base Model": "princeton-nlp/Llama-3-Instruct-8B-KTO-v0.2"}, {"eval_name": "princeton-nlp_Llama-3-Instruct-8B-ORPO_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/princeton-nlp/Llama-3-Instruct-8B-ORPO\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">princeton-nlp/Llama-3-Instruct-8B-ORPO</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/princeton-nlp__Llama-3-Instruct-8B-ORPO-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "princeton-nlp/Llama-3-Instruct-8B-ORPO", "Model sha": "4bb3ffcf9ede48cb01a10bf3223eb41b59aa3fef", "Average \u2b06\ufe0f": 23.421181993723103, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.712813113649561, "IFEval": 71.2813113649561, "BBH Raw": 0.5001206199104097, "BBH": 28.839356158957287, "MATH Lvl 5 Raw": 0.066465256797583, "MATH Lvl 5": 6.646525679758309, "GPQA Raw": 0.2583892617449664, "GPQA": 1.1185682326621946, "MUSR Raw": 0.3501875, "MUSR": 3.240104166666668, "MMLU-PRO Raw": 0.3646110372340425, "MMLU-PRO": 29.40122635933806, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-17T00:00:00", "Submission Date": "2024-09-28T00:00:00", "Generation": 0, "Base Model": "princeton-nlp/Llama-3-Instruct-8B-ORPO"}, {"eval_name": "princeton-nlp_Llama-3-Instruct-8B-ORPO-v0.2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/princeton-nlp/Llama-3-Instruct-8B-ORPO-v0.2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">princeton-nlp/Llama-3-Instruct-8B-ORPO-v0.2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/princeton-nlp__Llama-3-Instruct-8B-ORPO-v0.2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "princeton-nlp/Llama-3-Instruct-8B-ORPO-v0.2", "Model sha": "3ea5c542a3d8d61f6afb6cdbef5972a501ddf759", "Average \u2b06\ufe0f": 25.67661826148445, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7633213207622442, "IFEval": 76.33213207622441, "BBH Raw": 0.507835231782556, "BBH": 29.60483732707141, "MATH Lvl 5 Raw": 0.0845921450151057, "MATH Lvl 5": 8.459214501510575, "GPQA Raw": 0.2835570469798658, "GPQA": 4.4742729306487705, "MUSR Raw": 0.3779687499999999, "MUSR": 4.8460937500000005, "MMLU-PRO Raw": 0.3730884308510638, "MMLU-PRO": 30.34315898345153, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-06T00:00:00", "Submission Date": "2024-09-28T00:00:00", "Generation": 0, "Base Model": "princeton-nlp/Llama-3-Instruct-8B-ORPO-v0.2"}, {"eval_name": "princeton-nlp_Llama-3-Instruct-8B-RDPO_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/princeton-nlp/Llama-3-Instruct-8B-RDPO\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">princeton-nlp/Llama-3-Instruct-8B-RDPO</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/princeton-nlp__Llama-3-Instruct-8B-RDPO-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "princeton-nlp/Llama-3-Instruct-8B-RDPO", "Model sha": "9497ca226a68981f42df2e5b3a4a1a2ea702a942", "Average \u2b06\ufe0f": 22.546352583984863, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6660017642078574, "IFEval": 66.60017642078574, "BBH Raw": 0.5033626077797596, "BBH": 29.032479102136296, "MATH Lvl 5 Raw": 0.0211480362537764, "MATH Lvl 5": 2.114803625377644, "GPQA Raw": 0.2827181208053691, "GPQA": 4.36241610738255, "MUSR Raw": 0.3752083333333333, "MUSR": 4.201041666666666, "MMLU-PRO Raw": 0.3607047872340425, "MMLU-PRO": 28.96719858156028, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-17T00:00:00", "Submission Date": "2024-09-28T00:00:00", "Generation": 0, "Base Model": "princeton-nlp/Llama-3-Instruct-8B-RDPO"}, {"eval_name": "princeton-nlp_Llama-3-Instruct-8B-RDPO-v0.2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/princeton-nlp/Llama-3-Instruct-8B-RDPO-v0.2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">princeton-nlp/Llama-3-Instruct-8B-RDPO-v0.2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/princeton-nlp__Llama-3-Instruct-8B-RDPO-v0.2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "princeton-nlp/Llama-3-Instruct-8B-RDPO-v0.2", "Model sha": "4e5bc9779cba3a2f615379d3f8ef1bbb3ea487f7", "Average \u2b06\ufe0f": 24.4028192271865, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7076922565459647, "IFEval": 70.76922565459647, "BBH Raw": 0.5049218189829557, "BBH": 28.85427665062166, "MATH Lvl 5 Raw": 0.0490936555891238, "MATH Lvl 5": 4.909365558912387, "GPQA Raw": 0.2927852348993288, "GPQA": 5.7046979865771785, "MUSR Raw": 0.3804479166666666, "MUSR": 5.355989583333333, "MMLU-PRO Raw": 0.3774102393617021, "MMLU-PRO": 30.82335992907802, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-06T00:00:00", "Submission Date": "2024-09-28T00:00:00", "Generation": 0, "Base Model": "princeton-nlp/Llama-3-Instruct-8B-RDPO-v0.2"}, {"eval_name": "princeton-nlp_Llama-3-Instruct-8B-RRHF_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/princeton-nlp/Llama-3-Instruct-8B-RRHF\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">princeton-nlp/Llama-3-Instruct-8B-RRHF</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/princeton-nlp__Llama-3-Instruct-8B-RRHF-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "princeton-nlp/Llama-3-Instruct-8B-RRHF", "Model sha": "73561d9b0fd42b94250246f8d794251fe9f9d2e9", "Average \u2b06\ufe0f": 23.946024821299023, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7274509412802475, "IFEval": 72.74509412802476, "BBH Raw": 0.4910546876564721, "BBH": 27.21648494751436, "MATH Lvl 5 Raw": 0.0883685800604229, "MATH Lvl 5": 8.836858006042297, "GPQA Raw": 0.2802013422818792, "GPQA": 4.026845637583895, "MUSR Raw": 0.3475520833333334, "MUSR": 1.47734375, "MMLU-PRO Raw": 0.3643617021276595, "MMLU-PRO": 29.37352245862884, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-06T00:00:00", "Submission Date": "2024-10-07T00:00:00", "Generation": 0, "Base Model": "princeton-nlp/Llama-3-Instruct-8B-RRHF"}, {"eval_name": "princeton-nlp_Llama-3-Instruct-8B-RRHF-v0.2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/princeton-nlp/Llama-3-Instruct-8B-RRHF-v0.2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">princeton-nlp/Llama-3-Instruct-8B-RRHF-v0.2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/princeton-nlp__Llama-3-Instruct-8B-RRHF-v0.2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "princeton-nlp/Llama-3-Instruct-8B-RRHF-v0.2", "Model sha": "81191fbb214d17f0a4fec247da5d648f4cb61ef1", "Average \u2b06\ufe0f": 23.615281314977565, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.712488419615509, "IFEval": 71.24884196155091, "BBH Raw": 0.4983895257292753, "BBH": 28.498723991187727, "MATH Lvl 5 Raw": 0.0793051359516616, "MATH Lvl 5": 7.930513595166164, "GPQA Raw": 0.2600671140939597, "GPQA": 1.342281879194629, "MUSR Raw": 0.37378125, "MUSR": 5.089322916666668, "MMLU-PRO Raw": 0.3482380319148936, "MMLU-PRO": 27.582003546099287, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-06T00:00:00", "Submission Date": "2024-10-07T00:00:00", "Generation": 0, "Base Model": "princeton-nlp/Llama-3-Instruct-8B-RRHF-v0.2"}, {"eval_name": "princeton-nlp_Llama-3-Instruct-8B-SLiC-HF_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/princeton-nlp/Llama-3-Instruct-8B-SLiC-HF\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">princeton-nlp/Llama-3-Instruct-8B-SLiC-HF</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/princeton-nlp__Llama-3-Instruct-8B-SLiC-HF-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "princeton-nlp/Llama-3-Instruct-8B-SLiC-HF", "Model sha": "7e9001f6f4fe940c363bb7ea1814d33c79b21737", "Average \u2b06\ufe0f": 24.95567681444202, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7399655137258031, "IFEval": 73.99655137258031, "BBH Raw": 0.5029422936734547, "BBH": 29.211612180239623, "MATH Lvl 5 Raw": 0.0762839879154078, "MATH Lvl 5": 7.628398791540786, "GPQA Raw": 0.2860738255033557, "GPQA": 4.809843400447425, "MUSR Raw": 0.3722916666666667, "MUSR": 5.369791666666667, "MMLU-PRO Raw": 0.3584607712765957, "MMLU-PRO": 28.717863475177303, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-06T00:00:00", "Submission Date": "2024-10-07T00:00:00", "Generation": 0, "Base Model": "princeton-nlp/Llama-3-Instruct-8B-SLiC-HF"}, {"eval_name": "princeton-nlp_Llama-3-Instruct-8B-SLiC-HF-v0.2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/princeton-nlp/Llama-3-Instruct-8B-SLiC-HF-v0.2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">princeton-nlp/Llama-3-Instruct-8B-SLiC-HF-v0.2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/princeton-nlp__Llama-3-Instruct-8B-SLiC-HF-v0.2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "princeton-nlp/Llama-3-Instruct-8B-SLiC-HF-v0.2", "Model sha": "1821cc42189d8dab9e157c31b223dc60fc037c2d", "Average \u2b06\ufe0f": 23.5898857349536, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7109646848140712, "IFEval": 71.09646848140711, "BBH Raw": 0.4983895257292753, "BBH": 28.498723991187727, "MATH Lvl 5 Raw": 0.0793051359516616, "MATH Lvl 5": 7.930513595166164, "GPQA Raw": 0.2600671140939597, "GPQA": 1.342281879194629, "MUSR Raw": 0.37378125, "MUSR": 5.089322916666668, "MMLU-PRO Raw": 0.3482380319148936, "MMLU-PRO": 27.582003546099287, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-06T00:00:00", "Submission Date": "2024-10-07T00:00:00", "Generation": 0, "Base Model": "princeton-nlp/Llama-3-Instruct-8B-SLiC-HF-v0.2"}, {"eval_name": "princeton-nlp_Llama-3-Instruct-8B-SimPO_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/princeton-nlp/Llama-3-Instruct-8B-SimPO\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">princeton-nlp/Llama-3-Instruct-8B-SimPO</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/princeton-nlp__Llama-3-Instruct-8B-SimPO-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "princeton-nlp/Llama-3-Instruct-8B-SimPO", "Model sha": "f700cb6afb4509b10dea43ab72bb0e260e166be4", "Average \u2b06\ufe0f": 22.60676355758622, "Hub License": null, "Hub \u2764\ufe0f": 55, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6503898544750152, "IFEval": 65.03898544750152, "BBH Raw": 0.4844684852490536, "BBH": 26.709132779658223, "MATH Lvl 5 Raw": 0.0226586102719033, "MATH Lvl 5": 2.2658610271903323, "GPQA Raw": 0.2936241610738255, "GPQA": 5.8165548098434, "MUSR Raw": 0.3948333333333333, "MUSR": 8.154166666666669, "MMLU-PRO Raw": 0.3489029255319149, "MMLU-PRO": 27.655880614657207, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-17T00:00:00", "Submission Date": "2024-09-28T00:00:00", "Generation": 0, "Base Model": "princeton-nlp/Llama-3-Instruct-8B-SimPO"}, {"eval_name": "princeton-nlp_Llama-3-Instruct-8B-SimPO-v0.2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/princeton-nlp/Llama-3-Instruct-8B-SimPO-v0.2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">princeton-nlp/Llama-3-Instruct-8B-SimPO-v0.2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/princeton-nlp__Llama-3-Instruct-8B-SimPO-v0.2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "princeton-nlp/Llama-3-Instruct-8B-SimPO-v0.2", "Model sha": "9ac0fbee445e7755e50520e9881d67588b4b854c", "Average \u2b06\ufe0f": 24.399072407728763, "Hub License": null, "Hub \u2764\ufe0f": 5, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6808645505037745, "IFEval": 68.08645505037744, "BBH Raw": 0.503833834044343, "BBH": 29.214021710829385, "MATH Lvl 5 Raw": 0.052870090634441, "MATH Lvl 5": 5.287009063444108, "GPQA Raw": 0.3011744966442953, "GPQA": 6.823266219239373, "MUSR Raw": 0.3988020833333334, "MUSR": 7.8502604166666705, "MMLU-PRO Raw": 0.3622007978723404, "MMLU-PRO": 29.1334219858156, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-06T00:00:00", "Submission Date": "2024-09-28T00:00:00", "Generation": 0, "Base Model": "princeton-nlp/Llama-3-Instruct-8B-SimPO-v0.2"}, {"eval_name": "princeton-nlp_Mistral-7B-Base-SFT-CPO_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/princeton-nlp/Mistral-7B-Base-SFT-CPO\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">princeton-nlp/Mistral-7B-Base-SFT-CPO</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/princeton-nlp__Mistral-7B-Base-SFT-CPO-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "princeton-nlp/Mistral-7B-Base-SFT-CPO", "Model sha": "7f67394668b94a9ddfb64daff8976b48b135d96c", "Average \u2b06\ufe0f": 17.336029409624178, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4654926705585623, "IFEval": 46.54926705585624, "BBH Raw": 0.4382151250666357, "BBH": 21.857696499882195, "MATH Lvl 5 Raw": 0.0241691842900302, "MATH Lvl 5": 2.416918429003021, "GPQA Raw": 0.2919463087248322, "GPQA": 5.592841163310966, "MUSR Raw": 0.4070833333333333, "MUSR": 9.252083333333331, "MMLU-PRO Raw": 0.265126329787234, "MMLU-PRO": 18.34736997635934, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-06T00:00:00", "Submission Date": "2024-10-07T00:00:00", "Generation": 0, "Base Model": "princeton-nlp/Mistral-7B-Base-SFT-CPO"}, {"eval_name": "princeton-nlp_Mistral-7B-Base-SFT-DPO_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/princeton-nlp/Mistral-7B-Base-SFT-DPO\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">princeton-nlp/Mistral-7B-Base-SFT-DPO</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/princeton-nlp__Mistral-7B-Base-SFT-DPO-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "princeton-nlp/Mistral-7B-Base-SFT-DPO", "Model sha": "17134fd80cfbf3980353967a30dc6f450f18f78f", "Average \u2b06\ufe0f": 16.223736824549984, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4403383023710421, "IFEval": 44.03383023710421, "BBH Raw": 0.4350112397961269, "BBH": 20.79098038827006, "MATH Lvl 5 Raw": 0.0158610271903323, "MATH Lvl 5": 1.5861027190332326, "GPQA Raw": 0.2726510067114094, "GPQA": 3.0201342281879207, "MUSR Raw": 0.4122291666666666, "MUSR": 9.628645833333332, "MMLU-PRO Raw": 0.2645445478723404, "MMLU-PRO": 18.28272754137116, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-17T00:00:00", "Submission Date": "2024-10-07T00:00:00", "Generation": 0, "Base Model": "princeton-nlp/Mistral-7B-Base-SFT-DPO"}, {"eval_name": "princeton-nlp_Mistral-7B-Base-SFT-IPO_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/princeton-nlp/Mistral-7B-Base-SFT-IPO\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">princeton-nlp/Mistral-7B-Base-SFT-IPO</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/princeton-nlp__Mistral-7B-Base-SFT-IPO-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "princeton-nlp/Mistral-7B-Base-SFT-IPO", "Model sha": "eea781724e4d2ab8bdda7c13526f042de4cfae41", "Average \u2b06\ufe0f": 17.147487013322337, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4829530091268944, "IFEval": 48.29530091268944, "BBH Raw": 0.4458024605899282, "BBH": 23.70349052130433, "MATH Lvl 5 Raw": 0.0211480362537764, "MATH Lvl 5": 2.114803625377644, "GPQA Raw": 0.2802013422818792, "GPQA": 4.026845637583895, "MUSR Raw": 0.377625, "MUSR": 4.836458333333334, "MMLU-PRO Raw": 0.2791722074468085, "MMLU-PRO": 19.908023049645383, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-17T00:00:00", "Submission Date": "2024-10-07T00:00:00", "Generation": 0, "Base Model": "princeton-nlp/Mistral-7B-Base-SFT-IPO"}, {"eval_name": "princeton-nlp_Mistral-7B-Base-SFT-KTO_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/princeton-nlp/Mistral-7B-Base-SFT-KTO\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">princeton-nlp/Mistral-7B-Base-SFT-KTO</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/princeton-nlp__Mistral-7B-Base-SFT-KTO-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "princeton-nlp/Mistral-7B-Base-SFT-KTO", "Model sha": "02148bb9241b0f4bb0c75e93893eed005abe25e8", "Average \u2b06\ufe0f": 18.91228734989691, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.478481540091402, "IFEval": 47.8481540091402, "BBH Raw": 0.4476433446452867, "BBH": 23.10764227790982, "MATH Lvl 5 Raw": 0.0332326283987915, "MATH Lvl 5": 3.3232628398791544, "GPQA Raw": 0.2902684563758389, "GPQA": 5.369127516778524, "MUSR Raw": 0.4367812499999999, "MUSR": 13.030989583333335, "MMLU-PRO Raw": 0.2871509308510638, "MMLU-PRO": 20.794547872340427, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-17T00:00:00", "Submission Date": "2024-10-07T00:00:00", "Generation": 0, "Base Model": "princeton-nlp/Mistral-7B-Base-SFT-KTO"}, {"eval_name": "princeton-nlp_Mistral-7B-Base-SFT-RDPO_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/princeton-nlp/Mistral-7B-Base-SFT-RDPO\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">princeton-nlp/Mistral-7B-Base-SFT-RDPO</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/princeton-nlp__Mistral-7B-Base-SFT-RDPO-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "princeton-nlp/Mistral-7B-Base-SFT-RDPO", "Model sha": "2a63a6d9e1978c99444e440371268f7c2b7e0375", "Average \u2b06\ufe0f": 16.453169276263427, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4606466398046073, "IFEval": 46.064663980460736, "BBH Raw": 0.4439532862692421, "BBH": 22.98200980704625, "MATH Lvl 5 Raw": 0.0196374622356495, "MATH Lvl 5": 1.9637462235649543, "GPQA Raw": 0.2776845637583892, "GPQA": 3.691275167785232, "MUSR Raw": 0.3579375, "MUSR": 4.275520833333334, "MMLU-PRO Raw": 0.2776761968085106, "MMLU-PRO": 19.741799645390067, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-17T00:00:00", "Submission Date": "2024-10-07T00:00:00", "Generation": 0, "Base Model": "princeton-nlp/Mistral-7B-Base-SFT-RDPO"}, {"eval_name": "princeton-nlp_Mistral-7B-Base-SFT-RRHF_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/princeton-nlp/Mistral-7B-Base-SFT-RRHF\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">princeton-nlp/Mistral-7B-Base-SFT-RRHF</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/princeton-nlp__Mistral-7B-Base-SFT-RRHF-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "princeton-nlp/Mistral-7B-Base-SFT-RRHF", "Model sha": "0d5861072e9d01f420451bf6a5b108bc8d3a76bc", "Average \u2b06\ufe0f": 16.144260192559617, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.440662996405094, "IFEval": 44.0662996405094, "BBH Raw": 0.4280593740371601, "BBH": 19.59883081662414, "MATH Lvl 5 Raw": 0.0226586102719033, "MATH Lvl 5": 2.2658610271903323, "GPQA Raw": 0.2902684563758389, "GPQA": 5.369127516778524, "MUSR Raw": 0.4186770833333333, "MUSR": 10.034635416666664, "MMLU-PRO Raw": 0.2397772606382978, "MMLU-PRO": 15.530806737588652, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-06T00:00:00", "Submission Date": "2024-10-07T00:00:00", "Generation": 0, "Base Model": "princeton-nlp/Mistral-7B-Base-SFT-RRHF"}, {"eval_name": "princeton-nlp_Mistral-7B-Base-SFT-SLiC-HF_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/princeton-nlp/Mistral-7B-Base-SFT-SLiC-HF\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">princeton-nlp/Mistral-7B-Base-SFT-SLiC-HF</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/princeton-nlp__Mistral-7B-Base-SFT-SLiC-HF-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "princeton-nlp/Mistral-7B-Base-SFT-SLiC-HF", "Model sha": "65d2cc49ad05258da3d982b39682c7f672f5e4ab", "Average \u2b06\ufe0f": 18.905180746760617, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5127284494031392, "IFEval": 51.27284494031392, "BBH Raw": 0.4422399189040217, "BBH": 22.304722895019296, "MATH Lvl 5 Raw": 0.0294561933534743, "MATH Lvl 5": 2.9456193353474323, "GPQA Raw": 0.2919463087248322, "GPQA": 5.592841163310966, "MUSR Raw": 0.4260833333333333, "MUSR": 11.527083333333332, "MMLU-PRO Raw": 0.2780917553191489, "MMLU-PRO": 19.78797281323877, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-06T00:00:00", "Submission Date": "2024-10-07T00:00:00", "Generation": 0, "Base Model": "princeton-nlp/Mistral-7B-Base-SFT-SLiC-HF"}, {"eval_name": "princeton-nlp_Mistral-7B-Base-SFT-SimPO_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/princeton-nlp/Mistral-7B-Base-SFT-SimPO\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">princeton-nlp/Mistral-7B-Base-SFT-SimPO</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/princeton-nlp__Mistral-7B-Base-SFT-SimPO-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "princeton-nlp/Mistral-7B-Base-SFT-SimPO", "Model sha": "9d9e8b8de4f673d45bc826efc4a1444f9d480222", "Average \u2b06\ufe0f": 16.8935452731778, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4700638749628762, "IFEval": 47.00638749628763, "BBH Raw": 0.4398050727924064, "BBH": 22.33288648076616, "MATH Lvl 5 Raw": 0.0060422960725075, "MATH Lvl 5": 0.6042296072507553, "GPQA Raw": 0.2835570469798658, "GPQA": 4.4742729306487705, "MUSR Raw": 0.3970625, "MUSR": 8.0328125, "MMLU-PRO Raw": 0.2701961436170212, "MMLU-PRO": 18.910682624113477, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-17T00:00:00", "Submission Date": "2024-09-21T00:00:00", "Generation": 0, "Base Model": "princeton-nlp/Mistral-7B-Base-SFT-SimPO"}, {"eval_name": "princeton-nlp_Mistral-7B-Instruct-CPO_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/princeton-nlp/Mistral-7B-Instruct-CPO\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">princeton-nlp/Mistral-7B-Instruct-CPO</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/princeton-nlp__Mistral-7B-Instruct-CPO-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "princeton-nlp/Mistral-7B-Instruct-CPO", "Model sha": "32492f8e5588f06005689ac944c2ea39c394c28e", "Average \u2b06\ufe0f": 15.540359200506424, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4203047912871182, "IFEval": 42.03047912871182, "BBH Raw": 0.406922267565148, "BBH": 17.248538100586853, "MATH Lvl 5 Raw": 0.0203927492447129, "MATH Lvl 5": 2.0392749244712998, "GPQA Raw": 0.2659395973154362, "GPQA": 2.1252796420581683, "MUSR Raw": 0.41784375, "MUSR": 10.89713541666667, "MMLU-PRO Raw": 0.2701130319148936, "MMLU-PRO": 18.901447990543733, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-06T00:00:00", "Submission Date": "2024-10-07T00:00:00", "Generation": 0, "Base Model": "princeton-nlp/Mistral-7B-Instruct-CPO"}, {"eval_name": "princeton-nlp_Mistral-7B-Instruct-DPO_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/princeton-nlp/Mistral-7B-Instruct-DPO\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">princeton-nlp/Mistral-7B-Instruct-DPO</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/princeton-nlp__Mistral-7B-Instruct-DPO-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "princeton-nlp/Mistral-7B-Instruct-DPO", "Model sha": "5e96cff70d8db87cf17c616429c17c8dc9352543", "Average \u2b06\ufe0f": 16.537019279559413, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.517624347841505, "IFEval": 51.7624347841505, "BBH Raw": 0.4060358459697702, "BBH": 16.875389341982814, "MATH Lvl 5 Raw": 0.0294561933534743, "MATH Lvl 5": 2.9456193353474323, "GPQA Raw": 0.2684563758389262, "GPQA": 2.460850111856823, "MUSR Raw": 0.3833333333333333, "MUSR": 5.750000000000001, "MMLU-PRO Raw": 0.2748503989361702, "MMLU-PRO": 19.42782210401891, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-17T00:00:00", "Submission Date": "2024-10-07T00:00:00", "Generation": 0, "Base Model": "princeton-nlp/Mistral-7B-Instruct-DPO"}, {"eval_name": "princeton-nlp_Mistral-7B-Instruct-IPO_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/princeton-nlp/Mistral-7B-Instruct-IPO\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">princeton-nlp/Mistral-7B-Instruct-IPO</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/princeton-nlp__Mistral-7B-Instruct-IPO-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "princeton-nlp/Mistral-7B-Instruct-IPO", "Model sha": "32ad99c6e7231bbe8ebd9d24b28e084c60848558", "Average \u2b06\ufe0f": 17.681920141049467, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4929198969844457, "IFEval": 49.29198969844457, "BBH Raw": 0.4322183023180588, "BBH": 20.094109548877523, "MATH Lvl 5 Raw": 0.0181268882175226, "MATH Lvl 5": 1.812688821752266, "GPQA Raw": 0.273489932885906, "GPQA": 3.1319910514541416, "MUSR Raw": 0.4324166666666666, "MUSR": 12.785416666666668, "MMLU-PRO Raw": 0.2707779255319149, "MMLU-PRO": 18.975325059101653, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-17T00:00:00", "Submission Date": "2024-10-07T00:00:00", "Generation": 0, "Base Model": "princeton-nlp/Mistral-7B-Instruct-IPO"}, {"eval_name": "princeton-nlp_Mistral-7B-Instruct-KTO_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/princeton-nlp/Mistral-7B-Instruct-KTO\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">princeton-nlp/Mistral-7B-Instruct-KTO</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/princeton-nlp__Mistral-7B-Instruct-KTO-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "princeton-nlp/Mistral-7B-Instruct-KTO", "Model sha": "834422e5b9b9eee6aac2f8d4822b925a6574d628", "Average \u2b06\ufe0f": 16.65223931237281, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4907966417993147, "IFEval": 49.07966417993147, "BBH Raw": 0.4139586477181159, "BBH": 17.81264785919903, "MATH Lvl 5 Raw": 0.0234138972809667, "MATH Lvl 5": 2.3413897280966767, "GPQA Raw": 0.273489932885906, "GPQA": 3.1319910514541416, "MUSR Raw": 0.3952708333333333, "MUSR": 7.408854166666667, "MMLU-PRO Raw": 0.28125, "MMLU-PRO": 20.13888888888889, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-17T00:00:00", "Submission Date": "2024-10-07T00:00:00", "Generation": 0, "Base Model": "princeton-nlp/Mistral-7B-Instruct-KTO"}, {"eval_name": "princeton-nlp_Mistral-7B-Instruct-ORPO_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/princeton-nlp/Mistral-7B-Instruct-ORPO\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">princeton-nlp/Mistral-7B-Instruct-ORPO</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/princeton-nlp__Mistral-7B-Instruct-ORPO-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "princeton-nlp/Mistral-7B-Instruct-ORPO", "Model sha": "69c0481f4100629a49ae73f760ddbb61d8e98e48", "Average \u2b06\ufe0f": 16.02535252553198, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4719621714827768, "IFEval": 47.19621714827768, "BBH Raw": 0.410406157565661, "BBH": 18.03837283661216, "MATH Lvl 5 Raw": 0.0256797583081571, "MATH Lvl 5": 2.56797583081571, "GPQA Raw": 0.2743288590604026, "GPQA": 3.243847874720355, "MUSR Raw": 0.3912395833333333, "MUSR": 6.638281250000001, "MMLU-PRO Raw": 0.2662067819148936, "MMLU-PRO": 18.467420212765955, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-17T00:00:00", "Submission Date": "2024-10-07T00:00:00", "Generation": 0, "Base Model": "princeton-nlp/Mistral-7B-Instruct-ORPO"}, {"eval_name": "princeton-nlp_Mistral-7B-Instruct-RDPO_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/princeton-nlp/Mistral-7B-Instruct-RDPO\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">princeton-nlp/Mistral-7B-Instruct-RDPO</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/princeton-nlp__Mistral-7B-Instruct-RDPO-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "princeton-nlp/Mistral-7B-Instruct-RDPO", "Model sha": "23ec6ab4f996134eb15c19322dabb34d7332d7cd", "Average \u2b06\ufe0f": 16.407902452873568, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4887232542985944, "IFEval": 48.87232542985944, "BBH Raw": 0.4050147974507361, "BBH": 17.04838760964466, "MATH Lvl 5 Raw": 0.0234138972809667, "MATH Lvl 5": 2.3413897280966767, "GPQA Raw": 0.2802013422818792, "GPQA": 4.026845637583895, "MUSR Raw": 0.3873333333333333, "MUSR": 6.416666666666669, "MMLU-PRO Raw": 0.2776761968085106, "MMLU-PRO": 19.741799645390067, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-17T00:00:00", "Submission Date": "2024-10-07T00:00:00", "Generation": 0, "Base Model": "princeton-nlp/Mistral-7B-Instruct-RDPO"}, {"eval_name": "princeton-nlp_Mistral-7B-Instruct-RRHF_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/princeton-nlp/Mistral-7B-Instruct-RRHF\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">princeton-nlp/Mistral-7B-Instruct-RRHF</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/princeton-nlp__Mistral-7B-Instruct-RRHF-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "princeton-nlp/Mistral-7B-Instruct-RRHF", "Model sha": "493d3ceb571232fe3b2f55c0bf78692760f4fc7e", "Average \u2b06\ufe0f": 16.80390716928726, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4960172342717323, "IFEval": 49.60172342717323, "BBH Raw": 0.418976634766574, "BBH": 19.20655206374787, "MATH Lvl 5 Raw": 0.0226586102719033, "MATH Lvl 5": 2.2658610271903323, "GPQA Raw": 0.276006711409396, "GPQA": 3.467561521252797, "MUSR Raw": 0.397875, "MUSR": 7.934375000000003, "MMLU-PRO Raw": 0.265126329787234, "MMLU-PRO": 18.34736997635934, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-06T00:00:00", "Submission Date": "2024-10-07T00:00:00", "Generation": 0, "Base Model": "princeton-nlp/Mistral-7B-Instruct-RRHF"}, {"eval_name": "princeton-nlp_Mistral-7B-Instruct-SimPO_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/princeton-nlp/Mistral-7B-Instruct-SimPO\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">princeton-nlp/Mistral-7B-Instruct-SimPO</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/princeton-nlp__Mistral-7B-Instruct-SimPO-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "princeton-nlp/Mistral-7B-Instruct-SimPO", "Model sha": "03191ee1e60d21a698d11a515703a037073724f8", "Average \u2b06\ufe0f": 17.544375215453176, "Hub License": null, "Hub \u2764\ufe0f": 1, "#Params (B)": 7, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4686897432146704, "IFEval": 46.86897432146704, "BBH Raw": 0.4507226157033399, "BBH": 22.38227741589404, "MATH Lvl 5 Raw": 0.0249244712990936, "MATH Lvl 5": 2.492447129909366, "GPQA Raw": 0.2785234899328859, "GPQA": 3.803131991051453, "MUSR Raw": 0.40978125, "MUSR": 9.755989583333331, "MMLU-PRO Raw": 0.2796708776595745, "MMLU-PRO": 19.963430851063837, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-24T00:00:00", "Submission Date": "2024-09-21T00:00:00", "Generation": 0, "Base Model": "princeton-nlp/Mistral-7B-Instruct-SimPO"}, {"eval_name": "princeton-nlp_Sheared-LLaMA-1.3B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/princeton-nlp/Sheared-LLaMA-1.3B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">princeton-nlp/Sheared-LLaMA-1.3B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/princeton-nlp__Sheared-LLaMA-1.3B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "princeton-nlp/Sheared-LLaMA-1.3B", "Model sha": "a4b76938edbf571ea7d7d9904861cbdca08809b4", "Average \u2b06\ufe0f": 5.505396871233472, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 91, "#Params (B)": 1, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2197702097102355, "IFEval": 21.97702097102355, "BBH Raw": 0.3197046739246442, "BBH": 4.744629874421679, "MATH Lvl 5 Raw": 0.0083081570996978, "MATH Lvl 5": 0.8308157099697886, "GPQA Raw": 0.2399328859060402, "GPQA": 0.0, "MUSR Raw": 0.3713020833333333, "MUSR": 3.5794270833333326, "MMLU-PRO Raw": 0.1171043882978723, "MMLU-PRO": 1.9004875886524817, "Maintainer's Highlight": false, "Upload To Hub Date": "2023-10-10T00:00:00", "Submission Date": "2024-07-29T00:00:00", "Generation": 0, "Base Model": "princeton-nlp/Sheared-LLaMA-1.3B"}, {"eval_name": "princeton-nlp_Sheared-LLaMA-2.7B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/princeton-nlp/Sheared-LLaMA-2.7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">princeton-nlp/Sheared-LLaMA-2.7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/princeton-nlp__Sheared-LLaMA-2.7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "princeton-nlp/Sheared-LLaMA-2.7B", "Model sha": "2f157a0306b75d37694ae05f6a4067220254d540", "Average \u2b06\ufe0f": 6.312038892840872, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 59, "#Params (B)": 2, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2416521496296493, "IFEval": 24.16521496296493, "BBH Raw": 0.3258685569124595, "BBH": 5.655521329938437, "MATH Lvl 5 Raw": 0.0052870090634441, "MATH Lvl 5": 0.5287009063444109, "GPQA Raw": 0.2751677852348993, "GPQA": 3.355704697986576, "MUSR Raw": 0.3567291666666667, "MUSR": 2.091145833333335, "MMLU-PRO Raw": 0.1186835106382978, "MMLU-PRO": 2.0759456264775418, "Maintainer's Highlight": false, "Upload To Hub Date": "2023-10-10T00:00:00", "Submission Date": "2024-07-29T00:00:00", "Generation": 0, "Base Model": "princeton-nlp/Sheared-LLaMA-2.7B"}, {"eval_name": "princeton-nlp_gemma-2-9b-it-DPO_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/princeton-nlp/gemma-2-9b-it-DPO\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">princeton-nlp/gemma-2-9b-it-DPO</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/princeton-nlp__gemma-2-9b-it-DPO-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "princeton-nlp/gemma-2-9b-it-DPO", "Model sha": "f646c99fc3aa7afc7b22c3c7115fd03a40fc1d22", "Average \u2b06\ufe0f": 19.43403454119008, "Hub License": null, "Hub \u2764\ufe0f": 5, "#Params (B)": 9, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2768720328727775, "IFEval": 27.68720328727776, "BBH Raw": 0.5941444682956648, "BBH": 41.59365445538448, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.3355704697986577, "GPQA": 11.409395973154364, "MUSR Raw": 0.38203125, "MUSR": 5.653906250000001, "MMLU-PRO Raw": 0.3723404255319149, "MMLU-PRO": 30.26004728132387, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-16T00:00:00", "Submission Date": "2024-09-19T00:00:00", "Generation": 2, "Base Model": "google/gemma-2-9b"}, {"eval_name": "princeton-nlp_gemma-2-9b-it-SimPO_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/princeton-nlp/gemma-2-9b-it-SimPO\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">princeton-nlp/gemma-2-9b-it-SimPO</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/princeton-nlp__gemma-2-9b-it-SimPO-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "princeton-nlp/gemma-2-9b-it-SimPO", "Model sha": "8c87091f412e3aa6f74f66bd86c57fb81cbc3fde", "Average \u2b06\ufe0f": 21.161651627569334, "Hub License": "mit", "Hub \u2764\ufe0f": 97, "#Params (B)": 9, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3206857803960159, "IFEval": 32.06857803960159, "BBH Raw": 0.5839179923162123, "BBH": 40.093429916371655, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.3355704697986577, "GPQA": 11.409395973154364, "MUSR Raw": 0.4123229166666666, "MUSR": 10.340364583333338, "MMLU-PRO Raw": 0.3975232712765957, "MMLU-PRO": 33.05814125295508, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-16T00:00:00", "Submission Date": "2024-08-10T00:00:00", "Generation": 2, "Base Model": "google/gemma-2-9b"}, {"eval_name": "pszemraj_Llama-3-6.3b-v0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe9 continuously pretrained", "T": "\ud83d\udfe9", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/pszemraj/Llama-3-6.3b-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">pszemraj/Llama-3-6.3b-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/pszemraj__Llama-3-6.3b-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "pszemraj/Llama-3-6.3b-v0.1", "Model sha": "7000b39346162f95f19aa4ca3975242db61902d7", "Average \u2b06\ufe0f": 10.283601735840731, "Hub License": "llama3", "Hub \u2764\ufe0f": 6, "#Params (B)": 6, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1043896860330589, "IFEval": 10.438968603305897, "BBH Raw": 0.4196807046828414, "BBH": 18.67999639960586, "MATH Lvl 5 Raw": 0.0151057401812688, "MATH Lvl 5": 1.5105740181268883, "GPQA Raw": 0.2835570469798658, "GPQA": 4.4742729306487705, "MUSR Raw": 0.3908333333333333, "MUSR": 6.154166666666666, "MMLU-PRO Raw": 0.2839926861702128, "MMLU-PRO": 20.44363179669031, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-17T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "meta-llama/Meta-Llama-3-8B"}, {"eval_name": "pszemraj_Mistral-v0.3-6B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe9 continuously pretrained", "T": "\ud83d\udfe9", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/pszemraj/Mistral-v0.3-6B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">pszemraj/Mistral-v0.3-6B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/pszemraj__Mistral-v0.3-6B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "pszemraj/Mistral-v0.3-6B", "Model sha": "ae11a699012b83996361f04808f4d45debf3b01c", "Average \u2b06\ufe0f": 10.034262410190776, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 5, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2453744952282167, "IFEval": 24.537449522821667, "BBH Raw": 0.3774050646438491, "BBH": 13.51509134454944, "MATH Lvl 5 Raw": 0.0083081570996978, "MATH Lvl 5": 0.8308157099697886, "GPQA Raw": 0.2651006711409396, "GPQA": 2.0134228187919474, "MUSR Raw": 0.3907708333333333, "MUSR": 6.613020833333334, "MMLU-PRO Raw": 0.2142619680851064, "MMLU-PRO": 12.695774231678486, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-25T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 2, "Base Model": "pszemraj/Mistral-7B-v0.3-prune6 (Merge)"}, {"eval_name": "rasyosef_Mistral-NeMo-Minitron-8B-Chat_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/rasyosef/Mistral-NeMo-Minitron-8B-Chat\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">rasyosef/Mistral-NeMo-Minitron-8B-Chat</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/rasyosef__Mistral-NeMo-Minitron-8B-Chat-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "rasyosef/Mistral-NeMo-Minitron-8B-Chat", "Model sha": "cede47eac8a4e65aa27567d3f087c28185b537d9", "Average \u2b06\ufe0f": 17.218357525458583, "Hub License": "other", "Hub \u2764\ufe0f": 8, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4451843331249973, "IFEval": 44.51843331249973, "BBH Raw": 0.4759435337905853, "BBH": 26.036695387358723, "MATH Lvl 5 Raw": 0.0075528700906344, "MATH Lvl 5": 0.7552870090634441, "GPQA Raw": 0.276006711409396, "GPQA": 3.467561521252797, "MUSR Raw": 0.4304270833333333, "MUSR": 12.936718749999995, "MMLU-PRO Raw": 0.2403590425531915, "MMLU-PRO": 15.595449172576831, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-26T00:00:00", "Submission Date": "2024-08-26T00:00:00", "Generation": 1, "Base Model": "nvidia/Mistral-NeMo-Minitron-8B-Base"}, {"eval_name": "rasyosef_Phi-1_5-Instruct-v0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "PhiForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/rasyosef/Phi-1_5-Instruct-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">rasyosef/Phi-1_5-Instruct-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/rasyosef__Phi-1_5-Instruct-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "rasyosef/Phi-1_5-Instruct-v0.1", "Model sha": "f4c405ee4bff5dc1a69383f3fe682342c9c87c77", "Average \u2b06\ufe0f": 6.638161761630591, "Hub License": "mit", "Hub \u2764\ufe0f": 0, "#Params (B)": 1, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2402281501970327, "IFEval": 24.02281501970328, "BBH Raw": 0.3117898107092894, "BBH": 4.820243721122045, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2600671140939597, "GPQA": 1.342281879194629, "MUSR Raw": 0.34215625, "MUSR": 3.402864583333334, "MMLU-PRO Raw": 0.1561668882978723, "MMLU-PRO": 6.240765366430259, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-24T00:00:00", "Submission Date": "2024-07-25T00:00:00", "Generation": 1, "Base Model": "microsoft/phi-1_5"}, {"eval_name": "rasyosef_phi-2-instruct-apo_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "PhiForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/rasyosef/phi-2-instruct-apo\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">rasyosef/phi-2-instruct-apo</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/rasyosef__phi-2-instruct-apo-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "rasyosef/phi-2-instruct-apo", "Model sha": "2d3722d6db77a8c844a50dd32ddc4278fdc89e1f", "Average \u2b06\ufe0f": 12.043527849960943, "Hub License": "mit", "Hub \u2764\ufe0f": 0, "#Params (B)": 2, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3145919493610287, "IFEval": 31.459194936102875, "BBH Raw": 0.4445096463004863, "BBH": 21.672437586715603, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2701342281879195, "GPQA": 2.684563758389265, "MUSR Raw": 0.33421875, "MUSR": 3.6106770833333353, "MMLU-PRO Raw": 0.2155086436170212, "MMLU-PRO": 12.834293735224584, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-15T00:00:00", "Submission Date": "2024-09-17T00:00:00", "Generation": 1, "Base Model": "microsoft/phi-2"}, {"eval_name": "rasyosef_phi-2-instruct-v0.1_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "PhiForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/rasyosef/phi-2-instruct-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">rasyosef/phi-2-instruct-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/rasyosef__phi-2-instruct-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "rasyosef/phi-2-instruct-v0.1", "Model sha": "29aeb3ccf7c79e0169a038fbd0deaf9772a9fefd", "Average \u2b06\ufe0f": 14.218631101919176, "Hub License": "mit", "Hub \u2764\ufe0f": 2, "#Params (B)": 2, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3681476260765879, "IFEval": 36.81476260765879, "BBH Raw": 0.4726118429265447, "BBH": 26.35880186790661, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2743288590604026, "GPQA": 3.243847874720355, "MUSR Raw": 0.3523541666666667, "MUSR": 5.044270833333334, "MMLU-PRO Raw": 0.2246509308510638, "MMLU-PRO": 13.85010342789598, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-09T00:00:00", "Submission Date": "2024-08-10T00:00:00", "Generation": 1, "Base Model": "microsoft/phi-2"}, {"eval_name": "realtreetune_rho-1b-sft-MATH_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/realtreetune/rho-1b-sft-MATH\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">realtreetune/rho-1b-sft-MATH</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/realtreetune__rho-1b-sft-MATH-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "realtreetune/rho-1b-sft-MATH", "Model sha": "b5f93df6af679a860caac9a9598e0f70c326b4fb", "Average \u2b06\ufe0f": 5.304824966816412, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 1, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.212101668018635, "IFEval": 21.210166801863497, "BBH Raw": 0.3144153389594046, "BBH": 4.19762318329166, "MATH Lvl 5 Raw": 0.0188821752265861, "MATH Lvl 5": 1.8882175226586104, "GPQA Raw": 0.2525167785234899, "GPQA": 0.3355704697986553, "MUSR Raw": 0.34584375, "MUSR": 2.897135416666666, "MMLU-PRO Raw": 0.1117021276595744, "MMLU-PRO": 1.300236406619384, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-06T00:00:00", "Submission Date": "2024-10-05T00:00:00", "Generation": 1, "Base Model": "realtreetune/rho-1b-sft-MATH (Merge)"}, {"eval_name": "recoilme_Gemma-2-Ataraxy-Gemmasutra-9B-slerp_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/recoilme/Gemma-2-Ataraxy-Gemmasutra-9B-slerp\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">recoilme/Gemma-2-Ataraxy-Gemmasutra-9B-slerp</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/recoilme__Gemma-2-Ataraxy-Gemmasutra-9B-slerp-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "recoilme/Gemma-2-Ataraxy-Gemmasutra-9B-slerp", "Model sha": "9048af8616bc62b6efab2bc1bc77ba53c5dfed79", "Average \u2b06\ufe0f": 29.873991757144, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 3, "#Params (B)": 10, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7648949232480928, "IFEval": 76.48949232480928, "BBH Raw": 0.597438766061506, "BBH": 42.25120987807252, "MATH Lvl 5 Raw": 0.0173716012084592, "MATH Lvl 5": 1.7371601208459215, "GPQA Raw": 0.3305369127516778, "GPQA": 10.738255033557047, "MUSR Raw": 0.4244791666666667, "MUSR": 12.39322916666667, "MMLU-PRO Raw": 0.4207114361702128, "MMLU-PRO": 35.63460401891253, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-11T00:00:00", "Submission Date": "2024-09-12T00:00:00", "Generation": 0, "Base Model": "recoilme/Gemma-2-Ataraxy-Gemmasutra-9B-slerp"}, {"eval_name": "recoilme_Gemma-2-Ataraxy-Gemmasutra-9B-slerp_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/recoilme/Gemma-2-Ataraxy-Gemmasutra-9B-slerp\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">recoilme/Gemma-2-Ataraxy-Gemmasutra-9B-slerp</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/recoilme__Gemma-2-Ataraxy-Gemmasutra-9B-slerp-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "recoilme/Gemma-2-Ataraxy-Gemmasutra-9B-slerp", "Model sha": "5a4f7299d9f8ea5faad2b1edc68b7bf634dac40b", "Average \u2b06\ufe0f": 23.09232520953837, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 3, "#Params (B)": 10, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2853650536133015, "IFEval": 28.53650536133016, "BBH Raw": 0.5983926033872208, "BBH": 42.70379763449792, "MATH Lvl 5 Raw": 0.0513595166163142, "MATH Lvl 5": 5.13595166163142, "GPQA Raw": 0.3296979865771812, "GPQA": 10.626398210290828, "MUSR Raw": 0.46065625, "MUSR": 16.415364583333332, "MMLU-PRO Raw": 0.4162234042553192, "MMLU-PRO": 35.13593380614657, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-11T00:00:00", "Submission Date": "2024-09-27T00:00:00", "Generation": 0, "Base Model": "recoilme/Gemma-2-Ataraxy-Gemmasutra-9B-slerp"}, {"eval_name": "recoilme_recoilme-gemma-2-9B-v0.1_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/recoilme/recoilme-gemma-2-9B-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">recoilme/recoilme-gemma-2-9B-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/recoilme__recoilme-gemma-2-9B-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "recoilme/recoilme-gemma-2-9B-v0.1", "Model sha": "6dc0997046db4e9932f87d338ecdc2a4158abbda", "Average \u2b06\ufe0f": 29.52721694849769, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 10, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.751506004069203, "IFEval": 75.1506004069203, "BBH Raw": 0.5995309756292291, "BBH": 42.32186103147748, "MATH Lvl 5 Raw": 0.0120845921450151, "MATH Lvl 5": 1.2084592145015105, "GPQA Raw": 0.3389261744966443, "GPQA": 11.85682326621924, "MUSR Raw": 0.4191458333333333, "MUSR": 11.526562500000002, "MMLU-PRO Raw": 0.4158909574468085, "MMLU-PRO": 35.09899527186761, "Maintainer's Highlight": false, "Upload To Hub Date": "", "Submission Date": "2024-09-18T00:00:00", "Generation": 0, "Base Model": "Removed"}, {"eval_name": "recoilme_recoilme-gemma-2-9B-v0.2_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/recoilme/recoilme-gemma-2-9B-v0.2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">recoilme/recoilme-gemma-2-9B-v0.2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/recoilme__recoilme-gemma-2-9B-v0.2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "recoilme/recoilme-gemma-2-9B-v0.2", "Model sha": "483116e575fb3a56de25243b14d715c58fe127bc", "Average \u2b06\ufe0f": 30.048864030373213, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 10, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7591745457608035, "IFEval": 75.91745457608036, "BBH Raw": 0.6025964285724085, "BBH": 43.02796904930725, "MATH Lvl 5 Raw": 0.052870090634441, "MATH Lvl 5": 5.287009063444108, "GPQA Raw": 0.3288590604026846, "GPQA": 10.514541387024613, "MUSR Raw": 0.409875, "MUSR": 10.401041666666664, "MMLU-PRO Raw": 0.4163065159574468, "MMLU-PRO": 35.145168439716315, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-18T00:00:00", "Submission Date": "2024-09-18T00:00:00", "Generation": 0, "Base Model": "recoilme/recoilme-gemma-2-9B-v0.2"}, {"eval_name": "recoilme_recoilme-gemma-2-9B-v0.2_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/recoilme/recoilme-gemma-2-9B-v0.2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">recoilme/recoilme-gemma-2-9B-v0.2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/recoilme__recoilme-gemma-2-9B-v0.2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "recoilme/recoilme-gemma-2-9B-v0.2", "Model sha": "483116e575fb3a56de25243b14d715c58fe127bc", "Average \u2b06\ufe0f": 23.53626523833568, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 10, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2746989100032359, "IFEval": 27.469891000323585, "BBH Raw": 0.6030832642626502, "BBH": 43.56058143461737, "MATH Lvl 5 Raw": 0.0694864048338368, "MATH Lvl 5": 6.948640483383686, "GPQA Raw": 0.3305369127516778, "GPQA": 10.738255033557047, "MUSR Raw": 0.46859375, "MUSR": 17.807552083333327, "MMLU-PRO Raw": 0.4122340425531915, "MMLU-PRO": 34.692671394799056, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-18T00:00:00", "Submission Date": "2024-09-27T00:00:00", "Generation": 0, "Base Model": "recoilme/recoilme-gemma-2-9B-v0.2"}, {"eval_name": "recoilme_recoilme-gemma-2-9B-v0.3_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/recoilme/recoilme-gemma-2-9B-v0.3\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">recoilme/recoilme-gemma-2-9B-v0.3</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/recoilme__recoilme-gemma-2-9B-v0.3-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "recoilme/recoilme-gemma-2-9B-v0.3", "Model sha": "772cab46d9d22cbcc3c574d193021803ce5c444c", "Average \u2b06\ufe0f": 30.2074720895527, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 2, "#Params (B)": 10, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.743937197746424, "IFEval": 74.39371977464239, "BBH Raw": 0.5992527878628748, "BBH": 42.026279212829245, "MATH Lvl 5 Raw": 0.0876132930513595, "MATH Lvl 5": 8.761329305135952, "GPQA Raw": 0.3238255033557047, "GPQA": 9.843400447427292, "MUSR Raw": 0.4203854166666667, "MUSR": 12.081510416666664, "MMLU-PRO Raw": 0.4072473404255319, "MMLU-PRO": 34.13859338061466, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-18T00:00:00", "Submission Date": "2024-09-18T00:00:00", "Generation": 0, "Base Model": "recoilme/recoilme-gemma-2-9B-v0.3"}, {"eval_name": "recoilme_recoilme-gemma-2-9B-v0.3_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/recoilme/recoilme-gemma-2-9B-v0.3\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">recoilme/recoilme-gemma-2-9B-v0.3</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/recoilme__recoilme-gemma-2-9B-v0.3-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "recoilme/recoilme-gemma-2-9B-v0.3", "Model sha": "76c8fb761660e6eb237c91bb6e6761ee36266bba", "Average \u2b06\ufe0f": 29.80952351763429, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 2, "#Params (B)": 10, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.57607592299543, "IFEval": 57.60759229954299, "BBH Raw": 0.6019827101058847, "BBH": 43.326868296283614, "MATH Lvl 5 Raw": 0.154833836858006, "MATH Lvl 5": 15.483383685800604, "GPQA Raw": 0.337248322147651, "GPQA": 11.6331096196868, "MUSR Raw": 0.4632291666666666, "MUSR": 17.03697916666666, "MMLU-PRO Raw": 0.4039228723404255, "MMLU-PRO": 33.76920803782505, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-18T00:00:00", "Submission Date": "2024-09-27T00:00:00", "Generation": 0, "Base Model": "recoilme/recoilme-gemma-2-9B-v0.3"}, {"eval_name": "recoilme_recoilme-gemma-2-9B-v0.4_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/recoilme/recoilme-gemma-2-9B-v0.4\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">recoilme/recoilme-gemma-2-9B-v0.4</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/recoilme__recoilme-gemma-2-9B-v0.4-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "recoilme/recoilme-gemma-2-9B-v0.4", "Model sha": "2691f2cc8d80072f15d78cb7ae72831e1a12139e", "Average \u2b06\ufe0f": 23.96189393185898, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 10, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2561891337207498, "IFEval": 25.618913372074985, "BBH Raw": 0.5967285833554881, "BBH": 42.44248167542507, "MATH Lvl 5 Raw": 0.0740181268882175, "MATH Lvl 5": 7.401812688821751, "GPQA Raw": 0.3406040268456375, "GPQA": 12.080536912751676, "MUSR Raw": 0.4726875, "MUSR": 18.3859375, "MMLU-PRO Raw": 0.4405751329787234, "MMLU-PRO": 37.84168144208039, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-18T00:00:00", "Submission Date": "2024-09-19T00:00:00", "Generation": 0, "Base Model": "recoilme/recoilme-gemma-2-9B-v0.4"}, {"eval_name": "refuelai_Llama-3-Refueled_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/refuelai/Llama-3-Refueled\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">refuelai/Llama-3-Refueled</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/refuelai__Llama-3-Refueled-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "refuelai/Llama-3-Refueled", "Model sha": "ff6d1c3ba37b31d4af421951c2300f2256fb3691", "Average \u2b06\ufe0f": 22.728276100836258, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 189, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4619952836252255, "IFEval": 46.19952836252256, "BBH Raw": 0.5870766201705051, "BBH": 41.72197100339103, "MATH Lvl 5 Raw": 0.039274924471299, "MATH Lvl 5": 3.927492447129909, "GPQA Raw": 0.299496644295302, "GPQA": 6.599552572706939, "MUSR Raw": 0.44540625, "MUSR": 14.642447916666669, "MMLU-PRO Raw": 0.3095079787234042, "MMLU-PRO": 23.278664302600472, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-05-03T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "refuelai/Llama-3-Refueled"}, {"eval_name": "rhplus0831_maid-yuzu-v7_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/rhplus0831/maid-yuzu-v7\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">rhplus0831/maid-yuzu-v7</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/rhplus0831__maid-yuzu-v7-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "rhplus0831/maid-yuzu-v7", "Model sha": "a0bd8c707bb80024778da4a0d057917faa53d2f6", "Average \u2b06\ufe0f": 24.38122518998252, "Hub License": null, "Hub \u2764\ufe0f": 1, "#Params (B)": 46, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6462430794735745, "IFEval": 64.62430794735747, "BBH Raw": 0.480491692312673, "BBH": 26.8198371046094, "MATH Lvl 5 Raw": 0.0891238670694864, "MATH Lvl 5": 8.91238670694864, "GPQA Raw": 0.3095637583892617, "GPQA": 7.941834451901568, "MUSR Raw": 0.4136249999999999, "MUSR": 9.769791666666666, "MMLU-PRO Raw": 0.3539727393617021, "MMLU-PRO": 28.219193262411352, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-02-09T00:00:00", "Submission Date": "2024-09-08T00:00:00", "Generation": 1, "Base Model": "rhplus0831/maid-yuzu-v7 (Merge)"}, {"eval_name": "rhymes-ai_Aria_bfloat16", "Precision": "bfloat16", "Type": "\ud83c\udf38 multimodal", "T": "\ud83c\udf38", "Weight type": "Original", "Architecture": "AriaForConditionalGeneration", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/rhymes-ai/Aria\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">rhymes-ai/Aria</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/rhymes-ai__Aria-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "rhymes-ai/Aria", "Model sha": "5cc2703b3afd585f232ec5027e9c039a2001bcec", "Average \u2b06\ufe0f": 28.15264133664177, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 367, "#Params (B)": 25, "Available on the hub": true, "Not_Merged": true, "MoE": false, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4773079872516035, "IFEval": 47.73079872516036, "BBH Raw": 0.5695312446413633, "BBH": 39.28149335481041, "MATH Lvl 5 Raw": 0.1503021148036253, "MATH Lvl 5": 15.030211480362537, "GPQA Raw": 0.3624161073825503, "GPQA": 14.988814317673372, "MUSR Raw": 0.43375, "MUSR": 14.05208333333333, "MMLU-PRO Raw": 0.4404920212765957, "MMLU-PRO": 37.83244680851063, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-09-26T00:00:00", "Submission Date": "2024-10-10T00:00:00", "Generation": 0, "Base Model": "rhymes-ai/Aria"}, {"eval_name": "rhysjones_phi-2-orange-v2_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "PhiForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/rhysjones/phi-2-orange-v2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">rhysjones/phi-2-orange-v2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/rhysjones__phi-2-orange-v2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "rhysjones/phi-2-orange-v2", "Model sha": "f4085189114accfb65225deb8fbdf15767b7ee56", "Average \u2b06\ufe0f": 14.644426788213975, "Hub License": "mit", "Hub \u2764\ufe0f": 27, "#Params (B)": 2, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3669740732367895, "IFEval": 36.69740732367895, "BBH Raw": 0.4770220109816213, "BBH": 25.60654883732465, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.261744966442953, "GPQA": 1.5659955257270708, "MUSR Raw": 0.3629583333333333, "MUSR": 6.969791666666668, "MMLU-PRO Raw": 0.2532413563829787, "MMLU-PRO": 17.026817375886523, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-03-04T00:00:00", "Submission Date": "2024-06-28T00:00:00", "Generation": 0, "Base Model": "rhysjones/phi-2-orange-v2"}, {"eval_name": "riaz_FineLlama-3.1-8B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/riaz/FineLlama-3.1-8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">riaz/FineLlama-3.1-8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/riaz__FineLlama-3.1-8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "riaz/FineLlama-3.1-8B", "Model sha": "c4d8f16eb446910edce0c1afd0e6d5f3b06e2e7d", "Average \u2b06\ufe0f": 17.610295593029527, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4373407004525769, "IFEval": 43.734070045257695, "BBH Raw": 0.4585729649801348, "BBH": 24.14877809167861, "MATH Lvl 5 Raw": 0.0483383685800604, "MATH Lvl 5": 4.833836858006042, "GPQA Raw": 0.2751677852348993, "GPQA": 3.355704697986576, "MUSR Raw": 0.3762916666666667, "MUSR": 7.76979166666667, "MMLU-PRO Raw": 0.296376329787234, "MMLU-PRO": 21.81959219858156, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-07T00:00:00", "Submission Date": "2024-10-12T00:00:00", "Generation": 2, "Base Model": "meta-llama/Meta-Llama-3.1-8B"}, {"eval_name": "riaz_FineLlama-3.1-8B_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/riaz/FineLlama-3.1-8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">riaz/FineLlama-3.1-8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/riaz__FineLlama-3.1-8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "riaz/FineLlama-3.1-8B", "Model sha": "c4d8f16eb446910edce0c1afd0e6d5f3b06e2e7d", "Average \u2b06\ufe0f": 17.097158489448333, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.413660199382084, "IFEval": 41.3660199382084, "BBH Raw": 0.456451981676995, "BBH": 23.77338959053972, "MATH Lvl 5 Raw": 0.0422960725075528, "MATH Lvl 5": 4.229607250755287, "GPQA Raw": 0.276006711409396, "GPQA": 3.467561521252797, "MUSR Raw": 0.377625, "MUSR": 7.76979166666667, "MMLU-PRO Raw": 0.2977892287234042, "MMLU-PRO": 21.976580969267136, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-07T00:00:00", "Submission Date": "2024-10-12T00:00:00", "Generation": 2, "Base Model": "meta-llama/Meta-Llama-3.1-8B"}, {"eval_name": "rmdhirr_Gluon-8B_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/rmdhirr/Gluon-8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">rmdhirr/Gluon-8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/rmdhirr__Gluon-8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "rmdhirr/Gluon-8B", "Model sha": "cc949908c60ab7f696e133714222d6cab156e493", "Average \u2b06\ufe0f": 23.662260024131587, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.5052848663767692, "IFEval": 50.52848663767692, "BBH Raw": 0.5153305292144984, "BBH": 30.34224724618852, "MATH Lvl 5 Raw": 0.1253776435045317, "MATH Lvl 5": 12.537764350453172, "GPQA Raw": 0.3120805369127516, "GPQA": 8.277404921700223, "MUSR Raw": 0.4038854166666667, "MUSR": 9.085677083333335, "MMLU-PRO Raw": 0.3808178191489361, "MMLU-PRO": 31.201979905437344, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-14T00:00:00", "Submission Date": "2024-09-14T00:00:00", "Generation": 1, "Base Model": "rmdhirr/Gluon-8B (Merge)"}, {"eval_name": "rombodawg_Rombos-LLM-V2.5-Qwen-0.5b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/rombodawg/Rombos-LLM-V2.5-Qwen-0.5b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">rombodawg/Rombos-LLM-V2.5-Qwen-0.5b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/rombodawg__Rombos-LLM-V2.5-Qwen-0.5b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "rombodawg/Rombos-LLM-V2.5-Qwen-0.5b", "Model sha": "aae2e55548c8090ce357c64ca78e8b9ef6baf118", "Average \u2b06\ufe0f": 8.668397336268958, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2846669060315518, "IFEval": 28.466690603155183, "BBH Raw": 0.3293675183143625, "BBH": 8.412218566269734, "MATH Lvl 5 Raw": 0.0249244712990936, "MATH Lvl 5": 2.492447129909366, "GPQA Raw": 0.2667785234899328, "GPQA": 2.2371364653243813, "MUSR Raw": 0.3235833333333333, "MUSR": 0.7812499999999996, "MMLU-PRO Raw": 0.1865857712765957, "MMLU-PRO": 9.620641252955084, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-06T00:00:00", "Submission Date": "2024-09-29T00:00:00", "Generation": 1, "Base Model": "rombodawg/Rombos-LLM-V2.5-Qwen-0.5b (Merge)"}, {"eval_name": "rombodawg_Rombos-LLM-V2.5-Qwen-1.5b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/rombodawg/Rombos-LLM-V2.5-Qwen-1.5b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">rombodawg/Rombos-LLM-V2.5-Qwen-1.5b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/rombodawg__Rombos-LLM-V2.5-Qwen-1.5b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "rombodawg/Rombos-LLM-V2.5-Qwen-1.5b", "Model sha": "1f634da015ed671efe7dc574bc2a1954f5b2cc93", "Average \u2b06\ufe0f": 16.102623560824178, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 1, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3402461025634206, "IFEval": 34.02461025634206, "BBH Raw": 0.4256703145864387, "BBH": 18.711343783972325, "MATH Lvl 5 Raw": 0.0702416918429003, "MATH Lvl 5": 7.02416918429003, "GPQA Raw": 0.2885906040268456, "GPQA": 5.145413870246088, "MUSR Raw": 0.4185520833333333, "MUSR": 10.35234375, "MMLU-PRO Raw": 0.2922207446808511, "MMLU-PRO": 21.35786052009456, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-06T00:00:00", "Submission Date": "2024-09-29T00:00:00", "Generation": 1, "Base Model": "rombodawg/Rombos-LLM-V2.5-Qwen-1.5b (Merge)"}, {"eval_name": "rombodawg_Rombos-LLM-V2.5-Qwen-14b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/rombodawg/Rombos-LLM-V2.5-Qwen-14b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">rombodawg/Rombos-LLM-V2.5-Qwen-14b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/rombodawg__Rombos-LLM-V2.5-Qwen-14b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "rombodawg/Rombos-LLM-V2.5-Qwen-14b", "Model sha": "834ddb1712ae6d1b232b2d5b26be658d90d23e43", "Average \u2b06\ufe0f": 34.51606165784212, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 5, "#Params (B)": 14, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.5840447789642593, "IFEval": 58.40447789642593, "BBH Raw": 0.6481086261669653, "BBH": 49.38690027144481, "MATH Lvl 5 Raw": 0.1563444108761329, "MATH Lvl 5": 15.634441087613292, "GPQA Raw": 0.3716442953020134, "GPQA": 16.21923937360179, "MUSR Raw": 0.4717291666666667, "MUSR": 18.832812499999992, "MMLU-PRO Raw": 0.5375664893617021, "MMLU-PRO": 48.6184988179669, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-06T00:00:00", "Submission Date": "2024-09-29T00:00:00", "Generation": 1, "Base Model": "rombodawg/Rombos-LLM-V2.5-Qwen-14b (Merge)"}, {"eval_name": "rombodawg_Rombos-LLM-V2.5-Qwen-32b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/rombodawg/Rombos-LLM-V2.5-Qwen-32b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">rombodawg/Rombos-LLM-V2.5-Qwen-32b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/rombodawg__Rombos-LLM-V2.5-Qwen-32b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "rombodawg/Rombos-LLM-V2.5-Qwen-32b", "Model sha": "234abe4b494dbe83ba805b791f74feb33462a33d", "Average \u2b06\ufe0f": 44.09585172749646, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 8, "#Params (B)": 32, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.6826631116548536, "IFEval": 68.26631116548536, "BBH Raw": 0.7045537070859799, "BBH": 58.26189408678741, "MATH Lvl 5 Raw": 0.391238670694864, "MATH Lvl 5": 39.12386706948641, "GPQA Raw": 0.3968120805369127, "GPQA": 19.57494407158837, "MUSR Raw": 0.5034166666666667, "MUSR": 24.727083333333336, "MMLU-PRO Raw": 0.5915890957446809, "MMLU-PRO": 54.62101063829788, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-30T00:00:00", "Submission Date": "2024-10-07T00:00:00", "Generation": 1, "Base Model": "rombodawg/Rombos-LLM-V2.5-Qwen-32b (Merge)"}, {"eval_name": "rombodawg_Rombos-LLM-V2.5-Qwen-3b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/rombodawg/Rombos-LLM-V2.5-Qwen-3b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">rombodawg/Rombos-LLM-V2.5-Qwen-3b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/rombodawg__Rombos-LLM-V2.5-Qwen-3b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "rombodawg/Rombos-LLM-V2.5-Qwen-3b", "Model sha": "26601a8da5afce3b5959d91bdd0faaab6df8bf95", "Average \u2b06\ufe0f": 22.107582656042965, "Hub License": "other", "Hub \u2764\ufe0f": 2, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.5342358276040905, "IFEval": 53.42358276040905, "BBH Raw": 0.4808896246368473, "BBH": 27.213596951125695, "MATH Lvl 5 Raw": 0.0506042296072507, "MATH Lvl 5": 5.060422960725076, "GPQA Raw": 0.3078859060402684, "GPQA": 7.718120805369126, "MUSR Raw": 0.4041666666666666, "MUSR": 8.554166666666667, "MMLU-PRO Raw": 0.3760804521276595, "MMLU-PRO": 30.67560579196217, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-06T00:00:00", "Submission Date": "2024-09-29T00:00:00", "Generation": 1, "Base Model": "rombodawg/Rombos-LLM-V2.5-Qwen-3b (Merge)"}, {"eval_name": "rombodawg_Rombos-LLM-V2.5-Qwen-72b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/rombodawg/Rombos-LLM-V2.5-Qwen-72b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">rombodawg/Rombos-LLM-V2.5-Qwen-72b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/rombodawg__Rombos-LLM-V2.5-Qwen-72b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "rombodawg/Rombos-LLM-V2.5-Qwen-72b", "Model sha": "5260f182e7859e13d515c4cb3926ac85ad057504", "Average \u2b06\ufe0f": 45.39313285562691, "Hub License": "other", "Hub \u2764\ufe0f": 15, "#Params (B)": 72, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.715535889218385, "IFEval": 71.5535889218385, "BBH Raw": 0.7229589065788488, "BBH": 61.26714504573664, "MATH Lvl 5 Raw": 0.4758308157099697, "MATH Lvl 5": 47.583081570996974, "GPQA Raw": 0.398489932885906, "GPQA": 19.798657718120808, "MUSR Raw": 0.4599166666666667, "MUSR": 17.322916666666668, "MMLU-PRO Raw": 0.593500664893617, "MMLU-PRO": 54.83340721040189, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-30T00:00:00", "Submission Date": "2024-09-30T00:00:00", "Generation": 1, "Base Model": "rombodawg/Rombos-LLM-V2.5-Qwen-72b (Merge)"}, {"eval_name": "rombodawg_Rombos-LLM-V2.5-Qwen-7b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/rombodawg/Rombos-LLM-V2.5-Qwen-7b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">rombodawg/Rombos-LLM-V2.5-Qwen-7b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/rombodawg__Rombos-LLM-V2.5-Qwen-7b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "rombodawg/Rombos-LLM-V2.5-Qwen-7b", "Model sha": "dbd819e8f765181f774cb5b79812d081669eb302", "Average \u2b06\ufe0f": 30.79764542912299, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 6, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.6237117514860571, "IFEval": 62.3711751486057, "BBH Raw": 0.5543885046903589, "BBH": 36.37235041430064, "MATH Lvl 5 Raw": 0.2643504531722054, "MATH Lvl 5": 26.435045317220546, "GPQA Raw": 0.3179530201342282, "GPQA": 9.060402684563762, "MUSR Raw": 0.42909375, "MUSR": 12.003385416666667, "MMLU-PRO Raw": 0.4468916223404255, "MMLU-PRO": 38.54351359338061, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-06T00:00:00", "Submission Date": "2024-09-29T00:00:00", "Generation": 1, "Base Model": "rombodawg/Rombos-LLM-V2.5-Qwen-7b (Merge)"}, {"eval_name": "rombodawg_Rombos-LLM-V2.5.1-Qwen-3b_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/rombodawg/Rombos-LLM-V2.5.1-Qwen-3b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">rombodawg/Rombos-LLM-V2.5.1-Qwen-3b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/rombodawg__Rombos-LLM-V2.5.1-Qwen-3b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "rombodawg/Rombos-LLM-V2.5.1-Qwen-3b", "Model sha": "a3305ce148f4273ab334052ab47d3aebb51d104c", "Average \u2b06\ufe0f": 13.218655687058463, "Hub License": "other", "Hub \u2764\ufe0f": 0, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2595125378440316, "IFEval": 25.95125378440316, "BBH Raw": 0.3884043024656656, "BBH": 14.88140918445136, "MATH Lvl 5 Raw": 0.0830815709969788, "MATH Lvl 5": 8.308157099697885, "GPQA Raw": 0.2743288590604026, "GPQA": 3.243847874720355, "MUSR Raw": 0.3991145833333333, "MUSR": 7.822656250000001, "MMLU-PRO Raw": 0.2719414893617021, "MMLU-PRO": 19.104609929078016, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-08T00:00:00", "Submission Date": "2024-10-08T00:00:00", "Generation": 1, "Base Model": "rombodawg/Rombos-LLM-V2.5.1-Qwen-3b (Merge)"}, {"eval_name": "rombodawg_Rombos-LLM-V2.6-Qwen-14b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/rombodawg/Rombos-LLM-V2.6-Qwen-14b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">rombodawg/Rombos-LLM-V2.6-Qwen-14b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/rombodawg__Rombos-LLM-V2.6-Qwen-14b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "rombodawg/Rombos-LLM-V2.6-Qwen-14b", "Model sha": "887910d75a1837b8b8c7c3e50a257517d286ec60", "Average \u2b06\ufe0f": 35.88773487523238, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 21, "#Params (B)": 14, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.5214464288088938, "IFEval": 52.14464288088938, "BBH Raw": 0.6482048156327189, "BBH": 49.21778416393897, "MATH Lvl 5 Raw": 0.2885196374622356, "MATH Lvl 5": 28.851963746223564, "GPQA Raw": 0.3775167785234899, "GPQA": 17.00223713646532, "MUSR Raw": 0.47675, "MUSR": 19.26041666666666, "MMLU-PRO Raw": 0.5396442819148937, "MMLU-PRO": 48.84936465721041, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-12T00:00:00", "Submission Date": "2024-10-13T00:00:00", "Generation": 1, "Base Model": "rombodawg/Rombos-LLM-V2.6-Qwen-14b (Merge)"}, {"eval_name": "rwitz_go-bruins-v2_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/rwitz/go-bruins-v2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">rwitz/go-bruins-v2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/rwitz__go-bruins-v2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "rwitz/go-bruins-v2", "Model sha": "6d9e57d3a36dbad364ec77ca642873d9fc7fd61c", "Average \u2b06\ufe0f": 15.270321679842832, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4095887799926417, "IFEval": 40.958877999264175, "BBH Raw": 0.3798844684108968, "BBH": 12.69326018768569, "MATH Lvl 5 Raw": 0.0574018126888217, "MATH Lvl 5": 5.740181268882175, "GPQA Raw": 0.2625838926174497, "GPQA": 1.6778523489932915, "MUSR Raw": 0.41375, "MUSR": 10.985416666666664, "MMLU-PRO Raw": 0.2760970744680851, "MMLU-PRO": 19.56634160756501, "Maintainer's Highlight": false, "Upload To Hub Date": "", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "Removed"}, {"eval_name": "saishf_Fimbulvetr-Kuro-Lotus-10.7B_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/saishf/Fimbulvetr-Kuro-Lotus-10.7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">saishf/Fimbulvetr-Kuro-Lotus-10.7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/saishf__Fimbulvetr-Kuro-Lotus-10.7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "saishf/Fimbulvetr-Kuro-Lotus-10.7B", "Model sha": "ec1288fd8c06ac408a2a7e503ea62ac300e474e1", "Average \u2b06\ufe0f": 20.01069696692674, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 17, "#Params (B)": 10, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.493943846771012, "IFEval": 49.39438467710121, "BBH Raw": 0.4342316286386943, "BBH": 19.90882095261725, "MATH Lvl 5 Raw": 0.0135951661631419, "MATH Lvl 5": 1.3595166163141994, "GPQA Raw": 0.3011744966442953, "GPQA": 6.823266219239373, "MUSR Raw": 0.4445104166666667, "MUSR": 16.03046875, "MMLU-PRO Raw": 0.3389295212765957, "MMLU-PRO": 26.547724586288417, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-02-13T00:00:00", "Submission Date": "2024-07-09T00:00:00", "Generation": 1, "Base Model": "saishf/Fimbulvetr-Kuro-Lotus-10.7B (Merge)"}, {"eval_name": "sakhan10_quantized_open_llama_3b_v2_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/sakhan10/quantized_open_llama_3b_v2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">sakhan10/quantized_open_llama_3b_v2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/sakhan10__quantized_open_llama_3b_v2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "sakhan10/quantized_open_llama_3b_v2", "Model sha": "e8d51ad5204806edf9c2eeb8c56139a440a70265", "Average \u2b06\ufe0f": 5.142500028294101, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 3, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1872221261807559, "IFEval": 18.722212618075595, "BBH Raw": 0.3019800780121471, "BBH": 2.805733273363854, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2768456375838926, "GPQA": 3.5794183445190177, "MUSR Raw": 0.3681666666666667, "MUSR": 4.687499999999999, "MMLU-PRO Raw": 0.1095412234042553, "MMLU-PRO": 1.0601359338061456, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-23T00:00:00", "Submission Date": "2024-08-28T00:00:00", "Generation": 1, "Base Model": "openlm-research/open_llama_3b_v2"}, {"eval_name": "saltlux_luxia-21.4b-alignment-v1.0_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/saltlux/luxia-21.4b-alignment-v1.0\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">saltlux/luxia-21.4b-alignment-v1.0</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/saltlux__luxia-21.4b-alignment-v1.0-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "saltlux/luxia-21.4b-alignment-v1.0", "Model sha": "87d5673e6d9f60462f195e9414a0bf6874c89ceb", "Average \u2b06\ufe0f": 22.86293244634964, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 32, "#Params (B)": 21, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3692967991595632, "IFEval": 36.92967991595633, "BBH Raw": 0.6373342606775594, "BBH": 48.02111296160791, "MATH Lvl 5 Raw": 0.0619335347432024, "MATH Lvl 5": 6.193353474320242, "GPQA Raw": 0.3011744966442953, "GPQA": 6.823266219239373, "MUSR Raw": 0.4328437499999999, "MUSR": 12.50546875, "MMLU-PRO Raw": 0.3403424202127659, "MMLU-PRO": 26.70471335697399, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-03-12T00:00:00", "Submission Date": "2024-06-29T00:00:00", "Generation": 0, "Base Model": "saltlux/luxia-21.4b-alignment-v1.0"}, {"eval_name": "saltlux_luxia-21.4b-alignment-v1.2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/saltlux/luxia-21.4b-alignment-v1.2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">saltlux/luxia-21.4b-alignment-v1.2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/saltlux__luxia-21.4b-alignment-v1.2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "saltlux/luxia-21.4b-alignment-v1.2", "Model sha": "eed12b5574fa49cc81e57a88aff24c08c13721c0", "Average \u2b06\ufe0f": 23.43519184551844, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 7, "#Params (B)": 21, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4115369441969529, "IFEval": 41.1536944196953, "BBH Raw": 0.6371180708112368, "BBH": 47.76916471884749, "MATH Lvl 5 Raw": 0.0158610271903323, "MATH Lvl 5": 1.5861027190332326, "GPQA Raw": 0.3078859060402684, "GPQA": 7.718120805369126, "MUSR Raw": 0.4458958333333334, "MUSR": 14.903645833333329, "MMLU-PRO Raw": 0.3473238031914893, "MMLU-PRO": 27.480422576832154, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-27T00:00:00", "Submission Date": "2024-07-30T00:00:00", "Generation": 0, "Base Model": "saltlux/luxia-21.4b-alignment-v1.2"}, {"eval_name": "sci-m-wang_Mistral-7B-Instruct-sa-v0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Adapter", "Architecture": "?", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/sci-m-wang/Mistral-7B-Instruct-sa-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">sci-m-wang/Mistral-7B-Instruct-sa-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/sci-m-wang__Mistral-7B-Instruct-sa-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "sci-m-wang/Mistral-7B-Instruct-sa-v0.1", "Model sha": "2dcff66eac0c01dc50e4c41eea959968232187fe", "Average \u2b06\ufe0f": 12.187476170180467, "Hub License": "other", "Hub \u2764\ufe0f": 0, "#Params (B)": 14, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4335186194851882, "IFEval": 43.35186194851882, "BBH Raw": 0.3272782156141172, "BBH": 5.743646077429951, "MATH Lvl 5 Raw": 0.0098187311178247, "MATH Lvl 5": 0.9818731117824772, "GPQA Raw": 0.259228187919463, "GPQA": 1.230425055928408, "MUSR Raw": 0.3899999999999999, "MUSR": 6.683333333333335, "MMLU-PRO Raw": 0.2362034574468085, "MMLU-PRO": 15.133717494089836, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-31T00:00:00", "Submission Date": "2024-06-27T00:00:00", "Generation": 2, "Base Model": "mistralai/Mistral-7B-v0.1"}, {"eval_name": "sci-m-wang_Phi-3-mini-4k-instruct-sa-v0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Adapter", "Architecture": "?", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/sci-m-wang/Phi-3-mini-4k-instruct-sa-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">sci-m-wang/Phi-3-mini-4k-instruct-sa-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/sci-m-wang__Phi-3-mini-4k-instruct-sa-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "sci-m-wang/Phi-3-mini-4k-instruct-sa-v0.1", "Model sha": "5a516f86087853f9d560c95eb9209c1d4ed9ff69", "Average \u2b06\ufe0f": 25.54720594643266, "Hub License": "other", "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5020623057930734, "IFEval": 50.20623057930735, "BBH Raw": 0.5502038722383045, "BBH": 36.605419148768114, "MATH Lvl 5 Raw": 0.1314199395770392, "MATH Lvl 5": 13.141993957703926, "GPQA Raw": 0.3288590604026846, "GPQA": 10.514541387024613, "MUSR Raw": 0.4073020833333333, "MUSR": 9.64609375, "MMLU-PRO Raw": 0.3985206117021276, "MMLU-PRO": 33.16895685579196, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-01T00:00:00", "Submission Date": "2024-06-27T00:00:00", "Generation": 1, "Base Model": "microsoft/Phi-3-mini-4k-instruct"}, {"eval_name": "sci-m-wang_deepseek-llm-7b-chat-sa-v0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Adapter", "Architecture": "?", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/sci-m-wang/deepseek-llm-7b-chat-sa-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">sci-m-wang/deepseek-llm-7b-chat-sa-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/sci-m-wang__deepseek-llm-7b-chat-sa-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "sci-m-wang/deepseek-llm-7b-chat-sa-v0.1", "Model sha": "afbda8b347ec881666061fa67447046fc5164ec8", "Average \u2b06\ufe0f": 13.082168632807544, "Hub License": "other", "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4035935761557113, "IFEval": 40.35935761557113, "BBH Raw": 0.371772009952763, "BBH": 12.05197465522808, "MATH Lvl 5 Raw": 0.0188821752265861, "MATH Lvl 5": 1.8882175226586104, "GPQA Raw": 0.2567114093959731, "GPQA": 0.8948545861297527, "MUSR Raw": 0.4173125, "MUSR": 9.864062499999998, "MMLU-PRO Raw": 0.2209109042553191, "MMLU-PRO": 13.434544917257682, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-31T00:00:00", "Submission Date": "2024-06-27T00:00:00", "Generation": 1, "Base Model": "deepseek-ai/deepseek-llm-7b-chat"}, {"eval_name": "senseable_WestLake-7B-v2_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/senseable/WestLake-7B-v2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">senseable/WestLake-7B-v2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/senseable__WestLake-7B-v2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "senseable/WestLake-7B-v2", "Model sha": "41625004c47628837678859753b94c50c82f3bec", "Average \u2b06\ufe0f": 16.257065193895503, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 108, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4418620371724801, "IFEval": 44.18620371724801, "BBH Raw": 0.4073276290688943, "BBH": 17.858141685089326, "MATH Lvl 5 Raw": 0.0483383685800604, "MATH Lvl 5": 4.833836858006042, "GPQA Raw": 0.2768456375838926, "GPQA": 3.5794183445190177, "MUSR Raw": 0.3937187499999999, "MUSR": 7.481510416666669, "MMLU-PRO Raw": 0.2764295212765957, "MMLU-PRO": 19.60328014184397, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-01-22T00:00:00", "Submission Date": "2024-07-23T00:00:00", "Generation": 0, "Base Model": "senseable/WestLake-7B-v2"}, {"eval_name": "sequelbox_Llama3.1-8B-MOTH_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/sequelbox/Llama3.1-8B-MOTH\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">sequelbox/Llama3.1-8B-MOTH</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/sequelbox__Llama3.1-8B-MOTH-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "sequelbox/Llama3.1-8B-MOTH", "Model sha": "8db363e36b1efc9015ab14648e68bcfba9e8d8a0", "Average \u2b06\ufe0f": 20.49662445417503, "Hub License": "llama3.1", "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5244938984117696, "IFEval": 52.449389841176966, "BBH Raw": 0.490246673015408, "BBH": 27.91633224536528, "MATH Lvl 5 Raw": 0.1012084592145015, "MATH Lvl 5": 10.120845921450153, "GPQA Raw": 0.2684563758389262, "GPQA": 2.460850111856823, "MUSR Raw": 0.3689166666666666, "MUSR": 4.047916666666668, "MMLU-PRO Raw": 0.3338597074468085, "MMLU-PRO": 25.98441193853428, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-01T00:00:00", "Submission Date": "2024-09-19T00:00:00", "Generation": 2, "Base Model": "meta-llama/Meta-Llama-3.1-8B"}, {"eval_name": "sequelbox_Llama3.1-8B-PlumChat_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/sequelbox/Llama3.1-8B-PlumChat\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">sequelbox/Llama3.1-8B-PlumChat</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/sequelbox__Llama3.1-8B-PlumChat-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "sequelbox/Llama3.1-8B-PlumChat", "Model sha": "1afdc9856591f573e4fcb52dba19a9d8da631e0b", "Average \u2b06\ufe0f": 13.126613277979589, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.424276475307739, "IFEval": 42.427647530773896, "BBH Raw": 0.3873291395699702, "BBH": 13.935991387298124, "MATH Lvl 5 Raw": 0.0309667673716012, "MATH Lvl 5": 3.096676737160121, "GPQA Raw": 0.2651006711409396, "GPQA": 2.0134228187919474, "MUSR Raw": 0.3754583333333333, "MUSR": 4.765625000000001, "MMLU-PRO Raw": 0.2126828457446808, "MMLU-PRO": 12.520316193853429, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-02T00:00:00", "Submission Date": "2024-10-03T00:00:00", "Generation": 1, "Base Model": "sequelbox/Llama3.1-8B-PlumChat (Merge)"}, {"eval_name": "sequelbox_Llama3.1-8B-PlumCode_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/sequelbox/Llama3.1-8B-PlumCode\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">sequelbox/Llama3.1-8B-PlumCode</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/sequelbox__Llama3.1-8B-PlumCode-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "sequelbox/Llama3.1-8B-PlumCode", "Model sha": "171cd599d574000607491f08e6cf7b7eb199e33d", "Average \u2b06\ufe0f": 9.773647432150089, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2044829940114451, "IFEval": 20.44829940114452, "BBH Raw": 0.3368086861425416, "BBH": 8.502927271642019, "MATH Lvl 5 Raw": 0.0241691842900302, "MATH Lvl 5": 2.416918429003021, "GPQA Raw": 0.276006711409396, "GPQA": 3.467561521252797, "MUSR Raw": 0.37734375, "MUSR": 8.967968750000002, "MMLU-PRO Raw": 0.2335438829787234, "MMLU-PRO": 14.838209219858156, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-02T00:00:00", "Submission Date": "2024-10-03T00:00:00", "Generation": 1, "Base Model": "sequelbox/Llama3.1-8B-PlumCode (Merge)"}, {"eval_name": "sequelbox_Llama3.1-8B-PlumMath_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/sequelbox/Llama3.1-8B-PlumMath\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">sequelbox/Llama3.1-8B-PlumMath</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/sequelbox__Llama3.1-8B-PlumMath-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "sequelbox/Llama3.1-8B-PlumMath", "Model sha": "b857c30a626f7c020fcba89df7bece4bb7381ac2", "Average \u2b06\ufe0f": 13.79821578951725, "Hub License": "llama3.1", "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.224241678745728, "IFEval": 22.4241678745728, "BBH Raw": 0.4032302309004814, "BBH": 16.44658382894578, "MATH Lvl 5 Raw": 0.039274924471299, "MATH Lvl 5": 3.927492447129909, "GPQA Raw": 0.3179530201342282, "GPQA": 9.060402684563762, "MUSR Raw": 0.3918541666666666, "MUSR": 8.981770833333334, "MMLU-PRO Raw": 0.2975398936170212, "MMLU-PRO": 21.94887706855792, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-01T00:00:00", "Submission Date": "2024-10-03T00:00:00", "Generation": 1, "Base Model": "sequelbox/Llama3.1-8B-PlumMath (Merge)"}, {"eval_name": "sequelbox_gemma-2-9B-MOTH_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/sequelbox/gemma-2-9B-MOTH\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">sequelbox/gemma-2-9B-MOTH</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/sequelbox__gemma-2-9B-MOTH-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "sequelbox/gemma-2-9B-MOTH", "Model sha": "8dff98ab82ba0087706afa0d6c69874a45548212", "Average \u2b06\ufe0f": 4.553324231799516, "Hub License": "gemma", "Hub \u2764\ufe0f": 0, "#Params (B)": 9, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.205881505516474, "IFEval": 20.58815055164741, "BBH Raw": 0.3079700052156253, "BBH": 3.2122172300496232, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2600671140939597, "GPQA": 1.342281879194629, "MUSR Raw": 0.3409479166666667, "MUSR": 0.6184895833333329, "MMLU-PRO Raw": 0.1140292553191489, "MMLU-PRO": 1.5588061465721037, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-09T00:00:00", "Submission Date": "2024-09-10T00:00:00", "Generation": 2, "Base Model": "google/gemma-2-9b"}, {"eval_name": "shadowml_BeagSake-7B_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/shadowml/BeagSake-7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">shadowml/BeagSake-7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/shadowml__BeagSake-7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "shadowml/BeagSake-7B", "Model sha": "b7a3b25a188a4608fd05fc4247ddd504c1f529d1", "Average \u2b06\ufe0f": 20.50181699544753, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4019202383010412, "IFEval": 40.19202383010412, "BBH Raw": 0.5181666279815969, "BBH": 32.532091301992814, "MATH Lvl 5 Raw": 0.0626888217522658, "MATH Lvl 5": 6.268882175226587, "GPQA Raw": 0.2802013422818792, "GPQA": 4.026845637583895, "MUSR Raw": 0.45690625, "MUSR": 16.379947916666662, "MMLU-PRO Raw": 0.3125, "MMLU-PRO": 23.61111111111111, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-01-31T00:00:00", "Submission Date": "2024-06-29T00:00:00", "Generation": 1, "Base Model": "shadowml/BeagSake-7B (Merge)"}, {"eval_name": "shadowml_Mixolar-4x7b_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/shadowml/Mixolar-4x7b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">shadowml/Mixolar-4x7b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/shadowml__Mixolar-4x7b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "shadowml/Mixolar-4x7b", "Model sha": "bb793526b063765e9861cad8834160fb0945e66d", "Average \u2b06\ufe0f": 19.28341153049504, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 3, "#Params (B)": 36, "Available on the hub": true, "Not_Merged": false, "MoE": false, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3893303102434873, "IFEval": 38.93303102434873, "BBH Raw": 0.5215949876221495, "BBH": 32.728963576299655, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2927852348993288, "GPQA": 5.7046979865771785, "MUSR Raw": 0.42575, "MUSR": 12.718749999999996, "MMLU-PRO Raw": 0.3305352393617021, "MMLU-PRO": 25.615026595744684, "Maintainer's Highlight": false, "Upload To Hub Date": "2023-12-30T00:00:00", "Submission Date": "2024-08-05T00:00:00", "Generation": 0, "Base Model": "shadowml/Mixolar-4x7b"}, {"eval_name": "shivam9980_NEPALI-LLM_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe9 continuously pretrained", "T": "\ud83d\udfe9", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/shivam9980/NEPALI-LLM\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">shivam9980/NEPALI-LLM</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/shivam9980__NEPALI-LLM-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "shivam9980/NEPALI-LLM", "Model sha": "5fe146065b53bfd6d8e242cffbe9176bc245551d", "Average \u2b06\ufe0f": 6.8802009324240645, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 10, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.0416661125812843, "IFEval": 4.166611258128433, "BBH Raw": 0.3828457133787513, "BBH": 13.12524427731519, "MATH Lvl 5 Raw": 0.0060422960725075, "MATH Lvl 5": 0.6042296072507553, "GPQA Raw": 0.261744966442953, "GPQA": 1.5659955257270708, "MUSR Raw": 0.4121979166666666, "MUSR": 9.991406250000002, "MMLU-PRO Raw": 0.2064494680851064, "MMLU-PRO": 11.827718676122933, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-17T00:00:00", "Submission Date": "2024-09-24T00:00:00", "Generation": 1, "Base Model": "unsloth/gemma-2-9b-bnb-4bit"}, {"eval_name": "shivam9980_mistral-7b-news-cnn-merged_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Adapter", "Architecture": "?", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/shivam9980/mistral-7b-news-cnn-merged\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">shivam9980/mistral-7b-news-cnn-merged</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/shivam9980__mistral-7b-news-cnn-merged-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "shivam9980/mistral-7b-news-cnn-merged", "Model sha": "a0d7029cb00c122843aef3d7ad61d514de334ea3", "Average \u2b06\ufe0f": 17.08298307223133, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4634192830578421, "IFEval": 46.34192830578421, "BBH Raw": 0.3635484854246454, "BBH": 11.146535574656042, "MATH Lvl 5 Raw": 0.0120845921450151, "MATH Lvl 5": 1.2084592145015105, "GPQA Raw": 0.3087248322147651, "GPQA": 7.829977628635347, "MUSR Raw": 0.4522604166666666, "MUSR": 15.665885416666669, "MMLU-PRO Raw": 0.2827460106382978, "MMLU-PRO": 20.305112293144205, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-03-18T00:00:00", "Submission Date": "2024-09-12T00:00:00", "Generation": 1, "Base Model": "unsloth/mistral-7b-instruct-v0.2-bnb-4bit"}, {"eval_name": "shyamieee_Padma-v7.0_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/shyamieee/Padma-v7.0\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">shyamieee/Padma-v7.0</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/shyamieee__Padma-v7.0-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "shyamieee/Padma-v7.0", "Model sha": "caf70bd6e2f819cc6a18dda8516f2cbdc101fdde", "Average \u2b06\ufe0f": 19.6681015923831, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3841097177710696, "IFEval": 38.410971777106965, "BBH Raw": 0.5118785631761485, "BBH": 31.65752076487425, "MATH Lvl 5 Raw": 0.0649546827794562, "MATH Lvl 5": 6.495468277945619, "GPQA Raw": 0.2860738255033557, "GPQA": 4.809843400447425, "MUSR Raw": 0.4385520833333333, "MUSR": 14.085677083333332, "MMLU-PRO Raw": 0.3029421542553192, "MMLU-PRO": 22.549128250591018, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-26T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "shyamieee/Padma-v7.0 (Merge)"}, {"eval_name": "skymizer_Llama2-7b-sft-chat-custom-template-dpo_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/skymizer/Llama2-7b-sft-chat-custom-template-dpo\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">skymizer/Llama2-7b-sft-chat-custom-template-dpo</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/skymizer__Llama2-7b-sft-chat-custom-template-dpo-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "skymizer/Llama2-7b-sft-chat-custom-template-dpo", "Model sha": "22302ebd8c551a5f302fcb8366cc61fdeedf0e00", "Average \u2b06\ufe0f": 10.06501948104002, "Hub License": "llama2", "Hub \u2764\ufe0f": 0, "#Params (B)": 6, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2352823840742563, "IFEval": 23.528238407425636, "BBH Raw": 0.3688466230266156, "BBH": 11.238865074478818, "MATH Lvl 5 Raw": 0.0098187311178247, "MATH Lvl 5": 0.9818731117824772, "GPQA Raw": 0.2390939597315436, "GPQA": 0.0, "MUSR Raw": 0.4428645833333333, "MUSR": 14.124739583333332, "MMLU-PRO Raw": 0.1946476063829787, "MMLU-PRO": 10.51640070921986, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-11T00:00:00", "Submission Date": "2024-07-01T00:00:00", "Generation": 2, "Base Model": "meta-llama/Llama-2-7b-hf"}, {"eval_name": "sonthenguyen_zephyr-sft-bnb-4bit-DPO-mtbc-213steps_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/sonthenguyen/zephyr-sft-bnb-4bit-DPO-mtbc-213steps\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">sonthenguyen/zephyr-sft-bnb-4bit-DPO-mtbc-213steps</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/sonthenguyen__zephyr-sft-bnb-4bit-DPO-mtbc-213steps-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "sonthenguyen/zephyr-sft-bnb-4bit-DPO-mtbc-213steps", "Model sha": "4ae2af48b6ac53f14e153b91309624100ae3d7c2", "Average \u2b06\ufe0f": 15.765675817233188, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4275489035758454, "IFEval": 42.75489035758454, "BBH Raw": 0.4197290890050172, "BBH": 19.669907319611504, "MATH Lvl 5 Raw": 0.0203927492447129, "MATH Lvl 5": 2.0392749244712998, "GPQA Raw": 0.261744966442953, "GPQA": 1.5659955257270708, "MUSR Raw": 0.4086354166666666, "MUSR": 9.579427083333336, "MMLU-PRO Raw": 0.2708610372340425, "MMLU-PRO": 18.98455969267139, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-02T00:00:00", "Submission Date": "2024-10-03T00:00:00", "Generation": 0, "Base Model": "sonthenguyen/zephyr-sft-bnb-4bit-DPO-mtbc-213steps"}, {"eval_name": "sonthenguyen_zephyr-sft-bnb-4bit-DPO-mtbo-180steps_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/sonthenguyen/zephyr-sft-bnb-4bit-DPO-mtbo-180steps\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">sonthenguyen/zephyr-sft-bnb-4bit-DPO-mtbo-180steps</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/sonthenguyen__zephyr-sft-bnb-4bit-DPO-mtbo-180steps-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "sonthenguyen/zephyr-sft-bnb-4bit-DPO-mtbo-180steps", "Model sha": "0393baf362e29cf51867596fb64746b5edafa6ed", "Average \u2b06\ufe0f": 15.514247709099566, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4087144332593075, "IFEval": 40.87144332593076, "BBH Raw": 0.4322585223071556, "BBH": 21.35140303187909, "MATH Lvl 5 Raw": 0.0181268882175226, "MATH Lvl 5": 1.812688821752266, "GPQA Raw": 0.276006711409396, "GPQA": 3.467561521252797, "MUSR Raw": 0.3885104166666666, "MUSR": 6.163802083333335, "MMLU-PRO Raw": 0.2747672872340425, "MMLU-PRO": 19.418587470449168, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-02T00:00:00", "Submission Date": "2024-10-03T00:00:00", "Generation": 0, "Base Model": "sonthenguyen/zephyr-sft-bnb-4bit-DPO-mtbo-180steps"}, {"eval_name": "sonthenguyen_zephyr-sft-bnb-4bit-DPO-mtbr-180steps_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/sonthenguyen/zephyr-sft-bnb-4bit-DPO-mtbr-180steps\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">sonthenguyen/zephyr-sft-bnb-4bit-DPO-mtbr-180steps</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/sonthenguyen__zephyr-sft-bnb-4bit-DPO-mtbr-180steps-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "sonthenguyen/zephyr-sft-bnb-4bit-DPO-mtbr-180steps", "Model sha": "c4ee848caf14649f9260166653d4cdb30bcfc52a", "Average \u2b06\ufe0f": 16.437642795876286, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4032190144372487, "IFEval": 40.32190144372487, "BBH Raw": 0.4305355256519051, "BBH": 21.21356840671135, "MATH Lvl 5 Raw": 0.0226586102719033, "MATH Lvl 5": 2.2658610271903323, "GPQA Raw": 0.2802013422818792, "GPQA": 4.026845637583895, "MUSR Raw": 0.42575, "MUSR": 11.785416666666665, "MMLU-PRO Raw": 0.2711103723404255, "MMLU-PRO": 19.01226359338061, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-02T00:00:00", "Submission Date": "2024-10-03T00:00:00", "Generation": 0, "Base Model": "sonthenguyen/zephyr-sft-bnb-4bit-DPO-mtbr-180steps"}, {"eval_name": "spmurrayzzz_Mistral-Syndicate-7B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/spmurrayzzz/Mistral-Syndicate-7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">spmurrayzzz/Mistral-Syndicate-7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/spmurrayzzz__Mistral-Syndicate-7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "spmurrayzzz/Mistral-Syndicate-7B", "Model sha": "c74379dd6055ef4a70339b105ea315cebec23d24", "Average \u2b06\ufe0f": 13.849172145852185, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.249595517670891, "IFEval": 24.9595517670891, "BBH Raw": 0.4245057075567853, "BBH": 20.50625197041595, "MATH Lvl 5 Raw": 0.0241691842900302, "MATH Lvl 5": 2.416918429003021, "GPQA Raw": 0.276006711409396, "GPQA": 3.467561521252797, "MUSR Raw": 0.4385520833333333, "MUSR": 13.619010416666669, "MMLU-PRO Raw": 0.2631316489361702, "MMLU-PRO": 18.125738770685576, "Maintainer's Highlight": false, "Upload To Hub Date": "2023-12-30T00:00:00", "Submission Date": "2024-06-27T00:00:00", "Generation": 1, "Base Model": "mistralai/Mistral-7B-v0.1"}, {"eval_name": "spow12_ChatWaifu_12B_v2.0_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/spow12/ChatWaifu_12B_v2.0\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">spow12/ChatWaifu_12B_v2.0</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/spow12__ChatWaifu_12B_v2.0-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "spow12/ChatWaifu_12B_v2.0", "Model sha": "1fb38700b2e2a66d4ff32636817df76285cea5f1", "Average \u2b06\ufe0f": 21.703266331752037, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 6, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4782820693537591, "IFEval": 47.82820693537591, "BBH Raw": 0.5207681738205238, "BBH": 31.16523957802424, "MATH Lvl 5 Raw": 0.052870090634441, "MATH Lvl 5": 5.287009063444108, "GPQA Raw": 0.2768456375838926, "GPQA": 3.5794183445190177, "MUSR Raw": 0.4431770833333333, "MUSR": 15.83046875, "MMLU-PRO Raw": 0.3387632978723404, "MMLU-PRO": 26.529255319148938, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-10T00:00:00", "Submission Date": "2024-10-14T00:00:00", "Generation": 1, "Base Model": "spow12/ChatWaifu_12B_v2.0 (Merge)"}, {"eval_name": "spow12_ChatWaifu_22B_v2.0_preview_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/spow12/ChatWaifu_22B_v2.0_preview\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">spow12/ChatWaifu_22B_v2.0_preview</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/spow12__ChatWaifu_22B_v2.0_preview-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "spow12/ChatWaifu_22B_v2.0_preview", "Model sha": "36af7ec06bc85405e8641986ad45c6d21353b114", "Average \u2b06\ufe0f": 29.117973350540662, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 6, "#Params (B)": 22, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6744947849483814, "IFEval": 67.44947849483815, "BBH Raw": 0.6170153091362338, "BBH": 45.48829424136917, "MATH Lvl 5 Raw": 0.1631419939577039, "MATH Lvl 5": 16.314199395770395, "GPQA Raw": 0.3154362416107382, "GPQA": 8.7248322147651, "MUSR Raw": 0.3685416666666667, "MUSR": 3.5343750000000003, "MMLU-PRO Raw": 0.3987699468085106, "MMLU-PRO": 33.19666075650118, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-23T00:00:00", "Submission Date": "2024-09-24T00:00:00", "Generation": 1, "Base Model": "spow12/ChatWaifu_22B_v2.0_preview (Merge)"}, {"eval_name": "spow12_ChatWaifu_v1.4_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/spow12/ChatWaifu_v1.4\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">spow12/ChatWaifu_v1.4</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/spow12__ChatWaifu_v1.4-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "spow12/ChatWaifu_v1.4", "Model sha": "c5b2b30a8e9fa23722b6e30aa2ca1dab7fe1c2b5", "Average \u2b06\ufe0f": 25.25356190966725, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 10, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5690567693719332, "IFEval": 56.90567693719332, "BBH Raw": 0.5176247229970669, "BBH": 31.63055380047582, "MATH Lvl 5 Raw": 0.0785498489425981, "MATH Lvl 5": 7.854984894259818, "GPQA Raw": 0.3070469798657718, "GPQA": 7.606263982102905, "MUSR Raw": 0.4743333333333333, "MUSR": 20.025, "MMLU-PRO Raw": 0.3474900265957447, "MMLU-PRO": 27.498891843971627, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-03T00:00:00", "Submission Date": "2024-09-05T00:00:00", "Generation": 1, "Base Model": "spow12/ChatWaifu_v1.4 (Merge)"}, {"eval_name": "spow12_ChatWaifu_v2.0_22B_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/spow12/ChatWaifu_v2.0_22B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">spow12/ChatWaifu_v2.0_22B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/spow12__ChatWaifu_v2.0_22B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "spow12/ChatWaifu_v2.0_22B", "Model sha": "54771319920ed791ba3f0262b036f37a92b880f2", "Average \u2b06\ufe0f": 28.838097623831437, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 5, "#Params (B)": 22, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6510891102275296, "IFEval": 65.10891102275296, "BBH Raw": 0.592630190761292, "BBH": 42.28622796334265, "MATH Lvl 5 Raw": 0.1858006042296072, "MATH Lvl 5": 18.580060422960727, "GPQA Raw": 0.3246644295302013, "GPQA": 9.955257270693512, "MUSR Raw": 0.3841979166666667, "MUSR": 5.59140625, "MMLU-PRO Raw": 0.3835605053191489, "MMLU-PRO": 31.506722813238763, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-11T00:00:00", "Submission Date": "2024-10-11T00:00:00", "Generation": 1, "Base Model": "spow12/ChatWaifu_v2.0_22B (Merge)"}, {"eval_name": "spow12_ChatWaifu_v2.0_22B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/spow12/ChatWaifu_v2.0_22B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">spow12/ChatWaifu_v2.0_22B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/spow12__ChatWaifu_v2.0_22B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "spow12/ChatWaifu_v2.0_22B", "Model sha": "a6e7c206d9af77d3f85faf0ce4a711d62815b2ab", "Average \u2b06\ufe0f": 28.64207308475029, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 5, "#Params (B)": 22, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6517384982956334, "IFEval": 65.17384982956334, "BBH Raw": 0.5908050619550995, "BBH": 42.01979809251511, "MATH Lvl 5 Raw": 0.1797583081570997, "MATH Lvl 5": 17.97583081570997, "GPQA Raw": 0.3238255033557047, "GPQA": 9.843400447427292, "MUSR Raw": 0.3841979166666667, "MUSR": 5.59140625, "MMLU-PRO Raw": 0.3812333776595745, "MMLU-PRO": 31.24815307328605, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-11T00:00:00", "Submission Date": "2024-10-14T00:00:00", "Generation": 1, "Base Model": "spow12/ChatWaifu_v2.0_22B (Merge)"}, {"eval_name": "ssmits_Qwen2.5-95B-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/ssmits/Qwen2.5-95B-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">ssmits/Qwen2.5-95B-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/ssmits__Qwen2.5-95B-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "ssmits/Qwen2.5-95B-Instruct", "Model sha": "9c0e7df57a4fcf4d364efd916a0fc0abdd2d20a3", "Average \u2b06\ufe0f": 37.42753687155684, "Hub License": "other", "Hub \u2764\ufe0f": 1, "#Params (B)": 94, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.8431051831363006, "IFEval": 84.31051831363006, "BBH Raw": 0.7037799697488242, "BBH": 58.530351322851054, "MATH Lvl 5 Raw": 0.0604229607250755, "MATH Lvl 5": 6.042296072507553, "GPQA Raw": 0.3640939597315436, "GPQA": 15.212527964205815, "MUSR Raw": 0.4283854166666667, "MUSR": 13.61484375, "MMLU-PRO Raw": 0.5216921542553191, "MMLU-PRO": 46.85468380614657, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-24T00:00:00", "Submission Date": "2024-09-26T00:00:00", "Generation": 1, "Base Model": "ssmits/Qwen2.5-95B-Instruct (Merge)"}, {"eval_name": "stabilityai_StableBeluga2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/stabilityai/StableBeluga2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">stabilityai/StableBeluga2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/stabilityai__StableBeluga2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "stabilityai/StableBeluga2", "Model sha": "cb47d3db70ea3ddc2cabdeb358c303b328f65900", "Average \u2b06\ufe0f": 22.67025367632634, "Hub License": null, "Hub \u2764\ufe0f": 881, "#Params (B)": 68, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3787140343178322, "IFEval": 37.87140343178322, "BBH Raw": 0.5824128134553807, "BBH": 41.26326112722379, "MATH Lvl 5 Raw": 0.0354984894259818, "MATH Lvl 5": 3.5498489425981874, "GPQA Raw": 0.3162751677852349, "GPQA": 8.83668903803132, "MUSR Raw": 0.47296875, "MUSR": 18.65442708333333, "MMLU-PRO Raw": 0.3326130319148936, "MMLU-PRO": 25.845892434988176, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-07-20T00:00:00", "Submission Date": "2024-06-13T00:00:00", "Generation": 0, "Base Model": "stabilityai/StableBeluga2"}, {"eval_name": "stabilityai_stablelm-2-12b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "StableLmForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/stabilityai/stablelm-2-12b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">stabilityai/stablelm-2-12b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/stabilityai__stablelm-2-12b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "stabilityai/stablelm-2-12b", "Model sha": "fead13ddbf4492970666650c3cd6f85f485411ec", "Average \u2b06\ufe0f": 13.860193776162255, "Hub License": "other", "Hub \u2764\ufe0f": 114, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1569214129620518, "IFEval": 15.69214129620518, "BBH Raw": 0.4508654171114765, "BBH": 22.685797482043984, "MATH Lvl 5 Raw": 0.0347432024169184, "MATH Lvl 5": 3.474320241691843, "GPQA Raw": 0.2785234899328859, "GPQA": 3.803131991051453, "MUSR Raw": 0.4478854166666666, "MUSR": 14.485677083333334, "MMLU-PRO Raw": 0.3071808510638298, "MMLU-PRO": 23.02009456264776, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-03-21T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "stabilityai/stablelm-2-12b"}, {"eval_name": "stabilityai_stablelm-2-12b-chat_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "StableLmForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/stabilityai/stablelm-2-12b-chat\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">stabilityai/stablelm-2-12b-chat</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/stabilityai__stablelm-2-12b-chat-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "stabilityai/stablelm-2-12b-chat", "Model sha": "b6b62cd451b84e848514c00fafa66d9ead9297c5", "Average \u2b06\ufe0f": 16.224300881101808, "Hub License": "other", "Hub \u2764\ufe0f": 86, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4081647805600252, "IFEval": 40.81647805600252, "BBH Raw": 0.4672024731282805, "BBH": 25.25369709081264, "MATH Lvl 5 Raw": 0.0203927492447129, "MATH Lvl 5": 2.0392749244712998, "GPQA Raw": 0.2667785234899328, "GPQA": 2.2371364653243813, "MUSR Raw": 0.3914270833333333, "MUSR": 7.728385416666669, "MMLU-PRO Raw": 0.2734375, "MMLU-PRO": 19.27083333333333, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-04-04T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "stabilityai/stablelm-2-12b-chat"}, {"eval_name": "stabilityai_stablelm-2-1_6b_float16", "Precision": "float16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "StableLmForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/stabilityai/stablelm-2-1_6b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">stabilityai/stablelm-2-1_6b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/stabilityai__stablelm-2-1_6b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "stabilityai/stablelm-2-1_6b", "Model sha": "8879812cccd176fbbe9ceb747b815bcc7d6499f8", "Average \u2b06\ufe0f": 5.216126538850885, "Hub License": "other", "Hub \u2764\ufe0f": 182, "#Params (B)": 1, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1157052177112284, "IFEval": 11.570521771122843, "BBH Raw": 0.338457720511071, "BBH": 8.632695204968835, "MATH Lvl 5 Raw": 0.0015105740181268, "MATH Lvl 5": 0.1510574018126888, "GPQA Raw": 0.2483221476510067, "GPQA": 0.0, "MUSR Raw": 0.3881979166666666, "MUSR": 5.791406249999999, "MMLU-PRO Raw": 0.1463597074468085, "MMLU-PRO": 5.1510786052009445, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-01-18T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "stabilityai/stablelm-2-1_6b"}, {"eval_name": "stabilityai_stablelm-2-1_6b-chat_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "StableLmForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/stabilityai/stablelm-2-1_6b-chat\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">stabilityai/stablelm-2-1_6b-chat</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/stabilityai__stablelm-2-1_6b-chat-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "stabilityai/stablelm-2-1_6b-chat", "Model sha": "f3fe67057c2789ae1bb1fe42b038da99840d4f13", "Average \u2b06\ufe0f": 8.628186472564332, "Hub License": "other", "Hub \u2764\ufe0f": 31, "#Params (B)": 1, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3059991932516833, "IFEval": 30.59991932516833, "BBH Raw": 0.3390172395486522, "BBH": 7.493378297410634, "MATH Lvl 5 Raw": 0.0105740181268882, "MATH Lvl 5": 1.0574018126888218, "GPQA Raw": 0.24748322147651, "GPQA": 0.0, "MUSR Raw": 0.35796875, "MUSR": 5.712760416666669, "MMLU-PRO Raw": 0.1621509308510638, "MMLU-PRO": 6.905658983451536, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-04-08T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "stabilityai/stablelm-2-1_6b-chat"}, {"eval_name": "stabilityai_stablelm-2-zephyr-1_6b_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "StableLmForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/stabilityai/stablelm-2-zephyr-1_6b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">stabilityai/stablelm-2-zephyr-1_6b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/stabilityai__stablelm-2-zephyr-1_6b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "stabilityai/stablelm-2-zephyr-1_6b", "Model sha": "2f275b1127d59fc31e4f7c7426d528768ada9ea4", "Average \u2b06\ufe0f": 9.256757722537667, "Hub License": "other", "Hub \u2764\ufe0f": 179, "#Params (B)": 1, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3279310008555078, "IFEval": 32.79310008555078, "BBH Raw": 0.3351608706280727, "BBH": 6.708710147938231, "MATH Lvl 5 Raw": 0.0211480362537764, "MATH Lvl 5": 2.114803625377644, "GPQA Raw": 0.2432885906040268, "GPQA": 0.0, "MUSR Raw": 0.3511458333333333, "MUSR": 5.993229166666668, "MMLU-PRO Raw": 0.171376329787234, "MMLU-PRO": 7.930703309692672, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-01-19T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "stabilityai/stablelm-2-zephyr-1_6b"}, {"eval_name": "stabilityai_stablelm-3b-4e1t_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "StableLmForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/stabilityai/stablelm-3b-4e1t\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">stabilityai/stablelm-3b-4e1t</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/stabilityai__stablelm-3b-4e1t-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "stabilityai/stablelm-3b-4e1t", "Model sha": "fa4a6a92fca83c3b4223a3c9bf792887090ebfba", "Average \u2b06\ufe0f": 7.263250707596978, "Hub License": "cc-by-sa-4.0", "Hub \u2764\ufe0f": 309, "#Params (B)": 2, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2203198624095178, "IFEval": 22.031986240951785, "BBH Raw": 0.3504211415826912, "BBH": 9.01307034954628, "MATH Lvl 5 Raw": 0.0067975830815709, "MATH Lvl 5": 0.6797583081570997, "GPQA Raw": 0.2374161073825503, "GPQA": 0.0, "MUSR Raw": 0.3777812499999999, "MUSR": 4.422656249999999, "MMLU-PRO Raw": 0.1668882978723404, "MMLU-PRO": 7.432033096926712, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-09-29T00:00:00", "Submission Date": "2024-08-10T00:00:00", "Generation": 0, "Base Model": "stabilityai/stablelm-3b-4e1t"}, {"eval_name": "stabilityai_stablelm-zephyr-3b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "StableLmForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/stabilityai/stablelm-zephyr-3b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">stabilityai/stablelm-zephyr-3b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/stabilityai__stablelm-zephyr-3b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "stabilityai/stablelm-zephyr-3b", "Model sha": "a14f62d95754d96aea2be6e24c0f6966636797b9", "Average \u2b06\ufe0f": 12.331442611850518, "Hub License": "other", "Hub \u2764\ufe0f": 246, "#Params (B)": 2, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3683227170574076, "IFEval": 36.832271705740766, "BBH Raw": 0.3866361442837871, "BBH": 14.7591192080273, "MATH Lvl 5 Raw": 0.0407854984894259, "MATH Lvl 5": 4.078549848942599, "GPQA Raw": 0.2390939597315436, "GPQA": 0.0, "MUSR Raw": 0.4183020833333333, "MUSR": 9.787760416666666, "MMLU-PRO Raw": 0.1767785904255319, "MMLU-PRO": 8.530954491725769, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-11-21T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "stabilityai/stablelm-zephyr-3b"}, {"eval_name": "sunbaby_BrainCog-8B-0.1-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/sunbaby/BrainCog-8B-0.1-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">sunbaby/BrainCog-8B-0.1-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/sunbaby__BrainCog-8B-0.1-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "sunbaby/BrainCog-8B-0.1-Instruct", "Model sha": "6c03cb7af723c7f7785df9eee5d5838247619bee", "Average \u2b06\ufe0f": 17.889696127894855, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4253004250943053, "IFEval": 42.53004250943053, "BBH Raw": 0.4618217998324744, "BBH": 24.283467839476657, "MATH Lvl 5 Raw": 0.0672205438066465, "MATH Lvl 5": 6.722054380664652, "GPQA Raw": 0.3011744966442953, "GPQA": 6.823266219239373, "MUSR Raw": 0.36559375, "MUSR": 6.332552083333334, "MMLU-PRO Raw": 0.2858211436170212, "MMLU-PRO": 20.646793735224584, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-31T00:00:00", "Submission Date": "2024-08-27T00:00:00", "Generation": 1, "Base Model": "meta-llama/Meta-Llama-3-8B"}, {"eval_name": "talha2001_Beast-Soul-new_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/talha2001/Beast-Soul-new\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">talha2001/Beast-Soul-new</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/talha2001__Beast-Soul-new-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "talha2001/Beast-Soul-new", "Model sha": "e6cf8caa60264a3005df2ff4b9d967f684519d4b", "Average \u2b06\ufe0f": 21.716749131673964, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4853510906616666, "IFEval": 48.53510906616666, "BBH Raw": 0.5227143628884523, "BBH": 33.07275916855207, "MATH Lvl 5 Raw": 0.0694864048338368, "MATH Lvl 5": 6.948640483383686, "GPQA Raw": 0.2818791946308724, "GPQA": 4.250559284116329, "MUSR Raw": 0.4459270833333333, "MUSR": 14.140885416666668, "MMLU-PRO Raw": 0.3101728723404255, "MMLU-PRO": 23.352541371158388, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-07T00:00:00", "Submission Date": "2024-08-07T00:00:00", "Generation": 1, "Base Model": "talha2001/Beast-Soul-new (Merge)"}, {"eval_name": "tangledgroup_tangled-llama-pints-1.5b-v0.1-instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/tangledgroup/tangled-llama-pints-1.5b-v0.1-instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">tangledgroup/tangled-llama-pints-1.5b-v0.1-instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/tangledgroup__tangled-llama-pints-1.5b-v0.1-instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "tangledgroup/tangled-llama-pints-1.5b-v0.1-instruct", "Model sha": "3e1429f20007740877c51e44ed63b870a57a2e17", "Average \u2b06\ufe0f": 4.17767625591689, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 1, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.1509018293682983, "IFEval": 15.090182936829834, "BBH Raw": 0.3143444469228496, "BBH": 3.8421954101765152, "MATH Lvl 5 Raw": 0.0007552870090634, "MATH Lvl 5": 0.0755287009063444, "GPQA Raw": 0.2399328859060402, "GPQA": 0.0, "MUSR Raw": 0.3761354166666666, "MUSR": 4.850260416666665, "MMLU-PRO Raw": 0.1108710106382978, "MMLU-PRO": 1.2078900709219855, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-27T00:00:00", "Submission Date": "2024-08-29T00:00:00", "Generation": 1, "Base Model": "pints-ai/1.5-Pints-16K-v0.1"}, {"eval_name": "tangledgroup_tangled-llama-pints-1.5b-v0.2-instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/tangledgroup/tangled-llama-pints-1.5b-v0.2-instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">tangledgroup/tangled-llama-pints-1.5b-v0.2-instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/tangledgroup__tangled-llama-pints-1.5b-v0.2-instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "tangledgroup/tangled-llama-pints-1.5b-v0.2-instruct", "Model sha": "5c229e26f3ab3d0f0f613ed242f3f0f57c930155", "Average \u2b06\ufe0f": 4.657740221045246, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 1, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.1724092075692496, "IFEval": 17.24092075692496, "BBH Raw": 0.3158349391752727, "BBH": 4.080205486997016, "MATH Lvl 5 Raw": 0.0075528700906344, "MATH Lvl 5": 0.7552870090634441, "GPQA Raw": 0.2416107382550335, "GPQA": 0.0, "MUSR Raw": 0.3642916666666667, "MUSR": 4.569791666666666, "MMLU-PRO Raw": 0.1117021276595744, "MMLU-PRO": 1.300236406619384, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-14T00:00:00", "Submission Date": "2024-09-15T00:00:00", "Generation": 1, "Base Model": "pints-ai/1.5-Pints-16K-v0.1"}, {"eval_name": "tanliboy_lambda-gemma-2-9b-dpo_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/tanliboy/lambda-gemma-2-9b-dpo\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">tanliboy/lambda-gemma-2-9b-dpo</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/tanliboy__lambda-gemma-2-9b-dpo-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "tanliboy/lambda-gemma-2-9b-dpo", "Model sha": "b141471308bc41ffe15180a6668c735396c3949b", "Average \u2b06\ufe0f": 21.336889814787824, "Hub License": "gemma", "Hub \u2764\ufe0f": 1, "#Params (B)": 9, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4500802315633629, "IFEval": 45.0080231563363, "BBH Raw": 0.547172399190412, "BBH": 35.554545346782085, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.313758389261745, "GPQA": 8.501118568232664, "MUSR Raw": 0.40165625, "MUSR": 7.940364583333334, "MMLU-PRO Raw": 0.379155585106383, "MMLU-PRO": 31.017287234042552, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-24T00:00:00", "Submission Date": "2024-09-18T00:00:00", "Generation": 2, "Base Model": "google/gemma-2-9b"}, {"eval_name": "tanliboy_lambda-gemma-2-9b-dpo_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/tanliboy/lambda-gemma-2-9b-dpo\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">tanliboy/lambda-gemma-2-9b-dpo</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/tanliboy__lambda-gemma-2-9b-dpo-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "tanliboy/lambda-gemma-2-9b-dpo", "Model sha": "b141471308bc41ffe15180a6668c735396c3949b", "Average \u2b06\ufe0f": 16.97010860262216, "Hub License": "gemma", "Hub \u2764\ufe0f": 1, "#Params (B)": 9, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.1829246399553185, "IFEval": 18.29246399553185, "BBH Raw": 0.5487911206515993, "BBH": 35.73966330720827, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.3104026845637584, "GPQA": 8.05369127516779, "MUSR Raw": 0.4056249999999999, "MUSR": 8.569791666666665, "MMLU-PRO Raw": 0.3804853723404255, "MMLU-PRO": 31.165041371158388, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-24T00:00:00", "Submission Date": "2024-09-18T00:00:00", "Generation": 2, "Base Model": "google/gemma-2-9b"}, {"eval_name": "tanliboy_lambda-qwen2.5-14b-dpo-test_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/tanliboy/lambda-qwen2.5-14b-dpo-test\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">tanliboy/lambda-qwen2.5-14b-dpo-test</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/tanliboy__lambda-qwen2.5-14b-dpo-test-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "tanliboy/lambda-qwen2.5-14b-dpo-test", "Model sha": "96607eea3c67f14f73e576580610dba7530c5dd9", "Average \u2b06\ufe0f": 33.51619236741214, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 4, "#Params (B)": 14, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.8231215397367873, "IFEval": 82.31215397367873, "BBH Raw": 0.6393505282981286, "BBH": 48.45443982860533, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.3624161073825503, "GPQA": 14.988814317673372, "MUSR Raw": 0.42603125, "MUSR": 12.587239583333336, "MMLU-PRO Raw": 0.4847905585106383, "MMLU-PRO": 42.75450650118203, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-20T00:00:00", "Submission Date": "2024-09-20T00:00:00", "Generation": 2, "Base Model": "Qwen/Qwen2.5-14B"}, {"eval_name": "tanliboy_lambda-qwen2.5-32b-dpo-test_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/tanliboy/lambda-qwen2.5-32b-dpo-test\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">tanliboy/lambda-qwen2.5-32b-dpo-test</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/tanliboy__lambda-qwen2.5-32b-dpo-test-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "tanliboy/lambda-qwen2.5-32b-dpo-test", "Model sha": "675b60d6e859455a6139e6e284bbe1844b8ddf46", "Average \u2b06\ufe0f": 35.753394199467664, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 3, "#Params (B)": 32, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.8083839767372794, "IFEval": 80.83839767372794, "BBH Raw": 0.6763904009446838, "BBH": 54.40796058706255, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.3565436241610738, "GPQA": 14.205816554809845, "MUSR Raw": 0.4274270833333333, "MUSR": 13.328385416666665, "MMLU-PRO Raw": 0.565658244680851, "MMLU-PRO": 51.739804964539005, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-22T00:00:00", "Submission Date": "2024-09-30T00:00:00", "Generation": 2, "Base Model": "Qwen/Qwen2.5-32B"}, {"eval_name": "teknium_CollectiveCognition-v1.1-Mistral-7B_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/teknium/CollectiveCognition-v1.1-Mistral-7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">teknium/CollectiveCognition-v1.1-Mistral-7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/teknium__CollectiveCognition-v1.1-Mistral-7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "teknium/CollectiveCognition-v1.1-Mistral-7B", "Model sha": "5f57f70ec99450c70da2540e94dd7fd67be4b23c", "Average \u2b06\ufe0f": 14.23122081884668, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 78, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2790462639130839, "IFEval": 27.9046263913084, "BBH Raw": 0.4493426704276236, "BBH": 23.47613361696592, "MATH Lvl 5 Raw": 0.0294561933534743, "MATH Lvl 5": 2.9456193353474323, "GPQA Raw": 0.2869127516778523, "GPQA": 4.921700223713646, "MUSR Raw": 0.3869270833333333, "MUSR": 5.732552083333332, "MMLU-PRO Raw": 0.2836602393617021, "MMLU-PRO": 20.40669326241135, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-10-04T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 1, "Base Model": "mistralai/Mistral-7B-v0.1"}, {"eval_name": "teknium_OpenHermes-13B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/teknium/OpenHermes-13B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">teknium/OpenHermes-13B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/teknium__OpenHermes-13B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "teknium/OpenHermes-13B", "Model sha": "bcad6fff9f8591e091d2d57356a3f102197e8c5f", "Average \u2b06\ufe0f": 12.119323740918016, "Hub License": "mit", "Hub \u2764\ufe0f": 54, "#Params (B)": 13, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2668065178171696, "IFEval": 26.680651781716957, "BBH Raw": 0.4206438452191152, "BBH": 18.21332824040884, "MATH Lvl 5 Raw": 0.0083081570996978, "MATH Lvl 5": 0.8308157099697886, "GPQA Raw": 0.2726510067114094, "GPQA": 3.0201342281879207, "MUSR Raw": 0.4042604166666666, "MUSR": 8.532552083333334, "MMLU-PRO Raw": 0.2389461436170212, "MMLU-PRO": 15.438460401891252, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-09-06T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 1, "Base Model": "NousResearch/Llama-2-13b-hf"}, {"eval_name": "teknium_OpenHermes-2-Mistral-7B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/teknium/OpenHermes-2-Mistral-7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">teknium/OpenHermes-2-Mistral-7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/teknium__OpenHermes-2-Mistral-7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "teknium/OpenHermes-2-Mistral-7B", "Model sha": "4c6e34123b140ce773a8433cae5410949289102c", "Average \u2b06\ufe0f": 21.327183071003265, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 255, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5286151854856226, "IFEval": 52.86151854856226, "BBH Raw": 0.4947516371878204, "BBH": 29.251839211223317, "MATH Lvl 5 Raw": 0.0385196374622356, "MATH Lvl 5": 3.8519637462235647, "GPQA Raw": 0.2835570469798658, "GPQA": 4.4742729306487705, "MUSR Raw": 0.4519791666666666, "MUSR": 16.064062499999995, "MMLU-PRO Raw": 0.2931349734042553, "MMLU-PRO": 21.4594414893617, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-10-12T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 1, "Base Model": "mistralai/Mistral-7B-v0.1"}, {"eval_name": "teknium_OpenHermes-2.5-Mistral-7B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/teknium/OpenHermes-2.5-Mistral-7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">teknium/OpenHermes-2.5-Mistral-7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/teknium__OpenHermes-2.5-Mistral-7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "teknium/OpenHermes-2.5-Mistral-7B", "Model sha": "24c0bea14d53e6f67f1fbe2eca5bfe7cae389b33", "Average \u2b06\ufe0f": 21.21648409288127, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 806, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5571417173100706, "IFEval": 55.71417173100706, "BBH Raw": 0.4870013259924984, "BBH": 27.770026367807574, "MATH Lvl 5 Raw": 0.0445619335347432, "MATH Lvl 5": 4.45619335347432, "GPQA Raw": 0.2835570469798658, "GPQA": 4.4742729306487705, "MUSR Raw": 0.4241979166666667, "MUSR": 12.058072916666667, "MMLU-PRO Raw": 0.3054355053191489, "MMLU-PRO": 22.826167257683213, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-10-29T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 1, "Base Model": "mistralai/Mistral-7B-v0.1"}, {"eval_name": "teknium_OpenHermes-7B_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/teknium/OpenHermes-7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">teknium/OpenHermes-7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/teknium__OpenHermes-7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "teknium/OpenHermes-7B", "Model sha": "9f55d6eb15f1edd52ee1fd863a220aa682e78a00", "Average \u2b06\ufe0f": 9.481131901453509, "Hub License": "mit", "Hub \u2764\ufe0f": 13, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1812513021006485, "IFEval": 18.12513021006485, "BBH Raw": 0.362033648602934, "BBH": 12.08139546207365, "MATH Lvl 5 Raw": 0.0105740181268882, "MATH Lvl 5": 1.0574018126888218, "GPQA Raw": 0.2692953020134228, "GPQA": 2.572706935123044, "MUSR Raw": 0.4323854166666667, "MUSR": 12.681510416666669, "MMLU-PRO Raw": 0.1933178191489361, "MMLU-PRO": 10.368646572104018, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-09-14T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 1, "Base Model": "NousResearch/Llama-2-7b-hf"}, {"eval_name": "tensoropera_Fox-1-1.6B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/tensoropera/Fox-1-1.6B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">tensoropera/Fox-1-1.6B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/tensoropera__Fox-1-1.6B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "tensoropera/Fox-1-1.6B", "Model sha": "6389dde4d7e52aa1200ad954c565f03c7fdcf8db", "Average \u2b06\ufe0f": 7.68883694753367, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 29, "#Params (B)": 1, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.276598314693901, "IFEval": 27.659831469390102, "BBH Raw": 0.3307369914593792, "BBH": 7.399760932518088, "MATH Lvl 5 Raw": 0.0128398791540785, "MATH Lvl 5": 1.283987915407855, "GPQA Raw": 0.2634228187919463, "GPQA": 1.789709172259505, "MUSR Raw": 0.3549895833333333, "MUSR": 3.873697916666666, "MMLU-PRO Raw": 0.1371343085106383, "MMLU-PRO": 4.12603427895981, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-13T00:00:00", "Submission Date": "2024-06-29T00:00:00", "Generation": 0, "Base Model": "tensoropera/Fox-1-1.6B"}, {"eval_name": "tenyx_Llama3-TenyxChat-70B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/tenyx/Llama3-TenyxChat-70B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">tenyx/Llama3-TenyxChat-70B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/tenyx__Llama3-TenyxChat-70B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "tenyx/Llama3-TenyxChat-70B", "Model sha": "a85d31e3af8fcc847cc9169f1144cf02f5351fab", "Average \u2b06\ufe0f": 36.54495720644109, "Hub License": "llama3", "Hub \u2764\ufe0f": 63, "#Params (B)": 70, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.8087086707713311, "IFEval": 80.87086707713311, "BBH Raw": 0.6511486901811531, "BBH": 49.61562001611543, "MATH Lvl 5 Raw": 0.2265861027190332, "MATH Lvl 5": 22.658610271903324, "GPQA Raw": 0.3011744966442953, "GPQA": 6.823266219239373, "MUSR Raw": 0.42603125, "MUSR": 12.520572916666667, "MMLU-PRO Raw": 0.5210272606382979, "MMLU-PRO": 46.780806737588655, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-26T00:00:00", "Submission Date": "2024-08-04T00:00:00", "Generation": 0, "Base Model": "tenyx/Llama3-TenyxChat-70B"}, {"eval_name": "theprint_Boptruth-Agatha-7B_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/theprint/Boptruth-Agatha-7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">theprint/Boptruth-Agatha-7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/theprint__Boptruth-Agatha-7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "theprint/Boptruth-Agatha-7B", "Model sha": "ef7c7570be29a58f4a8358a6d4c75f59a5282191", "Average \u2b06\ufe0f": 17.36132320486955, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.312418826491487, "IFEval": 31.241882649148703, "BBH Raw": 0.4983936045348778, "BBH": 29.286422282807493, "MATH Lvl 5 Raw": 0.04607250755287, "MATH Lvl 5": 4.607250755287009, "GPQA Raw": 0.299496644295302, "GPQA": 6.599552572706939, "MUSR Raw": 0.4276666666666666, "MUSR": 11.758333333333336, "MMLU-PRO Raw": 0.2860704787234042, "MMLU-PRO": 20.674497635933804, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-11T00:00:00", "Submission Date": "2024-09-30T00:00:00", "Generation": 0, "Base Model": "theprint/Boptruth-Agatha-7B"}, {"eval_name": "theprint_CleverBoi-7B-v2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Adapter", "Architecture": "?", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/theprint/CleverBoi-7B-v2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">theprint/CleverBoi-7B-v2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/theprint__CleverBoi-7B-v2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "theprint/CleverBoi-7B-v2", "Model sha": "1d82629c1e6778cf8568b532a3c09b668805b15a", "Average \u2b06\ufe0f": 14.970033689212386, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2169975664570007, "IFEval": 21.699756645700077, "BBH Raw": 0.4531725332163452, "BBH": 23.44418148733149, "MATH Lvl 5 Raw": 0.0188821752265861, "MATH Lvl 5": 1.8882175226586104, "GPQA Raw": 0.2885906040268456, "GPQA": 5.145413870246088, "MUSR Raw": 0.46953125, "MUSR": 18.65807291666667, "MMLU-PRO Raw": 0.2708610372340425, "MMLU-PRO": 18.98455969267139, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-12T00:00:00", "Submission Date": "2024-09-13T00:00:00", "Generation": 1, "Base Model": "unsloth/mistral-7b-v0.3-bnb-4bit"}, {"eval_name": "theprint_CleverBoi-7B-v3_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Adapter", "Architecture": "?", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/theprint/CleverBoi-7B-v3\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">theprint/CleverBoi-7B-v3</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/theprint__CleverBoi-7B-v3-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "theprint/CleverBoi-7B-v3", "Model sha": "1d82629c1e6778cf8568b532a3c09b668805b15a", "Average \u2b06\ufe0f": 13.551998140795924, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2382301183083108, "IFEval": 23.823011830831085, "BBH Raw": 0.4414430902840938, "BBH": 21.93674717909172, "MATH Lvl 5 Raw": 0.0317220543806646, "MATH Lvl 5": 3.1722054380664653, "GPQA Raw": 0.2659395973154362, "GPQA": 2.1252796420581683, "MUSR Raw": 0.4071770833333333, "MUSR": 9.497135416666667, "MMLU-PRO Raw": 0.2868184840425531, "MMLU-PRO": 20.75760933806146, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-14T00:00:00", "Submission Date": "2024-09-22T00:00:00", "Generation": 1, "Base Model": "unsloth/mistral-7b-v0.3-bnb-4bit"}, {"eval_name": "theprint_CleverBoi-Llama-3.1-8B-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Adapter", "Architecture": "?", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/theprint/CleverBoi-Llama-3.1-8B-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">theprint/CleverBoi-Llama-3.1-8B-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/theprint__CleverBoi-Llama-3.1-8B-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "theprint/CleverBoi-Llama-3.1-8B-Instruct", "Model sha": "3514c510ea4ba4d650522f467d4d0cef7de4a43c", "Average \u2b06\ufe0f": 13.554986870490154, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 16, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1681626971989875, "IFEval": 16.816269719898756, "BBH Raw": 0.4559618469185147, "BBH": 24.04860308113929, "MATH Lvl 5 Raw": 0.0241691842900302, "MATH Lvl 5": 2.416918429003021, "GPQA Raw": 0.3003355704697986, "GPQA": 6.711409395973152, "MUSR Raw": 0.4014375, "MUSR": 8.279687500000003, "MMLU-PRO Raw": 0.3075132978723404, "MMLU-PRO": 23.05703309692672, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-27T00:00:00", "Submission Date": "2024-09-13T00:00:00", "Generation": 2, "Base Model": "unsloth/Meta-Llama-3.1-8B"}, {"eval_name": "theprint_CleverBoi-Llama-3.1-8B-v2_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Adapter", "Architecture": "?", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/theprint/CleverBoi-Llama-3.1-8B-v2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">theprint/CleverBoi-Llama-3.1-8B-v2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/theprint__CleverBoi-Llama-3.1-8B-v2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "theprint/CleverBoi-Llama-3.1-8B-v2", "Model sha": "a8b0fc584b10e0110e04f9d21c7f10d24391c1d5", "Average \u2b06\ufe0f": 14.007118284898745, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 9, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1961395763241532, "IFEval": 19.613957632415325, "BBH Raw": 0.4667816011064478, "BBH": 24.132844977310707, "MATH Lvl 5 Raw": 0.0445619335347432, "MATH Lvl 5": 4.45619335347432, "GPQA Raw": 0.2860738255033557, "GPQA": 4.809843400447425, "MUSR Raw": 0.37346875, "MUSR": 6.716927083333334, "MMLU-PRO Raw": 0.3188164893617021, "MMLU-PRO": 24.31294326241135, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-15T00:00:00", "Submission Date": "2024-09-22T00:00:00", "Generation": 2, "Base Model": "meta-llama/Meta-Llama-3.1-8B"}, {"eval_name": "theprint_CleverBoi-Nemo-12B-v2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Adapter", "Architecture": "?", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/theprint/CleverBoi-Nemo-12B-v2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">theprint/CleverBoi-Nemo-12B-v2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/theprint__CleverBoi-Nemo-12B-v2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "theprint/CleverBoi-Nemo-12B-v2", "Model sha": "cd1f9ee1c484f857bb0e5ae6aac37dc434911f10", "Average \u2b06\ufe0f": 17.56886662093839, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 2, "#Params (B)": 13, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2045827293802666, "IFEval": 20.45827293802666, "BBH Raw": 0.5241085887165254, "BBH": 31.65269522562221, "MATH Lvl 5 Raw": 0.0861027190332326, "MATH Lvl 5": 8.610271903323262, "GPQA Raw": 0.313758389261745, "GPQA": 8.501118568232664, "MUSR Raw": 0.4186770833333333, "MUSR": 11.434635416666666, "MMLU-PRO Raw": 0.3228058510638298, "MMLU-PRO": 24.756205673758867, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-16T00:00:00", "Submission Date": "2024-09-24T00:00:00", "Generation": 1, "Base Model": "unsloth/Mistral-Nemo-Instruct-2407-bnb-4bit"}, {"eval_name": "theprint_Code-Llama-Bagel-8B_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/theprint/Code-Llama-Bagel-8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">theprint/Code-Llama-Bagel-8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/theprint__Code-Llama-Bagel-8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "theprint/Code-Llama-Bagel-8B", "Model sha": "7fa415f3f758ab7930d7e1df27b2d16207513125", "Average \u2b06\ufe0f": 14.476429581495234, "Hub License": "llama3", "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2529676813078188, "IFEval": 25.29676813078188, "BBH Raw": 0.4697420004900108, "BBH": 25.33815455229531, "MATH Lvl 5 Raw": 0.0498489425981873, "MATH Lvl 5": 4.984894259818732, "GPQA Raw": 0.276006711409396, "GPQA": 3.467561521252797, "MUSR Raw": 0.3679791666666667, "MUSR": 7.530729166666667, "MMLU-PRO Raw": 0.2821642287234042, "MMLU-PRO": 20.240469858156025, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-21T00:00:00", "Submission Date": "2024-09-13T00:00:00", "Generation": 1, "Base Model": "theprint/Code-Llama-Bagel-8B (Merge)"}, {"eval_name": "theprint_ReWiz-7B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Adapter", "Architecture": "?", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/theprint/ReWiz-7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">theprint/ReWiz-7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/theprint__ReWiz-7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "theprint/ReWiz-7B", "Model sha": "d9f28e67d52181d1478e7788e3edf252f5bf32a8", "Average \u2b06\ufe0f": 17.535278312366717, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4047926169230973, "IFEval": 40.47926169230973, "BBH Raw": 0.4564215411912313, "BBH": 23.50442985462492, "MATH Lvl 5 Raw": 0.0256797583081571, "MATH Lvl 5": 2.56797583081571, "GPQA Raw": 0.2751677852348993, "GPQA": 3.355704697986576, "MUSR Raw": 0.46115625, "MUSR": 16.744531249999998, "MMLU-PRO Raw": 0.2670378989361702, "MMLU-PRO": 18.559766548463354, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-08T00:00:00", "Submission Date": "2024-10-08T00:00:00", "Generation": 1, "Base Model": "unsloth/mistral-7b-instruct-v0.3-bnb-4bit"}, {"eval_name": "theprint_phi-3-mini-4k-python_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Adapter", "Architecture": "?", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/theprint/phi-3-mini-4k-python\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">theprint/phi-3-mini-4k-python</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/theprint__phi-3-mini-4k-python-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "theprint/phi-3-mini-4k-python", "Model sha": "81453e5718775630581ab9950e6c0ccf0d7a4177", "Average \u2b06\ufe0f": 17.388258990039734, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 4, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2408775382651365, "IFEval": 24.08775382651365, "BBH Raw": 0.493759004635898, "BBH": 28.44601616578647, "MATH Lvl 5 Raw": 0.0845921450151057, "MATH Lvl 5": 8.459214501510575, "GPQA Raw": 0.2911073825503356, "GPQA": 5.480984340044745, "MUSR Raw": 0.3921666666666666, "MUSR": 9.22083333333333, "MMLU-PRO Raw": 0.3577127659574468, "MMLU-PRO": 28.63475177304965, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-03T00:00:00", "Submission Date": "2024-09-13T00:00:00", "Generation": 1, "Base Model": "unsloth/Phi-3-mini-4k-instruct-bnb-4bit"}, {"eval_name": "thomas-yanxin_XinYuan-Qwen2-1_5B_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/thomas-yanxin/XinYuan-Qwen2-1_5B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">thomas-yanxin/XinYuan-Qwen2-1_5B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/thomas-yanxin__XinYuan-Qwen2-1_5B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "thomas-yanxin/XinYuan-Qwen2-1_5B", "Model sha": "a01b362887832bea08d686737861ac3d5b437a32", "Average \u2b06\ufe0f": 11.414386328951702, "Hub License": "other", "Hub \u2764\ufe0f": 1, "#Params (B)": 1, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2985556102253133, "IFEval": 29.85556102253133, "BBH Raw": 0.3635491993150823, "BBH": 12.12557956003766, "MATH Lvl 5 Raw": 0.0611782477341389, "MATH Lvl 5": 6.117824773413897, "GPQA Raw": 0.2701342281879195, "GPQA": 2.684563758389265, "MUSR Raw": 0.3633958333333333, "MUSR": 2.6244791666666685, "MMLU-PRO Raw": 0.2357047872340425, "MMLU-PRO": 15.078309692671397, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-25T00:00:00", "Submission Date": "2024-09-04T00:00:00", "Generation": 1, "Base Model": "Removed"}, {"eval_name": "thomas-yanxin_XinYuan-Qwen2-7B_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/thomas-yanxin/XinYuan-Qwen2-7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">thomas-yanxin/XinYuan-Qwen2-7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/thomas-yanxin__XinYuan-Qwen2-7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "thomas-yanxin/XinYuan-Qwen2-7B", "Model sha": "c62d83eee2f4812ac17fc17d307f4aa1a77c5359", "Average \u2b06\ufe0f": 22.003715685780747, "Hub License": "other", "Hub \u2764\ufe0f": 1, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4437603336923806, "IFEval": 44.37603336923807, "BBH Raw": 0.4936629157238895, "BBH": 28.40148852275863, "MATH Lvl 5 Raw": 0.1200906344410876, "MATH Lvl 5": 12.009063444108762, "GPQA Raw": 0.2911073825503356, "GPQA": 5.480984340044745, "MUSR Raw": 0.4058124999999999, "MUSR": 9.259895833333337, "MMLU-PRO Raw": 0.3924534574468085, "MMLU-PRO": 32.494828605200944, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-21T00:00:00", "Submission Date": "2024-09-03T00:00:00", "Generation": 0, "Base Model": "thomas-yanxin/XinYuan-Qwen2-7B"}, {"eval_name": "thomas-yanxin_XinYuan-Qwen2-7B-0917_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/thomas-yanxin/XinYuan-Qwen2-7B-0917\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">thomas-yanxin/XinYuan-Qwen2-7B-0917</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/thomas-yanxin__XinYuan-Qwen2-7B-0917-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "thomas-yanxin/XinYuan-Qwen2-7B-0917", "Model sha": "6cee1b155fca9ae1f558f434953dfdadb9596af0", "Average \u2b06\ufe0f": 22.595735363963104, "Hub License": "other", "Hub \u2764\ufe0f": 4, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3719198393595659, "IFEval": 37.19198393595659, "BBH Raw": 0.5169215573786009, "BBH": 32.61993813582105, "MATH Lvl 5 Raw": 0.0808157099697885, "MATH Lvl 5": 8.08157099697885, "GPQA Raw": 0.3095637583892617, "GPQA": 7.941834451901568, "MUSR Raw": 0.4401041666666667, "MUSR": 13.6796875, "MMLU-PRO Raw": 0.4245345744680851, "MMLU-PRO": 36.059397163120565, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-17T00:00:00", "Submission Date": "2024-09-17T00:00:00", "Generation": 0, "Base Model": "thomas-yanxin/XinYuan-Qwen2-7B-0917"}, {"eval_name": "thomas-yanxin_XinYuan-Qwen2.5-7B-0917_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/thomas-yanxin/XinYuan-Qwen2.5-7B-0917\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">thomas-yanxin/XinYuan-Qwen2.5-7B-0917</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/thomas-yanxin__XinYuan-Qwen2.5-7B-0917-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "thomas-yanxin/XinYuan-Qwen2.5-7B-0917", "Model sha": "bbbeafd1003c4d5e13f09b7223671957384b961a", "Average \u2b06\ufe0f": 18.175036981235262, "Hub License": "other", "Hub \u2764\ufe0f": 4, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3577064411317526, "IFEval": 35.770644113175265, "BBH Raw": 0.5184106116987492, "BBH": 33.43966927024198, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2810402684563758, "GPQA": 4.138702460850116, "MUSR Raw": 0.3675520833333333, "MUSR": 3.677343750000001, "MMLU-PRO Raw": 0.3882147606382978, "MMLU-PRO": 32.023862293144205, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-17T00:00:00", "Submission Date": "2024-09-24T00:00:00", "Generation": 0, "Base Model": "thomas-yanxin/XinYuan-Qwen2.5-7B-0917"}, {"eval_name": "tiiuae_falcon-11B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "FalconForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/tiiuae/falcon-11B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">tiiuae/falcon-11B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/tiiuae__falcon-11B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "tiiuae/falcon-11B", "Model sha": "066e3bf4e2d9aaeefa129af0a6d39727d27816b3", "Average \u2b06\ufe0f": 13.776373885273868, "Hub License": "unknown", "Hub \u2764\ufe0f": 208, "#Params (B)": 11, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3261324397044287, "IFEval": 32.613243970442866, "BBH Raw": 0.4391637035549384, "BBH": 21.937999462890275, "MATH Lvl 5 Raw": 0.0234138972809667, "MATH Lvl 5": 2.3413897280966767, "GPQA Raw": 0.2709731543624161, "GPQA": 2.796420581655479, "MUSR Raw": 0.3986458333333333, "MUSR": 7.530729166666667, "MMLU-PRO Raw": 0.2389461436170212, "MMLU-PRO": 15.438460401891252, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-05-09T00:00:00", "Submission Date": "2024-06-09T00:00:00", "Generation": 0, "Base Model": "tiiuae/falcon-11B"}, {"eval_name": "tiiuae_falcon-40b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "FalconForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/tiiuae/falcon-40b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">tiiuae/falcon-40b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/tiiuae__falcon-40b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "tiiuae/falcon-40b", "Model sha": "4a70170c215b36a3cce4b4253f6d0612bb7d4146", "Average \u2b06\ufe0f": 11.325775761393745, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 2419, "#Params (B)": 40, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2496453853553017, "IFEval": 24.96453853553017, "BBH Raw": 0.4018532495595801, "BBH": 16.583304730312175, "MATH Lvl 5 Raw": 0.0135951661631419, "MATH Lvl 5": 1.3595166163141994, "GPQA Raw": 0.273489932885906, "GPQA": 3.1319910514541416, "MUSR Raw": 0.3631458333333333, "MUSR": 5.193229166666668, "MMLU-PRO Raw": 0.2504986702127659, "MMLU-PRO": 16.722074468085104, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-05-24T00:00:00", "Submission Date": "2024-06-09T00:00:00", "Generation": 0, "Base Model": "tiiuae/falcon-40b"}, {"eval_name": "tiiuae_falcon-40b-instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "FalconForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/tiiuae/falcon-40b-instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">tiiuae/falcon-40b-instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/tiiuae__falcon-40b-instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "tiiuae/falcon-40b-instruct", "Model sha": "ecb78d97ac356d098e79f0db222c9ce7c5d9ee5f", "Average \u2b06\ufe0f": 10.408978081192403, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1172, "#Params (B)": 40, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2454487426694503, "IFEval": 24.54487426694504, "BBH Raw": 0.4053867515159197, "BBH": 17.220114203264526, "MATH Lvl 5 Raw": 0.0151057401812688, "MATH Lvl 5": 1.5105740181268883, "GPQA Raw": 0.25, "GPQA": 0.0, "MUSR Raw": 0.3762291666666666, "MUSR": 5.161979166666666, "MMLU-PRO Raw": 0.2261469414893617, "MMLU-PRO": 14.016326832151298, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-05-25T00:00:00", "Submission Date": "2024-06-09T00:00:00", "Generation": 0, "Base Model": "tiiuae/falcon-40b-instruct"}, {"eval_name": "tiiuae_falcon-7b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "FalconForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/tiiuae/falcon-7b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">tiiuae/falcon-7b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/tiiuae__falcon-7b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "tiiuae/falcon-7b", "Model sha": "898df1396f35e447d5fe44e0a3ccaaaa69f30d36", "Average \u2b06\ufe0f": 5.097916019413136, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1073, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.182051401392749, "IFEval": 18.205140139274903, "BBH Raw": 0.3285244611732221, "BBH": 5.963936911876051, "MATH Lvl 5 Raw": 0.0052870090634441, "MATH Lvl 5": 0.5287009063444109, "GPQA Raw": 0.2449664429530201, "GPQA": 0.0, "MUSR Raw": 0.37784375, "MUSR": 4.497135416666667, "MMLU-PRO Raw": 0.112533244680851, "MMLU-PRO": 1.392582742316784, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-04-24T00:00:00", "Submission Date": "2024-06-09T00:00:00", "Generation": 0, "Base Model": "tiiuae/falcon-7b"}, {"eval_name": "tiiuae_falcon-7b-instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "FalconForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/tiiuae/falcon-7b-instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">tiiuae/falcon-7b-instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/tiiuae__falcon-7b-instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "tiiuae/falcon-7b-instruct", "Model sha": "cf4b3c42ce2fdfe24f753f0f0d179202fea59c99", "Average \u2b06\ufe0f": 5.015868974143408, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 909, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1968886997610783, "IFEval": 19.68886997610784, "BBH Raw": 0.3203422151235576, "BBH": 4.823178460674432, "MATH Lvl 5 Raw": 0.0060422960725075, "MATH Lvl 5": 0.6042296072507553, "GPQA Raw": 0.24748322147651, "GPQA": 0.0, "MUSR Raw": 0.3633645833333334, "MUSR": 3.2539062500000004, "MMLU-PRO Raw": 0.1155252659574468, "MMLU-PRO": 1.725029550827422, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-04-25T00:00:00", "Submission Date": "2024-06-09T00:00:00", "Generation": 0, "Base Model": "tiiuae/falcon-7b-instruct"}, {"eval_name": "tiiuae_falcon-mamba-7b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "FalconMambaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/tiiuae/falcon-mamba-7b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">tiiuae/falcon-mamba-7b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/tiiuae__falcon-mamba-7b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "tiiuae/falcon-mamba-7b", "Model sha": "5337fd73f19847e111ba2291f3f0e1617b90c37d", "Average \u2b06\ufe0f": 15.040768742616253, "Hub License": "other", "Hub \u2764\ufe0f": 208, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3335760227307987, "IFEval": 33.35760227307987, "BBH Raw": 0.4284854988604366, "BBH": 19.87687780354344, "MATH Lvl 5 Raw": 0.0362537764350453, "MATH Lvl 5": 3.625377643504532, "GPQA Raw": 0.3104026845637584, "GPQA": 8.05369127516779, "MUSR Raw": 0.4210312499999999, "MUSR": 10.862239583333334, "MMLU-PRO Raw": 0.230219414893617, "MMLU-PRO": 14.468823877068557, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-07-17T00:00:00", "Submission Date": "2024-07-23T00:00:00", "Generation": 0, "Base Model": "tiiuae/falcon-mamba-7b"}, {"eval_name": "tklohj_WindyFloLLM_float16", "Precision": "float16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/tklohj/WindyFloLLM\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">tklohj/WindyFloLLM</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/tklohj__WindyFloLLM-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "tklohj/WindyFloLLM", "Model sha": "21f4241ab3f091d1d309e9076a8d8e3f014908a8", "Average \u2b06\ufe0f": 14.168126702681912, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 13, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2668563855015802, "IFEval": 26.685638550158025, "BBH Raw": 0.4636616007058791, "BBH": 24.39876319785054, "MATH Lvl 5 Raw": 0.0113293051359516, "MATH Lvl 5": 1.1329305135951662, "GPQA Raw": 0.2751677852348993, "GPQA": 3.355704697986576, "MUSR Raw": 0.4253125, "MUSR": 11.864062500000005, "MMLU-PRO Raw": 0.2581449468085106, "MMLU-PRO": 17.57166075650118, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-30T00:00:00", "Submission Date": "2024-07-10T00:00:00", "Generation": 1, "Base Model": "tklohj/WindyFloLLM (Merge)"}, {"eval_name": "togethercomputer_GPT-JT-6B-v1_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "GPTJForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/togethercomputer/GPT-JT-6B-v1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">togethercomputer/GPT-JT-6B-v1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/togethercomputer__GPT-JT-6B-v1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "togethercomputer/GPT-JT-6B-v1", "Model sha": "f34aa35f906895602c1f86f5685e598afdea8051", "Average \u2b06\ufe0f": 6.827354360467209, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 302, "#Params (B)": 6, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2061064641817045, "IFEval": 20.61064641817045, "BBH Raw": 0.330266091274267, "BBH": 7.318523965141613, "MATH Lvl 5 Raw": 0.0075528700906344, "MATH Lvl 5": 0.7552870090634441, "GPQA Raw": 0.2609060402684564, "GPQA": 1.45413870246085, "MUSR Raw": 0.37365625, "MUSR": 3.873697916666666, "MMLU-PRO Raw": 0.1625664893617021, "MMLU-PRO": 6.951832151300234, "Maintainer's Highlight": true, "Upload To Hub Date": "2022-11-24T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "togethercomputer/GPT-JT-6B-v1"}, {"eval_name": "togethercomputer_GPT-NeoXT-Chat-Base-20B_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "GPTNeoXForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/togethercomputer/GPT-NeoXT-Chat-Base-20B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">togethercomputer/GPT-NeoXT-Chat-Base-20B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/togethercomputer__GPT-NeoXT-Chat-Base-20B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "togethercomputer/GPT-NeoXT-Chat-Base-20B", "Model sha": "d386708e84d862a65f7d2b4989f64750cb657227", "Average \u2b06\ufe0f": 4.938885587628826, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 694, "#Params (B)": 20, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1829756158104939, "IFEval": 18.297561581049397, "BBH Raw": 0.3320970257217303, "BBH": 6.830794983137852, "MATH Lvl 5 Raw": 0.0113293051359516, "MATH Lvl 5": 1.1329305135951662, "GPQA Raw": 0.25, "GPQA": 0.0, "MUSR Raw": 0.3460625, "MUSR": 1.7578124999999991, "MMLU-PRO Raw": 0.1145279255319148, "MMLU-PRO": 1.6142139479905429, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-03-03T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "togethercomputer/GPT-NeoXT-Chat-Base-20B"}, {"eval_name": "togethercomputer_LLaMA-2-7B-32K_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/togethercomputer/LLaMA-2-7B-32K\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">togethercomputer/LLaMA-2-7B-32K</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/togethercomputer__LLaMA-2-7B-32K-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "togethercomputer/LLaMA-2-7B-32K", "Model sha": "46c24bb5aef59722fa7aa6d75e832afd1d64b980", "Average \u2b06\ufe0f": 6.711834699417412, "Hub License": "llama2", "Hub \u2764\ufe0f": 533, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1864973825006538, "IFEval": 18.649738250065383, "BBH Raw": 0.3399517521730171, "BBH": 8.089984229889549, "MATH Lvl 5 Raw": 0.0067975830815709, "MATH Lvl 5": 0.6797583081570997, "GPQA Raw": 0.25, "GPQA": 0.0, "MUSR Raw": 0.3753645833333333, "MUSR": 4.320572916666666, "MMLU-PRO Raw": 0.1767785904255319, "MMLU-PRO": 8.530954491725769, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-07-26T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "togethercomputer/LLaMA-2-7B-32K"}, {"eval_name": "togethercomputer_Llama-2-7B-32K-Instruct_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/togethercomputer/Llama-2-7B-32K-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">togethercomputer/Llama-2-7B-32K-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/togethercomputer__Llama-2-7B-32K-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "togethercomputer/Llama-2-7B-32K-Instruct", "Model sha": "d27380af003252f5eb0d218e104938b4e673e3f3", "Average \u2b06\ufe0f": 8.170425368064842, "Hub License": "llama2", "Hub \u2764\ufe0f": 160, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2130003945087922, "IFEval": 21.300039450879225, "BBH Raw": 0.3443472423992754, "BBH": 8.563469919446954, "MATH Lvl 5 Raw": 0.0105740181268882, "MATH Lvl 5": 1.0574018126888218, "GPQA Raw": 0.2516778523489933, "GPQA": 0.2237136465324418, "MUSR Raw": 0.40559375, "MUSR": 9.199218750000002, "MMLU-PRO Raw": 0.1781083776595744, "MMLU-PRO": 8.678708628841607, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-08-08T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "togethercomputer/Llama-2-7B-32K-Instruct"}, {"eval_name": "togethercomputer_RedPajama-INCITE-7B-Base_float16", "Precision": "float16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "GPTNeoXForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/togethercomputer/RedPajama-INCITE-7B-Base\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">togethercomputer/RedPajama-INCITE-7B-Base</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/togethercomputer__RedPajama-INCITE-7B-Base-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "togethercomputer/RedPajama-INCITE-7B-Base", "Model sha": "78f7e482443971f4873ba3239f0ac810a367833b", "Average \u2b06\ufe0f": 5.461109359493478, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 94, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2082297193668355, "IFEval": 20.822971936683555, "BBH Raw": 0.3194889876501344, "BBH": 5.087242272916432, "MATH Lvl 5 Raw": 0.0098187311178247, "MATH Lvl 5": 0.9818731117824772, "GPQA Raw": 0.2550335570469799, "GPQA": 0.6711409395973182, "MUSR Raw": 0.3619999999999999, "MUSR": 3.0166666666666657, "MMLU-PRO Raw": 0.1196808510638298, "MMLU-PRO": 2.186761229314421, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-05-04T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "togethercomputer/RedPajama-INCITE-7B-Base"}, {"eval_name": "togethercomputer_RedPajama-INCITE-7B-Chat_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "GPTNeoXForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/togethercomputer/RedPajama-INCITE-7B-Chat\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">togethercomputer/RedPajama-INCITE-7B-Chat</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/togethercomputer__RedPajama-INCITE-7B-Chat-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "togethercomputer/RedPajama-INCITE-7B-Chat", "Model sha": "47b94a739e2f3164b438501c8684acc5d5acc146", "Average \u2b06\ufe0f": 3.962783773521173, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 92, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1557977278066641, "IFEval": 15.57977278066641, "BBH Raw": 0.3175449328457368, "BBH": 4.502173664381199, "MATH Lvl 5 Raw": 0.0015105740181268, "MATH Lvl 5": 0.1510574018126888, "GPQA Raw": 0.2525167785234899, "GPQA": 0.3355704697986553, "MUSR Raw": 0.3447604166666667, "MUSR": 1.86171875, "MMLU-PRO Raw": 0.1121176861702127, "MMLU-PRO": 1.3464095744680846, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-05-04T00:00:00", "Submission Date": "2024-06-13T00:00:00", "Generation": 0, "Base Model": "togethercomputer/RedPajama-INCITE-7B-Chat"}, {"eval_name": "togethercomputer_RedPajama-INCITE-7B-Instruct_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "GPTNeoXForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/togethercomputer/RedPajama-INCITE-7B-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">togethercomputer/RedPajama-INCITE-7B-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/togethercomputer__RedPajama-INCITE-7B-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "togethercomputer/RedPajama-INCITE-7B-Instruct", "Model sha": "7f36397b9985a3f981cdb618f8fec1c565ca5927", "Average \u2b06\ufe0f": 6.330844324541082, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 104, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2055069437980115, "IFEval": 20.55069437980115, "BBH Raw": 0.337743947089799, "BBH": 7.9054164937041635, "MATH Lvl 5 Raw": 0.0135951661631419, "MATH Lvl 5": 1.3595166163141994, "GPQA Raw": 0.2508389261744966, "GPQA": 0.1118568232662209, "MUSR Raw": 0.3685104166666666, "MUSR": 5.03046875, "MMLU-PRO Raw": 0.1272440159574468, "MMLU-PRO": 3.027112884160755, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-05-05T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "togethercomputer/RedPajama-INCITE-7B-Instruct"}, {"eval_name": "togethercomputer_RedPajama-INCITE-Base-3B-v1_float16", "Precision": "float16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "GPTNeoXForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/togethercomputer/RedPajama-INCITE-Base-3B-v1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">togethercomputer/RedPajama-INCITE-Base-3B-v1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/togethercomputer__RedPajama-INCITE-Base-3B-v1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "togethercomputer/RedPajama-INCITE-Base-3B-v1", "Model sha": "094fbdd0c911feb485ce55de1952ab2e75277e1e", "Average \u2b06\ufe0f": 5.432973566930115, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 90, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2293625358493242, "IFEval": 22.936253584932423, "BBH Raw": 0.3060403878987615, "BBH": 3.518607767474259, "MATH Lvl 5 Raw": 0.0090634441087613, "MATH Lvl 5": 0.906344410876133, "GPQA Raw": 0.2432885906040268, "GPQA": 0.0, "MUSR Raw": 0.3738749999999999, "MUSR": 4.001041666666667, "MMLU-PRO Raw": 0.1111203457446808, "MMLU-PRO": 1.2355939716312052, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-05-04T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "togethercomputer/RedPajama-INCITE-Base-3B-v1"}, {"eval_name": "togethercomputer_RedPajama-INCITE-Chat-3B-v1_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "GPTNeoXForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/togethercomputer/RedPajama-INCITE-Chat-3B-v1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">togethercomputer/RedPajama-INCITE-Chat-3B-v1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/togethercomputer__RedPajama-INCITE-Chat-3B-v1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "togethercomputer/RedPajama-INCITE-Chat-3B-v1", "Model sha": "f0e0995eba801096ed04cb87931d96a8316871af", "Average \u2b06\ufe0f": 4.748118992215374, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 152, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.165214962964933, "IFEval": 16.521496296493304, "BBH Raw": 0.3216693711920241, "BBH": 5.164727927050627, "MATH Lvl 5 Raw": 0.0030211480362537, "MATH Lvl 5": 0.3021148036253776, "GPQA Raw": 0.2441275167785234, "GPQA": 0.0, "MUSR Raw": 0.3684479166666667, "MUSR": 5.089322916666668, "MMLU-PRO Raw": 0.1126994680851063, "MMLU-PRO": 1.4110520094562635, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-05-05T00:00:00", "Submission Date": "2024-06-13T00:00:00", "Generation": 0, "Base Model": "togethercomputer/RedPajama-INCITE-Chat-3B-v1"}, {"eval_name": "togethercomputer_RedPajama-INCITE-Instruct-3B-v1_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "GPTNeoXForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/togethercomputer/RedPajama-INCITE-Instruct-3B-v1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">togethercomputer/RedPajama-INCITE-Instruct-3B-v1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/togethercomputer__RedPajama-INCITE-Instruct-3B-v1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "togethercomputer/RedPajama-INCITE-Instruct-3B-v1", "Model sha": "0c66778ee09a036886741707733620b91057909a", "Average \u2b06\ufe0f": 5.66393850876747, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 93, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2124263620526869, "IFEval": 21.24263620526869, "BBH Raw": 0.3146017752057237, "BBH": 4.510786368926982, "MATH Lvl 5 Raw": 0.0060422960725075, "MATH Lvl 5": 0.6042296072507553, "GPQA Raw": 0.24748322147651, "GPQA": 0.0, "MUSR Raw": 0.3886041666666666, "MUSR": 6.408854166666669, "MMLU-PRO Raw": 0.1109541223404255, "MMLU-PRO": 1.2171247044917255, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-05-05T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "togethercomputer/RedPajama-INCITE-Instruct-3B-v1"}, {"eval_name": "tokyotech-llm_Llama-3-Swallow-8B-Instruct-v0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/tokyotech-llm__Llama-3-Swallow-8B-Instruct-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "Model sha": "1fae784584dd03680b72dd4de7eefbc5b7cabcd5", "Average \u2b06\ufe0f": 22.206680532915925, "Hub License": "llama3", "Hub \u2764\ufe0f": 15, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5507719517546776, "IFEval": 55.07719517546776, "BBH Raw": 0.5009389976232003, "BBH": 29.267966131617708, "MATH Lvl 5 Raw": 0.066465256797583, "MATH Lvl 5": 6.646525679758309, "GPQA Raw": 0.2894295302013422, "GPQA": 5.257270693512303, "MUSR Raw": 0.4356979166666666, "MUSR": 13.795572916666664, "MMLU-PRO Raw": 0.3087599734042553, "MMLU-PRO": 23.19555260047281, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-26T00:00:00", "Submission Date": "2024-09-12T00:00:00", "Generation": 0, "Base Model": "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1"}, {"eval_name": "upstage_SOLAR-10.7B-Instruct-v1.0_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/upstage/SOLAR-10.7B-Instruct-v1.0\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">upstage/SOLAR-10.7B-Instruct-v1.0</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/upstage__SOLAR-10.7B-Instruct-v1.0-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "upstage/SOLAR-10.7B-Instruct-v1.0", "Model sha": "c08c25ed66414a878fe0401a3596d536c083606c", "Average \u2b06\ufe0f": 19.62825533189465, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 612, "#Params (B)": 10, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4736609972650345, "IFEval": 47.36609972650345, "BBH Raw": 0.5162494941446991, "BBH": 31.87240188800212, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.3087248322147651, "GPQA": 7.829977628635347, "MUSR Raw": 0.3899375, "MUSR": 6.942187500000002, "MMLU-PRO Raw": 0.3138297872340425, "MMLU-PRO": 23.758865248226947, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-12-12T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 1, "Base Model": "upstage/SOLAR-10.7B-Instruct-v1.0 (Merge)"}, {"eval_name": "upstage_SOLAR-10.7B-v1.0_float16", "Precision": "float16", "Type": "\ud83d\udfe2 pretrained", "T": "\ud83d\udfe2", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/upstage/SOLAR-10.7B-v1.0\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">upstage/SOLAR-10.7B-v1.0</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/upstage__SOLAR-10.7B-v1.0-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "upstage/SOLAR-10.7B-v1.0", "Model sha": "a45090b8e56bdc2b8e32e46b3cd782fc0bea1fa5", "Average \u2b06\ufe0f": 4.526216264931456, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 287, "#Params (B)": 10, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.171584728520326, "IFEval": 17.158472852032606, "BBH Raw": 0.2998351737549512, "BBH": 2.147162763818688, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2609060402684564, "GPQA": 1.45413870246085, "MUSR Raw": 0.3681979166666667, "MUSR": 4.524739583333332, "MMLU-PRO Raw": 0.1168550531914893, "MMLU-PRO": 1.8727836879432624, "Maintainer's Highlight": true, "Upload To Hub Date": "2023-12-12T00:00:00", "Submission Date": "2024-06-12T00:00:00", "Generation": 0, "Base Model": "upstage/SOLAR-10.7B-v1.0"}, {"eval_name": "upstage_solar-pro-preview-instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "SolarForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/upstage/solar-pro-preview-instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">upstage/solar-pro-preview-instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/upstage__solar-pro-preview-instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "upstage/solar-pro-preview-instruct", "Model sha": "b4db141b5fb08b23f8bc323bc34e2cff3e9675f8", "Average \u2b06\ufe0f": 39.61136382727226, "Hub License": "mit", "Hub \u2764\ufe0f": 406, "#Params (B)": 22, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.8415814483348626, "IFEval": 84.15814483348626, "BBH Raw": 0.6816843051379534, "BBH": 54.82235099983529, "MATH Lvl 5 Raw": 0.2009063444108761, "MATH Lvl 5": 20.09063444108761, "GPQA Raw": 0.3708053691275167, "GPQA": 16.10738255033557, "MUSR Raw": 0.44165625, "MUSR": 15.007031249999995, "MMLU-PRO Raw": 0.52734375, "MMLU-PRO": 47.48263888888889, "Maintainer's Highlight": true, "Upload To Hub Date": "2024-09-09T00:00:00", "Submission Date": "2024-09-11T00:00:00", "Generation": 0, "Base Model": "upstage/solar-pro-preview-instruct"}, {"eval_name": "uukuguy_speechless-code-mistral-7b-v1.0_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/uukuguy/speechless-code-mistral-7b-v1.0\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">uukuguy/speechless-code-mistral-7b-v1.0</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/uukuguy__speechless-code-mistral-7b-v1.0-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "uukuguy/speechless-code-mistral-7b-v1.0", "Model sha": "1862e0a712efc6002112e9c1235a197d58419b37", "Average \u2b06\ufe0f": 18.09188675578363, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 18, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3665241559063285, "IFEval": 36.652415590632856, "BBH Raw": 0.4571712887094195, "BBH": 24.091412067845624, "MATH Lvl 5 Raw": 0.04607250755287, "MATH Lvl 5": 4.607250755287009, "GPQA Raw": 0.2843959731543624, "GPQA": 4.586129753914992, "MUSR Raw": 0.4501770833333333, "MUSR": 14.772135416666666, "MMLU-PRO Raw": 0.3145777925531915, "MMLU-PRO": 23.841976950354614, "Maintainer's Highlight": false, "Upload To Hub Date": "2023-10-10T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "uukuguy/speechless-code-mistral-7b-v1.0"}, {"eval_name": "uukuguy_speechless-codellama-34b-v2.0_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/uukuguy/speechless-codellama-34b-v2.0\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">uukuguy/speechless-codellama-34b-v2.0</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/uukuguy__speechless-codellama-34b-v2.0-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "uukuguy/speechless-codellama-34b-v2.0", "Model sha": "419bc42a254102d6a5486a1a854068e912c4047c", "Average \u2b06\ufe0f": 17.209357596769955, "Hub License": "llama2", "Hub \u2764\ufe0f": 17, "#Params (B)": 34, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4604216811393768, "IFEval": 46.04216811393768, "BBH Raw": 0.4813126697444618, "BBH": 25.99329326784064, "MATH Lvl 5 Raw": 0.0430513595166163, "MATH Lvl 5": 4.305135951661631, "GPQA Raw": 0.2692953020134229, "GPQA": 2.572706935123052, "MUSR Raw": 0.3787083333333333, "MUSR": 7.205208333333334, "MMLU-PRO Raw": 0.2542386968085106, "MMLU-PRO": 17.137632978723403, "Maintainer's Highlight": false, "Upload To Hub Date": "2023-10-04T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "uukuguy/speechless-codellama-34b-v2.0"}, {"eval_name": "uukuguy_speechless-coder-ds-6.7b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/uukuguy/speechless-coder-ds-6.7b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">uukuguy/speechless-coder-ds-6.7b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/uukuguy__speechless-coder-ds-6.7b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "uukuguy/speechless-coder-ds-6.7b", "Model sha": "c813a5268c6dfe267a720ad3b51773f1ab0feb59", "Average \u2b06\ufe0f": 9.63932330169255, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 5, "#Params (B)": 6, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2504698644042252, "IFEval": 25.04698644042252, "BBH Raw": 0.4036373344669979, "BBH": 15.897457343156352, "MATH Lvl 5 Raw": 0.0166163141993957, "MATH Lvl 5": 1.6616314199395772, "GPQA Raw": 0.2642617449664429, "GPQA": 1.9015659955257265, "MUSR Raw": 0.3819375, "MUSR": 5.3421875000000005, "MMLU-PRO Raw": 0.171875, "MMLU-PRO": 7.986111111111111, "Maintainer's Highlight": false, "Upload To Hub Date": "2023-12-30T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "uukuguy/speechless-coder-ds-6.7b"}, {"eval_name": "uukuguy_speechless-instruct-mistral-7b-v0.2_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/uukuguy/speechless-instruct-mistral-7b-v0.2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">uukuguy/speechless-instruct-mistral-7b-v0.2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/uukuguy__speechless-instruct-mistral-7b-v0.2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "uukuguy/speechless-instruct-mistral-7b-v0.2", "Model sha": "87a4d214f7d028d61c3dc013a7410b3c34a24072", "Average \u2b06\ufe0f": 18.018596667256222, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3261324397044287, "IFEval": 32.613243970442866, "BBH Raw": 0.4606667950681749, "BBH": 24.558747365322688, "MATH Lvl 5 Raw": 0.0438066465256797, "MATH Lvl 5": 4.380664652567976, "GPQA Raw": 0.2818791946308724, "GPQA": 4.250559284116329, "MUSR Raw": 0.4901770833333334, "MUSR": 21.172135416666663, "MMLU-PRO Raw": 0.2902260638297872, "MMLU-PRO": 21.1362293144208, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-22T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "uukuguy/speechless-instruct-mistral-7b-v0.2"}, {"eval_name": "uukuguy_speechless-llama2-hermes-orca-platypus-wizardlm-13b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/uukuguy/speechless-llama2-hermes-orca-platypus-wizardlm-13b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">uukuguy/speechless-llama2-hermes-orca-platypus-wizardlm-13b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/uukuguy__speechless-llama2-hermes-orca-platypus-wizardlm-13b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "uukuguy/speechless-llama2-hermes-orca-platypus-wizardlm-13b", "Model sha": "954cc87b0ed5fa280126de546daf648861031512", "Average \u2b06\ufe0f": 18.60089096059006, "Hub License": null, "Hub \u2764\ufe0f": 32, "#Params (B)": 13, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4561751707691148, "IFEval": 45.61751707691148, "BBH Raw": 0.4845537304067666, "BBH": 26.79172729423422, "MATH Lvl 5 Raw": 0.0143504531722054, "MATH Lvl 5": 1.4350453172205435, "GPQA Raw": 0.2701342281879195, "GPQA": 2.684563758389265, "MUSR Raw": 0.4655, "MUSR": 17.754166666666666, "MMLU-PRO Raw": 0.2559009308510638, "MMLU-PRO": 17.322325650118206, "Maintainer's Highlight": false, "Upload To Hub Date": "2023-09-01T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "uukuguy/speechless-llama2-hermes-orca-platypus-wizardlm-13b"}, {"eval_name": "uukuguy_speechless-mistral-dolphin-orca-platypus-samantha-7b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/uukuguy/speechless-mistral-dolphin-orca-platypus-samantha-7b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">uukuguy/speechless-mistral-dolphin-orca-platypus-samantha-7b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/uukuguy__speechless-mistral-dolphin-orca-platypus-samantha-7b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "uukuguy/speechless-mistral-dolphin-orca-platypus-samantha-7b", "Model sha": "b1de043468a15198b55a6509293a4ee585139043", "Average \u2b06\ufe0f": 18.340089485864254, "Hub License": "llama2", "Hub \u2764\ufe0f": 17, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3700215428396654, "IFEval": 37.00215428396654, "BBH Raw": 0.4982774952761688, "BBH": 29.65312947574292, "MATH Lvl 5 Raw": 0.0294561933534743, "MATH Lvl 5": 2.9456193353474323, "GPQA Raw": 0.2835570469798658, "GPQA": 4.4742729306487705, "MUSR Raw": 0.4361354166666666, "MUSR": 13.850260416666664, "MMLU-PRO Raw": 0.2990359042553192, "MMLU-PRO": 22.11510047281324, "Maintainer's Highlight": false, "Upload To Hub Date": "2023-10-13T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "uukuguy/speechless-mistral-dolphin-orca-platypus-samantha-7b"}, {"eval_name": "uukuguy_speechless-zephyr-code-functionary-7b_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/uukuguy/speechless-zephyr-code-functionary-7b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">uukuguy/speechless-zephyr-code-functionary-7b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/uukuguy__speechless-zephyr-code-functionary-7b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "uukuguy/speechless-zephyr-code-functionary-7b", "Model sha": "d66fc775ece679966e352195c42444e9c70af7fa", "Average \u2b06\ufe0f": 16.36012940579845, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 2, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2695791610704043, "IFEval": 26.957916107040436, "BBH Raw": 0.4664275395719455, "BBH": 25.983622785908505, "MATH Lvl 5 Raw": 0.0362537764350453, "MATH Lvl 5": 3.625377643504532, "GPQA Raw": 0.3003355704697986, "GPQA": 6.711409395973152, "MUSR Raw": 0.4267708333333333, "MUSR": 11.613020833333332, "MMLU-PRO Raw": 0.3094248670212766, "MMLU-PRO": 23.26942966903073, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-01-23T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "uukuguy/speechless-zephyr-code-functionary-7b"}, {"eval_name": "v000000_L3.1-Niitorm-8B-DPO-t0.0001_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/v000000/L3.1-Niitorm-8B-DPO-t0.0001\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">v000000/L3.1-Niitorm-8B-DPO-t0.0001</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/v000000__L3.1-Niitorm-8B-DPO-t0.0001-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "v000000/L3.1-Niitorm-8B-DPO-t0.0001", "Model sha": "a34150b5f63de4bc83d79b1de127faff3750289f", "Average \u2b06\ufe0f": 27.886644368275697, "Hub License": null, "Hub \u2764\ufe0f": 4, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7688666072687137, "IFEval": 76.88666072687137, "BBH Raw": 0.5134234526726582, "BBH": 30.51317301580421, "MATH Lvl 5 Raw": 0.1487915407854985, "MATH Lvl 5": 14.879154078549847, "GPQA Raw": 0.2944630872483221, "GPQA": 5.92841163310962, "MUSR Raw": 0.3879791666666667, "MUSR": 7.2640625, "MMLU-PRO Raw": 0.3866356382978723, "MMLU-PRO": 31.848404255319146, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-19T00:00:00", "Submission Date": "2024-09-19T00:00:00", "Generation": 1, "Base Model": "v000000/L3.1-Niitorm-8B-DPO-t0.0001 (Merge)"}, {"eval_name": "v000000_L3.1-Storniitova-8B_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/v000000/L3.1-Storniitova-8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">v000000/L3.1-Storniitova-8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/v000000__L3.1-Storniitova-8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "v000000/L3.1-Storniitova-8B", "Model sha": "05b126857f43d1b1383e50f8c97d214ceb199723", "Average \u2b06\ufe0f": 28.055120701315676, "Hub License": null, "Hub \u2764\ufe0f": 5, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7816560060639104, "IFEval": 78.16560060639105, "BBH Raw": 0.5151452004311876, "BBH": 30.810993185589904, "MATH Lvl 5 Raw": 0.1329305135951661, "MATH Lvl 5": 13.293051359516618, "GPQA Raw": 0.2894295302013422, "GPQA": 5.257270693512303, "MUSR Raw": 0.4028958333333333, "MUSR": 9.961979166666664, "MMLU-PRO Raw": 0.3775764627659574, "MMLU-PRO": 30.841829196217496, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-12T00:00:00", "Submission Date": "2024-09-18T00:00:00", "Generation": 1, "Base Model": "v000000/L3.1-Storniitova-8B (Merge)"}, {"eval_name": "v000000_Qwen2.5-14B-Gutenberg-1e-Delta_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/v000000/Qwen2.5-14B-Gutenberg-1e-Delta\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">v000000/Qwen2.5-14B-Gutenberg-1e-Delta</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/v000000__Qwen2.5-14B-Gutenberg-1e-Delta-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "v000000/Qwen2.5-14B-Gutenberg-1e-Delta", "Model sha": "f624854b4380e01322e752ce4daadd49ac86580f", "Average \u2b06\ufe0f": 32.105096397160736, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 4, "#Params (B)": 14, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.8045120280854798, "IFEval": 80.45120280854799, "BBH Raw": 0.639849930188539, "BBH": 48.6166718794722, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.3288590604026846, "GPQA": 10.514541387024613, "MUSR Raw": 0.4073020833333333, "MUSR": 9.379427083333336, "MMLU-PRO Raw": 0.4930186170212766, "MMLU-PRO": 43.668735224586285, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-20T00:00:00", "Submission Date": "2024-09-28T00:00:00", "Generation": 1, "Base Model": "v000000/Qwen2.5-14B-Gutenberg-1e-Delta (Merge)"}, {"eval_name": "v000000_Qwen2.5-14B-Gutenberg-Instruct-Slerpeno_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/v000000/Qwen2.5-14B-Gutenberg-Instruct-Slerpeno\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">v000000/Qwen2.5-14B-Gutenberg-Instruct-Slerpeno</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/v000000__Qwen2.5-14B-Gutenberg-Instruct-Slerpeno-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "v000000/Qwen2.5-14B-Gutenberg-Instruct-Slerpeno", "Model sha": "1069abb4c25855e67ffaefa08a0befbb376e7ca7", "Average \u2b06\ufe0f": 33.388084020698415, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 4, "#Params (B)": 14, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4854763139580756, "IFEval": 48.54763139580757, "BBH Raw": 0.651078668009944, "BBH": 49.73940007466614, "MATH Lvl 5 Raw": 0.1971299093655589, "MATH Lvl 5": 19.71299093655589, "GPQA Raw": 0.3640939597315436, "GPQA": 15.212527964205815, "MUSR Raw": 0.4690625, "MUSR": 18.432812499999997, "MMLU-PRO Raw": 0.5381482712765957, "MMLU-PRO": 48.68314125295508, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-20T00:00:00", "Submission Date": "2024-09-28T00:00:00", "Generation": 1, "Base Model": "v000000/Qwen2.5-14B-Gutenberg-Instruct-Slerpeno (Merge)"}, {"eval_name": "v000000_Qwen2.5-Lumen-14B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/v000000/Qwen2.5-Lumen-14B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">v000000/Qwen2.5-Lumen-14B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/v000000__Qwen2.5-Lumen-14B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "v000000/Qwen2.5-Lumen-14B", "Model sha": "fbb1d184ed01dac52d307737893ebb6b0ace444c", "Average \u2b06\ufe0f": 32.20028820833853, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 12, "#Params (B)": 14, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.8063604569209697, "IFEval": 80.63604569209697, "BBH Raw": 0.6390809511149668, "BBH": 48.50786084405761, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.3280201342281879, "GPQA": 10.402684563758392, "MUSR Raw": 0.4113958333333333, "MUSR": 10.291145833333337, "MMLU-PRO Raw": 0.4902759308510638, "MMLU-PRO": 43.36399231678487, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-20T00:00:00", "Submission Date": "2024-09-20T00:00:00", "Generation": 1, "Base Model": "v000000/Qwen2.5-Lumen-14B (Merge)"}, {"eval_name": "vhab10_Llama-3.1-8B-Base-Instruct-SLERP_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/vhab10/Llama-3.1-8B-Base-Instruct-SLERP\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">vhab10/Llama-3.1-8B-Base-Instruct-SLERP</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/vhab10__Llama-3.1-8B-Base-Instruct-SLERP-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "vhab10/Llama-3.1-8B-Base-Instruct-SLERP", "Model sha": "eccb4bde0dc91f586954109ecdce7c94f47e2625", "Average \u2b06\ufe0f": 19.023031211597505, "Hub License": "mit", "Hub \u2764\ufe0f": 1, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.290711977552893, "IFEval": 29.0711977552893, "BBH Raw": 0.5057443268070797, "BBH": 29.92604162309261, "MATH Lvl 5 Raw": 0.1049848942598187, "MATH Lvl 5": 10.498489425981871, "GPQA Raw": 0.2961409395973154, "GPQA": 6.152125279642054, "MUSR Raw": 0.4010625, "MUSR": 9.366145833333334, "MMLU-PRO Raw": 0.3621176861702128, "MMLU-PRO": 29.12418735224587, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-16T00:00:00", "Submission Date": "2024-09-29T00:00:00", "Generation": 1, "Base Model": "vhab10/Llama-3.1-8B-Base-Instruct-SLERP (Merge)"}, {"eval_name": "vhab10_llama-3-8b-merged-linear_float16", "Precision": "float16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/vhab10/llama-3-8b-merged-linear\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">vhab10/llama-3-8b-merged-linear</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/vhab10__llama-3-8b-merged-linear-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "vhab10/llama-3-8b-merged-linear", "Model sha": "c37e7671b5ccfadbf3065fa5b48af05cd4f13292", "Average \u2b06\ufe0f": 23.74772281826365, "Hub License": "mit", "Hub \u2764\ufe0f": 0, "#Params (B)": 4, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5916634529714491, "IFEval": 59.16634529714492, "BBH Raw": 0.4937093744349853, "BBH": 27.8160513277408, "MATH Lvl 5 Raw": 0.0717522658610271, "MATH Lvl 5": 7.175226586102719, "GPQA Raw": 0.299496644295302, "GPQA": 6.599552572706939, "MUSR Raw": 0.4190520833333333, "MUSR": 11.681510416666669, "MMLU-PRO Raw": 0.3704288563829787, "MMLU-PRO": 30.04765070921986, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-26T00:00:00", "Submission Date": "2024-09-26T00:00:00", "Generation": 1, "Base Model": "vhab10/llama-3-8b-merged-linear (Merge)"}, {"eval_name": "vicgalle_CarbonBeagle-11B_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/vicgalle/CarbonBeagle-11B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">vicgalle/CarbonBeagle-11B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/vicgalle__CarbonBeagle-11B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "vicgalle/CarbonBeagle-11B", "Model sha": "3fe9bf5327606d013b182fed17a472f5f043759b", "Average \u2b06\ufe0f": 22.356892861229515, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 9, "#Params (B)": 10, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5415298075772285, "IFEval": 54.15298075772285, "BBH Raw": 0.5293652486530874, "BBH": 33.06060419684841, "MATH Lvl 5 Raw": 0.0551359516616314, "MATH Lvl 5": 5.5135951661631415, "GPQA Raw": 0.3020134228187919, "GPQA": 6.935123042505594, "MUSR Raw": 0.40203125, "MUSR": 9.18723958333334, "MMLU-PRO Raw": 0.327626329787234, "MMLU-PRO": 25.29181442080378, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-01-21T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "vicgalle/CarbonBeagle-11B (Merge)"}, {"eval_name": "vicgalle_CarbonBeagle-11B-truthy_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/vicgalle/CarbonBeagle-11B-truthy\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">vicgalle/CarbonBeagle-11B-truthy</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/vicgalle__CarbonBeagle-11B-truthy-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "vicgalle/CarbonBeagle-11B-truthy", "Model sha": "476cd2a6d938bddb38dfbeb4cb21e3e34303413d", "Average \u2b06\ufe0f": 21.29478627162108, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 9, "#Params (B)": 10, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5212214701436633, "IFEval": 52.12214701436632, "BBH Raw": 0.5348420085288232, "BBH": 33.98837559181831, "MATH Lvl 5 Raw": 0.0475830815709969, "MATH Lvl 5": 4.758308157099698, "GPQA Raw": 0.299496644295302, "GPQA": 6.599552572706939, "MUSR Raw": 0.3739687499999999, "MUSR": 4.112760416666666, "MMLU-PRO Raw": 0.335688164893617, "MMLU-PRO": 26.18757387706856, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-02-10T00:00:00", "Submission Date": "2024-07-13T00:00:00", "Generation": 0, "Base Model": "vicgalle/CarbonBeagle-11B-truthy"}, {"eval_name": "vicgalle_Configurable-Hermes-2-Pro-Llama-3-8B_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/vicgalle/Configurable-Hermes-2-Pro-Llama-3-8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">vicgalle/Configurable-Hermes-2-Pro-Llama-3-8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/vicgalle__Configurable-Hermes-2-Pro-Llama-3-8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "vicgalle/Configurable-Hermes-2-Pro-Llama-3-8B", "Model sha": "3cb5792509966a963645be24fdbeb2e7dc6cac15", "Average \u2b06\ufe0f": 22.289013901288712, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 5, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5762510139762497, "IFEval": 57.62510139762497, "BBH Raw": 0.5054841203275775, "BBH": 30.50962474895478, "MATH Lvl 5 Raw": 0.059667673716012, "MATH Lvl 5": 5.966767371601208, "GPQA Raw": 0.296979865771812, "GPQA": 6.263982102908276, "MUSR Raw": 0.4183645833333333, "MUSR": 10.062239583333334, "MMLU-PRO Raw": 0.3097573138297872, "MMLU-PRO": 23.30636820330969, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-02T00:00:00", "Submission Date": "2024-07-24T00:00:00", "Generation": 2, "Base Model": "NousResearch/Meta-Llama-3-8B"}, {"eval_name": "vicgalle_Configurable-Llama-3.1-8B-Instruct_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/vicgalle/Configurable-Llama-3.1-8B-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">vicgalle/Configurable-Llama-3.1-8B-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/vicgalle__Configurable-Llama-3.1-8B-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "vicgalle/Configurable-Llama-3.1-8B-Instruct", "Model sha": "133b3ab1a5385ff9b3d17da2addfe3fc1fd6f733", "Average \u2b06\ufe0f": 27.77093716838781, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 11, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.8312399987588488, "IFEval": 83.12399987588486, "BBH Raw": 0.5044756225072481, "BBH": 29.661397892084384, "MATH Lvl 5 Raw": 0.1586102719033232, "MATH Lvl 5": 15.861027190332328, "GPQA Raw": 0.2743288590604026, "GPQA": 3.243847874720355, "MUSR Raw": 0.3845416666666666, "MUSR": 5.934375, "MMLU-PRO Raw": 0.3592087765957447, "MMLU-PRO": 28.800975177304966, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-24T00:00:00", "Submission Date": "2024-08-05T00:00:00", "Generation": 0, "Base Model": "vicgalle/Configurable-Llama-3.1-8B-Instruct"}, {"eval_name": "vicgalle_Configurable-Yi-1.5-9B-Chat_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/vicgalle/Configurable-Yi-1.5-9B-Chat\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">vicgalle/Configurable-Yi-1.5-9B-Chat</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/vicgalle__Configurable-Yi-1.5-9B-Chat-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "vicgalle/Configurable-Yi-1.5-9B-Chat", "Model sha": "992cb2232caae78eff6a836b2e0642f7cbf6018e", "Average \u2b06\ufe0f": 23.771157303238123, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 2, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4323450666453897, "IFEval": 43.234506664538976, "BBH Raw": 0.5452196737175008, "BBH": 35.33444508462291, "MATH Lvl 5 Raw": 0.0611782477341389, "MATH Lvl 5": 6.117824773413897, "GPQA Raw": 0.3431208053691275, "GPQA": 12.416107382550338, "MUSR Raw": 0.4271145833333333, "MUSR": 12.02265625, "MMLU-PRO Raw": 0.4015126329787234, "MMLU-PRO": 33.5014036643026, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-12T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "vicgalle/Configurable-Yi-1.5-9B-Chat"}, {"eval_name": "vicgalle_ConfigurableBeagle-11B_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/vicgalle/ConfigurableBeagle-11B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">vicgalle/ConfigurableBeagle-11B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/vicgalle__ConfigurableBeagle-11B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "vicgalle/ConfigurableBeagle-11B", "Model sha": "bbc16dbf94b8e8a99bb3e2ada6755faf9c2990dd", "Average \u2b06\ufe0f": 22.52225106885845, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 2, "#Params (B)": 10, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5834452585805663, "IFEval": 58.34452585805663, "BBH Raw": 0.5286592318626696, "BBH": 32.392022902811185, "MATH Lvl 5 Raw": 0.0370090634441087, "MATH Lvl 5": 3.700906344410876, "GPQA Raw": 0.3020134228187919, "GPQA": 6.935123042505594, "MUSR Raw": 0.3953020833333333, "MUSR": 7.379427083333333, "MMLU-PRO Raw": 0.3374335106382978, "MMLU-PRO": 26.38150118203309, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-02-17T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "vicgalle/ConfigurableBeagle-11B"}, {"eval_name": "vicgalle_ConfigurableHermes-7B_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/vicgalle/ConfigurableHermes-7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">vicgalle/ConfigurableHermes-7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/vicgalle__ConfigurableHermes-7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "vicgalle/ConfigurableHermes-7B", "Model sha": "1333a88eaf6591836b2d9825d1eaec7260f336c9", "Average \u2b06\ufe0f": 19.46076671400103, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 3, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5410798902467675, "IFEval": 54.10798902467674, "BBH Raw": 0.4572969627830424, "BBH": 23.158164380406475, "MATH Lvl 5 Raw": 0.0430513595166163, "MATH Lvl 5": 4.305135951661631, "GPQA Raw": 0.2768456375838926, "GPQA": 3.5794183445190177, "MUSR Raw": 0.4056875, "MUSR": 9.110937500000004, "MMLU-PRO Raw": 0.3025265957446808, "MMLU-PRO": 22.50295508274231, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-02-17T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "vicgalle/ConfigurableHermes-7B"}, {"eval_name": "vicgalle_ConfigurableSOLAR-10.7B_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/vicgalle/ConfigurableSOLAR-10.7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">vicgalle/ConfigurableSOLAR-10.7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/vicgalle__ConfigurableSOLAR-10.7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "vicgalle/ConfigurableSOLAR-10.7B", "Model sha": "9d9baad88ea9dbaa61881f15e4f0d16e931033b4", "Average \u2b06\ufe0f": 19.04569592182013, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 2, "#Params (B)": 10, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5099558061499045, "IFEval": 50.995580614990445, "BBH Raw": 0.4866810097736045, "BBH": 27.45095014166692, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2986577181208054, "GPQA": 6.487695749440718, "MUSR Raw": 0.3804791666666666, "MUSR": 5.193229166666667, "MMLU-PRO Raw": 0.3173204787234042, "MMLU-PRO": 24.146719858156025, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-03-10T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "vicgalle/ConfigurableSOLAR-10.7B"}, {"eval_name": "vicgalle_Humanish-RP-Llama-3.1-8B_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/vicgalle/Humanish-RP-Llama-3.1-8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">vicgalle/Humanish-RP-Llama-3.1-8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/vicgalle__Humanish-RP-Llama-3.1-8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "vicgalle/Humanish-RP-Llama-3.1-8B", "Model sha": "d27aa731db1d390a8d17b0a4565c9231ee5ae8b9", "Average \u2b06\ufe0f": 25.171437118333888, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 4, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6669259786256023, "IFEval": 66.69259786256023, "BBH Raw": 0.5100385476143247, "BBH": 29.95856031523668, "MATH Lvl 5 Raw": 0.1367069486404833, "MATH Lvl 5": 13.670694864048338, "GPQA Raw": 0.2869127516778523, "GPQA": 4.921700223713646, "MUSR Raw": 0.3952083333333333, "MUSR": 8.26770833333333, "MMLU-PRO Raw": 0.34765625, "MMLU-PRO": 27.51736111111111, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-03T00:00:00", "Submission Date": "2024-08-03T00:00:00", "Generation": 0, "Base Model": "vicgalle/Humanish-RP-Llama-3.1-8B"}, {"eval_name": "vicgalle_Merge-Mistral-Prometheus-7B_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/vicgalle/Merge-Mistral-Prometheus-7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">vicgalle/Merge-Mistral-Prometheus-7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/vicgalle__Merge-Mistral-Prometheus-7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "vicgalle/Merge-Mistral-Prometheus-7B", "Model sha": "a7083581b508ce83c74f9267f07024bd462e7161", "Average \u2b06\ufe0f": 16.54887799713824, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4848014379623842, "IFEval": 48.48014379623842, "BBH Raw": 0.420139773821292, "BBH": 18.41040626692948, "MATH Lvl 5 Raw": 0.0158610271903323, "MATH Lvl 5": 1.5861027190332326, "GPQA Raw": 0.2634228187919463, "GPQA": 1.789709172259505, "MUSR Raw": 0.41, "MUSR": 9.950000000000005, "MMLU-PRO Raw": 0.2716921542553192, "MMLU-PRO": 19.0769060283688, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-04T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "vicgalle/Merge-Mistral-Prometheus-7B (Merge)"}, {"eval_name": "vicgalle_Merge-Mixtral-Prometheus-8x7B_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/vicgalle/Merge-Mixtral-Prometheus-8x7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">vicgalle/Merge-Mixtral-Prometheus-8x7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/vicgalle__Merge-Mixtral-Prometheus-8x7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "vicgalle/Merge-Mixtral-Prometheus-8x7B", "Model sha": "ba53ee5b52a81e56b01e919c069a0d045cfd4e83", "Average \u2b06\ufe0f": 24.60533600753256, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 2, "#Params (B)": 46, "Available on the hub": true, "Not_Merged": false, "MoE": false, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5744025851407598, "IFEval": 57.44025851407598, "BBH Raw": 0.5351498071096573, "BBH": 34.65142126614313, "MATH Lvl 5 Raw": 0.0830815709969788, "MATH Lvl 5": 8.308157099697885, "GPQA Raw": 0.3087248322147651, "GPQA": 7.829977628635347, "MUSR Raw": 0.40975, "MUSR": 9.585416666666667, "MMLU-PRO Raw": 0.3683510638297872, "MMLU-PRO": 29.81678486997636, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-04T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "vicgalle/Merge-Mixtral-Prometheus-8x7B (Merge)"}, {"eval_name": "vicgalle_Roleplay-Llama-3-8B_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/vicgalle/Roleplay-Llama-3-8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">vicgalle/Roleplay-Llama-3-8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/vicgalle__Roleplay-Llama-3-8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "vicgalle/Roleplay-Llama-3-8B", "Model sha": "57297eb57dcc2c116f061d9dda341094203da01b", "Average \u2b06\ufe0f": 23.944654235242627, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 36, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7320221456845614, "IFEval": 73.20221456845613, "BBH Raw": 0.5012318206922323, "BBH": 28.554603909240623, "MATH Lvl 5 Raw": 0.086858006042296, "MATH Lvl 5": 8.685800604229607, "GPQA Raw": 0.2609060402684564, "GPQA": 1.45413870246085, "MUSR Raw": 0.3528854166666666, "MUSR": 1.6773437499999992, "MMLU-PRO Raw": 0.370844414893617, "MMLU-PRO": 30.093823877068555, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-19T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "vicgalle/Roleplay-Llama-3-8B"}, {"eval_name": "vihangd_smart-dan-sft-v0.1_4bit", "Precision": "4bit", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/vihangd/smart-dan-sft-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">vihangd/smart-dan-sft-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/vihangd__smart-dan-sft-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "vihangd/smart-dan-sft-v0.1", "Model sha": "924b4a09153d4061fa9d58f03b10cd7cde7e3084", "Average \u2b06\ufe0f": 3.783095720107548, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 0, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1576461566421539, "IFEval": 15.764615664215391, "BBH Raw": 0.3061768918713888, "BBH": 3.1255992643495936, "MATH Lvl 5 Raw": 0.0045317220543806, "MATH Lvl 5": 0.4531722054380665, "GPQA Raw": 0.2550335570469799, "GPQA": 0.6711409395973182, "MUSR Raw": 0.3501875, "MUSR": 1.1067708333333328, "MMLU-PRO Raw": 0.1141954787234042, "MMLU-PRO": 1.5772754137115832, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-09T00:00:00", "Submission Date": "2024-08-20T00:00:00", "Generation": 0, "Base Model": "vihangd/smart-dan-sft-v0.1"}, {"eval_name": "w4r10ck_SOLAR-10.7B-Instruct-v1.0-uncensored_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/w4r10ck/SOLAR-10.7B-Instruct-v1.0-uncensored\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">w4r10ck/SOLAR-10.7B-Instruct-v1.0-uncensored</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/w4r10ck__SOLAR-10.7B-Instruct-v1.0-uncensored-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "w4r10ck/SOLAR-10.7B-Instruct-v1.0-uncensored", "Model sha": "baa7b3899e85af4b2f02b01fd93f203872140d27", "Average \u2b06\ufe0f": 20.56459264610032, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 29, "#Params (B)": 10, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.3884060958257423, "IFEval": 38.84060958257423, "BBH Raw": 0.5301525050503222, "BBH": 33.858639234912964, "MATH Lvl 5 Raw": 0.0022658610271903, "MATH Lvl 5": 0.2265861027190332, "GPQA Raw": 0.2944630872483221, "GPQA": 5.92841163310962, "MUSR Raw": 0.4639479166666667, "MUSR": 18.49348958333333, "MMLU-PRO Raw": 0.3343583776595745, "MMLU-PRO": 26.03981973995272, "Maintainer's Highlight": false, "Upload To Hub Date": "2023-12-14T00:00:00", "Submission Date": "2024-10-11T00:00:00", "Generation": 0, "Base Model": "w4r10ck/SOLAR-10.7B-Instruct-v1.0-uncensored"}, {"eval_name": "wannaphong_KhanomTanLLM-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/wannaphong/KhanomTanLLM-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">wannaphong/KhanomTanLLM-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/wannaphong__KhanomTanLLM-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "wannaphong/KhanomTanLLM-Instruct", "Model sha": "351239c92c0ff3304d1dd98fdf4ac054a8c1acc3", "Average \u2b06\ufe0f": 4.61787445145566, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 1, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.1621176256776464, "IFEval": 16.211762567764644, "BBH Raw": 0.3093123339251326, "BBH": 3.944866059804924, "MATH Lvl 5 Raw": 0.0015105740181268, "MATH Lvl 5": 0.1510574018126888, "GPQA Raw": 0.2634228187919463, "GPQA": 1.789709172259505, "MUSR Raw": 0.3700624999999999, "MUSR": 4.291145833333334, "MMLU-PRO Raw": 0.1118683510638298, "MMLU-PRO": 1.3187056737588652, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-24T00:00:00", "Submission Date": "2024-08-29T00:00:00", "Generation": 0, "Base Model": "wannaphong/KhanomTanLLM-Instruct"}, {"eval_name": "waqasali1707_Beast-Soul-new_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/waqasali1707/Beast-Soul-new\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">waqasali1707/Beast-Soul-new</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/waqasali1707__Beast-Soul-new-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "waqasali1707/Beast-Soul-new", "Model sha": "a23d68c4556d91a129de3f8fd8b9e0ff0890f4cc", "Average \u2b06\ufe0f": 22.007683288992222, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.5029865202108184, "IFEval": 50.29865202108184, "BBH Raw": 0.522494907014536, "BBH": 33.044262388969805, "MATH Lvl 5 Raw": 0.0641993957703927, "MATH Lvl 5": 6.419939577039275, "GPQA Raw": 0.2827181208053691, "GPQA": 4.36241610738255, "MUSR Raw": 0.4485625, "MUSR": 14.503645833333335, "MMLU-PRO Raw": 0.3107546542553192, "MMLU-PRO": 23.41718380614657, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-08-07T00:00:00", "Submission Date": "2024-08-07T00:00:00", "Generation": 1, "Base Model": "waqasali1707/Beast-Soul-new (Merge)"}, {"eval_name": "wave-on-discord_qwent-7b_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "Qwen2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/wave-on-discord/qwent-7b\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">wave-on-discord/qwent-7b</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/wave-on-discord__qwent-7b-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "wave-on-discord/qwent-7b", "Model sha": "40000e76d2a4d0ad054aff9fe873c5beb0e4925e", "Average \u2b06\ufe0f": 8.734092515058288, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2014853920929799, "IFEval": 20.148539209298, "BBH Raw": 0.4228103286118343, "BBH": 18.066398100675865, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.2651006711409396, "GPQA": 2.0134228187919474, "MUSR Raw": 0.38165625, "MUSR": 5.473697916666668, "MMLU-PRO Raw": 0.1603224734042553, "MMLU-PRO": 6.702497044917257, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-30T00:00:00", "Submission Date": "2024-09-30T00:00:00", "Generation": 1, "Base Model": "wave-on-discord/qwent-7b (Merge)"}, {"eval_name": "win10_Breeze-13B-32k-Instruct-v1_0_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/win10/Breeze-13B-32k-Instruct-v1_0\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">win10/Breeze-13B-32k-Instruct-v1_0</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/win10__Breeze-13B-32k-Instruct-v1_0-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "win10/Breeze-13B-32k-Instruct-v1_0", "Model sha": "220c957cf5d9c534a4ef75c11a18221c461de40a", "Average \u2b06\ufe0f": 15.39861784376948, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3584311848118547, "IFEval": 35.84311848118548, "BBH Raw": 0.4611230474671293, "BBH": 25.258698638977545, "MATH Lvl 5 Raw": 0.0090634441087613, "MATH Lvl 5": 0.906344410876133, "GPQA Raw": 0.2642617449664429, "GPQA": 1.9015659955257265, "MUSR Raw": 0.4201979166666666, "MUSR": 11.058072916666667, "MMLU-PRO Raw": 0.2568151595744681, "MMLU-PRO": 17.423906619385342, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-26T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "win10/Breeze-13B-32k-Instruct-v1_0"}, {"eval_name": "win10_Llama-3.2-3B-Instruct-24-9-29_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/win10/Llama-3.2-3B-Instruct-24-9-29\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">win10/Llama-3.2-3B-Instruct-24-9-29</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/win10__Llama-3.2-3B-Instruct-24-9-29-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "win10/Llama-3.2-3B-Instruct-24-9-29", "Model sha": "4defb10e2415111abb873d695dd40c387c1d6d57", "Average \u2b06\ufe0f": 23.70258328643864, "Hub License": "llama3.2", "Hub \u2764\ufe0f": 0, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7332211864519476, "IFEval": 73.32211864519475, "BBH Raw": 0.4614234982167829, "BBH": 24.196425775209622, "MATH Lvl 5 Raw": 0.1525679758308157, "MATH Lvl 5": 15.256797583081571, "GPQA Raw": 0.2743288590604026, "GPQA": 3.243847874720355, "MUSR Raw": 0.3555208333333333, "MUSR": 1.4401041666666683, "MMLU-PRO Raw": 0.3228058510638298, "MMLU-PRO": 24.756205673758867, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-29T00:00:00", "Submission Date": "2024-10-11T00:00:00", "Generation": 2, "Base Model": "meta-llama/Llama-3.2-3B-Instruct"}, {"eval_name": "win10_llama3-13.45b-Instruct_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/win10/llama3-13.45b-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">win10/llama3-13.45b-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/win10__llama3-13.45b-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "win10/llama3-13.45b-Instruct", "Model sha": "94cc0f415e355c6d3d47168a6ff5239ca586904a", "Average \u2b06\ufe0f": 17.264693399021013, "Hub License": "llama3", "Hub \u2764\ufe0f": 1, "#Params (B)": 13, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4144348107465968, "IFEval": 41.44348107465968, "BBH Raw": 0.486541523346714, "BBH": 26.67569043948038, "MATH Lvl 5 Raw": 0.0196374622356495, "MATH Lvl 5": 1.9637462235649543, "GPQA Raw": 0.2583892617449664, "GPQA": 1.1185682326621946, "MUSR Raw": 0.3847604166666666, "MUSR": 6.3283854166666655, "MMLU-PRO Raw": 0.3345246010638298, "MMLU-PRO": 26.0582890070922, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-09T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 1, "Base Model": "win10/llama3-13.45b-Instruct (Merge)"}, {"eval_name": "winglian_Llama-3-8b-64k-PoSE_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/winglian/Llama-3-8b-64k-PoSE\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">winglian/Llama-3-8b-64k-PoSE</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/winglian__Llama-3-8b-64k-PoSE-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "winglian/Llama-3-8b-64k-PoSE", "Model sha": "5481d9b74a3ec5a95789673e194c8ff86e2bc2bc", "Average \u2b06\ufe0f": 10.891445114212804, "Hub License": null, "Hub \u2764\ufe0f": 74, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2856908558181181, "IFEval": 28.569085581811816, "BBH Raw": 0.3702179600512179, "BBH": 13.30731679540503, "MATH Lvl 5 Raw": 0.0264350453172205, "MATH Lvl 5": 2.643504531722054, "GPQA Raw": 0.2609060402684564, "GPQA": 1.45413870246085, "MUSR Raw": 0.3395520833333333, "MUSR": 3.077343750000001, "MMLU-PRO Raw": 0.2466755319148936, "MMLU-PRO": 16.297281323877066, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-24T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "winglian/Llama-3-8b-64k-PoSE"}, {"eval_name": "winglian_llama-3-8b-256k-PoSE_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/winglian/llama-3-8b-256k-PoSE\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">winglian/llama-3-8b-256k-PoSE</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/winglian__llama-3-8b-256k-PoSE-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "winglian/llama-3-8b-256k-PoSE", "Model sha": "93e7b0b6433c96583ffcef3bc47203e6fdcbbe8b", "Average \u2b06\ufe0f": 6.545127111401093, "Hub License": null, "Hub \u2764\ufe0f": 42, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2909114482905358, "IFEval": 29.091144829053576, "BBH Raw": 0.3156583397739859, "BBH": 5.502848923020156, "MATH Lvl 5 Raw": 0.0143504531722054, "MATH Lvl 5": 1.4350453172205435, "GPQA Raw": 0.2575503355704698, "GPQA": 1.0067114093959737, "MUSR Raw": 0.3315520833333333, "MUSR": 0.9440104166666662, "MMLU-PRO Raw": 0.1116190159574468, "MMLU-PRO": 1.291001773049644, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-26T00:00:00", "Submission Date": "2024-06-26T00:00:00", "Generation": 0, "Base Model": "winglian/llama-3-8b-256k-PoSE"}, {"eval_name": "xMaulana_FinMatcha-3B-Instruct_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/xMaulana/FinMatcha-3B-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">xMaulana/FinMatcha-3B-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/xMaulana__FinMatcha-3B-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "xMaulana/FinMatcha-3B-Instruct", "Model sha": "be2c0c04fc4dc3fb93631e3c663721da92fea8fc", "Average \u2b06\ufe0f": 16.752023093602844, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 3, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6099981382731153, "IFEval": 60.99981382731153, "BBH Raw": 0.3179524242232189, "BBH": 6.317188891559348, "MATH Lvl 5 Raw": 0.1019637462235649, "MATH Lvl 5": 10.196374622356496, "GPQA Raw": 0.2525167785234899, "GPQA": 0.3355704697986553, "MUSR Raw": 0.3860625, "MUSR": 6.62447916666667, "MMLU-PRO Raw": 0.2443484042553191, "MMLU-PRO": 16.038711583924346, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-29T00:00:00", "Submission Date": "2024-10-13T00:00:00", "Generation": 1, "Base Model": "xMaulana/FinMatcha-3B-Instruct (Merge)"}, {"eval_name": "xinchen9_Llama3.1_8B_Instruct_CoT_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/xinchen9/Llama3.1_8B_Instruct_CoT\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">xinchen9/Llama3.1_8B_Instruct_CoT</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/xinchen9__Llama3.1_8B_Instruct_CoT-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "xinchen9/Llama3.1_8B_Instruct_CoT", "Model sha": "cab1b33ddff08de11c5daea8ae079d126d503d8b", "Average \u2b06\ufe0f": 16.12780284551221, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2973565694579272, "IFEval": 29.73565694579272, "BBH Raw": 0.4398206147249642, "BBH": 21.14286611806116, "MATH Lvl 5 Raw": 0.0490936555891238, "MATH Lvl 5": 4.909365558912387, "GPQA Raw": 0.3020134228187919, "GPQA": 6.935123042505594, "MUSR Raw": 0.4370624999999999, "MUSR": 13.166145833333337, "MMLU-PRO Raw": 0.2878989361702128, "MMLU-PRO": 20.877659574468087, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-16T00:00:00", "Submission Date": "2024-09-19T00:00:00", "Generation": 0, "Base Model": "xinchen9/Llama3.1_8B_Instruct_CoT"}, {"eval_name": "xinchen9_Llama3.1_CoT_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/xinchen9/Llama3.1_CoT\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">xinchen9/Llama3.1_CoT</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/xinchen9__Llama3.1_CoT-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "xinchen9/Llama3.1_CoT", "Model sha": "3cb467f51a59ff163bb942fcde3ef60573c12b79", "Average \u2b06\ufe0f": 13.351283385198409, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.2246162404641905, "IFEval": 22.461624046419058, "BBH Raw": 0.4341014366427724, "BBH": 19.899123541883053, "MATH Lvl 5 Raw": 0.0151057401812688, "MATH Lvl 5": 1.5105740181268883, "GPQA Raw": 0.2885906040268456, "GPQA": 5.145413870246088, "MUSR Raw": 0.4304583333333333, "MUSR": 11.773958333333333, "MMLU-PRO Raw": 0.2738530585106383, "MMLU-PRO": 19.317006501182032, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-04T00:00:00", "Submission Date": "2024-09-06T00:00:00", "Generation": 0, "Base Model": "xinchen9/Llama3.1_CoT"}, {"eval_name": "xinchen9_Llama3.1_CoT_V1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/xinchen9/Llama3.1_CoT_V1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">xinchen9/Llama3.1_CoT_V1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/xinchen9__Llama3.1_CoT_V1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "xinchen9/Llama3.1_CoT_V1", "Model sha": "c5ed4b8bfc364ebae1843af14799818551f5251f", "Average \u2b06\ufe0f": 14.382358822064056, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2452991396162183, "IFEval": 24.52991396162183, "BBH Raw": 0.4376001847280673, "BBH": 20.166003338515427, "MATH Lvl 5 Raw": 0.0120845921450151, "MATH Lvl 5": 1.2084592145015105, "GPQA Raw": 0.2793624161073825, "GPQA": 3.9149888143176734, "MUSR Raw": 0.45721875, "MUSR": 16.419010416666666, "MMLU-PRO Raw": 0.2805019946808511, "MMLU-PRO": 20.05577718676123, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-06T00:00:00", "Submission Date": "2024-09-07T00:00:00", "Generation": 0, "Base Model": "xinchen9/Llama3.1_CoT_V1"}, {"eval_name": "xinchen9_Mistral-7B-CoT_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/xinchen9/Mistral-7B-CoT\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">xinchen9/Mistral-7B-CoT</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/xinchen9__Mistral-7B-CoT-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "xinchen9/Mistral-7B-CoT", "Model sha": "9a3c8103dac20d5497d1b8fc041bb5125ff4dc00", "Average \u2b06\ufe0f": 11.17777842572204, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2798707429620075, "IFEval": 27.987074296200745, "BBH Raw": 0.3872676209806966, "BBH": 14.80619341451162, "MATH Lvl 5 Raw": 0.0181268882175226, "MATH Lvl 5": 1.812688821752266, "GPQA Raw": 0.2491610738255033, "GPQA": 0.0, "MUSR Raw": 0.3994270833333333, "MUSR": 8.195052083333335, "MMLU-PRO Raw": 0.2283909574468085, "MMLU-PRO": 14.265661938534278, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-09T00:00:00", "Submission Date": "2024-09-23T00:00:00", "Generation": 0, "Base Model": "xinchen9/Mistral-7B-CoT"}, {"eval_name": "xinchen9_llama3-b8-ft-dis_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/xinchen9/llama3-b8-ft-dis\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">xinchen9/llama3-b8-ft-dis</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/xinchen9__llama3-b8-ft-dis-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "xinchen9/llama3-b8-ft-dis", "Model sha": "e4da730f28f79543262de37908943c35f8df81fe", "Average \u2b06\ufe0f": 13.847610819384292, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.154598687039278, "IFEval": 15.459868703927802, "BBH Raw": 0.4625789691224553, "BBH": 24.72745698442778, "MATH Lvl 5 Raw": 0.0317220543806646, "MATH Lvl 5": 3.1722054380664653, "GPQA Raw": 0.3129194630872483, "GPQA": 8.389261744966444, "MUSR Raw": 0.365375, "MUSR": 6.405208333333333, "MMLU-PRO Raw": 0.3243849734042553, "MMLU-PRO": 24.931663711583923, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-06-28T00:00:00", "Submission Date": "2024-07-11T00:00:00", "Generation": 0, "Base Model": "xinchen9/llama3-b8-ft-dis"}, {"eval_name": "xkp24_Llama-3-8B-Instruct-SPPO-Iter2_bt_2b-table_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/xkp24/Llama-3-8B-Instruct-SPPO-Iter2_bt_2b-table\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">xkp24/Llama-3-8B-Instruct-SPPO-Iter2_bt_2b-table</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/xkp24__Llama-3-8B-Instruct-SPPO-Iter2_bt_2b-table-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "xkp24/Llama-3-8B-Instruct-SPPO-Iter2_bt_2b-table", "Model sha": "c083d6796f54f66b4cec2261657a02801c761093", "Average \u2b06\ufe0f": 22.307736062207017, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6374752323834094, "IFEval": 63.74752323834093, "BBH Raw": 0.4912273915261041, "BBH": 27.42282120153998, "MATH Lvl 5 Raw": 0.0611782477341389, "MATH Lvl 5": 6.117824773413897, "GPQA Raw": 0.259228187919463, "GPQA": 1.230425055928408, "MUSR Raw": 0.3819999999999999, "MUSR": 5.483333333333334, "MMLU-PRO Raw": 0.3686003989361702, "MMLU-PRO": 29.84448877068557, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-30T00:00:00", "Submission Date": "2024-10-01T00:00:00", "Generation": 0, "Base Model": "xkp24/Llama-3-8B-Instruct-SPPO-Iter2_bt_2b-table"}, {"eval_name": "xkp24_Llama-3-8B-Instruct-SPPO-Iter2_bt_8b-table_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/xkp24/Llama-3-8B-Instruct-SPPO-Iter2_bt_8b-table\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">xkp24/Llama-3-8B-Instruct-SPPO-Iter2_bt_8b-table</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/xkp24__Llama-3-8B-Instruct-SPPO-Iter2_bt_8b-table-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "xkp24/Llama-3-8B-Instruct-SPPO-Iter2_bt_8b-table", "Model sha": "5416d34b5243559914a377ee9d95ce4830bf8dba", "Average \u2b06\ufe0f": 24.351347707040382, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7274509412802475, "IFEval": 72.74509412802476, "BBH Raw": 0.5056858683165713, "BBH": 29.398353220629613, "MATH Lvl 5 Raw": 0.0755287009063444, "MATH Lvl 5": 7.552870090634441, "GPQA Raw": 0.2600671140939597, "GPQA": 1.342281879194629, "MUSR Raw": 0.3819062499999999, "MUSR": 5.104947916666667, "MMLU-PRO Raw": 0.3696808510638298, "MMLU-PRO": 29.9645390070922, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-30T00:00:00", "Submission Date": "2024-10-01T00:00:00", "Generation": 0, "Base Model": "xkp24/Llama-3-8B-Instruct-SPPO-Iter2_bt_8b-table"}, {"eval_name": "xkp24_Llama-3-8B-Instruct-SPPO-Iter2_gp_2b-table_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/xkp24/Llama-3-8B-Instruct-SPPO-Iter2_gp_2b-table\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">xkp24/Llama-3-8B-Instruct-SPPO-Iter2_gp_2b-table</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/xkp24__Llama-3-8B-Instruct-SPPO-Iter2_gp_2b-table-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "xkp24/Llama-3-8B-Instruct-SPPO-Iter2_gp_2b-table", "Model sha": "235204157d7fac0d64fa609d5aee3cebb49ccd11", "Average \u2b06\ufe0f": 22.1482366866411, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6568593553992297, "IFEval": 65.68593553992297, "BBH Raw": 0.4951831916389766, "BBH": 27.69519951055004, "MATH Lvl 5 Raw": 0.059667673716012, "MATH Lvl 5": 5.966767371601208, "GPQA Raw": 0.259228187919463, "GPQA": 1.230425055928408, "MUSR Raw": 0.3593958333333333, "MUSR": 2.291145833333333, "MMLU-PRO Raw": 0.3701795212765957, "MMLU-PRO": 30.019946808510632, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-30T00:00:00", "Submission Date": "2024-09-30T00:00:00", "Generation": 0, "Base Model": "xkp24/Llama-3-8B-Instruct-SPPO-Iter2_gp_2b-table"}, {"eval_name": "xkp24_Llama-3-8B-Instruct-SPPO-Iter2_gp_8b-table_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/xkp24/Llama-3-8B-Instruct-SPPO-Iter2_gp_8b-table\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">xkp24/Llama-3-8B-Instruct-SPPO-Iter2_gp_8b-table</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/xkp24__Llama-3-8B-Instruct-SPPO-Iter2_gp_8b-table-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "xkp24/Llama-3-8B-Instruct-SPPO-Iter2_gp_8b-table", "Model sha": "9db00cbbba84453b18956fcc76f264f94a205955", "Average \u2b06\ufe0f": 22.7967960304484, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6620799478716473, "IFEval": 66.20799478716472, "BBH Raw": 0.500449109241973, "BBH": 28.508587310114308, "MATH Lvl 5 Raw": 0.0694864048338368, "MATH Lvl 5": 6.948640483383686, "GPQA Raw": 0.259228187919463, "GPQA": 1.230425055928408, "MUSR Raw": 0.3805416666666666, "MUSR": 5.001041666666667, "MMLU-PRO Raw": 0.3599567819148936, "MMLU-PRO": 28.88408687943262, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-30T00:00:00", "Submission Date": "2024-09-30T00:00:00", "Generation": 0, "Base Model": "xkp24/Llama-3-8B-Instruct-SPPO-Iter2_gp_8b-table"}, {"eval_name": "xkp24_Llama-3-8B-Instruct-SPPO-score-Iter2_bt_2b-table-0.001_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/xkp24/Llama-3-8B-Instruct-SPPO-score-Iter2_bt_2b-table-0.001\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">xkp24/Llama-3-8B-Instruct-SPPO-score-Iter2_bt_2b-table-0.001</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/xkp24__Llama-3-8B-Instruct-SPPO-score-Iter2_bt_2b-table-0.001-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "xkp24/Llama-3-8B-Instruct-SPPO-score-Iter2_bt_2b-table-0.001", "Model sha": "1062757826de031a4ae82277e6e737e19e82e514", "Average \u2b06\ufe0f": 21.78254062518453, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6042278931014153, "IFEval": 60.42278931014154, "BBH Raw": 0.4936062924421171, "BBH": 27.61371406788812, "MATH Lvl 5 Raw": 0.0611782477341389, "MATH Lvl 5": 6.117824773413897, "GPQA Raw": 0.259228187919463, "GPQA": 1.230425055928408, "MUSR Raw": 0.3793333333333333, "MUSR": 5.216666666666668, "MMLU-PRO Raw": 0.370844414893617, "MMLU-PRO": 30.093823877068555, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-30T00:00:00", "Submission Date": "2024-10-01T00:00:00", "Generation": 0, "Base Model": "xkp24/Llama-3-8B-Instruct-SPPO-score-Iter2_bt_2b-table-0.001"}, {"eval_name": "xkp24_Llama-3-8B-Instruct-SPPO-score-Iter2_bt_8b-table-0.002_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/xkp24/Llama-3-8B-Instruct-SPPO-score-Iter2_bt_8b-table-0.002\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">xkp24/Llama-3-8B-Instruct-SPPO-score-Iter2_bt_8b-table-0.002</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/xkp24__Llama-3-8B-Instruct-SPPO-score-Iter2_bt_8b-table-0.002-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "xkp24/Llama-3-8B-Instruct-SPPO-score-Iter2_bt_8b-table-0.002", "Model sha": "e5d2f179b4a7bd851dcf2b7db6358b13001bf1af", "Average \u2b06\ufe0f": 23.838120302738314, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7131876753680235, "IFEval": 71.31876753680235, "BBH Raw": 0.4996376240562969, "BBH": 28.574878539626724, "MATH Lvl 5 Raw": 0.0634441087613293, "MATH Lvl 5": 6.3444108761329305, "GPQA Raw": 0.2583892617449664, "GPQA": 1.1185682326621946, "MUSR Raw": 0.3872083333333333, "MUSR": 6.067708333333335, "MMLU-PRO Raw": 0.3664394946808511, "MMLU-PRO": 29.604388297872337, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-30T00:00:00", "Submission Date": "2024-10-01T00:00:00", "Generation": 0, "Base Model": "xkp24/Llama-3-8B-Instruct-SPPO-score-Iter2_bt_8b-table-0.002"}, {"eval_name": "xkp24_Llama-3-8B-Instruct-SPPO-score-Iter2_gp_2b-table-0.001_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/xkp24/Llama-3-8B-Instruct-SPPO-score-Iter2_gp_2b-table-0.001\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">xkp24/Llama-3-8B-Instruct-SPPO-score-Iter2_gp_2b-table-0.001</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/xkp24__Llama-3-8B-Instruct-SPPO-score-Iter2_gp_2b-table-0.001-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "xkp24/Llama-3-8B-Instruct-SPPO-score-Iter2_gp_2b-table-0.001", "Model sha": "0e319ad47ed2b2636b72d07ee9b32657e1e50412", "Average \u2b06\ufe0f": 21.14909488516088, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.594710922574325, "IFEval": 59.4710922574325, "BBH Raw": 0.4899221180377506, "BBH": 26.943904089240508, "MATH Lvl 5 Raw": 0.0687311178247734, "MATH Lvl 5": 6.873111782477341, "GPQA Raw": 0.259228187919463, "GPQA": 1.230425055928408, "MUSR Raw": 0.3580937499999999, "MUSR": 2.328385416666666, "MMLU-PRO Raw": 0.3704288563829787, "MMLU-PRO": 30.04765070921986, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-30T00:00:00", "Submission Date": "2024-09-30T00:00:00", "Generation": 0, "Base Model": "xkp24/Llama-3-8B-Instruct-SPPO-score-Iter2_gp_2b-table-0.001"}, {"eval_name": "xkp24_Llama-3-8B-Instruct-SPPO-score-Iter2_gp_8b-table-0.002_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/xkp24/Llama-3-8B-Instruct-SPPO-score-Iter2_gp_8b-table-0.002\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">xkp24/Llama-3-8B-Instruct-SPPO-score-Iter2_gp_8b-table-0.002</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/xkp24__Llama-3-8B-Instruct-SPPO-score-Iter2_gp_8b-table-0.002-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "xkp24/Llama-3-8B-Instruct-SPPO-score-Iter2_gp_8b-table-0.002", "Model sha": "0877f2458ea667edcf9213383df41294c788190f", "Average \u2b06\ufe0f": 22.630639764441156, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6453188650558297, "IFEval": 64.53188650558296, "BBH Raw": 0.4951075713814987, "BBH": 28.046977965255564, "MATH Lvl 5 Raw": 0.0641993957703927, "MATH Lvl 5": 6.419939577039275, "GPQA Raw": 0.2600671140939597, "GPQA": 1.342281879194629, "MUSR Raw": 0.393875, "MUSR": 7.334375000000001, "MMLU-PRO Raw": 0.3529753989361702, "MMLU-PRO": 28.10837765957446, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-30T00:00:00", "Submission Date": "2024-10-01T00:00:00", "Generation": 0, "Base Model": "xkp24/Llama-3-8B-Instruct-SPPO-score-Iter2_gp_8b-table-0.002"}, {"eval_name": "xukp20_Llama-3-8B-Instruct-SPPO-Iter3_bt_2b-table_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/xukp20/Llama-3-8B-Instruct-SPPO-Iter3_bt_2b-table\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">xukp20/Llama-3-8B-Instruct-SPPO-Iter3_bt_2b-table</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/xukp20__Llama-3-8B-Instruct-SPPO-Iter3_bt_2b-table-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "xukp20/Llama-3-8B-Instruct-SPPO-Iter3_bt_2b-table", "Model sha": "d2b87100e5ba3215fddbd308bb17b7bf12fe6c9e", "Average \u2b06\ufe0f": 20.95483912880591, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.575601625908146, "IFEval": 57.5601625908146, "BBH Raw": 0.4901206199104098, "BBH": 26.866404089240515, "MATH Lvl 5 Raw": 0.0755287009063444, "MATH Lvl 5": 7.552870090634441, "GPQA Raw": 0.259228187919463, "GPQA": 1.230425055928408, "MUSR Raw": 0.3659687499999999, "MUSR": 2.9794270833333325, "MMLU-PRO Raw": 0.3658577127659574, "MMLU-PRO": 29.539745862884164, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-28T00:00:00", "Submission Date": "2024-09-29T00:00:00", "Generation": 0, "Base Model": "xukp20/Llama-3-8B-Instruct-SPPO-Iter3_bt_2b-table"}, {"eval_name": "xukp20_Llama-3-8B-Instruct-SPPO-Iter3_bt_8b-table_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/xukp20/Llama-3-8B-Instruct-SPPO-Iter3_bt_8b-table\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">xukp20/Llama-3-8B-Instruct-SPPO-Iter3_bt_8b-table</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/xukp20__Llama-3-8B-Instruct-SPPO-Iter3_bt_8b-table-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "xukp20/Llama-3-8B-Instruct-SPPO-Iter3_bt_8b-table", "Model sha": "19a48ccf5ea463afbbbc61d650b8fb63ff2d94c7", "Average \u2b06\ufe0f": 23.805580053943917, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7034457461757027, "IFEval": 70.34457461757027, "BBH Raw": 0.5091868512191421, "BBH": 29.73123940180749, "MATH Lvl 5 Raw": 0.0770392749244713, "MATH Lvl 5": 7.7039274924471295, "GPQA Raw": 0.259228187919463, "GPQA": 1.230425055928408, "MUSR Raw": 0.3739062499999999, "MUSR": 3.904947916666666, "MMLU-PRO Raw": 0.3692652925531915, "MMLU-PRO": 29.918365839243503, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-28T00:00:00", "Submission Date": "2024-09-29T00:00:00", "Generation": 0, "Base Model": "xukp20/Llama-3-8B-Instruct-SPPO-Iter3_bt_8b-table"}, {"eval_name": "xukp20_Llama-3-8B-Instruct-SPPO-Iter3_gp_2b-table_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/xukp20/Llama-3-8B-Instruct-SPPO-Iter3_gp_2b-table\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">xukp20/Llama-3-8B-Instruct-SPPO-Iter3_gp_2b-table</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/xukp20__Llama-3-8B-Instruct-SPPO-Iter3_gp_2b-table-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "xukp20/Llama-3-8B-Instruct-SPPO-Iter3_gp_2b-table", "Model sha": "0fe230b3432fb2b0f89942d7926291a4dbeb2820", "Average \u2b06\ufe0f": 21.68076130905524, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6023794642659255, "IFEval": 60.23794642659256, "BBH Raw": 0.4969531536151197, "BBH": 27.892403263090213, "MATH Lvl 5 Raw": 0.080060422960725, "MATH Lvl 5": 8.006042296072508, "GPQA Raw": 0.259228187919463, "GPQA": 1.230425055928408, "MUSR Raw": 0.3673645833333332, "MUSR": 3.187239583333333, "MMLU-PRO Raw": 0.3657746010638298, "MMLU-PRO": 29.53051122931442, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-28T00:00:00", "Submission Date": "2024-09-29T00:00:00", "Generation": 0, "Base Model": "xukp20/Llama-3-8B-Instruct-SPPO-Iter3_gp_2b-table"}, {"eval_name": "xukp20_Llama-3-8B-Instruct-SPPO-Iter3_gp_8b-table_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/xukp20/Llama-3-8B-Instruct-SPPO-Iter3_gp_8b-table\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">xukp20/Llama-3-8B-Instruct-SPPO-Iter3_gp_8b-table</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/xukp20__Llama-3-8B-Instruct-SPPO-Iter3_gp_8b-table-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "xukp20/Llama-3-8B-Instruct-SPPO-Iter3_gp_8b-table", "Model sha": "d1e19da1029f2d4d45de015754bc52dcb1ea5570", "Average \u2b06\ufe0f": 22.94642141544332, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6620300801872365, "IFEval": 66.20300801872366, "BBH Raw": 0.4999936939220816, "BBH": 28.43982384277912, "MATH Lvl 5 Raw": 0.0762839879154078, "MATH Lvl 5": 7.628398791540786, "GPQA Raw": 0.259228187919463, "GPQA": 1.230425055928408, "MUSR Raw": 0.3818124999999999, "MUSR": 5.1265625, "MMLU-PRO Raw": 0.3614527925531915, "MMLU-PRO": 29.050310283687946, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-28T00:00:00", "Submission Date": "2024-09-29T00:00:00", "Generation": 0, "Base Model": "xukp20/Llama-3-8B-Instruct-SPPO-Iter3_gp_8b-table"}, {"eval_name": "xukp20_Llama-3-8B-Instruct-SPPO-score-Iter3_bt_2b-table-0.001_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/xukp20/Llama-3-8B-Instruct-SPPO-score-Iter3_bt_2b-table-0.001\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">xukp20/Llama-3-8B-Instruct-SPPO-score-Iter3_bt_2b-table-0.001</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/xukp20__Llama-3-8B-Instruct-SPPO-score-Iter3_bt_2b-table-0.001-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "xukp20/Llama-3-8B-Instruct-SPPO-score-Iter3_bt_2b-table-0.001", "Model sha": "a478aa202c59773eba615ae37feb4cc750757695", "Average \u2b06\ufe0f": 20.28852344849613, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5336363072203975, "IFEval": 53.363630722039744, "BBH Raw": 0.4914872719261351, "BBH": 27.145373836403248, "MATH Lvl 5 Raw": 0.0611782477341389, "MATH Lvl 5": 6.117824773413897, "GPQA Raw": 0.259228187919463, "GPQA": 1.230425055928408, "MUSR Raw": 0.3779687499999999, "MUSR": 4.712760416666668, "MMLU-PRO Raw": 0.3624501329787234, "MMLU-PRO": 29.161125886524825, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-28T00:00:00", "Submission Date": "2024-09-29T00:00:00", "Generation": 0, "Base Model": "xukp20/Llama-3-8B-Instruct-SPPO-score-Iter3_bt_2b-table-0.001"}, {"eval_name": "xukp20_Llama-3-8B-Instruct-SPPO-score-Iter3_bt_8b-table-0.002_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/xukp20/Llama-3-8B-Instruct-SPPO-score-Iter3_bt_8b-table-0.002\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">xukp20/Llama-3-8B-Instruct-SPPO-score-Iter3_bt_8b-table-0.002</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/xukp20__Llama-3-8B-Instruct-SPPO-score-Iter3_bt_8b-table-0.002-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "xukp20/Llama-3-8B-Instruct-SPPO-score-Iter3_bt_8b-table-0.002", "Model sha": "8ef9ef7e2bf522e707a7b090af55f2ec1eafd4b9", "Average \u2b06\ufe0f": 23.19838174285213, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6851609285584471, "IFEval": 68.5160928558447, "BBH Raw": 0.507516320435292, "BBH": 29.740550305634912, "MATH Lvl 5 Raw": 0.0506042296072507, "MATH Lvl 5": 5.060422960725076, "GPQA Raw": 0.2583892617449664, "GPQA": 1.1185682326621946, "MUSR Raw": 0.3831770833333333, "MUSR": 5.630468750000001, "MMLU-PRO Raw": 0.3621176861702128, "MMLU-PRO": 29.12418735224587, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-28T00:00:00", "Submission Date": "2024-09-29T00:00:00", "Generation": 0, "Base Model": "xukp20/Llama-3-8B-Instruct-SPPO-score-Iter3_bt_8b-table-0.002"}, {"eval_name": "xukp20_Llama-3-8B-Instruct-SPPO-score-Iter3_gp_2b-table-0.001_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/xukp20/Llama-3-8B-Instruct-SPPO-score-Iter3_gp_2b-table-0.001\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">xukp20/Llama-3-8B-Instruct-SPPO-score-Iter3_gp_2b-table-0.001</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/xukp20__Llama-3-8B-Instruct-SPPO-score-Iter3_gp_2b-table-0.001-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "xukp20/Llama-3-8B-Instruct-SPPO-score-Iter3_gp_2b-table-0.001", "Model sha": "86673872245ad902f8d466bdc20edae9c115b965", "Average \u2b06\ufe0f": 19.944052349728118, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.5482242671666733, "IFEval": 54.82242671666733, "BBH Raw": 0.4887174689428852, "BBH": 26.839803365680336, "MATH Lvl 5 Raw": 0.039274924471299, "MATH Lvl 5": 3.927492447129909, "GPQA Raw": 0.2609060402684564, "GPQA": 1.45413870246085, "MUSR Raw": 0.3632708333333334, "MUSR": 2.9421875, "MMLU-PRO Raw": 0.3671043882978723, "MMLU-PRO": 29.678265366430256, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-28T00:00:00", "Submission Date": "2024-09-29T00:00:00", "Generation": 0, "Base Model": "xukp20/Llama-3-8B-Instruct-SPPO-score-Iter3_gp_2b-table-0.001"}, {"eval_name": "xukp20_llama-3-8b-instruct-sppo-iter1-gp-2b-tau01-table_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/xukp20/llama-3-8b-instruct-sppo-iter1-gp-2b-tau01-table\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">xukp20/llama-3-8b-instruct-sppo-iter1-gp-2b-tau01-table</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/xukp20__llama-3-8b-instruct-sppo-iter1-gp-2b-tau01-table-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "xukp20/llama-3-8b-instruct-sppo-iter1-gp-2b-tau01-table", "Model sha": "abb3afe2b0398b24ed823b0124c8a72d354487bd", "Average \u2b06\ufe0f": 23.39824983863128, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6909311737301471, "IFEval": 69.0931173730147, "BBH Raw": 0.4978456981516493, "BBH": 28.11988708608538, "MATH Lvl 5 Raw": 0.086858006042296, "MATH Lvl 5": 8.685800604229607, "GPQA Raw": 0.259228187919463, "GPQA": 1.230425055928408, "MUSR Raw": 0.3673333333333333, "MUSR": 3.0833333333333326, "MMLU-PRO Raw": 0.3715924202127659, "MMLU-PRO": 30.17693557919622, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-22T00:00:00", "Submission Date": "2024-09-23T00:00:00", "Generation": 0, "Base Model": "xukp20/llama-3-8b-instruct-sppo-iter1-gp-2b-tau01-table"}, {"eval_name": "xxx777xxxASD_L3.1-ClaudeMaid-4x8B_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/xxx777xxxASD/L3.1-ClaudeMaid-4x8B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">xxx777xxxASD/L3.1-ClaudeMaid-4x8B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/xxx777xxxASD__L3.1-ClaudeMaid-4x8B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "xxx777xxxASD/L3.1-ClaudeMaid-4x8B", "Model sha": "2a98d9cb91c7aa775acbf5bfe7bb91beb2faf682", "Average \u2b06\ufe0f": 26.190882979161238, "Hub License": "llama3.1", "Hub \u2764\ufe0f": 7, "#Params (B)": 24, "Available on the hub": true, "Not_Merged": true, "MoE": false, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6696487541944263, "IFEval": 66.96487541944263, "BBH Raw": 0.5070848048063867, "BBH": 29.437347820739543, "MATH Lvl 5 Raw": 0.1283987915407855, "MATH Lvl 5": 12.83987915407855, "GPQA Raw": 0.2911073825503356, "GPQA": 5.480984340044745, "MUSR Raw": 0.4289374999999999, "MUSR": 13.750520833333333, "MMLU-PRO Raw": 0.3580452127659574, "MMLU-PRO": 28.671690307328607, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-07-27T00:00:00", "Submission Date": "2024-07-28T00:00:00", "Generation": 0, "Base Model": "xxx777xxxASD/L3.1-ClaudeMaid-4x8B"}, {"eval_name": "yam-peleg_Hebrew-Gemma-11B-Instruct_float16", "Precision": "float16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "GemmaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/yam-peleg/Hebrew-Gemma-11B-Instruct\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">yam-peleg/Hebrew-Gemma-11B-Instruct</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/yam-peleg__Hebrew-Gemma-11B-Instruct-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "yam-peleg/Hebrew-Gemma-11B-Instruct", "Model sha": "a40259d1efbcac4829ed44d3b589716f615ed362", "Average \u2b06\ufe0f": 13.80646967251036, "Hub License": "other", "Hub \u2764\ufe0f": 22, "#Params (B)": 10, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.3020773769154731, "IFEval": 30.207737691547315, "BBH Raw": 0.4035784310981868, "BBH": 16.86274051283721, "MATH Lvl 5 Raw": 0.0506042296072507, "MATH Lvl 5": 5.060422960725076, "GPQA Raw": 0.276006711409396, "GPQA": 3.467561521252797, "MUSR Raw": 0.4088541666666667, "MUSR": 9.973437500000005, "MMLU-PRO Raw": 0.2554022606382978, "MMLU-PRO": 17.266917848699762, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-03-06T00:00:00", "Submission Date": "2024-07-31T00:00:00", "Generation": 0, "Base Model": "yam-peleg/Hebrew-Gemma-11B-Instruct"}, {"eval_name": "yam-peleg_Hebrew-Mistral-7B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/yam-peleg/Hebrew-Mistral-7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">yam-peleg/Hebrew-Mistral-7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/yam-peleg__Hebrew-Mistral-7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "yam-peleg/Hebrew-Mistral-7B", "Model sha": "3d32134b5959492fd7efbbf16395352594bc89f7", "Average \u2b06\ufe0f": 13.2265884787933, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 60, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2328344348550734, "IFEval": 23.28344348550734, "BBH Raw": 0.4334036699236203, "BBH": 20.176940422218426, "MATH Lvl 5 Raw": 0.0453172205438066, "MATH Lvl 5": 4.531722054380665, "GPQA Raw": 0.2793624161073825, "GPQA": 3.9149888143176734, "MUSR Raw": 0.39765625, "MUSR": 7.673697916666668, "MMLU-PRO Raw": 0.2780086436170212, "MMLU-PRO": 19.778738179669027, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-04-26T00:00:00", "Submission Date": "2024-07-11T00:00:00", "Generation": 0, "Base Model": "yam-peleg/Hebrew-Mistral-7B"}, {"eval_name": "yam-peleg_Hebrew-Mistral-7B-200K_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/yam-peleg/Hebrew-Mistral-7B-200K\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">yam-peleg/Hebrew-Mistral-7B-200K</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/yam-peleg__Hebrew-Mistral-7B-200K-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "yam-peleg/Hebrew-Mistral-7B-200K", "Model sha": "7b51c7b31e3d9e29ea964c579a45233cfad255fe", "Average \u2b06\ufe0f": 10.64429135893812, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 15, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.1855731680829089, "IFEval": 18.55731680829089, "BBH Raw": 0.4149272793394017, "BBH": 17.49360317518456, "MATH Lvl 5 Raw": 0.0234138972809667, "MATH Lvl 5": 2.3413897280966767, "GPQA Raw": 0.276006711409396, "GPQA": 3.467561521252797, "MUSR Raw": 0.3764791666666667, "MUSR": 4.5265625000000025, "MMLU-PRO Raw": 0.257313829787234, "MMLU-PRO": 17.47931442080378, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-05T00:00:00", "Submission Date": "2024-07-11T00:00:00", "Generation": 0, "Base Model": "yam-peleg/Hebrew-Mistral-7B-200K"}, {"eval_name": "yam-peleg_Hebrew-Mistral-7B-200K_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udfe9 continuously pretrained", "T": "\ud83d\udfe9", "Weight type": "Original", "Architecture": "MistralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/yam-peleg/Hebrew-Mistral-7B-200K\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">yam-peleg/Hebrew-Mistral-7B-200K</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/yam-peleg__Hebrew-Mistral-7B-200K-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "yam-peleg/Hebrew-Mistral-7B-200K", "Model sha": "7b51c7b31e3d9e29ea964c579a45233cfad255fe", "Average \u2b06\ufe0f": 8.210435440416354, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 15, "#Params (B)": 7, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.1769804119735634, "IFEval": 17.698041197356346, "BBH Raw": 0.3410500846818921, "BBH": 7.671323719331375, "MATH Lvl 5 Raw": 0.0203927492447129, "MATH Lvl 5": 2.0392749244712998, "GPQA Raw": 0.2533557046979866, "GPQA": 0.4474272930648763, "MUSR Raw": 0.3739999999999999, "MUSR": 4.416666666666667, "MMLU-PRO Raw": 0.2529089095744681, "MMLU-PRO": 16.989878841607567, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-05-05T00:00:00", "Submission Date": "2024-08-06T00:00:00", "Generation": 0, "Base Model": "yam-peleg/Hebrew-Mistral-7B-200K"}, {"eval_name": "ycros_BagelMIsteryTour-v2-8x7B_float16", "Precision": "float16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/ycros/BagelMIsteryTour-v2-8x7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">ycros/BagelMIsteryTour-v2-8x7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/ycros__BagelMIsteryTour-v2-8x7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "ycros/BagelMIsteryTour-v2-8x7B", "Model sha": "98a8b319707be3dab1659594da69a37ed8f8c148", "Average \u2b06\ufe0f": 24.258614269254902, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 16, "#Params (B)": 46, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.599431730031871, "IFEval": 59.9431730031871, "BBH Raw": 0.515923595752544, "BBH": 31.69928662894613, "MATH Lvl 5 Raw": 0.0785498489425981, "MATH Lvl 5": 7.854984894259818, "GPQA Raw": 0.3045302013422818, "GPQA": 7.270693512304249, "MUSR Raw": 0.4202916666666667, "MUSR": 11.303125, "MMLU-PRO Raw": 0.3473238031914893, "MMLU-PRO": 27.480422576832154, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-01-19T00:00:00", "Submission Date": "2024-06-28T00:00:00", "Generation": 1, "Base Model": "ycros/BagelMIsteryTour-v2-8x7B (Merge)"}, {"eval_name": "ycros_BagelMIsteryTour-v2-8x7B_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/ycros/BagelMIsteryTour-v2-8x7B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">ycros/BagelMIsteryTour-v2-8x7B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/ycros__BagelMIsteryTour-v2-8x7B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "ycros/BagelMIsteryTour-v2-8x7B", "Model sha": "98a8b319707be3dab1659594da69a37ed8f8c148", "Average \u2b06\ufe0f": 24.548568738609436, "Hub License": "cc-by-nc-4.0", "Hub \u2764\ufe0f": 16, "#Params (B)": 46, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6262095683896506, "IFEval": 62.62095683896506, "BBH Raw": 0.5141943573573103, "BBH": 31.36612301591548, "MATH Lvl 5 Raw": 0.0770392749244713, "MATH Lvl 5": 7.7039274924471295, "GPQA Raw": 0.3078859060402684, "GPQA": 7.718120805369126, "MUSR Raw": 0.41375, "MUSR": 10.31875, "MMLU-PRO Raw": 0.3480718085106383, "MMLU-PRO": 27.56353427895981, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-01-19T00:00:00", "Submission Date": "2024-08-04T00:00:00", "Generation": 1, "Base Model": "ycros/BagelMIsteryTour-v2-8x7B (Merge)"}, {"eval_name": "yfzp_Llama-3-8B-Instruct-SPPO-Iter1_bt_2b-table_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/yfzp/Llama-3-8B-Instruct-SPPO-Iter1_bt_2b-table\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">yfzp/Llama-3-8B-Instruct-SPPO-Iter1_bt_2b-table</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/yfzp__Llama-3-8B-Instruct-SPPO-Iter1_bt_2b-table-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "yfzp/Llama-3-8B-Instruct-SPPO-Iter1_bt_2b-table", "Model sha": "97b2d0e790a6fcdf39c34a2043f0818368c7dcb3", "Average \u2b06\ufe0f": 22.899041911723742, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6708976626462231, "IFEval": 67.08976626462231, "BBH Raw": 0.4986613434913193, "BBH": 28.170106538118223, "MATH Lvl 5 Raw": 0.0687311178247734, "MATH Lvl 5": 6.873111782477341, "GPQA Raw": 0.259228187919463, "GPQA": 1.230425055928408, "MUSR Raw": 0.3726979166666666, "MUSR": 3.85390625, "MMLU-PRO Raw": 0.3715924202127659, "MMLU-PRO": 30.17693557919622, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-29T00:00:00", "Submission Date": "2024-09-30T00:00:00", "Generation": 0, "Base Model": "yfzp/Llama-3-8B-Instruct-SPPO-Iter1_bt_2b-table"}, {"eval_name": "yfzp_Llama-3-8B-Instruct-SPPO-Iter1_bt_8b-table_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/yfzp/Llama-3-8B-Instruct-SPPO-Iter1_bt_8b-table\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">yfzp/Llama-3-8B-Instruct-SPPO-Iter1_bt_8b-table</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/yfzp__Llama-3-8B-Instruct-SPPO-Iter1_bt_8b-table-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "yfzp/Llama-3-8B-Instruct-SPPO-Iter1_bt_8b-table", "Model sha": "e8786291c206d5cd1b01d29466e3b397278f4e2b", "Average \u2b06\ufe0f": 24.76448329752785, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7332710541363582, "IFEval": 73.32710541363582, "BBH Raw": 0.5080359954971677, "BBH": 29.308127928492556, "MATH Lvl 5 Raw": 0.0906344410876132, "MATH Lvl 5": 9.06344410876133, "GPQA Raw": 0.2600671140939597, "GPQA": 1.342281879194629, "MUSR Raw": 0.3806041666666666, "MUSR": 5.008854166666667, "MMLU-PRO Raw": 0.3748337765957447, "MMLU-PRO": 30.53708628841608, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-29T00:00:00", "Submission Date": "2024-09-30T00:00:00", "Generation": 0, "Base Model": "yfzp/Llama-3-8B-Instruct-SPPO-Iter1_bt_8b-table"}, {"eval_name": "yfzp_Llama-3-8B-Instruct-SPPO-Iter1_gp_2b-table_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/yfzp/Llama-3-8B-Instruct-SPPO-Iter1_gp_2b-table\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">yfzp/Llama-3-8B-Instruct-SPPO-Iter1_gp_2b-table</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/yfzp__Llama-3-8B-Instruct-SPPO-Iter1_gp_2b-table-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "yfzp/Llama-3-8B-Instruct-SPPO-Iter1_gp_2b-table", "Model sha": "0d9cb29aa87b0c17ed011ffbc83803f3f6dd18e7", "Average \u2b06\ufe0f": 23.054820506524027, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6784664689690023, "IFEval": 67.84664689690022, "BBH Raw": 0.4941209189652045, "BBH": 27.469588233937547, "MATH Lvl 5 Raw": 0.0883685800604229, "MATH Lvl 5": 8.836858006042297, "GPQA Raw": 0.259228187919463, "GPQA": 1.230425055928408, "MUSR Raw": 0.3646666666666667, "MUSR": 2.7500000000000018, "MMLU-PRO Raw": 0.3717586436170212, "MMLU-PRO": 30.1954048463357, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-29T00:00:00", "Submission Date": "2024-09-29T00:00:00", "Generation": 0, "Base Model": "yfzp/Llama-3-8B-Instruct-SPPO-Iter1_gp_2b-table"}, {"eval_name": "yfzp_Llama-3-8B-Instruct-SPPO-Iter1_gp_8b-table_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/yfzp/Llama-3-8B-Instruct-SPPO-Iter1_gp_8b-table\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">yfzp/Llama-3-8B-Instruct-SPPO-Iter1_gp_8b-table</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/yfzp__Llama-3-8B-Instruct-SPPO-Iter1_gp_8b-table-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "yfzp/Llama-3-8B-Instruct-SPPO-Iter1_gp_8b-table", "Model sha": "7a326a956e6169b287a04ef93cdc0342a0f3311a", "Average \u2b06\ufe0f": 23.875795381763808, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7131876753680235, "IFEval": 71.31876753680235, "BBH Raw": 0.5025359954971677, "BBH": 28.60442422478885, "MATH Lvl 5 Raw": 0.0861027190332326, "MATH Lvl 5": 8.610271903323262, "GPQA Raw": 0.259228187919463, "GPQA": 1.230425055928408, "MUSR Raw": 0.3713333333333333, "MUSR": 3.683333333333333, "MMLU-PRO Raw": 0.3682679521276595, "MMLU-PRO": 29.807550236406616, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-29T00:00:00", "Submission Date": "2024-09-29T00:00:00", "Generation": 0, "Base Model": "yfzp/Llama-3-8B-Instruct-SPPO-Iter1_gp_8b-table"}, {"eval_name": "yfzp_Llama-3-8B-Instruct-SPPO-score-Iter1_bt_2b-table-0.001_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/yfzp/Llama-3-8B-Instruct-SPPO-score-Iter1_bt_2b-table-0.001\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">yfzp/Llama-3-8B-Instruct-SPPO-score-Iter1_bt_2b-table-0.001</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/yfzp__Llama-3-8B-Instruct-SPPO-score-Iter1_bt_2b-table-0.001-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "yfzp/Llama-3-8B-Instruct-SPPO-score-Iter1_bt_2b-table-0.001", "Model sha": "e5c8baadbf6ce17b344596ad42bd3546f66e253e", "Average \u2b06\ufe0f": 22.31451433353681, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6495653754260917, "IFEval": 64.95653754260917, "BBH Raw": 0.4979459532536201, "BBH": 28.09919885125768, "MATH Lvl 5 Raw": 0.0453172205438066, "MATH Lvl 5": 4.531722054380665, "GPQA Raw": 0.259228187919463, "GPQA": 1.230425055928408, "MUSR Raw": 0.3779687499999999, "MUSR": 4.8460937500000005, "MMLU-PRO Raw": 0.3720079787234042, "MMLU-PRO": 30.223108747044915, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-29T00:00:00", "Submission Date": "2024-09-30T00:00:00", "Generation": 0, "Base Model": "yfzp/Llama-3-8B-Instruct-SPPO-score-Iter1_bt_2b-table-0.001"}, {"eval_name": "yfzp_Llama-3-8B-Instruct-SPPO-score-Iter1_bt_8b-table-0.002_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/yfzp/Llama-3-8B-Instruct-SPPO-score-Iter1_bt_8b-table-0.002\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">yfzp/Llama-3-8B-Instruct-SPPO-score-Iter1_bt_8b-table-0.002</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/yfzp__Llama-3-8B-Instruct-SPPO-score-Iter1_bt_8b-table-0.002-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "yfzp/Llama-3-8B-Instruct-SPPO-score-Iter1_bt_8b-table-0.002", "Model sha": "064e237b850151938caf171a4c8c7e34c93e580e", "Average \u2b06\ufe0f": 24.19365797533473, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7196073086078272, "IFEval": 71.96073086078272, "BBH Raw": 0.5045147424411157, "BBH": 28.78591054243753, "MATH Lvl 5 Raw": 0.0709969788519637, "MATH Lvl 5": 7.099697885196375, "GPQA Raw": 0.2600671140939597, "GPQA": 1.342281879194629, "MUSR Raw": 0.3831458333333333, "MUSR": 5.593229166666667, "MMLU-PRO Raw": 0.3734208776595745, "MMLU-PRO": 30.38009751773049, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-29T00:00:00", "Submission Date": "2024-09-30T00:00:00", "Generation": 0, "Base Model": "yfzp/Llama-3-8B-Instruct-SPPO-score-Iter1_bt_8b-table-0.002"}, {"eval_name": "yfzp_Llama-3-8B-Instruct-SPPO-score-Iter1_gp_2b-table-0.001_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/yfzp/Llama-3-8B-Instruct-SPPO-score-Iter1_gp_2b-table-0.001\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">yfzp/Llama-3-8B-Instruct-SPPO-score-Iter1_gp_2b-table-0.001</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/yfzp__Llama-3-8B-Instruct-SPPO-score-Iter1_gp_2b-table-0.001-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "yfzp/Llama-3-8B-Instruct-SPPO-score-Iter1_gp_2b-table-0.001", "Model sha": "b685b90063258e05f8b4930fdbce2e565f13f620", "Average \u2b06\ufe0f": 22.284132011095167, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6504397221594258, "IFEval": 65.04397221594259, "BBH Raw": 0.4957875856318712, "BBH": 27.82525272195498, "MATH Lvl 5 Raw": 0.0672205438066465, "MATH Lvl 5": 6.722054380664652, "GPQA Raw": 0.259228187919463, "GPQA": 1.230425055928408, "MUSR Raw": 0.36603125, "MUSR": 2.853906249999999, "MMLU-PRO Raw": 0.3702626329787234, "MMLU-PRO": 30.029181442080382, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-29T00:00:00", "Submission Date": "2024-09-29T00:00:00", "Generation": 0, "Base Model": "yfzp/Llama-3-8B-Instruct-SPPO-score-Iter1_gp_2b-table-0.001"}, {"eval_name": "yfzp_Llama-3-8B-Instruct-SPPO-score-Iter1_gp_8b-table-0.002_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/yfzp/Llama-3-8B-Instruct-SPPO-score-Iter1_gp_8b-table-0.002\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">yfzp/Llama-3-8B-Instruct-SPPO-score-Iter1_gp_8b-table-0.002</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/yfzp__Llama-3-8B-Instruct-SPPO-score-Iter1_gp_8b-table-0.002-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "yfzp/Llama-3-8B-Instruct-SPPO-score-Iter1_gp_8b-table-0.002", "Model sha": "5ab3f2cfc96bdda3b5a629ab4a81adf7394ba90a", "Average \u2b06\ufe0f": 23.39664104800949, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7015973173402128, "IFEval": 70.15973173402128, "BBH Raw": 0.4991547169583548, "BBH": 28.12061516996449, "MATH Lvl 5 Raw": 0.0657099697885196, "MATH Lvl 5": 6.570996978851963, "GPQA Raw": 0.259228187919463, "GPQA": 1.230425055928408, "MUSR Raw": 0.3779062499999999, "MUSR": 4.63828125, "MMLU-PRO Raw": 0.366938164893617, "MMLU-PRO": 29.659796099290777, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-29T00:00:00", "Submission Date": "2024-09-29T00:00:00", "Generation": 0, "Base Model": "yfzp/Llama-3-8B-Instruct-SPPO-score-Iter1_gp_8b-table-0.002"}, {"eval_name": "yifAI_Llama-3-8B-Instruct-SPPO-score-Iter3_gp_8b-table-0.002_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/yifAI/Llama-3-8B-Instruct-SPPO-score-Iter3_gp_8b-table-0.002\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">yifAI/Llama-3-8B-Instruct-SPPO-score-Iter3_gp_8b-table-0.002</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/yifAI__Llama-3-8B-Instruct-SPPO-score-Iter3_gp_8b-table-0.002-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "yifAI/Llama-3-8B-Instruct-SPPO-score-Iter3_gp_8b-table-0.002", "Model sha": "7a046b74179225d6055dd8aa601b5234f817b1e5", "Average \u2b06\ufe0f": 22.51148924731595, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.6489658550423987, "IFEval": 64.89658550423985, "BBH Raw": 0.4914521707125487, "BBH": 27.28106392287093, "MATH Lvl 5 Raw": 0.0619335347432024, "MATH Lvl 5": 6.193353474320242, "GPQA Raw": 0.261744966442953, "GPQA": 1.5659955257270708, "MUSR Raw": 0.3898749999999999, "MUSR": 7.134375000000002, "MMLU-PRO Raw": 0.3519780585106383, "MMLU-PRO": 27.997562056737586, "Maintainer's Highlight": false, "Upload To Hub Date": "", "Submission Date": "2024-09-30T00:00:00", "Generation": 0, "Base Model": "Removed"}, {"eval_name": "yuvraj17_Llama3-8B-SuperNova-Spectrum-Hermes-DPO_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udcac chat models (RLHF, DPO, IFT, ...)", "T": "\ud83d\udcac", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/yuvraj17/Llama3-8B-SuperNova-Spectrum-Hermes-DPO\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">yuvraj17/Llama3-8B-SuperNova-Spectrum-Hermes-DPO</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/yuvraj17__Llama3-8B-SuperNova-Spectrum-Hermes-DPO-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "yuvraj17/Llama3-8B-SuperNova-Spectrum-Hermes-DPO", "Model sha": "0da9f780f7dd94ed1e10c8d3e082472ff2922177", "Average \u2b06\ufe0f": 18.000050768518598, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4690897928607206, "IFEval": 46.90897928607207, "BBH Raw": 0.4399870586095269, "BBH": 21.238562899271304, "MATH Lvl 5 Raw": 0.0513595166163142, "MATH Lvl 5": 5.13595166163142, "GPQA Raw": 0.3020134228187919, "GPQA": 6.935123042505594, "MUSR Raw": 0.40121875, "MUSR": 9.619010416666669, "MMLU-PRO Raw": 0.2634640957446808, "MMLU-PRO": 18.162677304964536, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-24T00:00:00", "Submission Date": "2024-09-30T00:00:00", "Generation": 0, "Base Model": "yuvraj17/Llama3-8B-SuperNova-Spectrum-Hermes-DPO"}, {"eval_name": "yuvraj17_Llama3-8B-SuperNova-Spectrum-dare_ties_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/yuvraj17/Llama3-8B-SuperNova-Spectrum-dare_ties\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">yuvraj17/Llama3-8B-SuperNova-Spectrum-dare_ties</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/yuvraj17__Llama3-8B-SuperNova-Spectrum-dare_ties-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "yuvraj17/Llama3-8B-SuperNova-Spectrum-dare_ties", "Model sha": "998d15b32900bc230727c8a7984e005f611723e9", "Average \u2b06\ufe0f": 18.99633149253658, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.4012708502329375, "IFEval": 40.12708502329375, "BBH Raw": 0.4615794426716074, "BBH": 23.492187889680057, "MATH Lvl 5 Raw": 0.0740181268882175, "MATH Lvl 5": 7.401812688821751, "GPQA Raw": 0.2751677852348993, "GPQA": 3.355704697986576, "MUSR Raw": 0.42109375, "MUSR": 11.003385416666667, "MMLU-PRO Raw": 0.3573803191489361, "MMLU-PRO": 28.59781323877068, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-22T00:00:00", "Submission Date": "2024-09-23T00:00:00", "Generation": 1, "Base Model": "yuvraj17/Llama3-8B-SuperNova-Spectrum-dare_ties (Merge)"}, {"eval_name": "yuvraj17_Llama3-8B-abliterated-Spectrum-slerp_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "LlamaForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/yuvraj17/Llama3-8B-abliterated-Spectrum-slerp\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">yuvraj17/Llama3-8B-abliterated-Spectrum-slerp</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/yuvraj17__Llama3-8B-abliterated-Spectrum-slerp-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "yuvraj17/Llama3-8B-abliterated-Spectrum-slerp", "Model sha": "28789950975ecf5aac846c3f2c0a5d6841651ee6", "Average \u2b06\ufe0f": 17.599434781971368, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 0, "#Params (B)": 8, "Available on the hub": true, "Not_Merged": false, "MoE": true, "Flagged": false, "Chat Template": false, "IFEval Raw": 0.2884878788281759, "IFEval": 28.84878788281759, "BBH Raw": 0.4977912063897858, "BBH": 28.54692976096071, "MATH Lvl 5 Raw": 0.052870090634441, "MATH Lvl 5": 5.287009063444108, "GPQA Raw": 0.3011744966442953, "GPQA": 6.823266219239373, "MUSR Raw": 0.3998229166666666, "MUSR": 11.011197916666662, "MMLU-PRO Raw": 0.3257147606382978, "MMLU-PRO": 25.07941784869976, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-09-22T00:00:00", "Submission Date": "2024-09-23T00:00:00", "Generation": 1, "Base Model": "yuvraj17/Llama3-8B-abliterated-Spectrum-slerp (Merge)"}, {"eval_name": "zelk12_MT-gemma-2-9B_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/zelk12/MT-gemma-2-9B\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">zelk12/MT-gemma-2-9B</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/zelk12__MT-gemma-2-9B-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "zelk12/MT-gemma-2-9B", "Model sha": "24e1f894517b86dd866c1a5999ced4a5924dcd90", "Average \u2b06\ufe0f": 30.239611687439066, "Hub License": null, "Hub \u2764\ufe0f": 2, "#Params (B)": 10, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7968434863938794, "IFEval": 79.68434863938793, "BBH Raw": 0.6063604478633632, "BBH": 43.32424255563143, "MATH Lvl 5 Raw": 0.0030211480362537, "MATH Lvl 5": 0.3021148036253776, "GPQA Raw": 0.3456375838926174, "GPQA": 12.751677852348994, "MUSR Raw": 0.4071145833333333, "MUSR": 9.555989583333336, "MMLU-PRO Raw": 0.4223736702127659, "MMLU-PRO": 35.819296690307326, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-11T00:00:00", "Submission Date": "2024-10-11T00:00:00", "Generation": 1, "Base Model": "zelk12/MT-gemma-2-9B (Merge)"}, {"eval_name": "zelk12_recoilme-gemma-2-Ataraxy-9B-v0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/zelk12/recoilme-gemma-2-Ataraxy-9B-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">zelk12/recoilme-gemma-2-Ataraxy-9B-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/zelk12__recoilme-gemma-2-Ataraxy-9B-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "zelk12/recoilme-gemma-2-Ataraxy-9B-v0.1", "Model sha": "b4208ddf6c741884c16c77b9433d9ead8f216354", "Average \u2b06\ufe0f": 30.33230535283381, "Hub License": null, "Hub \u2764\ufe0f": 2, "#Params (B)": 10, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7648949232480928, "IFEval": 76.48949232480928, "BBH Raw": 0.6074511952177571, "BBH": 43.70651609013871, "MATH Lvl 5 Raw": 0.0128398791540785, "MATH Lvl 5": 1.283987915407855, "GPQA Raw": 0.3498322147651007, "GPQA": 13.31096196868009, "MUSR Raw": 0.4136249999999999, "MUSR": 10.303125000000003, "MMLU-PRO Raw": 0.4320977393617021, "MMLU-PRO": 36.89974881796691, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-03T00:00:00", "Submission Date": "2024-10-03T00:00:00", "Generation": 1, "Base Model": "zelk12/recoilme-gemma-2-Ataraxy-9B-v0.1 (Merge)"}, {"eval_name": "zelk12_recoilme-gemma-2-Ataraxy-9B-v0.1-t0.25_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/zelk12/recoilme-gemma-2-Ataraxy-9B-v0.1-t0.25\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">zelk12/recoilme-gemma-2-Ataraxy-9B-v0.1-t0.25</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/zelk12__recoilme-gemma-2-Ataraxy-9B-v0.1-t0.25-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "zelk12/recoilme-gemma-2-Ataraxy-9B-v0.1-t0.25", "Model sha": "e652c9e07265526851dad994f4640aa265b9ab56", "Average \u2b06\ufe0f": 33.06107208850681, "Hub License": null, "Hub \u2764\ufe0f": 1, "#Params (B)": 10, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7706651684197928, "IFEval": 77.06651684197928, "BBH Raw": 0.6075432245295168, "BBH": 43.85035014659934, "MATH Lvl 5 Raw": 0.141238670694864, "MATH Lvl 5": 14.123867069486405, "GPQA Raw": 0.3431208053691275, "GPQA": 12.416107382550338, "MUSR Raw": 0.4322604166666666, "MUSR": 13.132552083333335, "MMLU-PRO Raw": 0.4399933510638298, "MMLU-PRO": 37.77703900709219, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-04T00:00:00", "Submission Date": "2024-10-04T00:00:00", "Generation": 1, "Base Model": "zelk12/recoilme-gemma-2-Ataraxy-9B-v0.1-t0.25 (Merge)"}, {"eval_name": "zelk12_recoilme-gemma-2-Ataraxy-9B-v0.1-t0.75_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/zelk12/recoilme-gemma-2-Ataraxy-9B-v0.1-t0.75\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">zelk12/recoilme-gemma-2-Ataraxy-9B-v0.1-t0.75</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/zelk12__recoilme-gemma-2-Ataraxy-9B-v0.1-t0.75-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "zelk12/recoilme-gemma-2-Ataraxy-9B-v0.1-t0.75", "Model sha": "eb0e589291630ba20328db650f74af949d217a97", "Average \u2b06\ufe0f": 28.421762158489, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 10, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7208063493752133, "IFEval": 72.08063493752132, "BBH Raw": 0.5995203934792884, "BBH": 42.48715312806591, "MATH Lvl 5 Raw": 0.0, "MATH Lvl 5": 0.0, "GPQA Raw": 0.3498322147651007, "GPQA": 13.31096196868009, "MUSR Raw": 0.3951145833333333, "MUSR": 7.755989583333336, "MMLU-PRO Raw": 0.4140625, "MMLU-PRO": 34.895833333333336, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-04T00:00:00", "Submission Date": "2024-10-04T00:00:00", "Generation": 1, "Base Model": "zelk12/recoilme-gemma-2-Ataraxy-9B-v0.1-t0.75 (Merge)"}, {"eval_name": "zelk12_recoilme-gemma-2-Ataraxy-9B-v0.2_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/zelk12/recoilme-gemma-2-Ataraxy-9B-v0.2\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">zelk12/recoilme-gemma-2-Ataraxy-9B-v0.2</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/zelk12__recoilme-gemma-2-Ataraxy-9B-v0.2-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "zelk12/recoilme-gemma-2-Ataraxy-9B-v0.2", "Model sha": "76f56b25bf6d8704282f8c77bfda28ca384883bc", "Average \u2b06\ufe0f": 30.10139102218594, "Hub License": null, "Hub \u2764\ufe0f": 1, "#Params (B)": 10, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.759999024809727, "IFEval": 75.99990248097271, "BBH Raw": 0.6066260664115647, "BBH": 43.63358839796041, "MATH Lvl 5 Raw": 0.0113293051359516, "MATH Lvl 5": 1.1329305135951662, "GPQA Raw": 0.3481543624161073, "GPQA": 13.087248322147648, "MUSR Raw": 0.4109583333333333, "MUSR": 9.836458333333338, "MMLU-PRO Raw": 0.4322639627659574, "MMLU-PRO": 36.91821808510639, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-07T00:00:00", "Submission Date": "2024-10-11T00:00:00", "Generation": 1, "Base Model": "zelk12/recoilme-gemma-2-Ataraxy-9B-v0.2 (Merge)"}, {"eval_name": "zelk12_recoilme-gemma-2-Gutenberg-Doppel-9B-v0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/zelk12/recoilme-gemma-2-Gutenberg-Doppel-9B-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">zelk12/recoilme-gemma-2-Gutenberg-Doppel-9B-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/zelk12__recoilme-gemma-2-Gutenberg-Doppel-9B-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "zelk12/recoilme-gemma-2-Gutenberg-Doppel-9B-v0.1", "Model sha": "1e3e623e9f0b386bfd967c629dd39c87daef5bed", "Average \u2b06\ufe0f": 31.46273045841367, "Hub License": null, "Hub \u2764\ufe0f": 1, "#Params (B)": 10, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7615227596111651, "IFEval": 76.15227596111652, "BBH Raw": 0.6098779556010631, "BBH": 43.94125829423596, "MATH Lvl 5 Raw": 0.0634441087613293, "MATH Lvl 5": 6.3444108761329305, "GPQA Raw": 0.3414429530201342, "GPQA": 12.192393736017896, "MUSR Raw": 0.4310208333333333, "MUSR": 13.310937499999996, "MMLU-PRO Raw": 0.4315159574468085, "MMLU-PRO": 36.83510638297872, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-07T00:00:00", "Submission Date": "2024-10-07T00:00:00", "Generation": 1, "Base Model": "zelk12/recoilme-gemma-2-Gutenberg-Doppel-9B-v0.1 (Merge)"}, {"eval_name": "zelk12_recoilme-gemma-2-Ifable-9B-v0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/zelk12/recoilme-gemma-2-Ifable-9B-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">zelk12/recoilme-gemma-2-Ifable-9B-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/zelk12__recoilme-gemma-2-Ifable-9B-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "zelk12/recoilme-gemma-2-Ifable-9B-v0.1", "Model sha": "8af6620b39c9a36239879b6b2bd88f66e9e9d930", "Average \u2b06\ufe0f": 32.05301303777705, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 10, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.7943955371746965, "IFEval": 79.43955371746965, "BBH Raw": 0.6064399292200404, "BBH": 43.39057008013784, "MATH Lvl 5 Raw": 0.0793051359516616, "MATH Lvl 5": 7.930513595166164, "GPQA Raw": 0.3515100671140939, "GPQA": 13.534675615212524, "MUSR Raw": 0.4202291666666666, "MUSR": 11.0953125, "MMLU-PRO Raw": 0.4323470744680851, "MMLU-PRO": 36.92745271867612, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-07T00:00:00", "Submission Date": "2024-10-07T00:00:00", "Generation": 1, "Base Model": "zelk12/recoilme-gemma-2-Ifable-9B-v0.1 (Merge)"}, {"eval_name": "zelk12_recoilme-gemma-2-psy10k-mental_healt-9B-v0.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83e\udd1d base merges and moerges", "T": "\ud83e\udd1d", "Weight type": "Original", "Architecture": "Gemma2ForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/zelk12/recoilme-gemma-2-psy10k-mental_healt-9B-v0.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">zelk12/recoilme-gemma-2-psy10k-mental_healt-9B-v0.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/zelk12__recoilme-gemma-2-psy10k-mental_healt-9B-v0.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "zelk12/recoilme-gemma-2-psy10k-mental_healt-9B-v0.1", "Model sha": "ced039b03be6f65ac0f713efcee76c6534e65639", "Average \u2b06\ufe0f": 32.18371087661533, "Hub License": null, "Hub \u2764\ufe0f": 0, "#Params (B)": 10, "Available on the hub": false, "Not_Merged": true, "MoE": true, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.744536718130117, "IFEval": 74.45367181301171, "BBH Raw": 0.597759349920723, "BBH": 42.1326829485998, "MATH Lvl 5 Raw": 0.1646525679758308, "MATH Lvl 5": 16.46525679758308, "GPQA Raw": 0.3439597315436241, "GPQA": 12.527964205816552, "MUSR Raw": 0.42946875, "MUSR": 12.18359375, "MMLU-PRO Raw": 0.4180518617021276, "MMLU-PRO": 35.33909574468085, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-10-07T00:00:00", "Submission Date": "2024-10-07T00:00:00", "Generation": 1, "Base Model": "zelk12/recoilme-gemma-2-psy10k-mental_healt-9B-v0.1 (Merge)"}, {"eval_name": "zhengr_MixTAO-7Bx2-MoE-v8.1_bfloat16", "Precision": "bfloat16", "Type": "\ud83d\udd36 fine-tuned on domain-specific datasets", "T": "\ud83d\udd36", "Weight type": "Original", "Architecture": "MixtralForCausalLM", "Model": "<a target=\"_blank\" href=\"https://huggingface.co/zhengr/MixTAO-7Bx2-MoE-v8.1\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">zhengr/MixTAO-7Bx2-MoE-v8.1</a>  <a target=\"_blank\" href=\"https://huggingface.co/datasets/open-llm-leaderboard/zhengr__MixTAO-7Bx2-MoE-v8.1-details\" style=\"color: var(--link-text-color); text-decoration: underline;text-decoration-style: dotted;\">\ud83d\udcd1</a>", "fullname": "zhengr/MixTAO-7Bx2-MoE-v8.1", "Model sha": "828e963abf2db0f5af9ed0d4034e538fc1cf5f40", "Average \u2b06\ufe0f": 17.055018301390223, "Hub License": "apache-2.0", "Hub \u2764\ufe0f": 53, "#Params (B)": 12, "Available on the hub": true, "Not_Merged": true, "MoE": false, "Flagged": false, "Chat Template": true, "IFEval Raw": 0.4187810564856802, "IFEval": 41.87810564856802, "BBH Raw": 0.4201943756023965, "BBH": 19.17690717348315, "MATH Lvl 5 Raw": 0.059667673716012, "MATH Lvl 5": 5.966767371601208, "GPQA Raw": 0.2986577181208054, "GPQA": 6.487695749440718, "MUSR Raw": 0.3976249999999999, "MUSR": 8.303124999999996, "MMLU-PRO Raw": 0.284657579787234, "MMLU-PRO": 20.517508865248228, "Maintainer's Highlight": false, "Upload To Hub Date": "2024-02-26T00:00:00", "Submission Date": "2024-06-27T00:00:00", "Generation": 0, "Base Model": "zhengr/MixTAO-7Bx2-MoE-v8.1"}], "data-622652e47e42a7364f5e71ddd4cfec7c": [{"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 33.02792147058693}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 28.411725333226947}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 31.186917379220468}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 60.66758423205982}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 45.6449997118756}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 26.166017278598567}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 48.02302335580704}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 29.35843561749492}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 23.031113002389212}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 60.455258713546726}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 42.14040966856828}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 30.45751938190668}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 15.424850507763844}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 46.98887839820566}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 28.93378458046871}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 8.433068702154728}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 33.95213588833185}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 27.08779372066118}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 23.270921155866432}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 48.17041006750976}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 51.81740005407873}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 36.07040430502179}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 36.07040430502179}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 22.13438121960841}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 27.55244972229241}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 31.911328608093196}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 24.065257959990603}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 25.67642743476199}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 75.93995044260342}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 73.1647583966099}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 52.47687247614108}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 26.88544173903022}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 27.562423259174547}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 24.012841482821138}, {"Architecture": "GPT2LMHeadModel", "Task": "IFEval", "Score": 14.702988071649887}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 35.28604103777975}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 22.55404548819355}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 53.48852156721942}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 63.59016298975607}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 52.96646231997766}, {"Architecture": "PhiForCausalLM", "Task": "IFEval", "Score": 32.87056122200207}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 51.92234382549414}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 46.05214165081983}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 52.3544196066437}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 43.4293230849701}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 56.96562897556262}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 50.85816744016986}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 31.763831079313995}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 68.21134589555712}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 53.19873491225504}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 74.42120240960651}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 60.50268842227513}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 58.67420666054956}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 55.53930238434022}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 51.85984299436606}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 61.31952109292233}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 61.61928128476886}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 73.35458804859994}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 61.31952109292233}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 61.46690780462506}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 20.745510800232275}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 19.506575885317623}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 13.843712460715349}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 23.860468002677344}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 19.88124842085666}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 15.552290145702292}, {"Architecture": "T5ForConditionalGeneration", "Task": "IFEval", "Score": 15.057713533424646}, {"Architecture": "T5ForConditionalGeneration", "Task": "IFEval", "Score": 13.206735905176044}, {"Architecture": "T5ForConditionalGeneration", "Task": "IFEval", "Score": 14.02855534426433}, {"Architecture": "T5ForConditionalGeneration", "Task": "IFEval", "Score": 13.299157346950537}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 51.30531434371911}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 30.115316249772825}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 43.234506664538976}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 79.98909559967552}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 45.9023169634348}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 77.09898624538445}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 71.22634609502786}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 27.882130524785342}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 30.43247472262486}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 32.428401086893885}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 32.76561745058666}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 46.674157901035926}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 39.984685080032094}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 48.137940664104576}, {"Architecture": "CohereForCausalLM", "Task": "IFEval", "Score": 64.61932117891638}, {"Architecture": "CohereForCausalLM", "Task": "IFEval", "Score": 46.98887839820566}, {"Architecture": "CohereForCausalLM", "Task": "IFEval", "Score": 76.64186580495308}, {"Architecture": "CohereForCausalLM", "Task": "IFEval", "Score": 75.39539532883859}, {"Architecture": "CohereForCausalLM", "Task": "IFEval", "Score": 67.48194789824333}, {"Architecture": "GemmaForCausalLM", "Task": "IFEval", "Score": 32.78312654866864}, {"Architecture": "GemmaForCausalLM", "Task": "IFEval", "Score": 31.02457036219453}, {"Architecture": "GemmaForCausalLM", "Task": "IFEval", "Score": 30.664858131978704}, {"Architecture": "GemmaForCausalLM", "Task": "IFEval", "Score": 36.924693147515256}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 49.57424079220912}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 39.6799381197445}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 38.17116362362975}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 50.33112142448702}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 19.151850423542868}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 20.21846478454944}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 23.860468002677344}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 23.0011923917428}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 14.832865685270637}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 70.76922565459647}, {"Architecture": "?", "Task": "IFEval", "Score": 27.562423259174547}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 46.07463751734288}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 80.81091503876381}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 47.990553952401854}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 73.7242738156979}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 21.11020979888917}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 8.250774611364513}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 6.682048076880455}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 9.105063453857984}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 50.64085515321569}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 40.70909630890482}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 41.34108609600305}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 39.6199860813752}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 39.24032677739509}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 43.032154682908015}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 34.38930925499896}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 40.279458503437546}, {"Architecture": "DeciLMForCausalLM", "Task": "IFEval", "Score": 28.129474239462404}, {"Architecture": "DeciLMForCausalLM", "Task": "IFEval", "Score": 48.802399854608}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 77.94828831943687}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 56.48856146136695}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 55.97148898256626}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 49.98891829235318}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 48.13295389566351}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 78.92746800711004}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 80.32631196336831}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 78.89499860370483}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 78.89499860370483}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 41.03379034295669}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 75.3029738870641}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 53.64843060856306}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 47.818233398493774}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 25.476624245889795}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 41.57335868828044}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 36.91970637907419}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 23.815476269631244}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 71.40620221013577}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 72.81003293483514}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 75.27050448365891}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 73.77923908562614}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 72.35291249440374}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 72.44533393617823}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 71.83584001560305}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 67.99403360860295}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 67.85662043378235}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 71.50361042035134}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 71.56356245872064}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 71.1289378848123}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 72.59272064788095}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 30.07786007792657}, {"Architecture": "GPTJForCausalLM", "Task": "IFEval", "Score": 25.221855787089368}, {"Architecture": "GPTNeoForCausalLM", "Task": "IFEval", "Score": 20.790502533278367}, {"Architecture": "GPTNeoForCausalLM", "Task": "IFEval", "Score": 19.054442213327302}, {"Architecture": "GPTNeoForCausalLM", "Task": "IFEval", "Score": 25.896288514474925}, {"Architecture": "GPTNeoXForCausalLM", "Task": "IFEval", "Score": 25.86880587951081}, {"Architecture": "GPTNeoXForCausalLM", "Task": "IFEval", "Score": 24.71475684517081}, {"Architecture": "GPTNeoXForCausalLM", "Task": "IFEval", "Score": 18.15516163778773}, {"Architecture": "GPTNeoXForCausalLM", "Task": "IFEval", "Score": 21.73222604910526}, {"Architecture": "GPTNeoXForCausalLM", "Task": "IFEval", "Score": 21.954525104500505}, {"Architecture": "GPTNeoXForCausalLM", "Task": "IFEval", "Score": 22.811362739752745}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 41.88807918545016}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 31.953771548380523}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 50.82569803676467}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 46.891470187990095}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 47.04384366813389}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 34.67156034876351}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 31.034543899076677}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 45.317756885064966}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 15.986914719610631}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 31.341728835046567}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 46.20950189940469}, {"Architecture": "GemmaForCausalLM", "Task": "IFEval", "Score": 40.299405577201824}, {"Architecture": "?", "Task": "IFEval", "Score": 8.000992921005155}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 18.33501775289565}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 8.755324760524298}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 45.77243934981405}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 72.74010735958367}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 46.731561146646456}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 44.57339858242796}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 59.753343351197046}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 45.78241288669619}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 46.22955979024543}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 46.109655713506825}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 18.607295309778056}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 53.99562050913798}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 6.946790072563022}, {"Architecture": "GemmaForCausalLM", "Task": "IFEval", "Score": 43.511770989862455}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 13.553925805750964}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 49.8640274471735}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 42.11791380204524}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 38.80814017916904}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 40.84396069096664}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 48.65756193566404}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 50.79079065767719}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 39.52257787115964}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 53.16382753316755}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 35.96047376516532}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 30.9720430679486}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 46.33195476890207}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 53.1288093370036}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 40.741565712310006}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 42.14539643700936}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 46.71914963408201}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 52.62924595628488}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 50.36115285220991}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 48.75242135312082}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 15.754642127333252}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 13.756277787381924}, {"Architecture": "?", "Task": "IFEval", "Score": 54.20041046645124}, {"Architecture": "?", "Task": "IFEval", "Score": 49.68417133206558}, {"Architecture": "?", "Task": "IFEval", "Score": 17.268403391889077}, {"Architecture": "?", "Task": "IFEval", "Score": 17.832905579418167}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 54.177914599928194}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 44.21368635221213}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 47.68580699211426}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 42.155369973891496}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 42.52505574098946}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 78.13811797142694}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 41.883092417009095}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 53.10132670203948}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 57.14049832222946}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 39.32521265796974}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 47.63084172218603}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 44.80567117470534}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 46.36187537954849}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 66.53523761397537}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 51.91480826429429}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 49.50431521695767}, {"Architecture": "GemmaForCausalLM", "Task": "IFEval", "Score": 33.637415391162115}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 65.10891102275296}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 23.61567308075905}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 23.478259905938465}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 21.24762297370976}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 12.14012154416947}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 21.33505764704318}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 19.51654942219977}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 64.97903340913221}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 54.51269298793867}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 72.84250233824031}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 16.968643200042553}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 20.24339862675479}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 27.779735546128716}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 46.86897432146704}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 49.88397452093778}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 47.62585495374495}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 25.526602747376963}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 24.76972211509905}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 73.17473193349201}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 78.41039552830932}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 38.79816664228691}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 36.36019095998617}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 37.02963691893066}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 37.524213531208304}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 49.04719477652628}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 43.32692810631347}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 65.40368444615842}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 67.17221416951466}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 65.55605792630222}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 63.150551647406665}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 62.84580468711906}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 66.77504576745258}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 66.05063453857986}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 64.91908137076291}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 80.9632885189076}, {"Architecture": "PhiForCausalLM", "Task": "IFEval", "Score": 23.565694579271884}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 26.695612087040164}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 24.692260978647766}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 0.784363267242029}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 61.79913739987677}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 61.052230304481}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 61.64676391973297}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 72.38039512936786}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 26.708134416681077}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 35.665700341759866}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 45.52509563513699}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 43.71412297149342}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 52.759123569905626}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 41.84563624516284}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 40.78400865259733}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 39.47259936967247}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 50.45102550122565}, {"Architecture": "ExaoneForCausalLM", "Task": "IFEval", "Score": 71.92826145737754}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 22.52157608478836}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 51.51763986223221}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 47.93813747523238}, {"Architecture": "GemmaForCausalLM", "Task": "IFEval", "Score": 21.49740466406912}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 22.211842356059694}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 31.094495937445977}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 41.11125147940797}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 35.8256093831035}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 43.70658741029358}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 15.339964627189191}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 15.557276914143362}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 27.64985793250797}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 18.11770546594148}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 21.949538336059437}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 24.12277202267761}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 14.14591062824417}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 22.09193827932109}, {"Architecture": "Phi3ForCausalLM", "Task": "IFEval", "Score": 19.45903535951276}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 27.122811916825132}, {"Architecture": "?", "Task": "IFEval", "Score": 4.453849120334047}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 11.533065599276586}, {"Architecture": "Phi3ForCausalLM", "Task": "IFEval", "Score": 30.440010283824694}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 69.46280314011267}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 67.62933460994606}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 64.92406813920398}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 32.10869382128308}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 64.90157227268094}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 66.30041622893921}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 60.068063848366776}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 44.89310584803876}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 53.70583385417359}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 13.36409615376091}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 54.59259210007225}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 56.28620947973599}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 70.98155117310957}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 57.73503193748144}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 51.12800702136997}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 52.49183278146429}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 43.61416596851908}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 50.63586838477463}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 41.181177054659415}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 40.27192294223771}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 44.97056698449004}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 47.82067137417607}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 44.57838535086903}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 37.00714105240761}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 47.20619068515982}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 33.42508987264902}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 55.74664113441224}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 25.484159807089632}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 27.949618124354487}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 16.973629968483625}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 43.15205875964662}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 42.9447200095746}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 47.14380067110822}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 76.67433520835827}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 75.27549125209998}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 76.3046494412603}, {"Architecture": "Qwen2MoeForCausalLM", "Task": "IFEval", "Score": 29.5432785010439}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 33.52249808286457}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 27.74726614272353}, {"Architecture": "Phi3ForCausalLM", "Task": "IFEval", "Score": 55.2520645221346}, {"Architecture": "Phi3ForCausalLM", "Task": "IFEval", "Score": 56.59095644002358}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 81.62774770941103}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 38.16119008674761}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 86.62360315075111}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 81.35547015252862}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 82.0848681498424}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 85.92667455684251}, {"Architecture": "Phi3ForCausalLM", "Task": "IFEval", "Score": 50.69083365470286}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 80.08151704145003}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 35.97299609480623}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 84.76763875406145}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 79.86420475449586}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 80.10401290797307}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 86.04657863358113}, {"Architecture": "Phi3ForCausalLM", "Task": "IFEval", "Score": 49.26450706348045}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 38.49840645044039}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 38.24862476008103}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 80.65854155862002}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 50.27371817887649}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 32.995452067181745}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 80.10899967641413}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 31.449221399220733}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 34.426765426845215}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 35.92301759331906}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 15.36744726215331}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 17.827918810977096}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 16.67885654507817}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 23.952889444451834}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 26.29844368497808}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 53.90818583580456}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 73.44202272193337}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 50.20124381086628}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 50.96311121158526}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 49.08465094837254}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 40.07211975336551}, {"Architecture": "GPTNeoXForCausalLM", "Task": "IFEval", "Score": 21.79716485591564}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 16.99612583500667}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 41.226168787705504}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 46.10710692074806}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 46.56422736117945}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 25.231829323971507}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 55.74165436597117}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 10.993497253952846}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 50.3810999259742}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 17.90781792311068}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 71.74840534226962}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 39.9072239435808}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 54.744965580216046}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 39.23777798463632}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 55.07719517546776}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 53.61839918084017}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 56.68337788179808}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 65.17883659800441}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 76.61438316998897}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 61.70172918966122}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 57.62510139762497}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 58.96898008395502}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 57.30783210769647}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 52.78660620486975}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 17.290788441335657}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 16.546430138698653}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 14.847825990593847}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 16.99856381068897}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 19.33669330709185}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 20.79548930171944}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 19.48153122603581}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 19.88867316498003}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 2.5654153202391874}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 20.30091268944179}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 44.131238447319774}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 28.91627548238673}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 59.63842604289951}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 49.77659277384008}, {"Architecture": "GPTNeoXForCausalLM", "Task": "IFEval", "Score": 10.553885911603434}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 55.69666263292508}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 61.91904147661538}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 73.32710541363582}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 66.57269378582163}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 59.97065563815122}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 35.90052172679601}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 54.9347952322061}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 63.0880508162786}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 61.31453432448127}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 56.7258208220854}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 54.20041046645124}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 37.529200299649375}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 38.02377691192702}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 50.57092957796425}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 43.70658741029358}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 77.76843220432897}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 77.91581891603168}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 28.05943784713449}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 63.30791189599152}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 69.3054428915278}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 50.40858256093832}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 21.91452013989548}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 49.81903571412741}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 62.38613545392891}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 43.384331351924}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 59.60595663949432}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 59.60595663949432}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 59.75833011963812}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 59.60595663949432}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 59.60595663949432}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 59.75833011963812}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 59.60595663949432}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 37.06210632233585}, {"Architecture": "GPTJForCausalLM", "Task": "IFEval", "Score": 20.91040661001697}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 53.00391849182392}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 17.056077873375976}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 18.072713732895387}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 21.54239639711521}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 20.190982149585324}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 34.21942667677318}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 59.38864435254016}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 29.05368865720732}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 47.68082022367319}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 32.97295620065869}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 55.32199009738605}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 24.447466056729475}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 31.566576683200577}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 26.842998798742894}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 43.71157417873464}, {"Architecture": "Qwen2MoeForCausalLM", "Task": "IFEval", "Score": 26.59820387682461}, {"Architecture": "Qwen2MoeForCausalLM", "Task": "IFEval", "Score": 37.95385133667558}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 18.672234116588427}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 22.466610814860125}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 21.132705665412217}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 33.712327734854625}, {"Architecture": "Qwen2MoeForCausalLM", "Task": "IFEval", "Score": 31.126965340851164}, {"Architecture": "Qwen2MoeForCausalLM", "Task": "IFEval", "Score": 63.37783747124297}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 38.23610243044012}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 79.89168738945996}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 31.48667757106699}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 56.79075962889577}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 56.93814634059851}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 26.87048143370701}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 16.271714606133948}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 30.712287840707106}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 26.74304179576856}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 44.75569267321818}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 36.94464022127954}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 81.57776920792386}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 40.76649955451536}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 83.46121623957765}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 26.89541527591236}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 64.74919879253714}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 41.37100670664947}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 86.5036990740125}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 33.74479713825982}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 75.85251576926998}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 34.4592348302504}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 61.037269999157786}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 40.03466358151925}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 24.59983953687328}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 26.358395723347385}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 18.54235650296768}, {"Architecture": "LlamaForRewardModelWithGating", "Task": "IFEval", "Score": 18.967007539993883}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 53.401086893886}, {"Architecture": "RwkvForCausalLM", "Task": "IFEval", "Score": 7.683723631076655}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 15.559714889825662}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 26.8555211283838}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 69.15306941138402}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 53.87571643239937}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 47.293625358493244}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 30.14279888473694}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 9.047549391170982}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 9.324813716494456}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 8.575468645416384}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 55.14966954347798}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 43.78903531518593}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 32.51084899178623}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 47.4959773401242}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 41.96554032190144}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 38.15620331830654}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 54.31034100630771}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 53.67835121920948}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 51.00056738343152}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 73.84417789243652}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 72.81003293483514}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 68.94573066131198}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 68.72841837435782}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 46.03718134549661}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 44.86063644463357}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 36.71236762900216}, {"Architecture": "GemmaForCausalLM", "Task": "IFEval", "Score": 45.21536190640833}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 43.76653944866288}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 40.07710652180658}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 37.86641666334215}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 9.554648333089537}, {"Architecture": "?", "Task": "IFEval", "Score": 55.169616617242255}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 43.78903531518593}, {"Architecture": "GemmaForCausalLM", "Task": "IFEval", "Score": 20.623168747811363}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 35.88057465303173}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 46.29948536549688}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 31.57909901284148}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 31.73147249298528}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 37.89389929830627}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 17.605619755581856}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 25.466650709007656}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 42.26530051374797}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 42.84232503091796}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 43.65915770156518}, {"Architecture": "Phi3ForCausalLM", "Task": "IFEval", "Score": 57.14049832222946}, {"Architecture": "ChatGLMModelM", "Task": "IFEval", "Score": 14.260827936541707}, {"Architecture": "ChatGLMModelM", "Task": "IFEval", "Score": 0.0}, {"Architecture": "ChatGLMModel", "Task": "IFEval", "Score": 0.0}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 55.74664113441224}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 43.91891292880668}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 23.363342597640923}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 22.77135777514772}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 44.86063644463357}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 21.18767093534045}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 21.145227995053123}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 24.155130609006328}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 60.764992442275386}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 56.21628390448454}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 44.82318027278731}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 5.957636848007731}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 20.00613926603634}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 30.027881576439405}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 25.771397669295247}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 69.0931173730147}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 74.00153814102137}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 30.8221075634871}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 31.00196367859502}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 31.671409637539504}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 72.98988904994303}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 69.88745417713888}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 68.34122350917787}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 67.02981422625301}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 43.54922716170872}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 50.47352136774869}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 44.45848127413042}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 43.50678422142138}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 74.0290207759855}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 28.43422119975}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 80.13648231137824}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 80.44621604010692}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 74.45367181301171}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 86.56365111238182}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 80.1739384832245}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 24.040324117785254}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 53.461038932255306}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 59.87823419637673}, {"Architecture": "GemmaForCausalLM", "Task": "IFEval", "Score": 24.75221301701707}, {"Architecture": "GemmaForCausalLM", "Task": "IFEval", "Score": 34.06705319662939}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 56.01891869129465}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 61.12969144093229}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 44.08879550703245}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 49.17208562170596}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 13.206625088099576}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 30.240096277876034}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 50.58345190760515}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 50.21376614050719}, {"Architecture": "?", "Task": "IFEval", "Score": 49.15712531638276}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 77.73596280092377}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 61.217126114265696}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 34.96134700372789}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 71.68346653545925}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 26.80554262689663}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 25.673989459079685}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 54.83240025354947}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 53.28118281714739}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 65.23878863637371}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 25.406698670638352}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 27.86218345102107}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 27.49748445236417}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 21.30258824363799}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 64.31457421862879}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 59.993151504674266}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 46.02720780861448}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 47.08129983998015}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 45.68245588372186}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 39.27024738804151}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 40.99633417111043}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 18.622255615101263}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 45.73243438520902}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 18.504900331121423}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 33.92465325336773}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 49.51428875383981}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 29.068648962530528}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 34.04455733010634}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 35.76310855197542}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 29.66816934622357}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 18.56485236949073}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 53.71336941537343}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 28.259351853083157}, {"Architecture": "Phi3ForCausalLM", "Task": "IFEval", "Score": 36.555007380417294}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 27.13766140507188}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 18.507338306803724}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 14.46317991817267}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 21.43745262569981}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 25.259311958935623}, {"Architecture": "Qwen2MoeForCausalLM", "Task": "IFEval", "Score": 12.639684924888185}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 54.76746144673909}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 72.08063493752132}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 69.02817856620433}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 75.96743307756752}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 78.55778224001206}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 36.310212458499}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 48.66753547254618}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 50.15625207782018}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 51.67001334237601}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 77.6110719557441}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 55.54428915278129}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 78.25303527972446}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 41.93805768693733}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 20.940327220663395}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 42.33023932055834}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 54.06055931594835}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 43.71656094717572}, {"Architecture": "?", "Task": "IFEval", "Score": 21.4224923203766}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 45.55257827010111}, {"Architecture": "JambaForCausalLM", "Task": "IFEval", "Score": 20.2559209563957}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 23.46828636905633}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 39.6799381197445}, {"Architecture": "?", "Task": "IFEval", "Score": 1.0566408241244345}, {"Architecture": "OlmoForCausalLM", "Task": "IFEval", "Score": 21.819660722438684}, {"Architecture": "OlmoForCausalLM", "Task": "IFEval", "Score": 34.72652561869174}, {"Architecture": "OlmoForCausalLM", "Task": "IFEval", "Score": 27.19273749207658}, {"Architecture": "OlmoeForCausalLM", "Task": "IFEval", "Score": 21.847143357402803}, {"Architecture": "OlmoeForCausalLM", "Task": "IFEval", "Score": 46.521784420892125}, {"Architecture": "Phi3ForCausalLM", "Task": "IFEval", "Score": 19.581488229010137}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 34.91136850224072}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 18.1451881009056}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 51.63754393897082}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 19.42911474886634}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 39.61001254449306}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 41.01883003763348}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 38.14368098866563}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 41.38851580473145}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 39.26526061960044}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 39.74487692655487}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 41.62832395820867}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 42.51009543566625}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 42.60750364588182}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 41.41599843969557}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 43.0046720479439}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 42.12788733892738}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 43.20702402957486}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 41.87810564856802}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 39.47758613811354}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 44.371046600796994}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 17.730510600761534}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 39.38516469633905}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 41.35604640132626}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 38.58584112377381}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 37.69154731667531}, {"Architecture": "Phi3ForCausalLM", "Task": "IFEval", "Score": 47.98556718396078}, {"Architecture": "Phi3ForCausalLM", "Task": "IFEval", "Score": 27.012881376968664}, {"Architecture": "Phi3ForCausalLM", "Task": "IFEval", "Score": 17.061064641817044}, {"Architecture": "Phi3ForCausalLM", "Task": "IFEval", "Score": 16.45157072124186}, {"Architecture": "Phi3ForCausalLM", "Task": "IFEval", "Score": 46.94643545791833}, {"Architecture": "Phi3ForCausalLM", "Task": "IFEval", "Score": 47.13127834146731}, {"Architecture": "Phi3ForCausalLM", "Task": "IFEval", "Score": 49.62421929369628}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 18.944511673470835}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 18.8421166948142}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 17.57813712061774}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 38.61332375873792}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 39.330199426410815}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 37.464261492839}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 48.3777488175818}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 41.48093724650594}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 20.08858717092869}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 42.34774841864032}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 16.968643200042553}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 36.91970637907419}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 39.99465861691424}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 42.41767399389176}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 40.17451473202215}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 19.2068156934711}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 17.42077687203287}, {"Architecture": "OlmoeForCausalLM", "Task": "IFEval", "Score": 27.050337548814923}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 19.636453498938373}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 52.72166739805937}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 76.06484128778308}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 42.83733826247689}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 52.0347123410329}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 18.42245242622907}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 19.18431982694805}, {"Architecture": "GemmaForCausalLM", "Task": "IFEval", "Score": 24.779695651981186}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 76.06484128778308}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 37.6166349729828}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 75.60273407891063}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 38.65576669902525}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 56.74831668860845}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 51.15294086357531}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 12.747066671985886}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 12.729557573903907}, {"Architecture": "OpenLMModel", "Task": "IFEval", "Score": 21.727239280664197}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 79.07485471881274}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 56.208748343284704}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 57.18294126251679}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 80.1739384832245}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 79.10732412221793}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 55.60180321546829}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 31.541642840995227}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 50.820711268323606}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 54.22290633297429}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 57.565149359255656}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 45.21037513796726}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 40.701560747704974}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 21.792178087474564}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 21.330070878602108}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 23.94291590756969}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 21.18268416689938}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 22.936253584932423}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 59.72586071623293}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 60.79247507723951}, {"Architecture": "GemmaForCausalLM", "Task": "IFEval", "Score": 20.29093915255965}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 54.467701254892575}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 54.80491761858535}, {"Architecture": "Starcoder2ForCausalLM", "Task": "IFEval", "Score": 27.802231412651764}, {"Architecture": "Starcoder2ForCausalLM", "Task": "IFEval", "Score": 20.370838264693237}, {"Architecture": "Starcoder2ForCausalLM", "Task": "IFEval", "Score": 22.09193827932109}, {"Architecture": "BloomForCausalLM", "Task": "IFEval", "Score": 13.733781920858878}, {"Architecture": "BloomForCausalLM", "Task": "IFEval", "Score": 10.438968603305897}, {"Architecture": "BloomForCausalLM", "Task": "IFEval", "Score": 12.709610500139627}, {"Architecture": "BloomForCausalLM", "Task": "IFEval", "Score": 6.202431769926019}, {"Architecture": "BloomForCausalLM", "Task": "IFEval", "Score": 13.221696210499251}, {"Architecture": "?", "Task": "IFEval", "Score": 55.60678998390936}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 78.83005979689446}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 49.24954675815725}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 48.095497723817246}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 55.28453392553979}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 57.23291976400395}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 11.228318638988991}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 36.08791340310377}, {"Architecture": "?", "Task": "IFEval", "Score": 34.39429602344003}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 13.641360479084383}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 30.147674836101544}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 29.418276838787747}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 27.050337548814923}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 52.889001183526375}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 64.33707008515184}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 36.7348634955252}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 54.82486469234964}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 45.37770892343427}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 53.1887613753729}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 38.503393218881456}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 37.60167466765959}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 38.52588908540451}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 44.653297694561545}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 42.47762603226107}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 36.12536957495002}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 41.23614232458765}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 63.43778950961227}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 35.34599307614906}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 36.39266036339136}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 41.26362495955176}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 56.00894515441252}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 8.955127949396491}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 27.572396796056683}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 38.08871571873739}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 73.56192679867198}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 50.9131327100981}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 42.390191358927645}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 43.58424535787267}, {"Architecture": "DbrxForCausalLM", "Task": "IFEval", "Score": 54.15796752616392}, {"Architecture": "GPTJForCausalLM", "Task": "IFEval", "Score": 22.244311759464885}, {"Architecture": "GPTNeoXForCausalLM", "Task": "IFEval", "Score": 23.55073427394868}, {"Architecture": "GPTNeoXForCausalLM", "Task": "IFEval", "Score": 22.4715975833012}, {"Architecture": "GPTNeoXForCausalLM", "Task": "IFEval", "Score": 20.098560707810837}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 1.4538092261865183}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 37.534187068090446}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 55.87153197959192}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 21.787191319033496}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 41.70822307034224}, {"Architecture": "DeepseekForCausalLM", "Task": "IFEval", "Score": 24.49744455821664}, {"Architecture": "DeepseekForCausalLM", "Task": "IFEval", "Score": 36.62991972410981}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 81.6327344778521}, {"Architecture": "?", "Task": "IFEval", "Score": 20.490742341431847}, {"Architecture": "?", "Task": "IFEval", "Score": 28.351773294857644}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 30.00039894147528}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 78.79759039348927}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 24.132745559559744}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 44.12126491043764}, {"Architecture": "GPT2LMHeadModel", "Task": "IFEval", "Score": 6.110010328151527}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 56.3011697850592}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 77.0340474385741}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 78.13313120298585}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 72.96739318341999}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 61.102208805968175}, {"Architecture": "Phi3ForCausalLM", "Task": "IFEval", "Score": 44.06131287206833}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 69.57772044841022}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 76.85917809190724}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 80.50616807847622}, {"Architecture": "?", "Task": "IFEval", "Score": 76.84920455502511}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 84.92001223420525}, {"Architecture": "Phi3ForCausalLM", "Task": "IFEval", "Score": 43.913926160365605}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 79.95662619627035}, {"Architecture": "?", "Task": "IFEval", "Score": 79.10233735377686}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 45.82984259542458}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 36.57750324694034}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 39.12042270065648}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 53.6733644507684}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 46.97890486132352}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 42.37523105360444}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 49.38939790866013}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 39.80482896492418}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 44.42601187072523}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 58.866585105298384}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 70.25215317579578}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 31.65656014929277}, {"Architecture": "StableLmForCausalLM", "Task": "IFEval", "Score": 24.192697597929048}, {"Architecture": "OPTForCausalLM", "Task": "IFEval", "Score": 23.83298536771322}, {"Architecture": "OPTForCausalLM", "Task": "IFEval", "Score": 24.52991396162183}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 67.50444376476638}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 59.08888416069362}, {"Architecture": "?", "Task": "IFEval", "Score": 77.46867201248244}, {"Architecture": "Phi3ForCausalLM", "Task": "IFEval", "Score": 63.19299458769399}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 80.23389052159382}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 45.56255180698325}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 36.887236975669}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 37.90387283518841}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 48.37276204914072}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 47.37108649494452}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 50.925655039739}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 45.52010886669592}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 67.5144173016485}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 47.98058041551971}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 53.30866545211151}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 20.500715878313983}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 20.265894493277838}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 23.20598234905606}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 23.05859563735333}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 40.094615619888565}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 45.50514856137272}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 55.32952565858589}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 80.71849359698932}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 42.72740772262043}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 59.90571683134084}, {"Architecture": "GemmaForCausalLM", "Task": "IFEval", "Score": 22.936253584932423}, {"Architecture": "T5ForConditionalGeneration", "Task": "IFEval", "Score": 18.907055501624576}, {"Architecture": "T5ForConditionalGeneration", "Task": "IFEval", "Score": 22.009490374428736}, {"Architecture": "T5ForConditionalGeneration", "Task": "IFEval", "Score": 15.24255641697363}, {"Architecture": "T5ForConditionalGeneration", "Task": "IFEval", "Score": 22.374189373085635}, {"Architecture": "T5ForConditionalGeneration", "Task": "IFEval", "Score": 22.06944241279804}, {"Architecture": "T5ForConditionalGeneration", "Task": "IFEval", "Score": 22.00450360598767}, {"Architecture": "T5ForConditionalGeneration", "Task": "IFEval", "Score": 23.925406809487715}, {"Architecture": "GemmaForCausalLM", "Task": "IFEval", "Score": 30.674831668860847}, {"Architecture": "GemmaForCausalLM", "Task": "IFEval", "Score": 50.391073462856326}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 24.75221301701707}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 79.77677008116243}, {"Architecture": "InternLM2ForCausalLM", "Task": "IFEval", "Score": 19.931226922343825}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 20.176021844262117}, {"Architecture": "InternLM2ForCausalLM", "Task": "IFEval", "Score": 56.68337788179808}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 50.77826832803628}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 20.39832089965736}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 74.35626360279613}, {"Architecture": "GemmaForCausalLM", "Task": "IFEval", "Score": 20.375825033134305}, {"Architecture": "GemmaForCausalLM", "Task": "IFEval", "Score": 26.9029508371122}, {"Architecture": "GemmaForCausalLM", "Task": "IFEval", "Score": 26.59321710838353}, {"Architecture": "GemmaForCausalLM", "Task": "IFEval", "Score": 38.68324933398937}, {"Architecture": "MT5ForConditionalGeneration", "Task": "IFEval", "Score": 16.45157072124186}, {"Architecture": "MT5ForConditionalGeneration", "Task": "IFEval", "Score": 17.180968718555654}, {"Architecture": "MT5ForConditionalGeneration", "Task": "IFEval", "Score": 19.596448534333348}, {"Architecture": "T5ForConditionalGeneration", "Task": "IFEval", "Score": 23.575668116154027}, {"Architecture": "RecurrentGemmaForCausalLM", "Task": "IFEval", "Score": 30.170281519701057}, {"Architecture": "RecurrentGemmaForCausalLM", "Task": "IFEval", "Score": 29.493299999556733}, {"Architecture": "RecurrentGemmaForCausalLM", "Task": "IFEval", "Score": 31.15943474425635}, {"Architecture": "RecurrentGemmaForCausalLM", "Task": "IFEval", "Score": 50.10383560065072}, {"Architecture": "SwitchTransformersForConditionalGeneration", "Task": "IFEval", "Score": 15.852050337548814}, {"Architecture": "UMT5ForConditionalGeneration", "Task": "IFEval", "Score": 17.463219812320197}, {"Architecture": "GPT2LMHeadModel", "Task": "IFEval", "Score": 18.07770050133645}, {"Architecture": "GPT2LMHeadModel", "Task": "IFEval", "Score": 8.333333333333332}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 44.55588948434598}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 42.71244741729721}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 68.05897241541332}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 48.69501810751029}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 29.96781872099363}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 42.77239945566652}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 39.22281767931311}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 38.95054012243071}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 41.73825449806513}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 26.93043347207632}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 23.380851695722903}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 36.28771659197596}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 22.079415949680183}, {"Architecture": "?", "Task": "IFEval", "Score": 0.3921816336210145}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 70.46447869430888}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 73.47449212533854}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 32.30849701015528}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 44.54835392314614}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 24.10526292459563}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 25.259311958935623}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 25.009530268576263}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 75.46033413564896}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 76.06484128778308}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 44.1112913735555}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 17.083560508340092}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 42.759877126025614}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 44.73075883101282}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 24.98703440205322}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 24.142719096441887}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 29.72313461615181}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 53.43355629729119}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 50.69083365470286}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 51.23538876846767}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 51.75744801570943}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 49.62421929369628}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 49.59174989029109}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 49.74911013887596}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 49.68417133206558}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 51.30032757527805}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 48.98225596971591}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 49.77160600539901}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 52.12214701436632}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 50.446038732784565}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 52.27950726295119}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 46.34192830578421}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 50.32613465604596}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 60.85741388404988}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 52.63423272472595}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 48.70997841283351}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 29.842927875813952}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 58.217086220118176}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 10.27662158627996}, {"Architecture": "InternLM2ForCausalLM", "Task": "IFEval", "Score": 21.97702097102355}, {"Architecture": "InternLM2ForCausalLM", "Task": "IFEval", "Score": 23.865454771118408}, {"Architecture": "InternLM2ForCausalLM", "Task": "IFEval", "Score": 38.49087088924056}, {"Architecture": "InternLM2ForCausalLM", "Task": "IFEval", "Score": 70.09977969565199}, {"Architecture": "InternLM2ForCausalLM", "Task": "IFEval", "Score": 61.40196899781469}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 51.55509603407847}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 45.54759150166004}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 39.03298802732306}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 36.82229816885863}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 46.466819150963886}, {"Architecture": "GPTNeoXForCausalLM", "Task": "IFEval", "Score": 15.722172723928066}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 25.43661928128477}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 45.79238642357833}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 34.24192254329623}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 42.71244741729721}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 42.5325913021893}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 33.7748285659827}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 42.73993005226133}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 32.03621945327288}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 43.96390466185278}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 28.14443454478561}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 43.02218114602588}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 27.899639622867326}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 42.22784434190171}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 43.58923212631373}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 42.01551882338861}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 35.178659290682056}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 42.03801468991166}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 34.54168273514276}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 40.916435058976845}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 29.03872835188411}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 41.98803618842449}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 29.131149793658604}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 41.6233371897676}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 21.454961723781786}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 18.907055501624576}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 21.132705665412217}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 20.33836886128805}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 21.607335203925583}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 43.08213318439518}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 41.161229980895136}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 36.26278274977061}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 37.966373666316485}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 36.81232463197649}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 38.58085435533274}, {"Architecture": "Phi3ForCausalLM", "Task": "IFEval", "Score": 46.886483419549016}, {"Architecture": "Phi3ForCausalLM", "Task": "IFEval", "Score": 68.52107962428579}, {"Architecture": "Phi3ForCausalLM", "Task": "IFEval", "Score": 56.22625744136669}, {"Architecture": "Phi3ForCausalLM", "Task": "IFEval", "Score": 37.37184005106451}, {"Architecture": "Phi3ForCausalLM", "Task": "IFEval", "Score": 54.55014915978493}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 40.299405577201824}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 41.99302295686556}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 53.6733644507684}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 19.85376578589254}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 47.2836518216111}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 25.98372318780835}, {"Architecture": "?", "Task": "IFEval", "Score": 54.55014915978493}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 34.04455733010634}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 44.006347602140096}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 29.320979445648653}, {"Architecture": "?", "Task": "IFEval", "Score": 33.01041237250495}, {"Architecture": "?", "Task": "IFEval", "Score": 42.67742922113326}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 71.25382872999197}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 30.08772279773224}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 55.15964308036011}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 70.83416446140684}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 21.362429464930827}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 15.946909755005606}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 37.911408396388246}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 66.01816513517468}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 68.09144181881851}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 42.03047912871182}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 41.69326276501904}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 48.64005283758206}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 49.00973860468002}, {"Architecture": "Phi3ForCausalLM", "Task": "IFEval", "Score": 34.69405621528655}, {"Architecture": "Phi3ForCausalLM", "Task": "IFEval", "Score": 30.13027655509603}, {"Architecture": "Phi3ForCausalLM", "Task": "IFEval", "Score": 37.861429894901086}, {"Architecture": "Phi3ForCausalLM", "Task": "IFEval", "Score": 53.8257379309122}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 66.78003253589365}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 58.174643279830846}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 62.49107922534431}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 66.36535503574959}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 66.87245397766813}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 37.70406964631621}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 36.39764713183243}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 33.43506340953115}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 29.086158060612505}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 23.515716077784724}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 35.14618988727687}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 66.69259786256023}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 54.35278394659503}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 43.771526217103954}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 11.59301763764589}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 22.918744486850443}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 46.94643545791833}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 48.60758343417688}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 49.194581488229005}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 53.03140112678803}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 65.62598350155366}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 62.94321289733463}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 43.47176602525742}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 28.139447776344547}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 25.009530268576263}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 48.317796779212486}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 39.8472719052115}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 24.82468738502728}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 49.57922756065019}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 24.06780675274937}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 39.86478100329349}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 25.18938638368418}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 14.7779004153424}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 56.9831380736446}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 13.374069690643047}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 73.93161256576994}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 16.031906452656727}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 80.99077115387172}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 14.550614591506092}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 74.08398604591373}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 47.823220166934846}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 16.843752354862875}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 86.6885419575615}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 12.69963696325749}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 78.55778224001206}, {"Architecture": "GPT2LMHeadModel", "Task": "IFEval", "Score": 14.79042274498331}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 31.27933882099496}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 21.83462102776189}, {"Architecture": "Phi3ForCausalLM", "Task": "IFEval", "Score": 60.400293443618494}, {"Architecture": "Phi3ForCausalLM", "Task": "IFEval", "Score": 64.22713954529537}, {"Architecture": "Phi3ForCausalLM", "Task": "IFEval", "Score": 59.76331688807919}, {"Architecture": "Phi3ForCausalLM", "Task": "IFEval", "Score": 56.12884923115112}, {"Architecture": "Phi3ForCausalLM", "Task": "IFEval", "Score": 54.76746144673909}, {"Architecture": "Phi3SmallForCausalLM", "Task": "IFEval", "Score": 63.68258443153056}, {"Architecture": "Phi3SmallForCausalLM", "Task": "IFEval", "Score": 64.96651107949131}, {"Architecture": "Phi3ForCausalLM", "Task": "IFEval", "Score": 69.2454908531585}, {"Architecture": "Phi3ForCausalLM", "Task": "IFEval", "Score": 57.74500547436358}, {"Architecture": "PhiForCausalLM", "Task": "IFEval", "Score": 20.6805719934219}, {"Architecture": "PhiForCausalLM", "Task": "IFEval", "Score": 20.32839532440591}, {"Architecture": "PhiForCausalLM", "Task": "IFEval", "Score": 27.3875539125077}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 60.764992442275386}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 50.69582042314393}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 39.46262583279033}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 33.549980717828696}, {"Architecture": "Phi3ForCausalLM", "Task": "IFEval", "Score": 45.3876824603164}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 44.943084349525925}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 42.02050559182968}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 43.44683218305208}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 44.30112102554556}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 27.779735546128716}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 22.663976028050016}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 25.82636293922349}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 57.71752283939946}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 44.87060998151571}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 54.96227786717022}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 54.65254413844156}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 23.855481234236272}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 22.663976028050016}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 16.299197241098064}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 63.80248850826917}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 66.69758463100129}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 62.82829558903709}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 71.83584001560305}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 25.82636293922349}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 55.991436056330535}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 24.152692633324023}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 23.260947618984297}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 41.6233371897676}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 49.39438467710121}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 56.08385749810503}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 79.28718023732586}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 73.56691356711303}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 44.6883158907255}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 44.07882197015032}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 45.4776659264086}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 44.2636648536993}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 73.29463601023062}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 49.35194173681387}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 75.60772084735169}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 41.6233371897676}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 36.52752474545318}, {"Architecture": "PhiForCausalLM", "Task": "IFEval", "Score": 34.31184811854767}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 46.48931501748693}, {"Architecture": "?", "Task": "IFEval", "Score": 22.728914834860397}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 39.02545246612322}, {"Architecture": "MPTForCausalLM", "Task": "IFEval", "Score": 21.51990053059216}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 63.92239258500778}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 58.36945970026197}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 38.41595854554804}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 71.71094917042336}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 29.161070404305026}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 37.21447980247965}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 34.94882467408698}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 22.12185888996751}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 25.851296781428832}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 35.67068711020093}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 65.35869271311232}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 63.3128986644326}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 48.93227746822875}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 32.743121584063616}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 29.47080413303368}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 27.95948084416016}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 43.71910973993448}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 50.68086011782072}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 67.94405510711579}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 14.3532493783162}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 34.25189608017837}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 35.0386973231027}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 62.033958784912926}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 21.827085466562057}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 23.7929804031082}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 33.847192116916446}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 65.20133246452745}, {"Architecture": "GPT2LMHeadModel", "Task": "IFEval", "Score": 24.39748755524231}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 25.906262051357064}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 37.9938563012806}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 42.167892303532405}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 44.29114748866341}, {"Architecture": "PhiForCausalLM", "Task": "IFEval", "Score": 20.12105657433388}, {"Architecture": "PhiForCausalLM", "Task": "IFEval", "Score": 22.06445564435697}, {"Architecture": "PhiForCausalLM", "Task": "IFEval", "Score": 22.581528123157664}, {"Architecture": "PhiForCausalLM", "Task": "IFEval", "Score": 21.934578030736223}, {"Architecture": "PhiForCausalLM", "Task": "IFEval", "Score": 19.151850423542868}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 30.567449921763146}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 34.78647765706104}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 32.33099287667832}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 30.894692748573785}, {"Architecture": "GemmaForCausalLM", "Task": "IFEval", "Score": 24.235140538216378}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 37.98632074008077}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 39.13538300597969}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 16.484040124647045}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 15.727159492369136}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 14.120976786038822}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 19.723888172271792}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 56.60092997690572}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 39.25273828995952}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 38.07375541341418}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 16.069362624502986}, {"Architecture": "NemotronForCausalLM", "Task": "IFEval", "Score": 22.17937295265451}, {"Architecture": "NemotronForCausalLM", "Task": "IFEval", "Score": 24.24267609941621}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 19.456597383830456}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 50.03889679384034}, {"Architecture": "NemotronForCausalLM", "Task": "IFEval", "Score": 66.68761109411916}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 48.68748254631046}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 34.851416463871416}, {"Architecture": "?", "Task": "IFEval", "Score": 15.986914719610631}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 52.50180631834643}, {"Architecture": "GPT2LMHeadModel", "Task": "IFEval", "Score": 17.925327021192658}, {"Architecture": "GPT2LMHeadModel", "Task": "IFEval", "Score": 17.795449407571912}, {"Architecture": "GPT2LMHeadModel", "Task": "IFEval", "Score": 20.47822001179094}, {"Architecture": "GPT2LMHeadModel", "Task": "IFEval", "Score": 22.08440271812125}, {"Architecture": "GPT2LMHeadModel", "Task": "IFEval", "Score": 20.385798570016444}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 59.51353519771983}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 60.3678240402133}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 53.43355629729119}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 59.31118321608887}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 29.805582521044165}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 28.61906408329898}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 21.61232197236665}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 55.349472732350165}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 22.54894790267601}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 45.52509563513699}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 54.02055435134332}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 53.16127874040878}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 36.93721547715617}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 30.564901129004376}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 7.421419611076388}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 13.57885964795631}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 28.966253983873894}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 40.14703209705803}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 28.20937335159599}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 48.06047952765329}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 48.964746871633935}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 8.243239050164673}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 1.1116060940526693}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 38.82564927725103}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 59.29622291076566}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 43.87646998851935}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 78.64521691334548}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 16.35914927946737}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 17.615593292463995}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 73.44202272193337}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 41.30108113139802}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 12.492298213185457}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 39.86478100329349}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 30.964618323825228}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 37.03462368737173}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 41.11125147940797}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 44.86562321307464}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 45.22533544329048}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 45.16538340492117}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 44.80068440626427}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 33.57247658435174}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 48.90479483326463}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 46.85401401614384}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 72.92993701157374}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 75.05817896514581}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 67.57436934001782}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 72.08063493752132}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 68.6409837010244}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 72.90245437660963}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 71.2813113649561}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 76.33213207622441}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 66.60017642078574}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 70.76922565459647}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 72.74509412802476}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 71.24884196155091}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 73.99655137258031}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 71.09646848140711}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 65.03898544750152}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 68.08645505037744}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 46.54926705585624}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 44.03383023710421}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 48.29530091268944}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 47.8481540091402}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 46.064663980460736}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 44.0662996405094}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 51.27284494031392}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 47.00638749628763}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 42.03047912871182}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 51.7624347841505}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 49.29198969844457}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 49.07966417993147}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 47.19621714827768}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 48.87232542985944}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 49.60172342717323}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 46.86897432146704}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 21.97702097102355}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 24.16521496296493}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 27.68720328727776}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 32.06857803960159}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 10.438968603305897}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 24.537449522821667}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 44.51843331249973}, {"Architecture": "PhiForCausalLM", "Task": "IFEval", "Score": 24.02281501970328}, {"Architecture": "PhiForCausalLM", "Task": "IFEval", "Score": 31.459194936102875}, {"Architecture": "PhiForCausalLM", "Task": "IFEval", "Score": 36.81476260765879}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 21.210166801863497}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 76.48949232480928}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 28.53650536133016}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 75.1506004069203}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 75.91745457608036}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 27.469891000323585}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 74.39371977464239}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 57.60759229954299}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 25.618913372074985}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 46.19952836252256}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 64.62430794735747}, {"Architecture": "AriaForConditionalGeneration", "Task": "IFEval", "Score": 47.73079872516036}, {"Architecture": "PhiForCausalLM", "Task": "IFEval", "Score": 36.69740732367895}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 43.734070045257695}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 41.3660199382084}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 50.52848663767692}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 28.466690603155183}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 34.02461025634206}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 58.40447789642593}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 68.26631116548536}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 53.42358276040905}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 71.5535889218385}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 62.3711751486057}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 25.95125378440316}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 52.14464288088938}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 40.958877999264175}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 49.39438467710121}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 18.722212618075595}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 36.92967991595633}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 41.1536944196953}, {"Architecture": "?", "Task": "IFEval", "Score": 43.35186194851882}, {"Architecture": "?", "Task": "IFEval", "Score": 50.20623057930735}, {"Architecture": "?", "Task": "IFEval", "Score": 40.35935761557113}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 44.18620371724801}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 52.449389841176966}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 42.427647530773896}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 20.44829940114452}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 22.4241678745728}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 20.58815055164741}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 40.19202383010412}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 38.93303102434873}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 4.166611258128433}, {"Architecture": "?", "Task": "IFEval", "Score": 46.34192830578421}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 38.410971777106965}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 23.528238407425636}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 42.75489035758454}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 40.87144332593076}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 40.32190144372487}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 24.9595517670891}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 47.82820693537591}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 67.44947849483815}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 56.90567693719332}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 65.10891102275296}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 65.17384982956334}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 84.31051831363006}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 37.87140343178322}, {"Architecture": "StableLmForCausalLM", "Task": "IFEval", "Score": 15.69214129620518}, {"Architecture": "StableLmForCausalLM", "Task": "IFEval", "Score": 40.81647805600252}, {"Architecture": "StableLmForCausalLM", "Task": "IFEval", "Score": 11.570521771122843}, {"Architecture": "StableLmForCausalLM", "Task": "IFEval", "Score": 30.59991932516833}, {"Architecture": "StableLmForCausalLM", "Task": "IFEval", "Score": 32.79310008555078}, {"Architecture": "StableLmForCausalLM", "Task": "IFEval", "Score": 22.031986240951785}, {"Architecture": "StableLmForCausalLM", "Task": "IFEval", "Score": 36.832271705740766}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 42.53004250943053}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 48.53510906616666}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 15.090182936829834}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 17.24092075692496}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 45.0080231563363}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 18.29246399553185}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 82.31215397367873}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 80.83839767372794}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 27.9046263913084}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 26.680651781716957}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 52.86151854856226}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 55.71417173100706}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 18.12513021006485}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 27.659831469390102}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 80.87086707713311}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 31.241882649148703}, {"Architecture": "?", "Task": "IFEval", "Score": 21.699756645700077}, {"Architecture": "?", "Task": "IFEval", "Score": 23.823011830831085}, {"Architecture": "?", "Task": "IFEval", "Score": 16.816269719898756}, {"Architecture": "?", "Task": "IFEval", "Score": 19.613957632415325}, {"Architecture": "?", "Task": "IFEval", "Score": 20.45827293802666}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 25.29676813078188}, {"Architecture": "?", "Task": "IFEval", "Score": 40.47926169230973}, {"Architecture": "?", "Task": "IFEval", "Score": 24.08775382651365}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 29.85556102253133}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 44.37603336923807}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 37.19198393595659}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 35.770644113175265}, {"Architecture": "FalconForCausalLM", "Task": "IFEval", "Score": 32.613243970442866}, {"Architecture": "FalconForCausalLM", "Task": "IFEval", "Score": 24.96453853553017}, {"Architecture": "FalconForCausalLM", "Task": "IFEval", "Score": 24.54487426694504}, {"Architecture": "FalconForCausalLM", "Task": "IFEval", "Score": 18.205140139274903}, {"Architecture": "FalconForCausalLM", "Task": "IFEval", "Score": 19.68886997610784}, {"Architecture": "FalconMambaForCausalLM", "Task": "IFEval", "Score": 33.35760227307987}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 26.685638550158025}, {"Architecture": "GPTJForCausalLM", "Task": "IFEval", "Score": 20.61064641817045}, {"Architecture": "GPTNeoXForCausalLM", "Task": "IFEval", "Score": 18.297561581049397}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 18.649738250065383}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 21.300039450879225}, {"Architecture": "GPTNeoXForCausalLM", "Task": "IFEval", "Score": 20.822971936683555}, {"Architecture": "GPTNeoXForCausalLM", "Task": "IFEval", "Score": 15.57977278066641}, {"Architecture": "GPTNeoXForCausalLM", "Task": "IFEval", "Score": 20.55069437980115}, {"Architecture": "GPTNeoXForCausalLM", "Task": "IFEval", "Score": 22.936253584932423}, {"Architecture": "GPTNeoXForCausalLM", "Task": "IFEval", "Score": 16.521496296493304}, {"Architecture": "GPTNeoXForCausalLM", "Task": "IFEval", "Score": 21.24263620526869}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 55.07719517546776}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 47.36609972650345}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 17.158472852032606}, {"Architecture": "SolarForCausalLM", "Task": "IFEval", "Score": 84.15814483348626}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 36.652415590632856}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 46.04216811393768}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 25.04698644042252}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 32.613243970442866}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 45.61751707691148}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 37.00215428396654}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 26.957916107040436}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 76.88666072687137}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 78.16560060639105}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 80.45120280854799}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 48.54763139580757}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 80.63604569209697}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 29.0711977552893}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 59.16634529714492}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 54.15298075772285}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 52.12214701436632}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 57.62510139762497}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 83.12399987588486}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 43.234506664538976}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 58.34452585805663}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 54.10798902467674}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 50.995580614990445}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 66.69259786256023}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 48.48014379623842}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 57.44025851407598}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 73.20221456845613}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 15.764615664215391}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 38.84060958257423}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 16.211762567764644}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 50.29865202108184}, {"Architecture": "Qwen2ForCausalLM", "Task": "IFEval", "Score": 20.148539209298}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 35.84311848118548}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 73.32211864519475}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 41.44348107465968}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 28.569085581811816}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 29.091144829053576}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 60.99981382731153}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 29.73565694579272}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 22.461624046419058}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 24.52991396162183}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 27.987074296200745}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 15.459868703927802}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 63.74752323834093}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 72.74509412802476}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 65.68593553992297}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 66.20799478716472}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 60.42278931014154}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 71.31876753680235}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 59.4710922574325}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 64.53188650558296}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 57.5601625908146}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 70.34457461757027}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 60.23794642659256}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 66.20300801872366}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 53.363630722039744}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 68.5160928558447}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 54.82242671666733}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 69.0931173730147}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 66.96487541944263}, {"Architecture": "GemmaForCausalLM", "Task": "IFEval", "Score": 30.207737691547315}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 23.28344348550734}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 18.55731680829089}, {"Architecture": "MistralForCausalLM", "Task": "IFEval", "Score": 17.698041197356346}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 59.9431730031871}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 62.62095683896506}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 67.08976626462231}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 73.32710541363582}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 67.84664689690022}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 71.31876753680235}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 64.95653754260917}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 71.96073086078272}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 65.04397221594259}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 70.15973173402128}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 64.89658550423985}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 46.90897928607207}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 40.12708502329375}, {"Architecture": "LlamaForCausalLM", "Task": "IFEval", "Score": 28.84878788281759}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 79.68434863938793}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 76.48949232480928}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 77.06651684197928}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 72.08063493752132}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 75.99990248097271}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 76.15227596111652}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 79.43955371746965}, {"Architecture": "Gemma2ForCausalLM", "Task": "IFEval", "Score": 74.45367181301171}, {"Architecture": "MixtralForCausalLM", "Task": "IFEval", "Score": 41.87810564856802}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 10.055525080241036}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 42.74936268839652}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 43.38184666762572}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 44.262825981005655}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 44.53615654671034}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 22.027904536694773}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 23.550511456633718}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 30.50071699492122}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.937011582169664}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 36.95293138417893}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 31.49760894701832}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 35.542431259008794}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 36.02211028900003}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 37.623987597243485}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 19.408504737915056}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 20.148020103768047}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 17.00016656742376}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 27.62695611207793}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 26.49249509714754}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 25.94315294491389}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 43.807147003691966}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 30.24383447882599}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 30.24383447882599}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 8.618063681935197}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 21.277103190106818}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 47.410670136906425}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 15.307880971954305}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 15.261078322847055}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 42.0902142313775}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 39.78753882674737}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 19.34889807323965}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 19.152364282090307}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 16.87354725795866}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 18.388095615027524}, {"Architecture": "GPT2LMHeadModel", "Task": "BBH", "Score": 6.894934050796576}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 43.61576498719506}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 21.92548248566236}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 24.80906331793277}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.787014099442825}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 24.20155738881327}, {"Architecture": "PhiForCausalLM", "Task": "BBH", "Score": 26.856515500031357}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 31.893554212659296}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 19.53766599736009}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 42.883055884713976}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 18.306535405618444}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 44.14770458838461}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 34.20124449031171}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 42.19084405906616}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 51.32716098252212}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 28.992936470320583}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 52.02816164280523}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.9882222457564}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 28.82328942958971}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 34.65682860864863}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 35.37870748220464}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 30.88880460756557}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 28.697915491520025}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 52.49894685232329}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 30.88880460756557}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 28.697915491520025}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 9.76871171424153}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 24.19903269979749}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 3.1980040943527936}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 3.03784275772053}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 2.314902449149024}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 3.107692077087363}, {"Architecture": "T5ForConditionalGeneration", "Task": "BBH", "Score": 4.411893932611097}, {"Architecture": "T5ForConditionalGeneration", "Task": "BBH", "Score": 4.737018282627999}, {"Architecture": "T5ForConditionalGeneration", "Task": "BBH", "Score": 5.013070335904381}, {"Architecture": "T5ForConditionalGeneration", "Task": "BBH", "Score": 3.267300577931774}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 37.24916418079274}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 26.877991478721707}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 30.64368722878725}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 30.75990006920939}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 30.793784752659278}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 32.61215762394777}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 32.48627762381486}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 24.780942674518663}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 36.677226262739055}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 24.283946726650168}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 24.559557672503782}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 31.63886474402479}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 34.63219258973313}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 31.62386474402479}, {"Architecture": "CohereForCausalLM", "Task": "BBH", "Score": 34.85836046775463}, {"Architecture": "CohereForCausalLM", "Task": "BBH", "Score": 20.20376064673937}, {"Architecture": "CohereForCausalLM", "Task": "BBH", "Score": 39.91995423143177}, {"Architecture": "CohereForCausalLM", "Task": "BBH", "Score": 42.83686540770696}, {"Architecture": "CohereForCausalLM", "Task": "BBH", "Score": 34.556659257058264}, {"Architecture": "GemmaForCausalLM", "Task": "BBH", "Score": 14.585976093815775}, {"Architecture": "GemmaForCausalLM", "Task": "BBH", "Score": 14.243045647726928}, {"Architecture": "GemmaForCausalLM", "Task": "BBH", "Score": 14.02392166541634}, {"Architecture": "GemmaForCausalLM", "Task": "BBH", "Score": 14.11717086360044}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 30.356398875749075}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 30.457173008350704}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 30.88426036029}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 46.39761279639615}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 2.2764835705971893}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 3.709041394335512}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 4.301149162861492}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 21.88855981925079}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 16.19327709708517}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 37.02437662584371}, {"Architecture": "?", "Task": "BBH", "Score": 22.65864266009636}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 29.827516654013998}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 32.49458680420566}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 51.029418403280296}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.600623499981847}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 26.046417064819565}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 26.33639354405325}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 26.737651950701505}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 26.412550636134668}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 24.734770612245036}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 31.84449091545611}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 29.78962694499553}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 25.869793144697734}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 24.504815583181397}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 26.130957088441544}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 26.692021341537863}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 27.36962320894452}, {"Architecture": "DeciLMForCausalLM", "Task": "BBH", "Score": 21.252729791067395}, {"Architecture": "DeciLMForCausalLM", "Task": "BBH", "Score": 23.8871490441846}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 30.393262902042363}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 8.292273657131942}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 7.042771972349901}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 4.257780193079653}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 5.18530518107402}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 30.51007603826353}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 31.101628224178786}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 31.162649496607862}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 31.162649496607862}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 32.6953311808552}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.077745566893725}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 31.333639113507697}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 32.54183409581636}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 32.88379503743108}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 30.865849451121655}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 34.83242280758616}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 31.73822449849867}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 32.534270073092834}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 36.26348248348271}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 34.19993531370101}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 34.21152011815682}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 34.21610348917685}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 34.44482164620488}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 32.354424456472486}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 32.08833034979686}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 36.4126125295027}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 35.253190231117536}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 34.60910725048443}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 31.3609793143707}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 31.97509368554489}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 28.890798050964488}, {"Architecture": "GPTJForCausalLM", "Task": "BBH", "Score": 4.912818068323685}, {"Architecture": "GPTNeoForCausalLM", "Task": "BBH", "Score": 3.024569180930987}, {"Architecture": "GPTNeoForCausalLM", "Task": "BBH", "Score": 3.436738951426704}, {"Architecture": "GPTNeoForCausalLM", "Task": "BBH", "Score": 4.178602667081014}, {"Architecture": "GPTNeoXForCausalLM", "Task": "BBH", "Score": 4.929114201526899}, {"Architecture": "GPTNeoXForCausalLM", "Task": "BBH", "Score": 4.987531038290507}, {"Architecture": "GPTNeoXForCausalLM", "Task": "BBH", "Score": 2.198832279508135}, {"Architecture": "GPTNeoXForCausalLM", "Task": "BBH", "Score": 5.077786161905462}, {"Architecture": "GPTNeoXForCausalLM", "Task": "BBH", "Score": 2.7154281203357478}, {"Architecture": "GPTNeoXForCausalLM", "Task": "BBH", "Score": 5.88163197981621}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 16.875928374989595}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 17.507545086854382}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 16.668385554519382}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 17.49829637438283}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 17.49829637438283}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 17.396414392379338}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 21.68824851395527}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 23.94053725590186}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 25.93522655511771}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 19.417817674461517}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 13.212088152695856}, {"Architecture": "GemmaForCausalLM", "Task": "BBH", "Score": 20.87379456667128}, {"Architecture": "?", "Task": "BBH", "Score": 23.506618815003453}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 30.666711502632054}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 30.33623264030357}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 26.377774027551386}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 26.897964171299805}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.24700927539328}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.02516078188715}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.17188778217276}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 25.82086537586569}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.95934409387967}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 26.31787775764873}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 28.56782489270228}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 19.02580948500905}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 33.835810999564586}, {"Architecture": "GemmaForCausalLM", "Task": "BBH", "Score": 18.971369774912947}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 29.776014226579218}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 29.259226071264724}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.628475325906475}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 27.99254879661235}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 27.963797525362725}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 27.207176615070413}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 26.901201452028392}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 27.571611204577167}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 26.76368521382555}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 27.76979570236311}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 21.145528378150857}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 26.400991557555106}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 46.20887281141656}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 33.299425909067885}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 33.08995159999345}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.952590926070883}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 22.902455222412783}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 32.822381370434904}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 33.01430008846961}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 3.166755569392556}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 2.4372895622895623}, {"Architecture": "?", "Task": "BBH", "Score": 26.59686097043189}, {"Architecture": "?", "Task": "BBH", "Score": 24.92582719493644}, {"Architecture": "?", "Task": "BBH", "Score": 18.06242392393546}, {"Architecture": "?", "Task": "BBH", "Score": 23.960171694414896}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 29.97606209295129}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 33.26225439614359}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 18.30601328940368}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 16.499503211302823}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 16.439711885397813}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 33.33398601463088}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 17.748016873381815}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 27.904317623033844}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 40.8261615594601}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 23.631914688111305}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 31.750144021634004}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 31.68734382617837}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 33.032200369425645}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 31.92884881074505}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 23.955291427068445}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 21.487542182806735}, {"Architecture": "GemmaForCausalLM", "Task": "BBH", "Score": 23.751162749201274}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 47.5037962865412}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 4.4111278515492005}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 2.0803742908537424}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 3.2853998220852616}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 2.69295800470458}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 3.284915303246592}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 2.0803742908537424}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.012476599572}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 32.70961342122556}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 34.47899758661866}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 1.4636170460989155}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 20.83116494676627}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 30.205692320538088}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 29.7397523676162}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 30.237457969159426}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 27.753850886523697}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 25.7872756997585}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 25.91957835941345}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 34.904315688323074}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 33.2945398202129}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 32.38700420411291}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 32.259183510828905}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 30.870822876627887}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 30.34084433030367}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 32.63252990159268}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 26.913110159424864}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 29.1238227637126}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 27.755228582197063}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.613596677525617}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 27.666183558964235}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 29.3297318748178}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.390676236054286}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.07503551511944}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.56256683836558}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 31.46581339489899}, {"Architecture": "PhiForCausalLM", "Task": "BBH", "Score": 22.45340222827221}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 3.804167155031377}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 3.107714473502144}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 4.164017098724634}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 51.328741195678994}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 51.8870262488106}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 51.328741195678994}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 55.48536459580824}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 6.058845092070314}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 17.689002759870313}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 16.386034485864904}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.008307823364888}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 22.39171190823084}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 31.83439540006779}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 31.811748341244265}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 31.99718681136041}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 33.044262388969805}, {"Architecture": "ExaoneForCausalLM", "Task": "BBH", "Score": 17.97733539518049}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.220402834201128}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 33.79382923599304}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 48.989609006737815}, {"Architecture": "GemmaForCausalLM", "Task": "BBH", "Score": 4.138296963728068}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 12.771666354808303}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 19.460966800253622}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 28.423430655930204}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 21.78100309570489}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 31.69912679947687}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 3.211683047233007}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 27.74553183153259}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 4.495993524198578}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 2.162400468558809}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 6.349580156104774}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 4.191974214495695}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 5.599561733978841}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 4.293436202390652}, {"Architecture": "Phi3ForCausalLM", "Task": "BBH", "Score": 34.877917500461}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 19.141465000010825}, {"Architecture": "?", "Task": "BBH", "Score": 26.530834895216355}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 2.2124311744899985}, {"Architecture": "Phi3ForCausalLM", "Task": "BBH", "Score": 35.553775523419816}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 26.655629407381003}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 27.02521610839599}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 26.37017668673992}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 24.57473532012109}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 24.185738827978955}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 26.63965184405082}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 24.151873375413786}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 16.34207153663529}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 26.922800957191782}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 3.181881126755549}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 34.44627563758498}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 34.95288411454464}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 27.83521213410715}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 8.894408584162113}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 26.927527973055067}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 46.135898982415}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 23.990124398411343}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 23.698815892387582}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 26.69176089392447}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 26.289712088654472}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 24.311446807587014}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 26.13667696363235}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 24.04053735093787}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 18.25580502860485}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 23.61231335017796}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 36.12470152357596}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 32.879942700903165}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 15.297499289020854}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 19.019948525917457}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 8.870227428732667}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 31.26187805626151}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 31.396819621762447}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 32.71291726367119}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 27.924674302120888}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.270418759783485}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 27.903013285410186}, {"Architecture": "Qwen2MoeForCausalLM", "Task": "BBH", "Score": 15.47343942401254}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 31.92360727430821}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 25.532524528361478}, {"Architecture": "Phi3ForCausalLM", "Task": "BBH", "Score": 38.1242795228128}, {"Architecture": "Phi3ForCausalLM", "Task": "BBH", "Score": 36.11009692957303}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 57.3258823447103}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 31.00709744702013}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 61.65570318314716}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 59.4700307859535}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 48.57170594999846}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 54.20646208605566}, {"Architecture": "Phi3ForCausalLM", "Task": "BBH", "Score": 37.733734155011526}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 56.79594225047665}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 33.10936559556884}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 61.80360419146786}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 59.268645675184494}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 48.0085850617923}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 55.58549511699308}, {"Architecture": "Phi3ForCausalLM", "Task": "BBH", "Score": 37.65889241962552}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 51.22830430718469}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 30.95608211537095}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 59.57454695904105}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 48.39776612820646}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 31.8182656422348}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 62.15654929467119}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 28.28099517875505}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 29.30841923308876}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 28.912244614673995}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 3.104609898338746}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 3.0952799822018195}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 2.2094810446663797}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 6.106919191919192}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 4.910622895622894}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 26.27454019814682}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 27.832818693945708}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 18.110133310152776}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 40.309033651453255}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 43.74245801092346}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 17.58000487008142}, {"Architecture": "GPTNeoXForCausalLM", "Task": "BBH", "Score": 3.015221141570497}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 5.107047129907727}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 30.873209425039573}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 29.419254274936463}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 30.03259699633449}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 17.690523920374847}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 31.802699112572423}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 34.40988943485442}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 31.963373781180238}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 15.336448395229596}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 32.826028565585965}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 5.741405038838561}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 19.52006065248879}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 5.801724673541757}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 19.457219278849333}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 30.667993420825}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 29.427578860536}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 32.046073848075835}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 53.76540869130056}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 30.724096614147957}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 27.792545658366084}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 37.10778379133987}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 30.594312778864406}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 34.990894584465195}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 13.78941955171473}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 13.505319085673955}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 6.1446917129934855}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 7.0440554144724175}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 20.633112436478672}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 20.23020020918289}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.99482436025671}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.395714153595826}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 1.8879990685708252}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 1.8153805514942332}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 27.073241609173305}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 5.043571655312187}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 26.038439832659787}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 25.840025395269805}, {"Architecture": "GPTNeoXForCausalLM", "Task": "BBH", "Score": 4.778508799161477}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 26.115045337590946}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 27.252334736558797}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 51.94077625159233}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 29.057538243651496}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 30.3195108847562}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 6.043619508652057}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 24.5354429684368}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 43.27649863201484}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 44.1839402106242}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 36.3981275172541}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 45.637092606204}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 26.289506846678147}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 15.293406418468868}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 44.79654161573056}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 19.573064881964964}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 29.24254324176861}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 29.687032745631218}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 31.80990734117942}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 32.56361170891586}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 23.80830677255767}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 22.759588390933697}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 13.232564953040011}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 25.68795976908214}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 31.091348681794813}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 23.52349513234211}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 24.05717251228861}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 24.05717251228861}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 24.05717251228861}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 24.075505845621944}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 24.05717251228861}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 24.075505845621944}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 24.05717251228861}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 10.910767600799836}, {"Architecture": "GPTJForCausalLM", "Task": "BBH", "Score": 5.089577143988909}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 8.434610644832558}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 5.035475836799366}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 4.318032636938059}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 9.759901587727937}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 5.908662877770453}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 44.28047655387545}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 44.98454525616634}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 30.063103282917453}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 32.75647930053065}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 38.980351633108974}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 44.55485402391639}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 16.249142581095292}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 16.29707852890831}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 23.075768754340448}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 22.379129599952787}, {"Architecture": "Qwen2MoeForCausalLM", "Task": "BBH", "Score": 18.837858500547185}, {"Architecture": "Qwen2MoeForCausalLM", "Task": "BBH", "Score": 20.041818895540956}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 7.994201896754274}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 5.876044259408482}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 11.781833653483533}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 13.695346827502664}, {"Architecture": "Qwen2MoeForCausalLM", "Task": "BBH", "Score": 38.87598905034189}, {"Architecture": "Qwen2MoeForCausalLM", "Task": "BBH", "Score": 41.785917734842535}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 51.85613118695519}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 57.48300911876294}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 34.711136202753416}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 37.80839092310167}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 47.96019950734914}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 14.064494488871304}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 6.953961634882263}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 8.434863610588833}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 16.660465167691854}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 19.80978649735897}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 45.078312404984935}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 48.36070661282705}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 53.954752851332}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 56.48934826159387}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 24.30424172637169}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 25.801393944088584}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 54.61505780163693}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 61.77823228154451}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 35.81347328754777}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 34.89211675876548}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 28.43894411525553}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 30.4662574668053}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 48.966096029421145}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 22.00876067958663}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 21.489765755272032}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 4.19666315993673}, {"Architecture": "LlamaForRewardModelWithGating", "Task": "BBH", "Score": 1.7494478703137453}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 29.787760272097795}, {"Architecture": "RwkvForCausalLM", "Task": "BBH", "Score": 6.763765061303336}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 20.98205231291448}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 20.23755200474476}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 26.88896431517229}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 21.937706578272657}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 7.055475836799367}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 10.4265158026681}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 2.8429334106486}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 2.7249704476856373}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 1.965676941851036}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 33.20757217219532}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 32.794801632016096}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 20.8519483855812}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 19.52953299453869}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 17.47886723805338}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 29.15028934976556}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 20.903472484123803}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 16.692746753586437}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 22.65512081005865}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 48.70118672944805}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 49.193003079898574}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 32.11434845509543}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 32.02159792407502}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 13.51200898319754}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 25.870963383072453}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 27.43815940157093}, {"Architecture": "GemmaForCausalLM", "Task": "BBH", "Score": 28.73815393010281}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 33.801622722378404}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 14.264686822563537}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 8.337659356727954}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 3.612865412111988}, {"Architecture": "?", "Task": "BBH", "Score": 36.28453127383045}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 16.007592932115813}, {"Architecture": "GemmaForCausalLM", "Task": "BBH", "Score": 7.68230049623281}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 25.95903682422342}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 16.98575485690441}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 46.7202351109504}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 46.7202351109504}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 42.113096716972805}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 1.992138996736096}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 5.008442306492267}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 32.97771006701662}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 31.20740955947399}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 32.881396834037055}, {"Architecture": "Phi3ForCausalLM", "Task": "BBH", "Score": 39.148157776889455}, {"Architecture": "ChatGLMModelM", "Task": "BBH", "Score": 35.811283581208905}, {"Architecture": "ChatGLMModelM", "Task": "BBH", "Score": 25.205183674440235}, {"Architecture": "ChatGLMModel", "Task": "BBH", "Score": 17.10802850816805}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 18.92595322755573}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 20.692627382557507}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 5.5227816982611495}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 9.2939499758607}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 19.485726056875954}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 22.37227879113455}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 22.89418875876804}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 41.20039631726062}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 30.025654065607256}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 48.82559521217237}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 22.6871057550123}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 4.013396848486799}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 3.2103010497128146}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 35.74623319855443}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 35.9731352844479}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 32.1807456461844}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 36.13825418700338}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 41.80922962006354}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 42.16983380174582}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 42.53675224107426}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 29.489353188071963}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 29.86944932809155}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 29.73968358044069}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 29.71670075746525}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 22.08465647856181}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 22.93229237099634}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 22.47992425019784}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 21.817495985928637}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.41381524085358}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 14.224326422972672}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 57.502411706281976}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 52.02957975911792}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.0492424520597}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 57.24162100868165}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 30.99936066535637}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 13.419518424915282}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 27.99187353683021}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 22.99208011647468}, {"Architecture": "GemmaForCausalLM", "Task": "BBH", "Score": 9.133870459903902}, {"Architecture": "GemmaForCausalLM", "Task": "BBH", "Score": 18.492651800030927}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 33.94516253986293}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 32.34378307249567}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 49.630350331717615}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 31.838919738784018}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 18.914195373183343}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 43.249988966600455}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 27.322411613379888}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 27.564318704783016}, {"Architecture": "?", "Task": "BBH", "Score": 25.8849543311167}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 49.55653001638277}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 46.71026104076922}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 27.41777700049443}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 27.235483048638358}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 22.012915076928262}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 22.195685067925837}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 24.07027321429611}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 24.08995379001348}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 26.35171605254804}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 22.518920723058404}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 12.434025970150064}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 13.851732907913409}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 14.329006110061371}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 32.66941729424733}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 31.41440911337631}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 41.957047480557854}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 14.30445141720726}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 29.38377348658535}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 29.69444747698505}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 32.84181889691276}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 3.013774178282933}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 31.82468678354313}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 2.147966883446335}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 22.88865497804447}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 37.54335453368136}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 31.879959562746524}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 34.665648637656034}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 35.63684056756332}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 30.387966946397217}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 2.267966388832264}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 31.799951193327704}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 24.495644420709063}, {"Architecture": "Phi3ForCausalLM", "Task": "BBH", "Score": 35.82766762143187}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 42.06417191239567}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 5.151599849335524}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 1.5012962555992375}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 16.18938601764277}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 7.632147610946966}, {"Architecture": "Qwen2MoeForCausalLM", "Task": "BBH", "Score": 8.194779944827593}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 26.387283588738622}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.968504695312703}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 29.07853088402274}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 47.14707467716792}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 56.93552010003367}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 28.020905999685464}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 27.880374189415942}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 34.261660667279955}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 43.12510043134919}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 49.07037043446443}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 31.919260543426763}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 56.26617189727526}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 25.5569024540723}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 19.94022305425607}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 41.56536227340845}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 39.88219882979646}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 4.380133995067516}, {"Architecture": "?", "Task": "BBH", "Score": 28.45661724854773}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 35.2764249557812}, {"Architecture": "JambaForCausalLM", "Task": "BBH", "Score": 10.722058918870276}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 30.55113831130312}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 38.74604345491756}, {"Architecture": "?", "Task": "BBH", "Score": 23.26508902496949}, {"Architecture": "OlmoForCausalLM", "Task": "BBH", "Score": 3.1965463124303173}, {"Architecture": "OlmoForCausalLM", "Task": "BBH", "Score": 13.159933415267032}, {"Architecture": "OlmoForCausalLM", "Task": "BBH", "Score": 5.761987041080832}, {"Architecture": "OlmoeForCausalLM", "Task": "BBH", "Score": 8.308106894895777}, {"Architecture": "OlmoeForCausalLM", "Task": "BBH", "Score": 14.571562821337196}, {"Architecture": "Phi3ForCausalLM", "Task": "BBH", "Score": 45.78594021531884}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 30.194567331120084}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 7.784282802508024}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 24.52948594942413}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 46.16462900339792}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 33.44855374433827}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 33.29836428588566}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 31.577918110916897}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 32.70636246605644}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 31.46648332199455}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 31.92567710646836}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 32.45250184104656}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 32.59670310684399}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 31.617950213580304}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 31.85636425596493}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 32.403879619181005}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 31.298150090327656}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 32.27299661531551}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 32.55261171624742}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 31.803983321994554}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 32.1508911391619}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 2.0803742908537424}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 31.66377531246577}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 33.41446681662389}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 33.79913505465432}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 32.10018047347172}, {"Architecture": "Phi3ForCausalLM", "Task": "BBH", "Score": 48.41436428305058}, {"Architecture": "Phi3ForCausalLM", "Task": "BBH", "Score": 48.88242371785896}, {"Architecture": "Phi3ForCausalLM", "Task": "BBH", "Score": 10.549967885447565}, {"Architecture": "Phi3ForCausalLM", "Task": "BBH", "Score": 10.391379646236162}, {"Architecture": "Phi3ForCausalLM", "Task": "BBH", "Score": 47.92690847304542}, {"Architecture": "Phi3ForCausalLM", "Task": "BBH", "Score": 44.08179620906436}, {"Architecture": "Phi3ForCausalLM", "Task": "BBH", "Score": 47.99849937558212}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 36.45877270267158}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 45.25041934691859}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 1.23986036838978}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 32.81903240379116}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 31.98716596760703}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 34.832235357083775}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 33.34281144377223}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 32.1333222251701}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 5.539183494900659}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 42.80824233844326}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 15.875797412234048}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 45.9816957285586}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 47.20230580445542}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 32.14072892807635}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 31.9314661071385}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 5.957911562958214}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 12.476996185725282}, {"Architecture": "OlmoeForCausalLM", "Task": "BBH", "Score": 4.8423440285205}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 22.096530251343516}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 48.57616817936264}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 57.65318485514271}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 45.38292724900714}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 19.291805959592}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 2.4854950529752244}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 2.537952680477511}, {"Architecture": "GemmaForCausalLM", "Task": "BBH", "Score": 7.94944502776896}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 57.65318485514271}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 28.785551595365877}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 57.85470432085098}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 29.625059445981027}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 41.1601029248443}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 44.32790341462959}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 35.31787541238543}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 34.11678334094384}, {"Architecture": "OpenLMModel", "Task": "BBH", "Score": 19.760934974772244}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 56.74098753952074}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 37.13852245584468}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 36.92439043586489}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 31.572340212980667}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 29.77025370020864}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 49.3042330268799}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 19.528234400992485}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 22.74711196116141}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 34.75806168290175}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 23.51631036482765}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.01590901759341}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 31.980235156677427}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 22.40015255970937}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 9.22769372478478}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 20.435230589690025}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 17.543031293477835}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 21.040436509874464}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 12.361177501580404}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 34.64240096637378}, {"Architecture": "GemmaForCausalLM", "Task": "BBH", "Score": 17.631391012223656}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 21.713423267203808}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 21.95402808715926}, {"Architecture": "Starcoder2ForCausalLM", "Task": "BBH", "Score": 20.373540752678547}, {"Architecture": "Starcoder2ForCausalLM", "Task": "BBH", "Score": 8.909299421083569}, {"Architecture": "Starcoder2ForCausalLM", "Task": "BBH", "Score": 11.395110106503443}, {"Architecture": "BloomForCausalLM", "Task": "BBH", "Score": 4.042705269260129}, {"Architecture": "BloomForCausalLM", "Task": "BBH", "Score": 4.39745292760164}, {"Architecture": "BloomForCausalLM", "Task": "BBH", "Score": 3.4200982840077354}, {"Architecture": "BloomForCausalLM", "Task": "BBH", "Score": 2.885363608028119}, {"Architecture": "BloomForCausalLM", "Task": "BBH", "Score": 4.038808518979752}, {"Architecture": "?", "Task": "BBH", "Score": 45.89740563396065}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 29.80665561261375}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 39.53548333481336}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 32.072941144614084}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 32.843258967002555}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 34.35218727198406}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 1.9479450969539605}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.4247368611983}, {"Architecture": "?", "Task": "BBH", "Score": 29.993501279427136}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 1.827812730226084}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 41.67630770023723}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 41.10464026733791}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 2.612714473502145}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 27.80383919259717}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 25.86828225174116}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 13.678635807519433}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 51.42213772529595}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 41.20912905359096}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 31.259298004231464}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 27.858929260905125}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 31.101151872569243}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 44.17408874277273}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 35.7760897255686}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 49.72194030508101}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 45.44126655093765}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 48.38534691270737}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 47.69617372826186}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 27.914874953255534}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 43.40647565235176}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 26.906353891780515}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 36.08275865915292}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 17.3676325443774}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 8.972088688921525}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 23.64850317610825}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 32.76366579584106}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 29.52088396885831}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.477953494418696}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 31.869311081858005}, {"Architecture": "DbrxForCausalLM", "Task": "BBH", "Score": 35.96381960359357}, {"Architecture": "GPTJForCausalLM", "Task": "BBH", "Score": 4.7813091701327}, {"Architecture": "GPTNeoXForCausalLM", "Task": "BBH", "Score": 6.377894137452961}, {"Architecture": "GPTNeoXForCausalLM", "Task": "BBH", "Score": 3.3247689565453875}, {"Architecture": "GPTNeoXForCausalLM", "Task": "BBH", "Score": 5.449892512817211}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 3.6707473002836015}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 26.631088145699614}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 33.22524192534525}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 9.76792479590425}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 11.258949371501748}, {"Architecture": "DeepseekForCausalLM", "Task": "BBH", "Score": 8.355555779389382}, {"Architecture": "DeepseekForCausalLM", "Task": "BBH", "Score": 6.573749026890635}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 61.92476379259157}, {"Architecture": "?", "Task": "BBH", "Score": 24.09381654636037}, {"Architecture": "?", "Task": "BBH", "Score": 13.68074574746978}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 13.773376256003464}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 57.41436351018751}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 16.48984561578202}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 19.68807585119424}, {"Architecture": "GPT2LMHeadModel", "Task": "BBH", "Score": 2.835219845513963}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 30.99205901512568}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 32.916050576064585}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 31.3912168031268}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 31.136638199988276}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 28.48357519092637}, {"Architecture": "Phi3ForCausalLM", "Task": "BBH", "Score": 47.73420132486152}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 25.373015462245583}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 49.07372077223325}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 49.66553902889135}, {"Architecture": "?", "Task": "BBH", "Score": 31.085445296018975}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 55.41486404819653}, {"Architecture": "Phi3ForCausalLM", "Task": "BBH", "Score": 46.748970518349154}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 58.77356748233938}, {"Architecture": "?", "Task": "BBH", "Score": 58.69214607657639}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 9.213113542615597}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 24.10995815732617}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 24.89219630627393}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 24.168293247720744}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 24.33177003879756}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 25.195784260224865}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 26.11610264109281}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 25.98749682684877}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 32.074208465442545}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 35.56600949863266}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 40.98762530159646}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 35.90894700063131}, {"Architecture": "StableLmForCausalLM", "Task": "BBH", "Score": 8.742082990875964}, {"Architecture": "OPTForCausalLM", "Task": "BBH", "Score": 3.6480520895226793}, {"Architecture": "OPTForCausalLM", "Task": "BBH", "Score": 3.4984293851759607}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 13.620495859752507}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 18.86459884908717}, {"Architecture": "?", "Task": "BBH", "Score": 37.87133313079306}, {"Architecture": "Phi3ForCausalLM", "Task": "BBH", "Score": 46.73283933573803}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 48.93981832466943}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 32.775788922324494}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 30.173396964633465}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 46.78807384004312}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 30.415072015961297}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 14.966964848379982}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.972587655292436}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 31.166750037107487}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 36.260510188013406}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 32.66511308584827}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 45.31740264996691}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 22.63518273833165}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 23.18242496978891}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 23.35420388572778}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 4.50167515878636}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 15.276579446085892}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.91423515333936}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 55.46361848802468}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 51.50838639894525}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 23.46396385965484}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 37.96048632437056}, {"Architecture": "GemmaForCausalLM", "Task": "BBH", "Score": 7.551225280004151}, {"Architecture": "T5ForConditionalGeneration", "Task": "BBH", "Score": 11.33769367730488}, {"Architecture": "T5ForConditionalGeneration", "Task": "BBH", "Score": 17.510018280067285}, {"Architecture": "T5ForConditionalGeneration", "Task": "BBH", "Score": 6.36311196167965}, {"Architecture": "T5ForConditionalGeneration", "Task": "BBH", "Score": 22.6950558112154}, {"Architecture": "T5ForConditionalGeneration", "Task": "BBH", "Score": 22.837587663523298}, {"Architecture": "T5ForConditionalGeneration", "Task": "BBH", "Score": 30.11925560010588}, {"Architecture": "T5ForConditionalGeneration", "Task": "BBH", "Score": 30.02029012567709}, {"Architecture": "GemmaForCausalLM", "Task": "BBH", "Score": 5.862826722774347}, {"Architecture": "GemmaForCausalLM", "Task": "BBH", "Score": 15.93420938501317}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 37.390737454186464}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 49.27284215130387}, {"Architecture": "InternLM2ForCausalLM", "Task": "BBH", "Score": 11.755807532236112}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 12.497306228573644}, {"Architecture": "InternLM2ForCausalLM", "Task": "BBH", "Score": 17.980792881523424}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 18.525626449832732}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 34.09681853589784}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 42.136619683664655}, {"Architecture": "GemmaForCausalLM", "Task": "BBH", "Score": 8.466712864840373}, {"Architecture": "GemmaForCausalLM", "Task": "BBH", "Score": 5.214303022163619}, {"Architecture": "GemmaForCausalLM", "Task": "BBH", "Score": 21.11609932329174}, {"Architecture": "GemmaForCausalLM", "Task": "BBH", "Score": 11.880091344549442}, {"Architecture": "MT5ForConditionalGeneration", "Task": "BBH", "Score": 1.29855138817669}, {"Architecture": "MT5ForConditionalGeneration", "Task": "BBH", "Score": 1.070971479500891}, {"Architecture": "MT5ForConditionalGeneration", "Task": "BBH", "Score": 3.2824619143354035}, {"Architecture": "T5ForConditionalGeneration", "Task": "BBH", "Score": 2.504710800447747}, {"Architecture": "RecurrentGemmaForCausalLM", "Task": "BBH", "Score": 4.8203622310347365}, {"Architecture": "RecurrentGemmaForCausalLM", "Task": "BBH", "Score": 7.978763840391559}, {"Architecture": "RecurrentGemmaForCausalLM", "Task": "BBH", "Score": 15.323368888997411}, {"Architecture": "RecurrentGemmaForCausalLM", "Task": "BBH", "Score": 21.62158008474012}, {"Architecture": "SwitchTransformersForConditionalGeneration", "Task": "BBH", "Score": 1.7024781049821334}, {"Architecture": "UMT5ForConditionalGeneration", "Task": "BBH", "Score": 0.8135531788472962}, {"Architecture": "GPT2LMHeadModel", "Task": "BBH", "Score": 2.674981367986987}, {"Architecture": "GPT2LMHeadModel", "Task": "BBH", "Score": 9.199754901960786}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 21.01052898715872}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.258014912987704}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 29.07328591447649}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 29.415990262794168}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 42.81812817526611}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 29.90753748907924}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 29.8962638406202}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 29.81966445991054}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.955635498374203}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 14.380522116367189}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 10.564444044561542}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 8.839702966263845}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 3.065370444981646}, {"Architecture": "?", "Task": "BBH", "Score": 8.819669166822672}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 29.762188091412483}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.2263760762505}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 20.761385180655164}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 28.53613616746739}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 16.145707376925767}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 25.254277114598622}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 7.076660678102023}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 32.886673214320496}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 34.369626512494015}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 26.56449513263172}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 7.246229410679451}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 44.07149752747837}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 32.40128043389345}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 29.97724776968684}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 9.050800002899097}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 12.639328702465264}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 30.130104071068587}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 29.58232083302582}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 30.37626243817209}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 30.72587571429055}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 29.63689549472275}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 29.39810739240589}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 28.84588139816073}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 26.22465405632467}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 30.6682514458964}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 28.241090201205957}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 31.303238558418094}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 30.135779642023177}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 29.685367916429147}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 31.6512550721568}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 29.234193217077536}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 30.391494717552195}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 28.966258233266576}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 30.6127340167025}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 22.57322577923665}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 41.03264464626528}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 37.79572344136589}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 2.317053716048478}, {"Architecture": "InternLM2ForCausalLM", "Task": "BBH", "Score": 13.63385796590672}, {"Architecture": "InternLM2ForCausalLM", "Task": "BBH", "Score": 20.67235743256185}, {"Architecture": "InternLM2ForCausalLM", "Task": "BBH", "Score": 21.03092693656956}, {"Architecture": "InternLM2ForCausalLM", "Task": "BBH", "Score": 62.83245915287989}, {"Architecture": "InternLM2ForCausalLM", "Task": "BBH", "Score": 57.67364804232054}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 29.731186868686876}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 31.635374808026484}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 30.28379136654109}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 30.080258475101616}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 43.4509951550532}, {"Architecture": "GPTNeoXForCausalLM", "Task": "BBH", "Score": 1.8203742908537424}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 27.843060379681305}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 31.80563982727619}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 32.33028437916087}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 29.55001380445773}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.607718394442788}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.135682301211705}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 30.51494334374904}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 27.665794638508448}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 30.854731427683628}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 27.16443115792157}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 31.163507714744892}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 27.22486881424896}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 31.124765884679533}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 29.53001282071684}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.504906370089667}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 29.136918888444114}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 30.244175919150702}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 29.32060751365874}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 30.69307747198892}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.739266057268598}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 31.007758447741608}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.219373273671145}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 30.841602413783743}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 19.610998997495773}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 16.85891694951123}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 23.0949356647322}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 25.253545989338345}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 24.68762324471831}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.778577217548463}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.768718884316492}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 27.724506656987163}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 26.01209708592899}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 25.371407671115207}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 25.46373486461887}, {"Architecture": "Phi3ForCausalLM", "Task": "BBH", "Score": 48.02072159780435}, {"Architecture": "Phi3ForCausalLM", "Task": "BBH", "Score": 49.845064475726}, {"Architecture": "Phi3ForCausalLM", "Task": "BBH", "Score": 37.1552860906475}, {"Architecture": "Phi3ForCausalLM", "Task": "BBH", "Score": 36.55452005645581}, {"Architecture": "Phi3ForCausalLM", "Task": "BBH", "Score": 35.99938785144921}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 32.21799819533692}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 32.82672418068055}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 23.434359116276923}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 2.831363636363637}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 31.9932224557197}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 16.637813694151937}, {"Architecture": "?", "Task": "BBH", "Score": 19.079190454097787}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 11.125830654491324}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 13.57894913417845}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 2.598263938597983}, {"Architecture": "?", "Task": "BBH", "Score": 14.698639898107368}, {"Architecture": "?", "Task": "BBH", "Score": 20.302342129934097}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.448045037118614}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 42.03199052898647}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 41.16143815473681}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 41.59231281593379}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 39.79685359725269}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 31.19852836941699}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 31.421336195418803}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 42.21047229127766}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 41.62398549212332}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 38.238824874777286}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 38.16656919949616}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 19.475746974326068}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 18.69206874721008}, {"Architecture": "Phi3ForCausalLM", "Task": "BBH", "Score": 31.286439186186243}, {"Architecture": "Phi3ForCausalLM", "Task": "BBH", "Score": 36.35313296509659}, {"Architecture": "Phi3ForCausalLM", "Task": "BBH", "Score": 36.46408334995511}, {"Architecture": "Phi3ForCausalLM", "Task": "BBH", "Score": 33.353311441745}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.895092037237777}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 25.07547488849692}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 26.34859792572119}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 27.665285015300118}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.05625593898892}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 14.86315851911541}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 15.59149132338697}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 7.48978931162921}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 6.461378796018201}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 15.15250931284372}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 14.43786307942362}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 26.79103884029782}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 32.45321665791298}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 31.41189390746123}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 6.910280939116192}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 5.323155419813335}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 30.153238604373765}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.10305001435372}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 30.51396514214568}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 26.8783606145384}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 42.38944488022307}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 49.27446660003019}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 30.54356147647468}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 2.8953053502640427}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 5.466179719646344}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 17.48643895465503}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 7.155379968626988}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 17.222559825058127}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 4.613767082590614}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 35.900061863721675}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 4.459171645959485}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 10.35141665784897}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 4.366029656556756}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 8.742521312303046}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 14.232664884364109}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 24.059186446885477}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 48.709812647505885}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 50.18513318440344}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 24.50076379676797}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.24494957634361}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 26.795283502573653}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 46.39941295581887}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 55.92799173898473}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 25.29477985108717}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 29.89275635245275}, {"Architecture": "GPT2LMHeadModel", "Task": "BBH", "Score": 2.5568557723352243}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 27.308019499942574}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 22.429468402818458}, {"Architecture": "Phi3ForCausalLM", "Task": "BBH", "Score": 48.46045127399018}, {"Architecture": "Phi3ForCausalLM", "Task": "BBH", "Score": 49.38061007422016}, {"Architecture": "Phi3ForCausalLM", "Task": "BBH", "Score": 37.09976663224031}, {"Architecture": "Phi3ForCausalLM", "Task": "BBH", "Score": 39.2693352377728}, {"Architecture": "Phi3ForCausalLM", "Task": "BBH", "Score": 36.55985530518785}, {"Architecture": "Phi3SmallForCausalLM", "Task": "BBH", "Score": 45.63406964144793}, {"Architecture": "Phi3SmallForCausalLM", "Task": "BBH", "Score": 46.20557036638908}, {"Architecture": "Phi3ForCausalLM", "Task": "BBH", "Score": 48.77464635932187}, {"Architecture": "Phi3ForCausalLM", "Task": "BBH", "Score": 36.74585390851661}, {"Architecture": "PhiForCausalLM", "Task": "BBH", "Score": 4.273999212214679}, {"Architecture": "PhiForCausalLM", "Task": "BBH", "Score": 7.468938770070243}, {"Architecture": "PhiForCausalLM", "Task": "BBH", "Score": 28.038519293439304}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 49.118159695748176}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 27.54233943005765}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 24.123847398237004}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 28.042728344416503}, {"Architecture": "Phi3ForCausalLM", "Task": "BBH", "Score": 46.21582810863877}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 52.30813577387958}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 36.41273800501431}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 37.61424608895926}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 37.78604101957199}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 7.561477534247794}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 23.950865383029598}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 45.73104089763324}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 30.737634411945635}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 7.647020535827543}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 22.910601936713604}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 25.56911494885904}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 22.16840245789813}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 23.950865383029598}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 29.374736440966878}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 29.679970381152803}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 30.7920960925092}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 40.5597130348992}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 44.11434558724835}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 45.58840384342722}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 29.74239838096733}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 30.294194918961484}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 30.4002992674255}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 32.31034233969924}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 23.947378025426246}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 24.55720918011033}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 59.80960695923371}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 44.52224375363397}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.47879573339652}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 27.64609355033005}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 31.62685476252992}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 19.865777111108127}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 27.12916478111247}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 23.959695145493203}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 30.30798586214647}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 29.763198395755456}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 21.95410762879941}, {"Architecture": "PhiForCausalLM", "Task": "BBH", "Score": 28.502644855771297}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 50.02266053282724}, {"Architecture": "?", "Task": "BBH", "Score": 1.3404688979507675}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 11.965057260762338}, {"Architecture": "MPTForCausalLM", "Task": "BBH", "Score": 6.550600790794161}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 29.915044266358997}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 37.74683385346309}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 32.39377187272594}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 41.08306318800703}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 35.56934797458052}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 28.907334664767347}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 36.99243243937594}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 34.23559275480162}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 33.73063962440059}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 32.42152675939865}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 34.35741284991507}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 40.12177010845507}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 40.93134519747112}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 35.364516100686416}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 13.091524912026523}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 42.35561106809721}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 27.958132724191334}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 26.48381169342659}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 29.543905352144947}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 34.44654701952267}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 34.57440821872691}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 32.43387434197657}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 34.73061633928093}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 34.95791456295642}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 31.97125827358258}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 32.04475928596384}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 29.567999415715217}, {"Architecture": "GPT2LMHeadModel", "Task": "BBH", "Score": 3.747096495974056}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 22.28062513418979}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 27.1872703942033}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 27.026315532744476}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 27.35361826731554}, {"Architecture": "PhiForCausalLM", "Task": "BBH", "Score": 23.46934667082661}, {"Architecture": "PhiForCausalLM", "Task": "BBH", "Score": 23.07340376774899}, {"Architecture": "PhiForCausalLM", "Task": "BBH", "Score": 22.9070546869096}, {"Architecture": "PhiForCausalLM", "Task": "BBH", "Score": 22.790710795250103}, {"Architecture": "PhiForCausalLM", "Task": "BBH", "Score": 22.58342571657233}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 24.92410586579366}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 22.401696904581677}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 22.058431786302453}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 23.602792666118614}, {"Architecture": "GemmaForCausalLM", "Task": "BBH", "Score": 3.4510601516101125}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 52.227468077653526}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 51.68027687329707}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 22.06890968577206}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 14.382673288078204}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 3.3982664477164874}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 30.18020271418596}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 21.933181635654744}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 28.424782963573875}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 30.873001626388614}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 19.44410955550794}, {"Architecture": "NemotronForCausalLM", "Task": "BBH", "Score": 17.215600655061085}, {"Architecture": "NemotronForCausalLM", "Task": "BBH", "Score": 22.04079297000523}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 31.822015157490156}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 34.126491245346166}, {"Architecture": "NemotronForCausalLM", "Task": "BBH", "Score": 14.203825178862052}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 33.07275916855207}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 17.23541035561212}, {"Architecture": "?", "Task": "BBH", "Score": 25.206881738811884}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 8.562465862636055}, {"Architecture": "GPT2LMHeadModel", "Task": "BBH", "Score": 2.674981367986987}, {"Architecture": "GPT2LMHeadModel", "Task": "BBH", "Score": 2.8159113095085133}, {"Architecture": "GPT2LMHeadModel", "Task": "BBH", "Score": 3.2537905449787403}, {"Architecture": "GPT2LMHeadModel", "Task": "BBH", "Score": 2.719972238356244}, {"Architecture": "GPT2LMHeadModel", "Task": "BBH", "Score": 2.580960647452716}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 24.03871121391158}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 23.236296582166464}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 33.23293691836929}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 21.58216684769999}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 20.32300299720885}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 19.153539587477532}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 20.96137115221118}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 46.69713905397109}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 43.17326773447519}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 43.46251365157702}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 44.96329362428286}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 45.61110998256794}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 27.247898492647995}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 25.454420185872465}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 4.6859845437903855}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 10.199953477088153}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 25.549482064607844}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 42.975787003923045}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 17.843955571096647}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 29.34579501072649}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 29.605372989233757}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 27.87762825685837}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 3.219809856556432}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 32.47882597428379}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 55.05552307693972}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 33.95043410425148}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 53.70222770817057}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 3.658292060342125}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 2.3744704635071923}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 22.54671082396668}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.43975489639733}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 25.018708351323117}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.710959529198124}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 24.388576484696543}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 25.474648628373444}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 26.001873821480995}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 25.705433288023944}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 25.55523001299593}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 26.48589369385502}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 25.526521127200017}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 23.659142323042403}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 26.37396261839453}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 26.39594961870209}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.604298572618475}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 29.086406714200837}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.50739167799402}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.939587046939987}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.64965788695442}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 29.648405523209775}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.839356158957287}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 29.60483732707141}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 29.032479102136296}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.85427665062166}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 27.21648494751436}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.498723991187727}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 29.211612180239623}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.498723991187727}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 26.709132779658223}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 29.214021710829385}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 21.857696499882195}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 20.79098038827006}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 23.70349052130433}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 23.10764227790982}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 22.98200980704625}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 19.59883081662414}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 22.304722895019296}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 22.33288648076616}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 17.248538100586853}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 16.875389341982814}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 20.094109548877523}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 17.81264785919903}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 18.03837283661216}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 17.04838760964466}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 19.20655206374787}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 22.38227741589404}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 4.744629874421679}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 5.655521329938437}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 41.59365445538448}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 40.093429916371655}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 18.67999639960586}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 13.51509134454944}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 26.036695387358723}, {"Architecture": "PhiForCausalLM", "Task": "BBH", "Score": 4.820243721122045}, {"Architecture": "PhiForCausalLM", "Task": "BBH", "Score": 21.672437586715603}, {"Architecture": "PhiForCausalLM", "Task": "BBH", "Score": 26.35880186790661}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 4.19762318329166}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 42.25120987807252}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 42.70379763449792}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 42.32186103147748}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 43.02796904930725}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 43.56058143461737}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 42.026279212829245}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 43.326868296283614}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 42.44248167542507}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 41.72197100339103}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 26.8198371046094}, {"Architecture": "AriaForConditionalGeneration", "Task": "BBH", "Score": 39.28149335481041}, {"Architecture": "PhiForCausalLM", "Task": "BBH", "Score": 25.60654883732465}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 24.14877809167861}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 23.77338959053972}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 30.34224724618852}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 8.412218566269734}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 18.711343783972325}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 49.38690027144481}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 58.26189408678741}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 27.213596951125695}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 61.26714504573664}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 36.37235041430064}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 14.88140918445136}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 49.21778416393897}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 12.69326018768569}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 19.90882095261725}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 2.805733273363854}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 48.02111296160791}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 47.76916471884749}, {"Architecture": "?", "Task": "BBH", "Score": 5.743646077429951}, {"Architecture": "?", "Task": "BBH", "Score": 36.605419148768114}, {"Architecture": "?", "Task": "BBH", "Score": 12.05197465522808}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 17.858141685089326}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 27.91633224536528}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 13.935991387298124}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 8.502927271642019}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 16.44658382894578}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 3.2122172300496232}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 32.532091301992814}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 32.728963576299655}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 13.12524427731519}, {"Architecture": "?", "Task": "BBH", "Score": 11.146535574656042}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 31.65752076487425}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 11.238865074478818}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 19.669907319611504}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 21.35140303187909}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 21.21356840671135}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 20.50625197041595}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 31.16523957802424}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 45.48829424136917}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 31.63055380047582}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 42.28622796334265}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 42.01979809251511}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 58.530351322851054}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 41.26326112722379}, {"Architecture": "StableLmForCausalLM", "Task": "BBH", "Score": 22.685797482043984}, {"Architecture": "StableLmForCausalLM", "Task": "BBH", "Score": 25.25369709081264}, {"Architecture": "StableLmForCausalLM", "Task": "BBH", "Score": 8.632695204968835}, {"Architecture": "StableLmForCausalLM", "Task": "BBH", "Score": 7.493378297410634}, {"Architecture": "StableLmForCausalLM", "Task": "BBH", "Score": 6.708710147938231}, {"Architecture": "StableLmForCausalLM", "Task": "BBH", "Score": 9.01307034954628}, {"Architecture": "StableLmForCausalLM", "Task": "BBH", "Score": 14.7591192080273}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 24.283467839476657}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 33.07275916855207}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 3.8421954101765152}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 4.080205486997016}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 35.554545346782085}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 35.73966330720827}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 48.45443982860533}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 54.40796058706255}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 23.47613361696592}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 18.21332824040884}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 29.251839211223317}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 27.770026367807574}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 12.08139546207365}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 7.399760932518088}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 49.61562001611543}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 29.286422282807493}, {"Architecture": "?", "Task": "BBH", "Score": 23.44418148733149}, {"Architecture": "?", "Task": "BBH", "Score": 21.93674717909172}, {"Architecture": "?", "Task": "BBH", "Score": 24.04860308113929}, {"Architecture": "?", "Task": "BBH", "Score": 24.132844977310707}, {"Architecture": "?", "Task": "BBH", "Score": 31.65269522562221}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 25.33815455229531}, {"Architecture": "?", "Task": "BBH", "Score": 23.50442985462492}, {"Architecture": "?", "Task": "BBH", "Score": 28.44601616578647}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 12.12557956003766}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 28.40148852275863}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 32.61993813582105}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 33.43966927024198}, {"Architecture": "FalconForCausalLM", "Task": "BBH", "Score": 21.937999462890275}, {"Architecture": "FalconForCausalLM", "Task": "BBH", "Score": 16.583304730312175}, {"Architecture": "FalconForCausalLM", "Task": "BBH", "Score": 17.220114203264526}, {"Architecture": "FalconForCausalLM", "Task": "BBH", "Score": 5.963936911876051}, {"Architecture": "FalconForCausalLM", "Task": "BBH", "Score": 4.823178460674432}, {"Architecture": "FalconMambaForCausalLM", "Task": "BBH", "Score": 19.87687780354344}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 24.39876319785054}, {"Architecture": "GPTJForCausalLM", "Task": "BBH", "Score": 7.318523965141613}, {"Architecture": "GPTNeoXForCausalLM", "Task": "BBH", "Score": 6.830794983137852}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 8.089984229889549}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 8.563469919446954}, {"Architecture": "GPTNeoXForCausalLM", "Task": "BBH", "Score": 5.087242272916432}, {"Architecture": "GPTNeoXForCausalLM", "Task": "BBH", "Score": 4.502173664381199}, {"Architecture": "GPTNeoXForCausalLM", "Task": "BBH", "Score": 7.9054164937041635}, {"Architecture": "GPTNeoXForCausalLM", "Task": "BBH", "Score": 3.518607767474259}, {"Architecture": "GPTNeoXForCausalLM", "Task": "BBH", "Score": 5.164727927050627}, {"Architecture": "GPTNeoXForCausalLM", "Task": "BBH", "Score": 4.510786368926982}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 29.267966131617708}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 31.87240188800212}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 2.147162763818688}, {"Architecture": "SolarForCausalLM", "Task": "BBH", "Score": 54.82235099983529}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 24.091412067845624}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 25.99329326784064}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 15.897457343156352}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 24.558747365322688}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 26.79172729423422}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 29.65312947574292}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 25.983622785908505}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 30.51317301580421}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 30.810993185589904}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 48.6166718794722}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 49.73940007466614}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 48.50786084405761}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 29.92604162309261}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 27.8160513277408}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 33.06060419684841}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 33.98837559181831}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 30.50962474895478}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 29.661397892084384}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 35.33444508462291}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 32.392022902811185}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 23.158164380406475}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 27.45095014166692}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 29.95856031523668}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 18.41040626692948}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 34.65142126614313}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.554603909240623}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 3.1255992643495936}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 33.858639234912964}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 3.944866059804924}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 33.044262388969805}, {"Architecture": "Qwen2ForCausalLM", "Task": "BBH", "Score": 18.066398100675865}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 25.258698638977545}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 24.196425775209622}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 26.67569043948038}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 13.30731679540503}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 5.502848923020156}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 6.317188891559348}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 21.14286611806116}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 19.899123541883053}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 20.166003338515427}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 14.80619341451162}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 24.72745698442778}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 27.42282120153998}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 29.398353220629613}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 27.69519951055004}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.508587310114308}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 27.61371406788812}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.574878539626724}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 26.943904089240508}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.046977965255564}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 26.866404089240515}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 29.73123940180749}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 27.892403263090213}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.43982384277912}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 27.145373836403248}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 29.740550305634912}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 26.839803365680336}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.11988708608538}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 29.437347820739543}, {"Architecture": "GemmaForCausalLM", "Task": "BBH", "Score": 16.86274051283721}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 20.176940422218426}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 17.49360317518456}, {"Architecture": "MistralForCausalLM", "Task": "BBH", "Score": 7.671323719331375}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 31.69928662894613}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 31.36612301591548}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.170106538118223}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 29.308127928492556}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 27.469588233937547}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.60442422478885}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.09919885125768}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.78591054243753}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 27.82525272195498}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.12061516996449}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 27.28106392287093}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 21.238562899271304}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 23.492187889680057}, {"Architecture": "LlamaForCausalLM", "Task": "BBH", "Score": 28.54692976096071}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 43.32424255563143}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 43.70651609013871}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 43.85035014659934}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 42.48715312806591}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 43.63358839796041}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 43.94125829423596}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 43.39057008013784}, {"Architecture": "Gemma2ForCausalLM", "Task": "BBH", "Score": 42.1326829485998}, {"Architecture": "MixtralForCausalLM", "Task": "BBH", "Score": 19.17690717348315}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 0.8308157099697886}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 14.04833836858006}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 13.444108761329304}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 23.338368580060425}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 18.80664652567976}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 5.362537764350453}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 12.537764350453172}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 10.196374622356496}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 9.59214501510574}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 11.63141993957704}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 12.613293051359516}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 4.45619335347432}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 4.45619335347432}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 4.305135951661631}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.5105740181268883}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.2084592145015105}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.6797583081570997}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 4.380664652567976}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 5.81570996978852}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 2.9456193353474323}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 10.80060422960725}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 4.531722054380665}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 4.531722054380665}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 21.07250755287009}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 4.229607250755287}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.3595166163141994}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 10.27190332326284}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 7.930513595166164}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.7371601208459215}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.4531722054380665}, {"Architecture": "GPT2LMHeadModel", "Task": "MATH Lvl 5", "Score": 0.6042296072507553}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 3.927492447129909}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 3.474320241691843}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 9.214501510574015}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 11.329305135951662}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 7.930513595166164}, {"Architecture": "PhiForCausalLM", "Task": "MATH Lvl 5", "Score": 1.5861027190332326}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 13.897280966767372}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 7.477341389728097}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 9.667673716012084}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 4.003021148036254}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 14.425981873111782}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 10.498489425981871}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 14.879154078549847}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 6.646525679758309}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 16.314199395770395}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 5.287009063444108}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 6.722054380664652}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 6.117824773413897}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 13.972809667673715}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 9.743202416918429}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 5.589123867069486}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 21.07250755287009}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 9.743202416918429}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 5.589123867069486}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 3.8519637462235647}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "T5ForConditionalGeneration", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "T5ForConditionalGeneration", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "T5ForConditionalGeneration", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "T5ForConditionalGeneration", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 10.196374622356496}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 4.003021148036254}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 7.854984894259818}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 10.27190332326284}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 9.365558912386708}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 11.48036253776435}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 10.120845921450153}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 3.3232628398791544}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 4.154078549848943}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 4.531722054380665}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 4.078549848942599}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 6.419939577039275}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 8.761329305135952}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 6.419939577039275}, {"Architecture": "CohereForCausalLM", "Task": "MATH Lvl 5", "Score": 2.643504531722054}, {"Architecture": "CohereForCausalLM", "Task": "MATH Lvl 5", "Score": 1.4350453172205435}, {"Architecture": "CohereForCausalLM", "Task": "MATH Lvl 5", "Score": 7.552870090634441}, {"Architecture": "CohereForCausalLM", "Task": "MATH Lvl 5", "Score": 11.027190332326285}, {"Architecture": "CohereForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "GemmaForCausalLM", "Task": "MATH Lvl 5", "Score": 4.305135951661631}, {"Architecture": "GemmaForCausalLM", "Task": "MATH Lvl 5", "Score": 4.305135951661631}, {"Architecture": "GemmaForCausalLM", "Task": "MATH Lvl 5", "Score": 3.700906344410876}, {"Architecture": "GemmaForCausalLM", "Task": "MATH Lvl 5", "Score": 5.13595166163142}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 9.06344410876133}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 7.250755287009064}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 8.459214501510575}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 19.788519637462237}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 1.5105740181268883}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 1.812688821752266}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 2.114803625377644}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 4.380664652567976}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.0574018126888218}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 6.3444108761329305}, {"Architecture": "?", "Task": "MATH Lvl 5", "Score": 2.56797583081571}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 4.758308157099698}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 14.954682779456194}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 17.447129909365557}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 5.740181268882175}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 0.5287009063444109}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 4.758308157099698}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 5.287009063444108}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 4.909365558912387}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 4.078549848942599}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 7.930513595166164}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 7.477341389728097}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 4.078549848942599}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 3.8519637462235647}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 4.078549848942599}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.5861027190332326}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 4.984894259818732}, {"Architecture": "DeciLMForCausalLM", "Task": "MATH Lvl 5", "Score": 2.416918429003021}, {"Architecture": "DeciLMForCausalLM", "Task": "MATH Lvl 5", "Score": 2.794561933534743}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 17.522658610271904}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 5.438066465256798}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 4.229607250755287}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.283987915407855}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.3595166163141994}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 7.930513595166164}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 11.555891238670696}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 10.42296072507553}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 10.42296072507553}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 13.746223564954684}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 5.362537764350453}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 15.256797583081571}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 12.613293051359516}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 5.060422960725076}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 20.694864048338367}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 12.537764350453172}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 5.438066465256798}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 12.990936555891238}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 15.181268882175228}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 12.915407854984895}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 13.821752265861026}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 13.897280966767372}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 14.652567975830816}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 13.595166163141997}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 9.06344410876133}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 9.214501510574015}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 13.670694864048338}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 13.746223564954684}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 12.084592145015106}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 13.746223564954684}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 4.45619335347432}, {"Architecture": "GPTJForCausalLM", "Task": "MATH Lvl 5", "Score": 1.2084592145015105}, {"Architecture": "GPTNeoForCausalLM", "Task": "MATH Lvl 5", "Score": 0.6797583081570997}, {"Architecture": "GPTNeoForCausalLM", "Task": "MATH Lvl 5", "Score": 0.4531722054380665}, {"Architecture": "GPTNeoForCausalLM", "Task": "MATH Lvl 5", "Score": 0.5287009063444109}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MATH Lvl 5", "Score": 0.6042296072507553}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MATH Lvl 5", "Score": 0.906344410876133}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MATH Lvl 5", "Score": 0.2265861027190332}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MATH Lvl 5", "Score": 0.6797583081570997}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MATH Lvl 5", "Score": 0.3021148036253776}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MATH Lvl 5", "Score": 0.7552870090634441}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.6042296072507553}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.1510574018126888}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.0574018126888218}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 1.6616314199395772}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 2.719033232628399}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 2.719033232628399}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 4.154078549848943}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 3.2477341389728096}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.3021148036253776}, {"Architecture": "GemmaForCausalLM", "Task": "MATH Lvl 5", "Score": 5.589123867069486}, {"Architecture": "?", "Task": "MATH Lvl 5", "Score": 2.3413897280966767}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 3.5498489425981874}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 3.8519637462235647}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 10.80060422960725}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 13.217522658610273}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 11.027190332326285}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 11.178247734138973}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 12.084592145015106}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 12.386706948640484}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 9.818731117824774}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 10.876132930513595}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 3.096676737160121}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 9.818731117824774}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 8.534743202416918}, {"Architecture": "GemmaForCausalLM", "Task": "MATH Lvl 5", "Score": 3.3987915407854987}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 3.3232628398791544}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 10.876132930513595}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 12.537764350453172}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 11.782477341389727}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 10.27190332326284}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 11.706948640483382}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 10.498489425981871}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 11.329305135951662}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 10.876132930513595}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 12.009063444108762}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 3.2477341389728096}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 10.498489425981871}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 12.990936555891238}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 7.7039274924471295}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 7.326283987915408}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 2.794561933534743}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0755287009063444}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 14.123867069486405}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 4.607250755287009}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "?", "Task": "MATH Lvl 5", "Score": 0.1510574018126888}, {"Architecture": "?", "Task": "MATH Lvl 5", "Score": 3.474320241691843}, {"Architecture": "?", "Task": "MATH Lvl 5", "Score": 0.2265861027190332}, {"Architecture": "?", "Task": "MATH Lvl 5", "Score": 2.0392749244712998}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 6.495468277945619}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 5.13595166163142}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 1.7371601208459215}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.9818731117824772}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.6042296072507553}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 2.492447129909366}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 2.190332326283988}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 8.534743202416918}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 5.211480362537765}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 4.380664652567976}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 3.096676737160121}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 3.8519637462235647}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 8.534743202416918}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 1.5105740181268883}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 2.416918429003021}, {"Architecture": "GemmaForCausalLM", "Task": "MATH Lvl 5", "Score": 6.646525679758309}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 18.35347432024169}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.7552870090634441}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.6797583081570997}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.4531722054380665}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 8.459214501510575}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 7.628398791540786}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.0574018126888218}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 2.190332326283988}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 3.1722054380664653}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 4.531722054380665}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 0.6797583081570997}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 4.682779456193353}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 3.8519637462235647}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 6.042296072507553}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 5.664652567975831}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 5.740181268882175}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 5.13595166163142}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 6.3444108761329305}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 5.81570996978852}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 4.003021148036254}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 3.625377643504532}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 2.9456193353474323}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 4.45619335347432}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.6616314199395772}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 4.003021148036254}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 4.154078549848943}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 4.154078549848943}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 15.55891238670695}, {"Architecture": "PhiForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.3776435045317221}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0755287009063444}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.906344410876133}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 20.09063444108761}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 19.335347432024168}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 20.09063444108761}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 29.607250755287005}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 1.1329305135951662}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 5.060422960725076}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 6.117824773413897}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 7.250755287009064}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 3.474320241691843}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 5.664652567975831}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 7.175226586102719}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 5.81570996978852}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 6.419939577039275}, {"Architecture": "ExaoneForCausalLM", "Task": "MATH Lvl 5", "Score": 4.45619335347432}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 2.0392749244712998}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.5861027190332326}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 19.788519637462237}, {"Architecture": "GemmaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.3021148036253776}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 1.0574018126888218}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 2.190332326283988}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 4.833836858006042}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 3.474320241691843}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 6.3444108761329305}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 0.8308157099697886}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 0.7552870090634441}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 0.3776435045317221}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 0.1510574018126888}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 1.1329305135951662}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 0.3021148036253776}, {"Architecture": "Phi3ForCausalLM", "Task": "MATH Lvl 5", "Score": 9.818731117824774}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 8.006042296072508}, {"Architecture": "?", "Task": "MATH Lvl 5", "Score": 3.625377643504532}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "Phi3ForCausalLM", "Task": "MATH Lvl 5", "Score": 8.761329305135952}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 5.740181268882175}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 5.664652567975831}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 6.495468277945619}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 5.060422960725076}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 9.969788519637463}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 13.36858006042296}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 15.634441087613292}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 3.625377643504532}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 6.873111782477341}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 5.966767371601208}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 5.966767371601208}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 14.803625377643504}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 6.646525679758309}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 8.38368580060423}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 16.1631419939577}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 4.984894259818732}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 6.268882175226587}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 3.3987915407854987}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 3.2477341389728096}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 2.56797583081571}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 7.930513595166164}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 2.2658610271903323}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 6.419939577039275}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 9.214501510574015}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 6.570996978851963}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 8.91238670694864}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 0.3021148036253776}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 7.401812688821751}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 6.722054380664652}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 14.954682779456194}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 4.909365558912387}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 7.175226586102719}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 6.797583081570997}, {"Architecture": "Qwen2MoeForCausalLM", "Task": "MATH Lvl 5", "Score": 2.8700906344410875}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 20.39274924471299}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 15.634441087613292}, {"Architecture": "Phi3ForCausalLM", "Task": "MATH Lvl 5", "Score": 4.305135951661631}, {"Architecture": "Phi3ForCausalLM", "Task": "MATH Lvl 5", "Score": 14.425981873111782}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 36.027190332326285}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 21.07250755287009}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 2.2658610271903323}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 36.40483383685801}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 22.9607250755287}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 2.114803625377644}, {"Architecture": "Phi3ForCausalLM", "Task": "MATH Lvl 5", "Score": 2.3413897280966767}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 41.1631419939577}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 19.335347432024168}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 3.625377643504532}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 37.91540785498489}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 21.90332326283988}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 21.45015105740181}, {"Architecture": "Phi3ForCausalLM", "Task": "MATH Lvl 5", "Score": 2.9456193353474323}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 14.72809667673716}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 18.65558912386707}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 36.5558912386707}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 22.658610271903324}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 18.35347432024169}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 37.68882175226586}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 20.694864048338367}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 11.253776435045316}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 12.084592145015106}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.6797583081570997}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 2.8700906344410875}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 2.0392749244712998}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 15.256797583081571}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 17.220543806646525}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 2.56797583081571}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 13.897280966767372}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 15.709969788519636}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 1.7371601208459215}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MATH Lvl 5", "Score": 0.7552870090634441}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.6042296072507553}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 7.099697885196375}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 4.078549848942599}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.283987915407855}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 11.706948640483382}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 3.3987915407854987}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 12.613293051359516}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.812688821752266}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 9.214501510574015}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.283987915407855}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 5.287009063444108}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.3595166163141994}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 5.13595166163142}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 5.740181268882175}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 4.833836858006042}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 8.685800604229607}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 13.746223564954684}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 4.758308157099698}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 4.229607250755287}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 10.876132930513595}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 1.7371601208459215}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 5.211480362537765}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.6797583081570997}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.1329305135951662}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.7552870090634441}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.9818731117824772}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 2.492447129909366}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 3.0211480362537766}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 2.416918429003021}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 2.2658610271903323}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 4.078549848942599}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.3776435045317221}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 4.531722054380665}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 2.9456193353474323}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MATH Lvl 5", "Score": 1.4350453172205435}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 2.719033232628399}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 6.495468277945619}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 3.3987915407854987}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 9.365558912386708}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 9.743202416918429}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.1510574018126888}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 9.516616314199396}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 15.709969788519636}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 2.416918429003021}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 11.404833836858003}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 12.764350453172204}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 7.779456193353475}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.906344410876133}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 12.990936555891238}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 2.9456193353474323}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 13.821752265861026}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 16.91842900302115}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 9.667673716012084}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 8.610271903323262}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 10.42296072507553}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 10.725075528700906}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 4.531722054380665}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 4.833836858006042}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 6.3444108761329305}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 4.003021148036254}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 6.797583081570997}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 6.797583081570997}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 6.797583081570997}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 6.797583081570997}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 6.797583081570997}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 6.797583081570997}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 6.797583081570997}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 3.8519637462235647}, {"Architecture": "GPTJForCausalLM", "Task": "MATH Lvl 5", "Score": 0.6042296072507553}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.4531722054380665}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 2.2658610271903323}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.4531722054380665}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 23.036253776435046}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 16.46525679758308}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 26.66163141993957}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 6.646525679758309}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 2.416918429003021}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.9818731117824772}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 4.45619335347432}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "Qwen2MoeForCausalLM", "Task": "MATH Lvl 5", "Score": 0.1510574018126888}, {"Architecture": "Qwen2MoeForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 2.56797583081571}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 1.6616314199395772}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 6.268882175226587}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 5.81570996978852}, {"Architecture": "Qwen2MoeForCausalLM", "Task": "MATH Lvl 5", "Score": 18.65558912386707}, {"Architecture": "Qwen2MoeForCausalLM", "Task": "MATH Lvl 5", "Score": 7.7039274924471295}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 29.154078549848943}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 35.12084592145015}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 18.80664652567976}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 8.610271903323262}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 35.95166163141994}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 22.432024169184288}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 1.9637462235649543}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 7.628398791540786}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 1.283987915407855}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 25.98187311178248}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 32.85498489425982}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 7.930513595166164}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 36.102719033232624}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 1.283987915407855}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 17.14501510574018}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 17.447129909365557}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 7.02416918429003}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 18.50453172205438}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 28.323262839879156}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 24.848942598187318}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForRewardModelWithGating", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "RwkvForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 1.8882175226586104}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 2.794561933534743}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 4.833836858006042}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 7.099697885196375}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 2.9456193353474323}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.906344410876133}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 13.217522658610273}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 4.758308157099698}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 5.664652567975831}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 3.927492447129909}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 3.700906344410876}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.1510574018126888}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 6.570996978851963}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 5.966767371601208}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.4531722054380665}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 20.84592145015106}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 20.241691842900305}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 8.459214501510575}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 8.534743202416918}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.9818731117824772}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 7.175226586102719}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 7.401812688821751}, {"Architecture": "GemmaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 15.105740181268882}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.9637462235649543}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 2.0392749244712998}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "?", "Task": "MATH Lvl 5", "Score": 14.954682779456194}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 4.003021148036254}, {"Architecture": "GemmaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.7371601208459215}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 6.646525679758309}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 10.120845921450153}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 29.38066465256798}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 29.38066465256798}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 27.870090634441087}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.1510574018126888}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 7.175226586102719}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 5.589123867069486}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 6.570996978851963}, {"Architecture": "Phi3ForCausalLM", "Task": "MATH Lvl 5", "Score": 7.628398791540786}, {"Architecture": "ChatGLMModelM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "ChatGLMModelM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "ChatGLMModel", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 16.08761329305136}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 2.190332326283988}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.6616314199395772}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.6616314199395772}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 4.607250755287009}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 5.664652567975831}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 7.326283987915408}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 5.966767371601208}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 21.148036253776432}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.7371601208459215}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.8308157099697886}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.4531722054380665}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 4.758308157099698}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 7.477341389728097}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 8.157099697885197}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.1510574018126888}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 9.59214501510574}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 8.761329305135952}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 7.326283987915408}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 7.175226586102719}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 2.416918429003021}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 2.190332326283988}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 1.5105740181268883}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 1.5861027190332326}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 8.534743202416918}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 1.5861027190332326}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 33.610271903323266}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 21.676737160120847}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 5.740181268882175}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 29.909365558912388}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 11.178247734138973}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 2.492447129909366}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 4.003021148036254}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 6.722054380664652}, {"Architecture": "GemmaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.9637462235649543}, {"Architecture": "GemmaForCausalLM", "Task": "MATH Lvl 5", "Score": 4.909365558912387}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 8.610271903323262}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 8.685800604229607}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 14.123867069486405}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0755287009063444}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.5287009063444109}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 9.290030211480364}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 9.290030211480364}, {"Architecture": "?", "Task": "MATH Lvl 5", "Score": 7.175226586102719}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 19.637462235649547}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 7.099697885196375}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 11.404833836858003}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 15.332326283987916}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 8.08157099697885}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 4.531722054380665}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 5.81570996978852}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 5.664652567975831}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 11.63141993957704}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 8.23262839879154}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 3.3987915407854987}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 2.190332326283988}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 5.211480362537765}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 16.76737160120846}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 12.613293051359516}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 4.909365558912387}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 1.7371601208459215}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 5.740181268882175}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 5.589123867069486}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 15.181268882175228}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.7371601208459215}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 3.474320241691843}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 10.27190332326284}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 8.534743202416918}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 9.667673716012084}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 9.214501510574015}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 13.141993957703926}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 9.894259818731117}, {"Architecture": "Phi3ForCausalLM", "Task": "MATH Lvl 5", "Score": 13.821752265861026}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 7.401812688821751}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 6.117824773413897}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 1.2084592145015105}, {"Architecture": "Qwen2MoeForCausalLM", "Task": "MATH Lvl 5", "Score": 1.283987915407855}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 5.966767371601208}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 7.326283987915408}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 5.740181268882175}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 18.202416918429005}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 33.610271903323266}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 11.178247734138973}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 7.326283987915408}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 16.76737160120846}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 21.22356495468278}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 35.34743202416919}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 0.9818731117824772}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 2.3413897280966767}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.4531722054380665}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 18.731117824773413}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 4.229607250755287}, {"Architecture": "?", "Task": "MATH Lvl 5", "Score": 12.537764350453172}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 4.833836858006042}, {"Architecture": "JambaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.9818731117824772}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 8.761329305135952}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 8.459214501510575}, {"Architecture": "?", "Task": "MATH Lvl 5", "Score": 0.2265861027190332}, {"Architecture": "OlmoForCausalLM", "Task": "MATH Lvl 5", "Score": 0.7552870090634441}, {"Architecture": "OlmoForCausalLM", "Task": "MATH Lvl 5", "Score": 0.8308157099697886}, {"Architecture": "OlmoForCausalLM", "Task": "MATH Lvl 5", "Score": 0.6797583081570997}, {"Architecture": "OlmoeForCausalLM", "Task": "MATH Lvl 5", "Score": 1.1329305135951662}, {"Architecture": "OlmoeForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "Phi3ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 5.966767371601208}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 4.229607250755287}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 7.930513595166164}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 7.099697885196375}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 5.589123867069486}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 5.8912386706948645}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 5.664652567975831}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 7.477341389728097}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 6.3444108761329305}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 6.646525679758309}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 5.8912386706948645}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 5.81570996978852}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 6.419939577039275}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 6.495468277945619}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 6.948640483383686}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 7.175226586102719}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 6.3444108761329305}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 5.740181268882175}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 7.02416918429003}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 6.873111782477341}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 6.646525679758309}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 6.193353474320242}, {"Architecture": "Phi3ForCausalLM", "Task": "MATH Lvl 5", "Score": 14.350453172205436}, {"Architecture": "Phi3ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.1510574018126888}, {"Architecture": "Phi3ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "Phi3ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "Phi3ForCausalLM", "Task": "MATH Lvl 5", "Score": 13.897280966767372}, {"Architecture": "Phi3ForCausalLM", "Task": "MATH Lvl 5", "Score": 12.462235649546828}, {"Architecture": "Phi3ForCausalLM", "Task": "MATH Lvl 5", "Score": 14.577039274924472}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 6.873111782477341}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 6.646525679758309}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 6.268882175226587}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 6.722054380664652}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 5.81570996978852}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 7.477341389728097}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 12.235649546827794}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 19.561933534743204}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 20.996978851963743}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 4.758308157099698}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 6.419939577039275}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "OlmoeForCausalLM", "Task": "MATH Lvl 5", "Score": 1.3595166163141994}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.3595166163141994}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 22.2809667673716}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 35.27190332326284}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 20.619335347432024}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 2.114803625377644}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.5287009063444109}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.5287009063444109}, {"Architecture": "GemmaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.2084592145015105}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 35.27190332326284}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 4.758308157099698}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 31.64652567975831}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 4.45619335347432}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 15.483383685800604}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 17.82477341389728}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 5.664652567975831}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 6.117824773413897}, {"Architecture": "OpenLMModel", "Task": "MATH Lvl 5", "Score": 2.9456193353474323}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 40.48338368580061}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 12.31117824773414}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 10.725075528700906}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 15.483383685800604}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.0574018126888218}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 32.477341389728096}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 7.628398791540786}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 2.56797583081571}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 8.459214501510575}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 5.362537764350453}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 8.836858006042297}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 5.740181268882175}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 2.719033232628399}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 2.2658610271903323}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 2.794561933534743}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 2.190332326283988}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 3.2477341389728096}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 2.643504531722054}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 0.8308157099697886}, {"Architecture": "GemmaForCausalLM", "Task": "MATH Lvl 5", "Score": 4.154078549848943}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 5.211480362537765}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 7.175226586102719}, {"Architecture": "Starcoder2ForCausalLM", "Task": "MATH Lvl 5", "Score": 5.362537764350453}, {"Architecture": "Starcoder2ForCausalLM", "Task": "MATH Lvl 5", "Score": 1.4350453172205435}, {"Architecture": "Starcoder2ForCausalLM", "Task": "MATH Lvl 5", "Score": 2.56797583081571}, {"Architecture": "BloomForCausalLM", "Task": "MATH Lvl 5", "Score": 0.1510574018126888}, {"Architecture": "BloomForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0755287009063444}, {"Architecture": "BloomForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0755287009063444}, {"Architecture": "BloomForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0755287009063444}, {"Architecture": "BloomForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "?", "Task": "MATH Lvl 5", "Score": 15.78549848942598}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 16.012084592145015}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 11.404833836858003}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 12.990936555891238}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 10.649546827794564}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 9.818731117824774}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 15.634441087613292}, {"Architecture": "?", "Task": "MATH Lvl 5", "Score": 12.68882175226586}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 3.474320241691843}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 7.250755287009064}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.5287009063444109}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 0.906344410876133}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 19.86404833836858}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 6.570996978851963}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 6.193353474320242}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 5.060422960725076}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 5.438066465256798}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 15.181268882175228}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 10.42296072507553}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 0.5287009063444109}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 12.386706948640484}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 0.5287009063444109}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 18.65558912386707}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 11.555891238670696}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 15.181268882175228}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 4.833836858006042}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 5.060422960725076}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 4.154078549848943}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.1510574018126888}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 5.362537764350453}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 13.36858006042296}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 5.8912386706948645}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 5.740181268882175}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 11.10271903323263}, {"Architecture": "DbrxForCausalLM", "Task": "MATH Lvl 5", "Score": 6.873111782477341}, {"Architecture": "GPTJForCausalLM", "Task": "MATH Lvl 5", "Score": 1.3595166163141994}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MATH Lvl 5", "Score": 1.4350453172205435}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MATH Lvl 5", "Score": 0.6042296072507553}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MATH Lvl 5", "Score": 0.9818731117824772}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 5.5135951661631415}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.6797583081570997}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 6.646525679758309}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.2084592145015105}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.7371601208459215}, {"Architecture": "DeepseekForCausalLM", "Task": "MATH Lvl 5", "Score": 1.812688821752266}, {"Architecture": "DeepseekForCausalLM", "Task": "MATH Lvl 5", "Score": 1.6616314199395772}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 37.91540785498489}, {"Architecture": "?", "Task": "MATH Lvl 5", "Score": 13.51963746223565}, {"Architecture": "?", "Task": "MATH Lvl 5", "Score": 4.380664652567976}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 3.776435045317221}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 35.422960725075534}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 1.5105740181268883}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 1.0574018126888218}, {"Architecture": "GPT2LMHeadModel", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 3.1722054380664653}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 12.915407854984895}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 9.894259818731117}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 10.498489425981871}, {"Architecture": "Phi3ForCausalLM", "Task": "MATH Lvl 5", "Score": 7.779456193353475}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 6.193353474320242}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 21.22356495468278}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 21.827794561933533}, {"Architecture": "?", "Task": "MATH Lvl 5", "Score": 11.329305135951662}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 28.3987915407855}, {"Architecture": "Phi3ForCausalLM", "Task": "MATH Lvl 5", "Score": 11.782477341389727}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 38.97280966767372}, {"Architecture": "?", "Task": "MATH Lvl 5", "Score": 34.66767371601209}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 2.492447129909366}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 10.649546827794564}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 11.63141993957704}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 11.329305135951662}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 9.290030211480364}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 11.404833836858003}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 12.613293051359516}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 13.670694864048338}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 6.722054380664652}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 12.16012084592145}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 8.38368580060423}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 4.380664652567976}, {"Architecture": "StableLmForCausalLM", "Task": "MATH Lvl 5", "Score": 1.7371601208459215}, {"Architecture": "OPTForCausalLM", "Task": "MATH Lvl 5", "Score": 0.7552870090634441}, {"Architecture": "OPTForCausalLM", "Task": "MATH Lvl 5", "Score": 0.6042296072507553}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.4350453172205435}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 3.1722054380664653}, {"Architecture": "?", "Task": "MATH Lvl 5", "Score": 11.858006042296072}, {"Architecture": "Phi3ForCausalLM", "Task": "MATH Lvl 5", "Score": 14.123867069486405}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 23.716012084592144}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.1510574018126888}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 6.873111782477341}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 9.59214501510574}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 2.8700906344410875}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 3.3232628398791544}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 7.552870090634441}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 5.81570996978852}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 5.060422960725076}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 6.722054380664652}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 16.238670694864048}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0755287009063444}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.8308157099697886}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 11.63141993957704}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 29.984894259818727}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 26.812688821752268}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.2084592145015105}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "GemmaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.6042296072507553}, {"Architecture": "T5ForConditionalGeneration", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "T5ForConditionalGeneration", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "T5ForConditionalGeneration", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "T5ForConditionalGeneration", "Task": "MATH Lvl 5", "Score": 0.0755287009063444}, {"Architecture": "T5ForConditionalGeneration", "Task": "MATH Lvl 5", "Score": 0.0755287009063444}, {"Architecture": "T5ForConditionalGeneration", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "T5ForConditionalGeneration", "Task": "MATH Lvl 5", "Score": 0.1510574018126888}, {"Architecture": "GemmaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.1510574018126888}, {"Architecture": "GemmaForCausalLM", "Task": "MATH Lvl 5", "Score": 3.1722054380664653}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 14.879154078549847}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.6797583081570997}, {"Architecture": "InternLM2ForCausalLM", "Task": "MATH Lvl 5", "Score": 2.8700906344410875}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 2.416918429003021}, {"Architecture": "InternLM2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0755287009063444}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 3.474320241691843}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 11.782477341389727}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.2265861027190332}, {"Architecture": "GemmaForCausalLM", "Task": "MATH Lvl 5", "Score": 2.719033232628399}, {"Architecture": "GemmaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.4531722054380665}, {"Architecture": "GemmaForCausalLM", "Task": "MATH Lvl 5", "Score": 6.419939577039275}, {"Architecture": "GemmaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.5861027190332326}, {"Architecture": "MT5ForConditionalGeneration", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "MT5ForConditionalGeneration", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "MT5ForConditionalGeneration", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "T5ForConditionalGeneration", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "RecurrentGemmaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.5861027190332326}, {"Architecture": "RecurrentGemmaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.5105740181268883}, {"Architecture": "RecurrentGemmaForCausalLM", "Task": "MATH Lvl 5", "Score": 5.362537764350453}, {"Architecture": "RecurrentGemmaForCausalLM", "Task": "MATH Lvl 5", "Score": 6.042296072507553}, {"Architecture": "SwitchTransformersForConditionalGeneration", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "UMT5ForConditionalGeneration", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "GPT2LMHeadModel", "Task": "MATH Lvl 5", "Score": 0.2265861027190332}, {"Architecture": "GPT2LMHeadModel", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 4.380664652567976}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 9.365558912386708}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 6.193353474320242}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 12.386706948640484}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 4.003021148036254}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 8.157099697885197}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 9.516616314199396}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 8.987915407854985}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 9.138972809667674}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.8882175226586104}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.6616314199395767}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 2.794561933534743}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.5287009063444109}, {"Architecture": "?", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 7.7039274924471295}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 7.099697885196375}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 2.794561933534743}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 17.900302114803626}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.2084592145015105}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 2.190332326283988}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.6797583081570997}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 5.81570996978852}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.7552870090634441}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 4.833836858006042}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 5.211480362537765}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 2.3413897280966767}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.6042296072507553}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.6042296072507553}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 5.211480362537765}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 5.13595166163142}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 5.438066465256798}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 6.193353474320242}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 5.438066465256798}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 4.833836858006042}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 4.909365558912387}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 3.5498489425981874}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 5.664652567975831}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 5.81570996978852}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 5.5135951661631415}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 4.833836858006041}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 6.419939577039275}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 5.81570996978852}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 5.211480362537765}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 5.664652567975831}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 5.664652567975831}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 5.362537764350453}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 3.2477341389728096}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 8.91238670694864}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 8.38368580060423}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "InternLM2ForCausalLM", "Task": "MATH Lvl 5", "Score": 1.1329305135951662}, {"Architecture": "InternLM2ForCausalLM", "Task": "MATH Lvl 5", "Score": 2.416918429003021}, {"Architecture": "InternLM2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "InternLM2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "InternLM2ForCausalLM", "Task": "MATH Lvl 5", "Score": 8.308157099697885}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 3.700906344410876}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 7.552870090634441}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 6.570996978851963}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 5.438066465256798}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.9818731117824772}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 5.966767371601208}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 3.700906344410876}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 8.534743202416918}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 7.02416918429003}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 6.873111782477341}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 6.042296072507553}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 6.722054380664652}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 4.305135951661631}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 8.836858006042297}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.1329305135951662}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 8.006042296072508}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.0574018126888218}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 6.873111782477341}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.5287009063444109}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 7.099697885196375}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 6.948640483383686}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 9.06344410876133}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 7.099697885196375}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 5.740181268882175}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 5.438066465256798}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 5.740181268882175}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 5.589123867069486}, {"Architecture": "Phi3ForCausalLM", "Task": "MATH Lvl 5", "Score": 14.879154078549847}, {"Architecture": "Phi3ForCausalLM", "Task": "MATH Lvl 5", "Score": 17.97583081570997}, {"Architecture": "Phi3ForCausalLM", "Task": "MATH Lvl 5", "Score": 14.501510574018129}, {"Architecture": "Phi3ForCausalLM", "Task": "MATH Lvl 5", "Score": 15.256797583081571}, {"Architecture": "Phi3ForCausalLM", "Task": "MATH Lvl 5", "Score": 12.83987915407855}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 5.740181268882175}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 7.099697885196375}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 3.3232628398791544}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 3.3987915407854987}, {"Architecture": "?", "Task": "MATH Lvl 5", "Score": 3.096676737160121}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 0.6042296072507553}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.9818731117824772}, {"Architecture": "?", "Task": "MATH Lvl 5", "Score": 1.9637462235649543}, {"Architecture": "?", "Task": "MATH Lvl 5", "Score": 3.0211480362537766}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 12.537764350453172}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.8308157099697886}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.1510574018126888}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 1.283987915407855}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.8308157099697886}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.1510574018126888}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 2.114803625377644}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.1510574018126888}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0755287009063444}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 8.308157099697885}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 9.516616314199396}, {"Architecture": "Phi3ForCausalLM", "Task": "MATH Lvl 5", "Score": 8.836858006042297}, {"Architecture": "Phi3ForCausalLM", "Task": "MATH Lvl 5", "Score": 4.682779456193353}, {"Architecture": "Phi3ForCausalLM", "Task": "MATH Lvl 5", "Score": 14.501510574018129}, {"Architecture": "Phi3ForCausalLM", "Task": "MATH Lvl 5", "Score": 9.138972809667674}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 7.854984894259818}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 3.0211480362537766}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 7.7039274924471295}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 8.534743202416918}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 6.570996978851963}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 0.5287009063444109}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 0.1510574018126888}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.4531722054380665}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.7552870090634441}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.7371601208459215}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 8.23262839879154}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 8.761329305135952}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 18.95770392749245}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.6042296072507553}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.5861027190332326}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 7.628398791540786}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 8.308157099697885}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 2.2658610271903323}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 6.570996978851963}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 20.619335347432024}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.6042296072507553}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.1510574018126888}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 4.909365558912387}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.6042296072507553}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.0574018126888218}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.906344410876133}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 2.492447129909366}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.6797583081570997}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.2084592145015105}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.2265861027190332}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 2.9456193353474323}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.2084592145015105}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 15.55891238670695}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 16.540785498489427}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 23.338368580060425}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 3.2477341389728096}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 8.685800604229607}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 8.38368580060423}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 16.691842900302113}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 28.02114803625378}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 4.607250755287009}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 17.598187311178247}, {"Architecture": "GPT2LMHeadModel", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.9818731117824772}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.8308157099697886}, {"Architecture": "Phi3ForCausalLM", "Task": "MATH Lvl 5", "Score": 16.1631419939577}, {"Architecture": "Phi3ForCausalLM", "Task": "MATH Lvl 5", "Score": 16.993957703927492}, {"Architecture": "Phi3ForCausalLM", "Task": "MATH Lvl 5", "Score": 8.91238670694864}, {"Architecture": "Phi3ForCausalLM", "Task": "MATH Lvl 5", "Score": 11.63141993957704}, {"Architecture": "Phi3ForCausalLM", "Task": "MATH Lvl 5", "Score": 14.19939577039275}, {"Architecture": "Phi3SmallForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "Phi3SmallForCausalLM", "Task": "MATH Lvl 5", "Score": 2.643504531722054}, {"Architecture": "Phi3ForCausalLM", "Task": "MATH Lvl 5", "Score": 20.54380664652568}, {"Architecture": "Phi3ForCausalLM", "Task": "MATH Lvl 5", "Score": 14.954682779456194}, {"Architecture": "PhiForCausalLM", "Task": "MATH Lvl 5", "Score": 0.6797583081570997}, {"Architecture": "PhiForCausalLM", "Task": "MATH Lvl 5", "Score": 1.1329305135951662}, {"Architecture": "PhiForCausalLM", "Task": "MATH Lvl 5", "Score": 2.416918429003021}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 18.95770392749245}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 5.060422960725076}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 3.3232628398791544}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 4.682779456193353}, {"Architecture": "Phi3ForCausalLM", "Task": "MATH Lvl 5", "Score": 2.643504531722054}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 27.416918429003022}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 8.610271903323262}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 8.38368580060423}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 7.854984894259818}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.2265861027190332}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 2.643504531722054}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 16.842900302114806}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 8.761329305135952}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 1.6616314199395772}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 2.643504531722054}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 3.1722054380664653}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 2.492447129909366}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 2.643504531722054}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 4.984894259818732}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 5.8912386706948645}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 14.350453172205436}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 18.12688821752266}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 18.731117824773413}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 16.842900302114806}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 8.157099697885197}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 8.761329305135952}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 9.365558912386708}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 8.006042296072508}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 3.8519637462235647}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 4.758308157099698}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 17.82477341389728}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 3.474320241691843}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 8.308157099697885}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 7.854984894259818}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 8.987915407854985}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 8.610271903323262}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 6.419939577039275}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 4.758308157099698}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 8.006042296072508}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 8.534743202416918}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 3.8519637462235647}, {"Architecture": "PhiForCausalLM", "Task": "MATH Lvl 5", "Score": 2.56797583081571}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 24.24471299093656}, {"Architecture": "?", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.9818731117824772}, {"Architecture": "MPTForCausalLM", "Task": "MATH Lvl 5", "Score": 1.283987915407855}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 5.664652567975831}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 10.27190332326284}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 6.193353474320242}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 3.474320241691843}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 11.027190332326285}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 5.664652567975831}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 8.308157099697885}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 11.706948640483382}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 10.498489425981871}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 10.649546827794564}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 4.078549848942599}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 16.691842900302113}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 19.486404833836858}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 10.42296072507553}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 1.4350453172205435}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 7.02416918429003}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 6.3444108761329305}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 6.268882175226587}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 1.812688821752266}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 9.894259818731117}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 10.42296072507553}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 2.114803625377644}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 4.607250755287009}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 10.95166163141994}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 10.196374622356496}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 6.570996978851963}, {"Architecture": "GPT2LMHeadModel", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 4.531722054380665}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 5.81570996978852}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 6.193353474320242}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 6.570996978851963}, {"Architecture": "PhiForCausalLM", "Task": "MATH Lvl 5", "Score": 1.9637462235649543}, {"Architecture": "PhiForCausalLM", "Task": "MATH Lvl 5", "Score": 1.8882175226586104}, {"Architecture": "PhiForCausalLM", "Task": "MATH Lvl 5", "Score": 1.4350453172205435}, {"Architecture": "PhiForCausalLM", "Task": "MATH Lvl 5", "Score": 1.3595166163141994}, {"Architecture": "PhiForCausalLM", "Task": "MATH Lvl 5", "Score": 1.2084592145015105}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 2.643504531722054}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 4.682779456193353}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 5.287009063444108}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 4.984894259818732}, {"Architecture": "GemmaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 30.28700906344411}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 28.700906344410875}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 0.6797583081570997}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 0.5287009063444109}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 4.682779456193353}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 6.419939577039275}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 4.45619335347432}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 6.570996978851963}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.1329305135951662}, {"Architecture": "NemotronForCausalLM", "Task": "MATH Lvl 5", "Score": 1.6616314199395772}, {"Architecture": "NemotronForCausalLM", "Task": "MATH Lvl 5", "Score": 2.2658610271903323}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 4.229607250755287}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 0.4531722054380665}, {"Architecture": "NemotronForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 6.948640483383686}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 1.8882175226586104}, {"Architecture": "?", "Task": "MATH Lvl 5", "Score": 4.305135951661631}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.5287009063444109}, {"Architecture": "GPT2LMHeadModel", "Task": "MATH Lvl 5", "Score": 0.2265861027190332}, {"Architecture": "GPT2LMHeadModel", "Task": "MATH Lvl 5", "Score": 0.3021148036253776}, {"Architecture": "GPT2LMHeadModel", "Task": "MATH Lvl 5", "Score": 0.6797583081570997}, {"Architecture": "GPT2LMHeadModel", "Task": "MATH Lvl 5", "Score": 0.2265861027190332}, {"Architecture": "GPT2LMHeadModel", "Task": "MATH Lvl 5", "Score": 0.3021148036253776}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 6.495468277945619}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 6.873111782477341}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 7.326283987915408}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 6.570996978851963}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.1329305135951662}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.5861027190332326}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 4.305135951661631}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 11.858006042296072}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 16.314199395770395}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 16.540785498489424}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 17.447129909365557}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 15.861027190332328}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 3.0211480362537766}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.2084592145015105}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.5287009063444109}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.1329305135951662}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.8882175226586104}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 3.625377643504532}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.3021148036253776}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 7.854984894259818}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 7.477341389728097}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 5.966767371601208}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 5.5135951661631415}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 26.435045317220546}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 2.643504531722054}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 26.132930513595166}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.8308157099697886}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 16.314199395770395}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 4.45619335347432}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 5.81570996978852}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 5.5135951661631415}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 2.719033232628399}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 4.45619335347432}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 2.56797583081571}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.2084592145015105}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.1329305135951662}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 3.927492447129909}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 3.700906344410876}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 2.8700906344410875}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 4.45619335347432}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 2.0392749244712998}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 8.534743202416918}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 9.894259818731117}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 3.3232628398791544}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 5.5135951661631415}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 3.2477341389728096}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 7.175226586102719}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 6.646525679758309}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 8.459214501510575}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 2.114803625377644}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 4.909365558912387}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 8.836858006042297}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 7.930513595166164}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 7.628398791540786}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 7.930513595166164}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 2.2658610271903323}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 5.287009063444108}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 2.416918429003021}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 1.5861027190332326}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 2.114803625377644}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 3.3232628398791544}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 1.9637462235649543}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 2.2658610271903323}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 2.9456193353474323}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 0.6042296072507553}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 2.0392749244712998}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 2.9456193353474323}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 1.812688821752266}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 2.3413897280966767}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 2.56797583081571}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 2.3413897280966767}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 2.2658610271903323}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 2.492447129909366}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.8308157099697886}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.5287009063444109}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.5105740181268883}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 0.8308157099697886}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 0.7552870090634441}, {"Architecture": "PhiForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "PhiForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "PhiForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.8882175226586104}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 1.7371601208459215}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 5.13595166163142}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 1.2084592145015105}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 5.287009063444108}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 6.948640483383686}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 8.761329305135952}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 15.483383685800604}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 7.401812688821751}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 3.927492447129909}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 8.91238670694864}, {"Architecture": "AriaForConditionalGeneration", "Task": "MATH Lvl 5", "Score": 15.030211480362537}, {"Architecture": "PhiForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 4.833836858006042}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 4.229607250755287}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 12.537764350453172}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 2.492447129909366}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 7.02416918429003}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 15.634441087613292}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 39.12386706948641}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 5.060422960725076}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 47.583081570996974}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 26.435045317220546}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 8.308157099697885}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 28.851963746223564}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 5.740181268882175}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 1.3595166163141994}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 6.193353474320242}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.5861027190332326}, {"Architecture": "?", "Task": "MATH Lvl 5", "Score": 0.9818731117824772}, {"Architecture": "?", "Task": "MATH Lvl 5", "Score": 13.141993957703926}, {"Architecture": "?", "Task": "MATH Lvl 5", "Score": 1.8882175226586104}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 4.833836858006042}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 10.120845921450153}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 3.096676737160121}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 2.416918429003021}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 3.927492447129909}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 6.268882175226587}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.6042296072507553}, {"Architecture": "?", "Task": "MATH Lvl 5", "Score": 1.2084592145015105}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 6.495468277945619}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.9818731117824772}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 2.0392749244712998}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 1.812688821752266}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 2.2658610271903323}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 2.416918429003021}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 5.287009063444108}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 16.314199395770395}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 7.854984894259818}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 18.580060422960727}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 17.97583081570997}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 6.042296072507553}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 3.5498489425981874}, {"Architecture": "StableLmForCausalLM", "Task": "MATH Lvl 5", "Score": 3.474320241691843}, {"Architecture": "StableLmForCausalLM", "Task": "MATH Lvl 5", "Score": 2.0392749244712998}, {"Architecture": "StableLmForCausalLM", "Task": "MATH Lvl 5", "Score": 0.1510574018126888}, {"Architecture": "StableLmForCausalLM", "Task": "MATH Lvl 5", "Score": 1.0574018126888218}, {"Architecture": "StableLmForCausalLM", "Task": "MATH Lvl 5", "Score": 2.114803625377644}, {"Architecture": "StableLmForCausalLM", "Task": "MATH Lvl 5", "Score": 0.6797583081570997}, {"Architecture": "StableLmForCausalLM", "Task": "MATH Lvl 5", "Score": 4.078549848942599}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 6.722054380664652}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 6.948640483383686}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0755287009063444}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.7552870090634441}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 2.9456193353474323}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.8308157099697886}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 3.8519637462235647}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 4.45619335347432}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.0574018126888218}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.283987915407855}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 22.658610271903324}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 4.607250755287009}, {"Architecture": "?", "Task": "MATH Lvl 5", "Score": 1.8882175226586104}, {"Architecture": "?", "Task": "MATH Lvl 5", "Score": 3.1722054380664653}, {"Architecture": "?", "Task": "MATH Lvl 5", "Score": 2.416918429003021}, {"Architecture": "?", "Task": "MATH Lvl 5", "Score": 4.45619335347432}, {"Architecture": "?", "Task": "MATH Lvl 5", "Score": 8.610271903323262}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 4.984894259818732}, {"Architecture": "?", "Task": "MATH Lvl 5", "Score": 2.56797583081571}, {"Architecture": "?", "Task": "MATH Lvl 5", "Score": 8.459214501510575}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 6.117824773413897}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 12.009063444108762}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 8.08157099697885}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "FalconForCausalLM", "Task": "MATH Lvl 5", "Score": 2.3413897280966767}, {"Architecture": "FalconForCausalLM", "Task": "MATH Lvl 5", "Score": 1.3595166163141994}, {"Architecture": "FalconForCausalLM", "Task": "MATH Lvl 5", "Score": 1.5105740181268883}, {"Architecture": "FalconForCausalLM", "Task": "MATH Lvl 5", "Score": 0.5287009063444109}, {"Architecture": "FalconForCausalLM", "Task": "MATH Lvl 5", "Score": 0.6042296072507553}, {"Architecture": "FalconMambaForCausalLM", "Task": "MATH Lvl 5", "Score": 3.625377643504532}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.1329305135951662}, {"Architecture": "GPTJForCausalLM", "Task": "MATH Lvl 5", "Score": 0.7552870090634441}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MATH Lvl 5", "Score": 1.1329305135951662}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.6797583081570997}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.0574018126888218}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MATH Lvl 5", "Score": 0.9818731117824772}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MATH Lvl 5", "Score": 0.1510574018126888}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MATH Lvl 5", "Score": 1.3595166163141994}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MATH Lvl 5", "Score": 0.906344410876133}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MATH Lvl 5", "Score": 0.3021148036253776}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MATH Lvl 5", "Score": 0.6042296072507553}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 6.646525679758309}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "SolarForCausalLM", "Task": "MATH Lvl 5", "Score": 20.09063444108761}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 4.607250755287009}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 4.305135951661631}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.6616314199395772}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 4.380664652567976}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.4350453172205435}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 2.9456193353474323}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 3.625377643504532}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 14.879154078549847}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 13.293051359516618}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 19.71299093655589}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 10.498489425981871}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 7.175226586102719}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 5.5135951661631415}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 4.758308157099698}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 5.966767371601208}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 15.861027190332328}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 6.117824773413897}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 3.700906344410876}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 4.305135951661631}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 13.670694864048338}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 1.5861027190332326}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 8.308157099697885}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 8.685800604229607}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.4531722054380665}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.2265861027190332}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 0.1510574018126888}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 6.419939577039275}, {"Architecture": "Qwen2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 0.906344410876133}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 15.256797583081571}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.9637462235649543}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 2.643504531722054}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.4350453172205435}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 10.196374622356496}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 4.909365558912387}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.5105740181268883}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 1.2084592145015105}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 1.812688821752266}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 3.1722054380664653}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 6.117824773413897}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 7.552870090634441}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 5.966767371601208}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 6.948640483383686}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 6.117824773413897}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 6.3444108761329305}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 6.873111782477341}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 6.419939577039275}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 7.552870090634441}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 7.7039274924471295}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 8.006042296072508}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 7.628398791540786}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 6.117824773413897}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 5.060422960725076}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 3.927492447129909}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 8.685800604229607}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 12.83987915407855}, {"Architecture": "GemmaForCausalLM", "Task": "MATH Lvl 5", "Score": 5.060422960725076}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 4.531722054380665}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 2.3413897280966767}, {"Architecture": "MistralForCausalLM", "Task": "MATH Lvl 5", "Score": 2.0392749244712998}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 7.854984894259818}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 7.7039274924471295}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 6.873111782477341}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 9.06344410876133}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 8.836858006042297}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 8.610271903323262}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 4.531722054380665}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 7.099697885196375}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 6.722054380664652}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 6.570996978851963}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 6.193353474320242}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 5.13595166163142}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 7.401812688821751}, {"Architecture": "LlamaForCausalLM", "Task": "MATH Lvl 5", "Score": 5.287009063444108}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.3021148036253776}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 1.283987915407855}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 14.123867069486405}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 0.0}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 1.1329305135951662}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 6.3444108761329305}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 7.930513595166164}, {"Architecture": "Gemma2ForCausalLM", "Task": "MATH Lvl 5", "Score": 16.46525679758308}, {"Architecture": "MixtralForCausalLM", "Task": "MATH Lvl 5", "Score": 5.966767371601208}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 1.230425055928408}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 15.436241610738255}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 15.100671140939594}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 15.324384787472036}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 11.74496644295302}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 8.501118568232664}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 9.060402684563762}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 17.225950782997764}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 14.5413870246085}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 11.297539149888143}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.829977628635347}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 15.548098434004473}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 14.205816554809845}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 11.74496644295302}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.572706935123044}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.250559284116329}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.92841163310962}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 9.060402684563762}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 8.7248322147651}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 13.422818791946312}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.697986577181204}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.697986577181204}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.8948545861297527}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.9082774049217}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 10.290827740492167}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 4.026845637583895}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 5.145413870246088}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 11.185682326621922}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 10.402684563758392}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.1252796420581683}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.1252796420581683}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.1185682326621946}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.1252796420581683}, {"Architecture": "GPT2LMHeadModel", "Task": "GPQA", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 11.85682326621924}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.250559284116329}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.4742729306487705}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 7.38255033557047}, {"Architecture": "PhiForCausalLM", "Task": "GPQA", "Score": 2.348993288590602}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.823266219239373}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 2.1252796420581683}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 8.165548098434002}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.0134228187919474}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.941834451901568}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 11.409395973154364}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 11.968680089485462}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 14.429530201342288}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 6.152125279642054}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 14.317673378076066}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.355704697986576}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.921700223713646}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 8.389261744966444}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 13.870246085011187}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.7046979865771785}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 5.369127516778524}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 16.778523489932887}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.7046979865771785}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 5.369127516778524}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.243847874720355}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 8.501118568232664}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.0067114093959737}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.7829977628635317}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.230425055928408}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.348993288590602}, {"Architecture": "T5ForConditionalGeneration", "Task": "GPQA", "Score": 0.0}, {"Architecture": "T5ForConditionalGeneration", "Task": "GPQA", "Score": 0.5592841163310973}, {"Architecture": "T5ForConditionalGeneration", "Task": "GPQA", "Score": 1.230425055928408}, {"Architecture": "T5ForConditionalGeneration", "Task": "GPQA", "Score": 1.230425055928408}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 10.17897091722595}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 1.6778523489932915}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.7046979865771785}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.138702460850116}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.243847874720355}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.592841163310966}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.921700223713646}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.046979865771815}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 12.863534675615217}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.138702460850116}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 1.9015659955257265}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 2.9082774049217}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 7.606263982102905}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 3.355704697986576}, {"Architecture": "CohereForCausalLM", "Task": "GPQA", "Score": 5.92841163310962}, {"Architecture": "CohereForCausalLM", "Task": "GPQA", "Score": 4.586129753914992}, {"Architecture": "CohereForCausalLM", "Task": "GPQA", "Score": 7.38255033557047}, {"Architecture": "CohereForCausalLM", "Task": "GPQA", "Score": 13.422818791946312}, {"Architecture": "CohereForCausalLM", "Task": "GPQA", "Score": 7.606263982102905}, {"Architecture": "GemmaForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "GemmaForCausalLM", "Task": "GPQA", "Score": 0.4474272930648763}, {"Architecture": "GemmaForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "GemmaForCausalLM", "Task": "GPQA", "Score": 0.7829977628635317}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.138702460850116}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.697986577181204}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.691275167785232}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 14.093959731543624}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 0.4474272930648763}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 1.342281879194629}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 1.9015659955257265}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.375838926174497}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.4474272930648763}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 8.389261744966444}, {"Architecture": "?", "Task": "GPQA", "Score": 5.480984340044745}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 5.257270693512303}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.592841163310966}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 10.17897091722595}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.606263982102905}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.026845637583895}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.92841163310962}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.809843400447425}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.480984340044745}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.8165548098434}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.494407158836691}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.711409395973152}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.803131991051453}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.5794183445190177}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.250559284116329}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.796420581655479}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.355704697986576}, {"Architecture": "DeciLMForCausalLM", "Task": "GPQA", "Score": 6.040268456375841}, {"Architecture": "DeciLMForCausalLM", "Task": "GPQA", "Score": 5.257270693512303}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.4742729306487705}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.7829977628635317}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.789709172259505}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.348993288590602}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.592841163310966}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.257270693512303}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.480984340044745}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.480984340044745}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 7.38255033557047}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.38255033557047}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.494407158836691}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.935123042505594}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 9.955257270693512}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 5.369127516778524}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 12.192393736017896}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 9.843400447427292}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 8.612975391498878}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.606263982102905}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.935123042505594}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.487695749440718}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.606263982102905}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 8.948545861297541}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.823266219239373}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.586129753914992}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.38255033557047}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.270693512304249}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.158836689038028}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.243847874720355}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.809843400447425}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 5.592841163310966}, {"Architecture": "GPTJForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "GPTNeoForCausalLM", "Task": "GPQA", "Score": 0.7829977628635317}, {"Architecture": "GPTNeoForCausalLM", "Task": "GPQA", "Score": 0.4474272930648763}, {"Architecture": "GPTNeoForCausalLM", "Task": "GPQA", "Score": 2.1252796420581683}, {"Architecture": "GPTNeoXForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "GPTNeoXForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "GPTNeoXForCausalLM", "Task": "GPQA", "Score": 1.1185682326621946}, {"Architecture": "GPTNeoXForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "GPTNeoXForCausalLM", "Task": "GPQA", "Score": 1.230425055928408}, {"Architecture": "GPTNeoXForCausalLM", "Task": "GPQA", "Score": 0.2237136465324418}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.796420581655479}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.5659955257270708}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.0134228187919474}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.1252796420581683}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.1252796420581683}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 1.45413870246085}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 3.467561521252797}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 2.1252796420581683}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.369127516778524}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 2.460850111856823}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 4.138702460850116}, {"Architecture": "GemmaForCausalLM", "Task": "GPQA", "Score": 4.026845637583895}, {"Architecture": "?", "Task": "GPQA", "Score": 4.026845637583895}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 1.5659955257270708}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 6.823266219239373}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.711409395973152}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.026845637583895}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.809843400447425}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.92841163310962}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.935123042505594}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.8165548098434}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.480984340044745}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.711409395973152}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 5.592841163310966}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.0067114093959737}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 10.850111856823268}, {"Architecture": "GemmaForCausalLM", "Task": "GPQA", "Score": 2.796420581655479}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 6.487695749440718}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.7046979865771785}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.145413870246088}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.803131991051453}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.369127516778524}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.375838926174497}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.152125279642054}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.599552572706939}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.263982102908276}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.718120805369126}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 1.789709172259505}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 8.277404921700223}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 10.96196868008949}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 5.592841163310966}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 5.592841163310966}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.809843400447425}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.460850111856823}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.152125279642054}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 3.9149888143176734}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.0067114093959737}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 0.7829977628635317}, {"Architecture": "?", "Task": "GPQA", "Score": 3.803131991051453}, {"Architecture": "?", "Task": "GPQA", "Score": 3.691275167785232}, {"Architecture": "?", "Task": "GPQA", "Score": 3.9149888143176734}, {"Architecture": "?", "Task": "GPQA", "Score": 4.4742729306487705}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.697986577181204}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.586129753914992}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 6.487695749440718}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 0.1118568232662209}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 6.375838926174497}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 6.152125279642054}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.467561521252797}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 3.0201342281879207}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 3.691275167785232}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 6.040268456375841}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 7.046979865771815}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 6.375838926174497}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 5.369127516778524}, {"Architecture": "GemmaForCausalLM", "Task": "GPQA", "Score": 5.92841163310962}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 17.114093959731544}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.342281879194629}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.1185682326621946}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.230425055928408}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.348993288590602}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.9015659955257265}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.7829977628635317}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 5.033557046979867}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 6.487695749440718}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.599552572706939}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 5.592841163310966}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 5.369127516778524}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 5.369127516778524}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 5.257270693512303}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.592841163310966}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.480984340044745}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 7.046979865771815}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 6.487695749440718}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 5.257270693512303}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 6.711409395973152}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 5.92841163310962}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 6.487695749440718}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 6.040268456375841}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 7.38255033557047}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 8.612975391498878}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.92841163310962}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.270693512304249}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.809843400447425}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.7046979865771785}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.494407158836691}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.158836689038028}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.935123042505594}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.941834451901568}, {"Architecture": "PhiForCausalLM", "Task": "GPQA", "Score": 4.250559284116329}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 16.666666666666664}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 17.4496644295302}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 16.666666666666664}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 19.463087248322143}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 1.789709172259505}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 4.809843400447425}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 6.152125279642054}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.046979865771815}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.138702460850116}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.026845637583895}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 3.691275167785232}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.36241610738255}, {"Architecture": "ExaoneForCausalLM", "Task": "GPQA", "Score": 2.1252796420581683}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.5794183445190177}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.494407158836691}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 16.890380313199106}, {"Architecture": "GemmaForCausalLM", "Task": "GPQA", "Score": 2.1252796420581683}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 1.5659955257270708}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 1.789709172259505}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 4.36241610738255}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 2.348993288590602}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.809843400447425}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 2.0134228187919474}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 5.7046979865771785}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 2.460850111856823}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 2.1252796420581683}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.586129753914992}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 1.0067114093959737}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 2.1252796420581683}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 2.796420581655479}, {"Architecture": "Phi3ForCausalLM", "Task": "GPQA", "Score": 9.50782997762864}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 4.138702460850116}, {"Architecture": "?", "Task": "GPQA", "Score": 4.36241610738255}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "Phi3ForCausalLM", "Task": "GPQA", "Score": 9.395973154362418}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.0134228187919474}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.1185682326621946}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.460850111856823}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.941834451901568}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.9015659955257265}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.9015659955257265}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.45413870246085}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.460850111856823}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.6778523489932915}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 0.1118568232662209}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 3.467561521252797}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 5.8165548098434}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.684563758389265}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.342281879194629}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.6778523489932915}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 13.870246085011187}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.6778523489932915}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.1252796420581683}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.355704697986576}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.5794183445190177}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.0134228187919474}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.45413870246085}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.789709172259505}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.5659955257270708}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.348993288590602}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 9.060402684563762}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 5.592841163310966}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 3.355704697986576}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 4.250559284116329}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 1.230425055928408}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 4.250559284116329}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 3.9149888143176734}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.586129753914992}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.829977628635347}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.38255033557047}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.718120805369126}, {"Architecture": "Qwen2MoeForCausalLM", "Task": "GPQA", "Score": 3.355704697986576}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 4.697986577181204}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 5.8165548098434}, {"Architecture": "Phi3ForCausalLM", "Task": "GPQA", "Score": 10.626398210290828}, {"Architecture": "Phi3ForCausalLM", "Task": "GPQA", "Score": 12.527964205816552}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 17.4496644295302}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 5.257270693512303}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 15.100671140939594}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 19.239373601789712}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 12.192393736017896}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 9.955257270693512}, {"Architecture": "Phi3ForCausalLM", "Task": "GPQA", "Score": 9.50782997762864}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 16.554809843400445}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 5.480984340044745}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 14.5413870246085}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 20.917225950783}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 11.74496644295302}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 12.527964205816552}, {"Architecture": "Phi3ForCausalLM", "Task": "GPQA", "Score": 9.060402684563762}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 16.21923937360179}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 6.263982102908276}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 20.581655480984335}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 11.968680089485462}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 4.4742729306487705}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 20.3579418344519}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 8.05369127516779}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 4.586129753914999}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 5.480984340044745}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 2.9082774049217}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 1.45413870246085}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 1.789709172259505}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 1.789709172259505}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.599552572706939}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.9149888143176734}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.460850111856823}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 9.955257270693512}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 10.738255033557047}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 0.5592841163310973}, {"Architecture": "GPTNeoXForCausalLM", "Task": "GPQA", "Score": 2.1252796420581683}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.4474272930648763}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.369127516778524}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 8.83668903803132}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.480984340044745}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.684563758389265}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.263982102908276}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 8.612975391498878}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 8.165548098434002}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.342281879194629}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.921700223713646}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.0201342281879207}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.1118568232662209}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.5659955257270708}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.7046979865771785}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 3.1319910514541416}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.158836689038028}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 14.87695749440716}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.375838926174497}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 5.7046979865771785}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 9.50782997762864}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 6.935123042505594}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.8165548098434}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.789709172259505}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.1185682326621946}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.342281879194629}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.9015659955257265}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 6.487695749440718}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 5.369127516778524}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.046979865771815}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.935123042505594}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.0067114093959737}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.1185682326621946}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 3.803131991051453}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 2.9082774049217}, {"Architecture": "GPTNeoXForCausalLM", "Task": "GPQA", "Score": 1.0067114093959737}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.796420581655479}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.9149888143176734}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 16.666666666666664}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.9149888143176734}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.9149888143176734}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.1185682326621946}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 7.270693512304249}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 11.0738255033557}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 10.290827740492167}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 8.612975391498878}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 13.19910514541387}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.606263982102905}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.342281879194629}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 9.060402684563762}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.9082774049217}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.36241610738255}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 8.501118568232664}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.243847874720355}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.243847874720355}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.36241610738255}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.36241610738255}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.697986577181204}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 10.402684563758392}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.718120805369126}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 7.606263982102905}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 7.270693512304249}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 7.606263982102905}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 7.270693512304249}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 7.606263982102905}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 7.270693512304249}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 7.606263982102905}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 2.9082774049217}, {"Architecture": "GPTJForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.2237136465324418}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 0.5592841163310973}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 2.572706935123044}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 7.38255033557047}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 6.375838926174497}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 13.646532438478744}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 12.192393736017896}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 5.92841163310962}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 2.684563758389265}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 10.626398210290828}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 7.494407158836691}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 3.5794183445190177}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 2.2371364653243813}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 6.487695749440718}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 7.046979865771815}, {"Architecture": "Qwen2MoeForCausalLM", "Task": "GPQA", "Score": 1.230425055928408}, {"Architecture": "Qwen2MoeForCausalLM", "Task": "GPQA", "Score": 3.243847874720355}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 0.7829977628635317}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 1.9015659955257265}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 1.5659955257270708}, {"Architecture": "Qwen2MoeForCausalLM", "Task": "GPQA", "Score": 7.494407158836691}, {"Architecture": "Qwen2MoeForCausalLM", "Task": "GPQA", "Score": 10.850111856823268}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 19.239373601789712}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 16.33109619686801}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 7.270693512304249}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 6.375838926174497}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 15.771812080536916}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 1.789709172259505}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 1.0067114093959737}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 4.697986577181204}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 0.7829977628635317}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 17.561521252796418}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 9.61968680089485}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 21.588366890380318}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 11.74496644295302}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 6.375838926174497}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 3.0201342281879207}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 20.69351230425056}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 17.4496644295302}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 9.955257270693512}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 5.480984340044745}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 1.230425055928408}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 3.803131991051453}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 10.850111856823268}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 5.8165548098434}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 1.5659955257270708}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "LlamaForRewardModelWithGating", "Task": "GPQA", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.4742729306487705}, {"Architecture": "RwkvForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 5.257270693512303}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 0.8948545861297527}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.138702460850116}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.572706935123044}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.4541387024608574}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 2.460850111856823}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 0.4474272930648763}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 8.501118568232664}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 3.691275167785232}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.789709172259505}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 4.4742729306487705}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 2.684563758389265}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.033557046979867}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 6.152125279642054}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 5.369127516778524}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.592841163310966}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 10.850111856823268}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 10.850111856823268}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.823266219239373}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 8.05369127516779}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.8948545861297527}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 3.691275167785232}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 3.803131991051453}, {"Architecture": "GemmaForCausalLM", "Task": "GPQA", "Score": 3.467561521252797}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 6.487695749440718}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.1118568232662209}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.243847874720355}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.230425055928408}, {"Architecture": "?", "Task": "GPQA", "Score": 11.297539149888143}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 4.138702460850116}, {"Architecture": "GemmaForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.829977628635347}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.033557046979867}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 17.561521252796418}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 17.561521252796418}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 10.626398210290828}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 1.0067114093959737}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.230425055928408}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.921700223713646}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.697986577181204}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 5.369127516778524}, {"Architecture": "Phi3ForCausalLM", "Task": "GPQA", "Score": 10.738255033557047}, {"Architecture": "ChatGLMModelM", "Task": "GPQA", "Score": 8.83668903803132}, {"Architecture": "ChatGLMModelM", "Task": "GPQA", "Score": 8.501118568232664}, {"Architecture": "ChatGLMModel", "Task": "GPQA", "Score": 7.158836689038028}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.026845637583895}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 6.375838926174497}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.467561521252797}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.342281879194629}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.243847874720355}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 2.572706935123044}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.026845637583895}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 8.05369127516779}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 5.480984340044745}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 12.527964205816552}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.36241610738255}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 9.731543624161072}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 10.290827740492167}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.941834451901568}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 7.829977628635347}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 11.521252796420578}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 11.297539149888143}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 11.85682326621924}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.348993288590602}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.2371364653243813}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.0134228187919474}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.0134228187919474}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.138702460850116}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.4742729306487705}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 5.145413870246088}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 3.355704697986576}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.7829977628635317}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 18.008948545861294}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 10.402684563758392}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.829977628635347}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 12.192393736017896}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.369127516778524}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 2.796420581655479}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 3.0201342281879207}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 6.711409395973152}, {"Architecture": "GemmaForCausalLM", "Task": "GPQA", "Score": 0.8948545861297527}, {"Architecture": "GemmaForCausalLM", "Task": "GPQA", "Score": 4.809843400447425}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 6.375838926174497}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 7.941834451901568}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 11.297539149888143}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.38255033557047}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 3.0201342281879207}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 10.290827740492167}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.796420581655479}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.796420581655479}, {"Architecture": "?", "Task": "GPQA", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 13.982102908277405}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 10.738255033557047}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.158836689038028}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.809843400447425}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.033557046979867}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.0201342281879207}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.145413870246088}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.257270693512303}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 8.948545861297541}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.7046979865771785}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.5659955257270708}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.684563758389265}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.4742729306487705}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 5.480984340044745}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 11.297539149888143}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.250559284116329}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.250559284116329}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.1319910514541416}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 6.599552572706939}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.1185682326621946}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 8.165548098434002}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.230425055928408}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.45413870246085}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.1252796420581683}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 9.395973154362418}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 6.375838926174497}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 11.521252796420578}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 10.17897091722595}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.9015659955257265}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 9.843400447427292}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.606263982102905}, {"Architecture": "Phi3ForCausalLM", "Task": "GPQA", "Score": 10.17897091722595}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 10.738255033557047}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 0.7829977628635317}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 3.803131991051453}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 2.2371364653243813}, {"Architecture": "Qwen2MoeForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 5.033557046979867}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.033557046979867}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.1185682326621946}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 9.731543624161072}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 18.791946308724835}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 4.4742729306487705}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 10.626398210290828}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 9.843400447427292}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.152125279642054}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 6.823266219239373}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 14.87695749440716}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 5.7046979865771785}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.941834451901568}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.8165548098434}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.2371364653243813}, {"Architecture": "?", "Task": "GPQA", "Score": 9.284116331096197}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 10.96196868008949}, {"Architecture": "JambaForCausalLM", "Task": "GPQA", "Score": 2.460850111856823}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 8.83668903803132}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 6.711409395973152}, {"Architecture": "?", "Task": "GPQA", "Score": 4.809843400447425}, {"Architecture": "OlmoForCausalLM", "Task": "GPQA", "Score": 1.5659955257270708}, {"Architecture": "OlmoForCausalLM", "Task": "GPQA", "Score": 2.796420581655479}, {"Architecture": "OlmoForCausalLM", "Task": "GPQA", "Score": 3.0201342281879207}, {"Architecture": "OlmoeForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "OlmoeForCausalLM", "Task": "GPQA", "Score": 2.348993288590602}, {"Architecture": "Phi3ForCausalLM", "Task": "GPQA", "Score": 10.067114093959727}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 6.487695749440718}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.92841163310962}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.809843400447425}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 10.96196868008949}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 5.92841163310962}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 6.375838926174497}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 4.586129753914992}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 4.586129753914992}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.36241610738255}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 3.5794183445190177}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 4.809843400447425}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 4.36241610738255}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 3.9149888143176734}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 3.691275167785232}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 3.243847874720355}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 3.803131991051453}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 5.145413870246088}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 4.026845637583895}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.36241610738255}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 4.026845637583895}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 1.230425055928408}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.36241610738255}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 2.796420581655479}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.697986577181204}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.586129753914992}, {"Architecture": "Phi3ForCausalLM", "Task": "GPQA", "Score": 12.304250559284116}, {"Architecture": "Phi3ForCausalLM", "Task": "GPQA", "Score": 11.74496644295302}, {"Architecture": "Phi3ForCausalLM", "Task": "GPQA", "Score": 5.480984340044745}, {"Architecture": "Phi3ForCausalLM", "Task": "GPQA", "Score": 4.697986577181204}, {"Architecture": "Phi3ForCausalLM", "Task": "GPQA", "Score": 13.422818791946312}, {"Architecture": "Phi3ForCausalLM", "Task": "GPQA", "Score": 10.738255033557047}, {"Architecture": "Phi3ForCausalLM", "Task": "GPQA", "Score": 12.192393736017896}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 9.955257270693512}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 9.284116331096197}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 5.145413870246088}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.026845637583895}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 5.257270693512303}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 7.158836689038028}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.026845637583895}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.243847874720355}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 14.093959731543624}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.36241610738255}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 14.429530201342288}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 15.212527964205815}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 4.138702460850116}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.138702460850116}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.494407158836691}, {"Architecture": "OlmoeForCausalLM", "Task": "GPQA", "Score": 1.1185682326621946}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.92841163310962}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 17.561521252796418}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 18.791946308724835}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 16.21923937360179}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 3.1319910514541416}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.3355704697986553}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.1185682326621946}, {"Architecture": "GemmaForCausalLM", "Task": "GPQA", "Score": 1.5659955257270708}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 18.791946308724835}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 5.480984340044745}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 18.12080536912752}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 5.8165548098434}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 14.093959731543624}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 14.76510067114094}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 12.751677852348994}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 10.514541387024613}, {"Architecture": "OpenLMModel", "Task": "GPQA", "Score": 8.7248322147651}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 18.008948545861294}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 7.606263982102905}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 7.494407158836691}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.494407158836691}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.599552572706939}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 17.897091722595075}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 3.691275167785232}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 5.257270693512303}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 7.829977628635347}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.2371364653243813}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.592841163310966}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.921700223713646}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 7.606263982102905}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 2.684563758389265}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 7.158836689038028}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.138702460850116}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 7.158836689038028}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.36241610738255}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 3.803131991051453}, {"Architecture": "GemmaForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 5.92841163310962}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 6.263982102908276}, {"Architecture": "Starcoder2ForCausalLM", "Task": "GPQA", "Score": 3.1319910514541416}, {"Architecture": "Starcoder2ForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "Starcoder2ForCausalLM", "Task": "GPQA", "Score": 0.2237136465324418}, {"Architecture": "BloomForCausalLM", "Task": "GPQA", "Score": 1.230425055928408}, {"Architecture": "BloomForCausalLM", "Task": "GPQA", "Score": 1.1185682326621946}, {"Architecture": "BloomForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "BloomForCausalLM", "Task": "GPQA", "Score": 1.5659955257270708}, {"Architecture": "BloomForCausalLM", "Task": "GPQA", "Score": 1.9015659955257265}, {"Architecture": "?", "Task": "GPQA", "Score": 15.548098434004473}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.921700223713646}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.040268456375841}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.829977628635347}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 8.389261744966444}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.592841163310966}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.9015659955257265}, {"Architecture": "?", "Task": "GPQA", "Score": 5.7046979865771785}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 12.639821029082771}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 12.080536912751676}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.1252796420581683}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.0201342281879207}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.921700223713646}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 3.5794183445190177}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 19.12751677852349}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 11.74496644295302}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 9.61968680089485}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.921700223713646}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.829977628635347}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 12.416107382550338}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 11.74496644295302}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 10.290827740492167}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 10.402684563758392}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 10.514541387024613}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 15.99552572706935}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 5.369127516778524}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 12.416107382550338}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.697986577181204}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 8.7248322147651}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 4.586129753914992}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.789709172259505}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 11.0738255033557}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.36241610738255}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.5794183445190177}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.92841163310962}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.487695749440718}, {"Architecture": "DbrxForCausalLM", "Task": "GPQA", "Score": 12.192393736017896}, {"Architecture": "GPTJForCausalLM", "Task": "GPQA", "Score": 1.9015659955257265}, {"Architecture": "GPTNeoXForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "GPTNeoXForCausalLM", "Task": "GPQA", "Score": 1.45413870246085}, {"Architecture": "GPTNeoXForCausalLM", "Task": "GPQA", "Score": 2.460850111856823}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.3355704697986553}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.606263982102905}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 8.83668903803132}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.1319910514541416}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.1252796420581683}, {"Architecture": "DeepseekForCausalLM", "Task": "GPQA", "Score": 0.5592841163310973}, {"Architecture": "DeepseekForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 20.02237136465324}, {"Architecture": "?", "Task": "GPQA", "Score": 1.0067114093959737}, {"Architecture": "?", "Task": "GPQA", "Score": 1.45413870246085}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.5659955257270708}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 17.897091722595075}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 5.592841163310966}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 7.046979865771815}, {"Architecture": "GPT2LMHeadModel", "Task": "GPQA", "Score": 1.230425055928408}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 10.067114093959727}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 11.409395973154364}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.480984340044745}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.250559284116329}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 6.152125279642054}, {"Architecture": "Phi3ForCausalLM", "Task": "GPQA", "Score": 10.402684563758392}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.0067114093959737}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.45413870246085}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.257270693512303}, {"Architecture": "?", "Task": "GPQA", "Score": 2.348993288590602}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 16.554809843400445}, {"Architecture": "Phi3ForCausalLM", "Task": "GPQA", "Score": 13.982102908277405}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 17.897091722595075}, {"Architecture": "?", "Task": "GPQA", "Score": 17.225950782997764}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.921700223713646}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.5592841163310973}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.684563758389265}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.796420581655479}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.6778523489932915}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.5659955257270708}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 4.809843400447425}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 11.6331096196868}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 10.514541387024613}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 9.060402684563762}, {"Architecture": "StableLmForCausalLM", "Task": "GPQA", "Score": 2.2371364653243813}, {"Architecture": "OPTForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "OPTForCausalLM", "Task": "GPQA", "Score": 2.572706935123044}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.467561521252797}, {"Architecture": "?", "Task": "GPQA", "Score": 6.263982102908276}, {"Architecture": "Phi3ForCausalLM", "Task": "GPQA", "Score": 8.948545861297541}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.257270693512303}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 8.948545861297541}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.586129753914992}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.935123042505594}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 6.152125279642054}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 6.375838926174497}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.145413870246088}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 2.9082774049217}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 3.467561521252797}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.586129753914992}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 14.205816554809845}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.480984340044745}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.697986577181204}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.145413870246088}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.4474272930648763}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.586129753914992}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.2371364653243813}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 12.863534675615217}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 10.290827740492167}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.1185682326621946}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 8.612975391498878}, {"Architecture": "GemmaForCausalLM", "Task": "GPQA", "Score": 2.0134228187919474}, {"Architecture": "T5ForConditionalGeneration", "Task": "GPQA", "Score": 0.0}, {"Architecture": "T5ForConditionalGeneration", "Task": "GPQA", "Score": 0.1118568232662209}, {"Architecture": "T5ForConditionalGeneration", "Task": "GPQA", "Score": 1.45413870246085}, {"Architecture": "T5ForConditionalGeneration", "Task": "GPQA", "Score": 0.3355704697986553}, {"Architecture": "T5ForConditionalGeneration", "Task": "GPQA", "Score": 0.0}, {"Architecture": "T5ForConditionalGeneration", "Task": "GPQA", "Score": 2.684563758389265}, {"Architecture": "T5ForConditionalGeneration", "Task": "GPQA", "Score": 5.033557046979867}, {"Architecture": "GemmaForCausalLM", "Task": "GPQA", "Score": 2.572706935123044}, {"Architecture": "GemmaForCausalLM", "Task": "GPQA", "Score": 5.8165548098434}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 13.422818791946312}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 16.666666666666664}, {"Architecture": "InternLM2ForCausalLM", "Task": "GPQA", "Score": 1.6778523489932915}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 1.6778523489932915}, {"Architecture": "InternLM2ForCausalLM", "Task": "GPQA", "Score": 3.243847874720355}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 4.697986577181204}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 10.514541387024613}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 14.76510067114094}, {"Architecture": "GemmaForCausalLM", "Task": "GPQA", "Score": 0.6711409395973182}, {"Architecture": "GemmaForCausalLM", "Task": "GPQA", "Score": 3.803131991051453}, {"Architecture": "GemmaForCausalLM", "Task": "GPQA", "Score": 4.921700223713646}, {"Architecture": "GemmaForCausalLM", "Task": "GPQA", "Score": 4.586129753914992}, {"Architecture": "MT5ForConditionalGeneration", "Task": "GPQA", "Score": 0.0}, {"Architecture": "MT5ForConditionalGeneration", "Task": "GPQA", "Score": 0.0}, {"Architecture": "MT5ForConditionalGeneration", "Task": "GPQA", "Score": 1.9015659955257265}, {"Architecture": "T5ForConditionalGeneration", "Task": "GPQA", "Score": 0.0}, {"Architecture": "RecurrentGemmaForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "RecurrentGemmaForCausalLM", "Task": "GPQA", "Score": 0.4474272930648763}, {"Architecture": "RecurrentGemmaForCausalLM", "Task": "GPQA", "Score": 4.697986577181204}, {"Architecture": "RecurrentGemmaForCausalLM", "Task": "GPQA", "Score": 2.684563758389265}, {"Architecture": "SwitchTransformersForConditionalGeneration", "Task": "GPQA", "Score": 0.0}, {"Architecture": "UMT5ForConditionalGeneration", "Task": "GPQA", "Score": 0.5592841163310973}, {"Architecture": "GPT2LMHeadModel", "Task": "GPQA", "Score": 1.1185682326621946}, {"Architecture": "GPT2LMHeadModel", "Task": "GPQA", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.691275167785232}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.369127516778524}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.6778523489932915}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 8.501118568232664}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 12.863534675615217}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.935123042505594}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.599552572706939}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.599552572706939}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.040268456375841}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.6778523489932915}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.480984340044745}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.342281879194629}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "?", "Task": "GPQA", "Score": 1.0067114093959737}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.7046979865771785}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.369127516778524}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.691275167785232}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 9.61968680089485}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.6711409395973182}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.467561521252797}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.3355704697986553}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 8.7248322147651}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 7.829977628635347}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.92841163310962}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.9082774049217}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.829977628635347}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 7.158836689038028}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 6.263982102908276}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.697986577181204}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 3.691275167785232}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 3.9149888143176734}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.250559284116329}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 5.033557046979867}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 6.040268456375841}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.697986577181204}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 1.5659955257270708}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 2.460850111856823}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 3.691275167785232}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 3.5794183445190177}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 5.257270693512303}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 5.369127516778524}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 3.9149888143176734}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.697986577181204}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 5.92841163310962}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 5.480984340044745}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 3.467561521252797}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.4742729306487705}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.586129753914992}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 12.192393736017896}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 6.823266219239373}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 0.8948545861297527}, {"Architecture": "InternLM2ForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "InternLM2ForCausalLM", "Task": "GPQA", "Score": 2.1252796420581683}, {"Architecture": "InternLM2ForCausalLM", "Task": "GPQA", "Score": 5.369127516778524}, {"Architecture": "InternLM2ForCausalLM", "Task": "GPQA", "Score": 9.50782997762864}, {"Architecture": "InternLM2ForCausalLM", "Task": "GPQA", "Score": 10.626398210290828}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 5.145413870246088}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.38255033557047}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.046979865771815}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.270693512304249}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 11.85682326621924}, {"Architecture": "GPTNeoXForCausalLM", "Task": "GPQA", "Score": 1.230425055928408}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.1319910514541416}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.494407158836691}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 7.718120805369126}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 9.61968680089485}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.823266219239373}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 8.277404921700223}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.829977628635347}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.935123042505594}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.606263982102905}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.369127516778524}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.718120805369126}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.92841163310962}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.718120805369126}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 8.05369127516779}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.711409395973152}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.494407158836691}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.270693512304249}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.263982102908276}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.040268456375841}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.599552572706939}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.487695749440718}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.711409395973152}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.263982102908276}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.152125279642054}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.9082774049217}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.263982102908276}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.158836689038028}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.718120805369126}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.040268456375841}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.145413870246088}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.152125279642054}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.270693512304249}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.941834451901568}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.599552572706939}, {"Architecture": "Phi3ForCausalLM", "Task": "GPQA", "Score": 12.192393736017896}, {"Architecture": "Phi3ForCausalLM", "Task": "GPQA", "Score": 10.067114093959727}, {"Architecture": "Phi3ForCausalLM", "Task": "GPQA", "Score": 9.61968680089485}, {"Architecture": "Phi3ForCausalLM", "Task": "GPQA", "Score": 8.7248322147651}, {"Architecture": "Phi3ForCausalLM", "Task": "GPQA", "Score": 11.85682326621924}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 4.809843400447425}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 4.586129753914992}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.809843400447425}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.45413870246085}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.494407158836691}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 1.9015659955257265}, {"Architecture": "?", "Task": "GPQA", "Score": 2.684563758389265}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 2.0134228187919474}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.138702460850116}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.1319910514541416}, {"Architecture": "?", "Task": "GPQA", "Score": 0.0}, {"Architecture": "?", "Task": "GPQA", "Score": 8.277404921700223}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.7046979865771785}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 11.297539149888143}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 11.409395973154364}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 11.85682326621924}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 12.304250559284116}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 11.968680089485462}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 11.85682326621924}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 11.521252796420578}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 11.0738255033557}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 10.402684563758392}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 10.402684563758392}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.369127516778524}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.145413870246088}, {"Architecture": "Phi3ForCausalLM", "Task": "GPQA", "Score": 10.850111856823268}, {"Architecture": "Phi3ForCausalLM", "Task": "GPQA", "Score": 11.409395973154364}, {"Architecture": "Phi3ForCausalLM", "Task": "GPQA", "Score": 10.626398210290828}, {"Architecture": "Phi3ForCausalLM", "Task": "GPQA", "Score": 9.61968680089485}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.4742729306487705}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.230425055928408}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.0201342281879207}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.0201342281879207}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 2.2371364653243813}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 2.572706935123044}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.348993288590602}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.1185682326621946}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.0201342281879207}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.8165548098434}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 6.040268456375841}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 3.0201342281879207}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.45413870246085}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.046979865771815}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.250559284116329}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.230425055928408}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.257270693512303}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.45413870246085}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 11.409395973154364}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 6.263982102908276}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.691275167785232}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.809843400447425}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 7.270693512304249}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.138702460850116}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.9015659955257265}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.046979865771815}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.4474272930648763}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.2371364653243813}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.355704697986576}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.348993288590602}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.803131991051453}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 19.686800894854585}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.921700223713646}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.38255033557047}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.230425055928408}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.7046979865771785}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 18.34451901565996}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 14.205816554809845}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.152125279642054}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.348993288590602}, {"Architecture": "GPT2LMHeadModel", "Task": "GPQA", "Score": 0.5592841163310973}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.026845637583895}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.45413870246085}, {"Architecture": "Phi3ForCausalLM", "Task": "GPQA", "Score": 11.521252796420578}, {"Architecture": "Phi3ForCausalLM", "Task": "GPQA", "Score": 11.521252796420578}, {"Architecture": "Phi3ForCausalLM", "Task": "GPQA", "Score": 9.060402684563762}, {"Architecture": "Phi3ForCausalLM", "Task": "GPQA", "Score": 9.284116331096197}, {"Architecture": "Phi3ForCausalLM", "Task": "GPQA", "Score": 10.96196868008949}, {"Architecture": "Phi3SmallForCausalLM", "Task": "GPQA", "Score": 8.948545861297541}, {"Architecture": "Phi3SmallForCausalLM", "Task": "GPQA", "Score": 8.277404921700223}, {"Architecture": "Phi3ForCausalLM", "Task": "GPQA", "Score": 14.093959731543624}, {"Architecture": "Phi3ForCausalLM", "Task": "GPQA", "Score": 11.968680089485462}, {"Architecture": "PhiForCausalLM", "Task": "GPQA", "Score": 2.0134228187919474}, {"Architecture": "PhiForCausalLM", "Task": "GPQA", "Score": 2.348993288590602}, {"Architecture": "PhiForCausalLM", "Task": "GPQA", "Score": 2.9082774049217}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 18.34451901565996}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.9082774049217}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 2.796420581655479}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 0.1118568232662209}, {"Architecture": "Phi3ForCausalLM", "Task": "GPQA", "Score": 7.718120805369126}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 13.422818791946312}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 8.612975391498878}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 6.711409395973152}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 7.718120805369126}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 4.4742729306487705}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 5.592841163310966}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 17.00223713646532}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 6.487695749440718}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 3.467561521252797}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 3.9149888143176734}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 5.592841163310966}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 5.592841163310966}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 5.8165548098434}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 5.369127516778524}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 9.843400447427292}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 11.0738255033557}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 16.442953020134222}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 16.778523489932887}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 7.046979865771815}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 8.501118568232664}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 9.395973154362418}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 4.586129753914992}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 2.684563758389265}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 4.697986577181204}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 6.935123042505594}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 8.612975391498878}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.697986577181204}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.592841163310966}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.718120805369126}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.369127516778524}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.8948545861297527}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.250559284116329}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.494407158836691}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.046979865771815}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.9149888143176734}, {"Architecture": "PhiForCausalLM", "Task": "GPQA", "Score": 2.0134228187919474}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.809843400447425}, {"Architecture": "?", "Task": "GPQA", "Score": 0.0}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 2.684563758389265}, {"Architecture": "MPTForCausalLM", "Task": "GPQA", "Score": 1.342281879194629}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.921700223713646}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 6.823266219239373}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 7.158836689038028}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 10.626398210290828}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 11.6331096196868}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 5.257270693512303}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 11.185682326621922}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 9.172259507829976}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 8.389261744966444}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 8.83668903803132}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 2.796420581655479}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 12.416107382550338}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 12.863534675615217}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 10.96196868008949}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 3.0201342281879207}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 11.74496644295302}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.823266219239373}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.697986577181204}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.697986577181204}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 8.7248322147651}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 8.7248322147651}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 7.606263982102905}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 3.691275167785232}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 8.612975391498878}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 8.83668903803132}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 8.948545861297541}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 5.7046979865771785}, {"Architecture": "GPT2LMHeadModel", "Task": "GPQA", "Score": 2.0134228187919545}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.1319910514541416}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.480984340044745}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.7046979865771785}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.7046979865771785}, {"Architecture": "PhiForCausalLM", "Task": "GPQA", "Score": 0.2237136465324418}, {"Architecture": "PhiForCausalLM", "Task": "GPQA", "Score": 1.0067114093959737}, {"Architecture": "PhiForCausalLM", "Task": "GPQA", "Score": 1.0067114093959737}, {"Architecture": "PhiForCausalLM", "Task": "GPQA", "Score": 1.230425055928408}, {"Architecture": "PhiForCausalLM", "Task": "GPQA", "Score": 1.9015659955257265}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.606263982102905}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.369127516778524}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.803131991051453}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.467561521252797}, {"Architecture": "GemmaForCausalLM", "Task": "GPQA", "Score": 1.9015659955257265}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 20.46979865771812}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 14.5413870246085}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.026845637583895}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 3.1319910514541416}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 1.230425055928408}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 7.046979865771815}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 6.040268456375841}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 3.803131991051453}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 3.1319910514541416}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.789709172259505}, {"Architecture": "NemotronForCausalLM", "Task": "GPQA", "Score": 2.572706935123044}, {"Architecture": "NemotronForCausalLM", "Task": "GPQA", "Score": 3.1319910514541416}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 10.067114093959727}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 5.033557046979867}, {"Architecture": "NemotronForCausalLM", "Task": "GPQA", "Score": 4.026845637583895}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.250559284116329}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 1.230425055928408}, {"Architecture": "?", "Task": "GPQA", "Score": 6.711409395973152}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.8948545861297527}, {"Architecture": "GPT2LMHeadModel", "Task": "GPQA", "Score": 1.1185682326621946}, {"Architecture": "GPT2LMHeadModel", "Task": "GPQA", "Score": 1.1185682326621946}, {"Architecture": "GPT2LMHeadModel", "Task": "GPQA", "Score": 1.230425055928408}, {"Architecture": "GPT2LMHeadModel", "Task": "GPQA", "Score": 1.6778523489932915}, {"Architecture": "GPT2LMHeadModel", "Task": "GPQA", "Score": 1.1185682326621946}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 7.718120805369126}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 6.823266219239373}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 9.060402684563762}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 6.487695749440718}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.684563758389265}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.9015659955257265}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.257270693512303}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 12.975391498881436}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 10.850111856823268}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 12.192393736017896}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 13.19910514541387}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 14.5413870246085}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.599552572706939}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.4742729306487705}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.0134228187919474}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 9.060402684563762}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.921700223713646}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.243847874720355}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.586129753914992}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.823266219239373}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 18.008948545861294}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 6.152125279642054}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 18.232662192393736}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.348993288590602}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.2371364653243813}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.809843400447425}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.9082774049217}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.4742729306487705}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.243847874720355}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 8.05369127516779}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.375838926174497}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.38255033557047}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 8.501118568232664}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.494407158836691}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.38255033557047}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.921700223713646}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.145413870246088}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.342281879194629}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.45413870246085}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.9082774049217}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.921700223713646}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.467561521252797}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.342281879194629}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.1185682326621946}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.4742729306487705}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.36241610738255}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.7046979865771785}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.026845637583895}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.342281879194629}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.809843400447425}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.342281879194629}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.8165548098434}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.823266219239373}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 5.592841163310966}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 3.0201342281879207}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.026845637583895}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 5.369127516778524}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 3.691275167785232}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 5.369127516778524}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 5.592841163310966}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.4742729306487705}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 2.1252796420581683}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 2.460850111856823}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 3.1319910514541416}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 3.1319910514541416}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 3.243847874720355}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.026845637583895}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 3.467561521252797}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 3.803131991051453}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.355704697986576}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 11.409395973154364}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 11.409395973154364}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.4742729306487705}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 2.0134228187919474}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 3.467561521252797}, {"Architecture": "PhiForCausalLM", "Task": "GPQA", "Score": 1.342281879194629}, {"Architecture": "PhiForCausalLM", "Task": "GPQA", "Score": 2.684563758389265}, {"Architecture": "PhiForCausalLM", "Task": "GPQA", "Score": 3.243847874720355}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.3355704697986553}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 10.738255033557047}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 10.626398210290828}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 11.85682326621924}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 10.514541387024613}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 10.738255033557047}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 9.843400447427292}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 11.6331096196868}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 12.080536912751676}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.599552572706939}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 7.941834451901568}, {"Architecture": "AriaForConditionalGeneration", "Task": "GPQA", "Score": 14.988814317673372}, {"Architecture": "PhiForCausalLM", "Task": "GPQA", "Score": 1.5659955257270708}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.355704697986576}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.467561521252797}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 8.277404921700223}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 2.2371364653243813}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 5.145413870246088}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 16.21923937360179}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 19.57494407158837}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 7.718120805369126}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 19.798657718120808}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 9.060402684563762}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 3.243847874720355}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 17.00223713646532}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 1.6778523489932915}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 6.823266219239373}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.5794183445190177}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.823266219239373}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.718120805369126}, {"Architecture": "?", "Task": "GPQA", "Score": 1.230425055928408}, {"Architecture": "?", "Task": "GPQA", "Score": 10.514541387024613}, {"Architecture": "?", "Task": "GPQA", "Score": 0.8948545861297527}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 3.5794183445190177}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.460850111856823}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.0134228187919474}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.467561521252797}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 9.060402684563762}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 1.342281879194629}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.026845637583895}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 5.7046979865771785}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 1.5659955257270708}, {"Architecture": "?", "Task": "GPQA", "Score": 7.829977628635347}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.809843400447425}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 1.5659955257270708}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 3.467561521252797}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.026845637583895}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 3.467561521252797}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 3.5794183445190177}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 8.7248322147651}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 7.606263982102905}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 9.955257270693512}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 9.843400447427292}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 15.212527964205815}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 8.83668903803132}, {"Architecture": "StableLmForCausalLM", "Task": "GPQA", "Score": 3.803131991051453}, {"Architecture": "StableLmForCausalLM", "Task": "GPQA", "Score": 2.2371364653243813}, {"Architecture": "StableLmForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "StableLmForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "StableLmForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "StableLmForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "StableLmForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.823266219239373}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.250559284116329}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 8.501118568232664}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 8.05369127516779}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 14.988814317673372}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 14.205816554809845}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.921700223713646}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.0201342281879207}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.4742729306487705}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.4742729306487705}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.572706935123044}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.789709172259505}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.823266219239373}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 6.599552572706939}, {"Architecture": "?", "Task": "GPQA", "Score": 5.145413870246088}, {"Architecture": "?", "Task": "GPQA", "Score": 2.1252796420581683}, {"Architecture": "?", "Task": "GPQA", "Score": 6.711409395973152}, {"Architecture": "?", "Task": "GPQA", "Score": 4.809843400447425}, {"Architecture": "?", "Task": "GPQA", "Score": 8.501118568232664}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.467561521252797}, {"Architecture": "?", "Task": "GPQA", "Score": 3.355704697986576}, {"Architecture": "?", "Task": "GPQA", "Score": 5.480984340044745}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 2.684563758389265}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 5.480984340044745}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 7.941834451901568}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 4.138702460850116}, {"Architecture": "FalconForCausalLM", "Task": "GPQA", "Score": 2.796420581655479}, {"Architecture": "FalconForCausalLM", "Task": "GPQA", "Score": 3.1319910514541416}, {"Architecture": "FalconForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "FalconForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "FalconForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "FalconMambaForCausalLM", "Task": "GPQA", "Score": 8.05369127516779}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.355704697986576}, {"Architecture": "GPTJForCausalLM", "Task": "GPQA", "Score": 1.45413870246085}, {"Architecture": "GPTNeoXForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.2237136465324418}, {"Architecture": "GPTNeoXForCausalLM", "Task": "GPQA", "Score": 0.6711409395973182}, {"Architecture": "GPTNeoXForCausalLM", "Task": "GPQA", "Score": 0.3355704697986553}, {"Architecture": "GPTNeoXForCausalLM", "Task": "GPQA", "Score": 0.1118568232662209}, {"Architecture": "GPTNeoXForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "GPTNeoXForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "GPTNeoXForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.257270693512303}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 7.829977628635347}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.45413870246085}, {"Architecture": "SolarForCausalLM", "Task": "GPQA", "Score": 16.10738255033557}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.586129753914992}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.572706935123052}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.9015659955257265}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.250559284116329}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 2.684563758389265}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.4742729306487705}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 6.711409395973152}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.92841163310962}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.257270693512303}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 10.514541387024613}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 15.212527964205815}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 10.402684563758392}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.152125279642054}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.599552572706939}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 6.935123042505594}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 6.599552572706939}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.263982102908276}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.243847874720355}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 12.416107382550338}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 6.935123042505594}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 3.5794183445190177}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.487695749440718}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 4.921700223713646}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 1.789709172259505}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 7.829977628635347}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.45413870246085}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.6711409395973182}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.92841163310962}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.789709172259505}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 4.36241610738255}, {"Architecture": "Qwen2ForCausalLM", "Task": "GPQA", "Score": 2.0134228187919474}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 1.9015659955257265}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.243847874720355}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.1185682326621946}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.45413870246085}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.0067114093959737}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 0.3355704697986553}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.935123042505594}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 5.145413870246088}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.9149888143176734}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 8.389261744966444}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.230425055928408}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.342281879194629}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.230425055928408}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.230425055928408}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.230425055928408}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.1185682326621946}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.230425055928408}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.342281879194629}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.230425055928408}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.230425055928408}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.230425055928408}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.230425055928408}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.230425055928408}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.1185682326621946}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.45413870246085}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.230425055928408}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 5.480984340044745}, {"Architecture": "GemmaForCausalLM", "Task": "GPQA", "Score": 3.467561521252797}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 3.9149888143176734}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 3.467561521252797}, {"Architecture": "MistralForCausalLM", "Task": "GPQA", "Score": 0.4474272930648763}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 7.270693512304249}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 7.718120805369126}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.230425055928408}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.342281879194629}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.230425055928408}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.230425055928408}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.230425055928408}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.342281879194629}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.230425055928408}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.230425055928408}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 1.5659955257270708}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.935123042505594}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 3.355704697986576}, {"Architecture": "LlamaForCausalLM", "Task": "GPQA", "Score": 6.823266219239373}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 12.751677852348994}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 13.31096196868009}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 12.416107382550338}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 13.31096196868009}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 13.087248322147648}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 12.192393736017896}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 13.534675615212524}, {"Architecture": "Gemma2ForCausalLM", "Task": "GPQA", "Score": 12.527964205816552}, {"Architecture": "MixtralForCausalLM", "Task": "GPQA", "Score": 6.487695749440718}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 5.871874999999999}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 11.217187500000003}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 14.07786458333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 13.058072916666664}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 13.73671875}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 13.309114583333336}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 14.704947916666669}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 12.030989583333332}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 10.82682291666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 12.838281249999996}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 10.03828125}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 9.648437500000004}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 9.414843749999998}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.363802083333338}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 7.044270833333335}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 16.842447916666668}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.5656250000000003}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.909114583333334}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 12.109114583333332}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 7.963802083333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 17.209374999999998}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 13.554166666666667}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 13.554166666666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 0.7812499999999996}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 1.9518229166666672}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 12.430989583333334}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 1.5950520833333328}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 0.7812499999999996}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 9.046093750000004}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 8.912760416666671}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 5.165625000000001}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 0.8263020833333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 4.199218749999999}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 19.93671875}, {"Architecture": "GPT2LMHeadModel", "Task": "MUSR", "Score": 2.83828125}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 20.23880208333333}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 6.315104166666665}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 5.563802083333336}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 5.3109375000000005}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 8.124739583333334}, {"Architecture": "PhiForCausalLM", "Task": "MUSR", "Score": 9.265885416666665}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 14.713281249999996}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 3.789062500000001}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 8.350000000000001}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 5.3109375000000005}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 7.298958333333334}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.024479166666667}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 8.104947916666669}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 16.53255208333333}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 13.252083333333331}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 18.34036458333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 5.667708333333335}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 12.23828125}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 6.461718749999999}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 16.724739583333335}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 5.297135416666668}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 10.04010416666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 16.97161458333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 5.297135416666668}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 10.04010416666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.579427083333334}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 6.242447916666666}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 4.275520833333334}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 9.067708333333334}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 14.261718750000002}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 6.224479166666669}, {"Architecture": "T5ForConditionalGeneration", "Task": "MUSR", "Score": 3.718750000000001}, {"Architecture": "T5ForConditionalGeneration", "Task": "MUSR", "Score": 13.808854166666668}, {"Architecture": "T5ForConditionalGeneration", "Task": "MUSR", "Score": 11.187239583333335}, {"Architecture": "T5ForConditionalGeneration", "Task": "MUSR", "Score": 1.1067708333333328}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 9.532552083333336}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 8.930729166666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 10.628645833333335}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 9.467708333333327}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 9.532552083333336}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.3109375}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 5.550000000000002}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 11.468229166666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 6.924739583333334}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 6.7992187500000005}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 7.842447916666667}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 10.658072916666663}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 18.276041666666668}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 10.658072916666663}, {"Architecture": "CohereForCausalLM", "Task": "MUSR", "Score": 13.47369791666666}, {"Architecture": "CohereForCausalLM", "Task": "MUSR", "Score": 8.424479166666664}, {"Architecture": "CohereForCausalLM", "Task": "MUSR", "Score": 20.42317708333333}, {"Architecture": "CohereForCausalLM", "Task": "MUSR", "Score": 19.835156249999997}, {"Architecture": "CohereForCausalLM", "Task": "MUSR", "Score": 16.12890625}, {"Architecture": "GemmaForCausalLM", "Task": "MUSR", "Score": 9.834635416666668}, {"Architecture": "GemmaForCausalLM", "Task": "MUSR", "Score": 9.109114583333335}, {"Architecture": "GemmaForCausalLM", "Task": "MUSR", "Score": 12.056250000000004}, {"Architecture": "GemmaForCausalLM", "Task": "MUSR", "Score": 8.309114583333335}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 10.281510416666665}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 9.718749999999998}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 15.483854166666664}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 14.367968750000005}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 1.47734375}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 3.891145833333335}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 2.1283854166666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.014843750000002}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 5.542187500000001}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 15.31510416666667}, {"Architecture": "?", "Task": "MUSR", "Score": 10.567968750000002}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 11.972135416666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.607031250000002}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 20.527083333333334}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 11.169791666666669}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 5.712760416666669}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 9.677864583333337}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.122916666666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 7.811197916666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.755989583333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 5.740364583333334}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 6.332552083333334}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.312760416666668}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 11.26171875}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 9.624479166666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.555989583333334}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 10.314583333333331}, {"Architecture": "DeciLMForCausalLM", "Task": "MUSR", "Score": 13.0484375}, {"Architecture": "DeciLMForCausalLM", "Task": "MUSR", "Score": 5.985416666666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 9.63645833333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 1.359635416666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 0.4557291666666662}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 5.195052083333335}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 4.053906250000002}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 10.983593749999995}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 11.51692708333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 11.51692708333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 11.51692708333333}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 14.76015625}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 11.6796875}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 15.156510416666665}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 14.011197916666664}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 9.019010416666667}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 8.701302083333335}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 17.56432291666666}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 8.819010416666666}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 13.456249999999995}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 12.389583333333327}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 13.781770833333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 13.781770833333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 12.611197916666663}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 12.361979166666666}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 9.754166666666665}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.636458333333332}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 10.967968749999995}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 13.338541666666666}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 13.840624999999998}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 10.671874999999996}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 11.413020833333327}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 15.477864583333336}, {"Architecture": "GPTJForCausalLM", "Task": "MUSR", "Score": 5.252083333333334}, {"Architecture": "GPTNeoForCausalLM", "Task": "MUSR", "Score": 4.873697916666666}, {"Architecture": "GPTNeoForCausalLM", "Task": "MUSR", "Score": 2.6166666666666654}, {"Architecture": "GPTNeoForCausalLM", "Task": "MUSR", "Score": 3.5205729166666675}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MUSR", "Score": 2.816666666666666}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MUSR", "Score": 3.787239583333335}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MUSR", "Score": 10.675520833333332}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MUSR", "Score": 3.63828125}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MUSR", "Score": 3.0598958333333326}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MUSR", "Score": 3.81484375}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 10.758333333333336}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 9.081510416666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 12.313281249999996}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 5.43046875}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 5.43046875}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 6.365625000000002}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 10.897135416666666}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 13.608854166666664}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 6.599218750000001}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 13.348177083333333}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 12.85390625}, {"Architecture": "GemmaForCausalLM", "Task": "MUSR", "Score": 14.854427083333334}, {"Architecture": "?", "Task": "MUSR", "Score": 4.954166666666666}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 12.521093749999997}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 9.975781249999995}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 6.907291666666666}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 4.275520833333334}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 16.995572916666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 4.895312499999999}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.462239583333334}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 6.450260416666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 5.97578125}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.077864583333334}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 9.501302083333336}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 7.783593750000001}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 12.885677083333327}, {"Architecture": "GemmaForCausalLM", "Task": "MUSR", "Score": 10.387760416666667}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 11.264062499999996}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 11.891666666666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 13.432812500000002}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 12.034635416666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 13.685677083333337}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 6.848437499999999}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 7.854427083333334}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 10.4015625}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.454427083333332}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 9.632812500000002}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 8.96979166666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 5.013020833333332}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 10.704947916666669}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 15.348697916666667}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 14.662239583333337}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 6.683333333333335}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 2.0557291666666675}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 13.53671875}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 15.952343750000002}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.165625}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 4.640104166666668}, {"Architecture": "?", "Task": "MUSR", "Score": 11.20520833333333}, {"Architecture": "?", "Task": "MUSR", "Score": 9.428645833333327}, {"Architecture": "?", "Task": "MUSR", "Score": 5.636458333333335}, {"Architecture": "?", "Task": "MUSR", "Score": 3.9265625000000015}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 10.963802083333327}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 15.183593749999996}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 4.002864583333333}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 4.706770833333335}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 4.240104166666668}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 13.957812500000005}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 1.4401041666666683}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 6.644270833333335}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 11.673697916666669}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 5.504947916666667}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 15.053906250000004}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 12.92838541666667}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 12.165625}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 6.453906249999996}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 7.503125000000001}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 7.7343749999999964}, {"Architecture": "GemmaForCausalLM", "Task": "MUSR", "Score": 4.179427083333334}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 14.715104166666668}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 2.1283854166666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 2.0833333333333326}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 13.3421875}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.365625}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.089322916666665}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 2.897135416666666}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 2.0028645833333325}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 9.395052083333336}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 8.424479166666668}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.881510416666668}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 16.750520833333336}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 23.01953125}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 22.236979166666657}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 20.05677083333333}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 20.578125}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 6.0796875}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 6.346354166666667}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 9.616666666666667}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 13.957812500000005}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 12.338541666666671}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 13.264062499999996}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 13.813020833333328}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 10.960156250000002}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 14.12109375}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 12.29166666666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.389583333333334}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.709114583333337}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.167968750000002}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 7.087500000000001}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 9.071875000000002}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.005208333333334}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 7.805208333333336}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 7.383593750000003}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 10.74036458333333}, {"Architecture": "PhiForCausalLM", "Task": "MUSR", "Score": 1.965625}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 2.232291666666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 0.6184895833333329}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.63828125}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 17.801041666666663}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 16.993229166666666}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 17.801041666666663}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 17.830468749999998}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 1.432291666666666}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 9.95234375}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 13.058072916666664}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 9.68932291666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.65390625}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 13.160156250000004}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 13.389583333333327}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 13.056250000000004}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 14.503645833333335}, {"Architecture": "ExaoneForCausalLM", "Task": "MUSR", "Score": 3.298958333333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.550000000000004}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 16.824999999999996}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 19.625}, {"Architecture": "GemmaForCausalLM", "Task": "MUSR", "Score": 3.63828125}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 3.873697916666666}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 13.328906250000005}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 15.560156250000004}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 7.444270833333334}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 12.426822916666673}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 1.920572916666666}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 10.303125000000003}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 2.2028645833333327}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 1.1067708333333328}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 2.45390625}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 2.7890625000000004}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 2.5578125000000003}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 5.830468750000001}, {"Architecture": "Phi3ForCausalLM", "Task": "MUSR", "Score": 15.71328125}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 5.279687499999999}, {"Architecture": "?", "Task": "MUSR", "Score": 7.693489583333334}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 4.452083333333333}, {"Architecture": "Phi3ForCausalLM", "Task": "MUSR", "Score": 17.2015625}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 2.218489583333334}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 1.1518229166666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.565625000000001}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 9.399218750000005}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 6.038281250000002}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 2.432291666666666}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.4166666666666674}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 6.7757812500000005}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.073697916666669}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 5.069531250000002}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 13.755989583333331}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 14.259895833333331}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 4.898958333333336}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 2.5440104166666675}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.632291666666669}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 18.815364583333327}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 0.3968749999999998}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 1.920572916666666}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 1.920572916666666}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.7421875}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 1.8666666666666685}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.091145833333334}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 2.824479166666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.877343750000002}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 15.668229166666665}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 12.75598958333333}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 9.273697916666668}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 6.509114583333333}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 7.852083333333335}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 10.619010416666669}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 12.536718750000004}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 15.312760416666672}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 10.813020833333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 10.924739583333334}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 9.850260416666666}, {"Architecture": "Qwen2MoeForCausalLM", "Task": "MUSR", "Score": 2.010677083333334}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 13.868229166666667}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 12.0640625}, {"Architecture": "Phi3ForCausalLM", "Task": "MUSR", "Score": 8.258072916666668}, {"Architecture": "Phi3ForCausalLM", "Task": "MUSR", "Score": 9.765624999999998}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 20.15234375}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 13.795572916666666}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 13.297135416666665}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 18.99739583333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 15.30494791666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 17.06953125}, {"Architecture": "Phi3ForCausalLM", "Task": "MUSR", "Score": 7.695312500000001}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 16.516927083333332}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 13.277864583333338}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 12.016666666666673}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 16.82864583333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 12.565625000000002}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 17.736197916666658}, {"Architecture": "Phi3ForCausalLM", "Task": "MUSR", "Score": 7.754166666666667}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 11.23828125}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 13.313281249999998}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 16.999218749999997}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 13.098958333333336}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 14.426822916666667}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 34.56614583333333}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 15.791927083333334}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 16.560156250000002}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 19.93671875}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 10.440104166666668}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 12.216666666666669}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 7.565625}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 2.675520833333333}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 4.3343750000000005}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 7.205208333333334}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 13.964322916666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.675520833333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 14.979947916666662}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 13.883854166666673}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 7.04609375}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MUSR", "Score": 5.3343750000000005}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 7.718750000000001}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 9.183593750000002}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 16.860416666666666}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 11.561979166666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.891666666666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 11.070052083333328}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 21.297656250000003}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 12.32109375}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.7109375}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 5.557812500000004}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 2.6617187500000004}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.963802083333334}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 2.498958333333334}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 4.067708333333334}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 11.246614583333336}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 14.132552083333335}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.36197916666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 23.42864583333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 13.617187499999996}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 8.330729166666668}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 16.676041666666666}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 11.138541666666669}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 13.826822916666664}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 11.681510416666669}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.385416666666666}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.253906250000004}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 6.934374999999998}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 8.948177083333333}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 9.881510416666666}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 10.597395833333332}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 9.013020833333336}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.5481770833333326}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 2.734375}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 6.318750000000001}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 10.61484375}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 8.201041666666667}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 5.889322916666667}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MUSR", "Score": 2.987239583333334}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 10.346354166666664}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 5.934375000000003}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 18.23645833333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 9.81302083333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.316927083333335}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 1.2106770833333331}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 5.281510416666666}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 11.538541666666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 12.722916666666668}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 13.807031250000003}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 14.693489583333337}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 11.3421875}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 2.24609375}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 12.781770833333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.7421875}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 6.422656250000002}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 7.76979166666667}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 11.381770833333327}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.036458333333336}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 4.053906250000002}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 4.677343750000003}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 9.561979166666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.936197916666668}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 5.636458333333335}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 2.45390625}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 11.77578125}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 11.77578125}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 11.77578125}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 11.509114583333334}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 11.77578125}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 11.509114583333334}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 11.77578125}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 20.56796875}, {"Architecture": "GPTJForCausalLM", "Task": "MUSR", "Score": 3.7109375}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 0.7812499999999996}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 4.303125}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 6.063541666666667}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 3.963802083333334}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 12.179427083333335}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 13.70546875}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 16.287499999999994}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 10.464062500000002}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 13.930729166666667}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 12.040625000000004}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 10.197395833333337}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 4.8226562500000005}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 7.355989583333333}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 9.158333333333331}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 4.63828125}, {"Architecture": "Qwen2MoeForCausalLM", "Task": "MUSR", "Score": 7.967968750000003}, {"Architecture": "Qwen2MoeForCausalLM", "Task": "MUSR", "Score": 6.334375000000001}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 4.601041666666668}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 2.408854166666666}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 3.5932291666666667}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 12.026822916666667}, {"Architecture": "Qwen2MoeForCausalLM", "Task": "MUSR", "Score": 10.538541666666667}, {"Architecture": "Qwen2MoeForCausalLM", "Task": "MUSR", "Score": 14.183593749999996}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 19.728906250000005}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 17.167968749999996}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 14.322916666666666}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 7.365625}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 15.728906249999994}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 2.4166666666666683}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 2.0833333333333326}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 0.9440104166666662}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 5.265885416666666}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 3.1890625000000004}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 15.913281249999995}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 10.157812500000004}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 22.69583333333333}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 13.498958333333327}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 11.758333333333336}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 7.565625}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 19.640625}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 11.808854166666668}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 14.13671875}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 8.453906250000001}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 2.1734375000000004}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 8.608854166666667}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 16.342187499999998}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 4.995052083333334}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 2.891145833333333}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 3.3265625}, {"Architecture": "LlamaForRewardModelWithGating", "Task": "MUSR", "Score": 6.650260416666666}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 5.075520833333335}, {"Architecture": "RwkvForCausalLM", "Task": "MUSR", "Score": 7.193229166666666}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 4.659895833333335}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 5.903125}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 2.824479166666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.4539062499999997}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 7.512760416666666}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 9.742187500000002}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 5.861718749999999}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 7.26171875}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 7.7578125}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.375781250000001}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 11.493489583333336}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 10.936718750000004}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 8.577604166666665}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 8.103125000000002}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 5.550000000000002}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 11.087500000000004}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 11.087500000000004}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 14.920572916666666}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 12.247916666666669}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 12.047916666666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 5.550000000000002}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 6.453906249999996}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 4.067708333333334}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 9.038281250000004}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 9.36979166666667}, {"Architecture": "GemmaForCausalLM", "Task": "MUSR", "Score": 11.60703125}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 10.471875000000002}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 10.402864583333336}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 0.4557291666666662}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.401041666666666}, {"Architecture": "?", "Task": "MUSR", "Score": 15.146354166666663}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 8.124739583333335}, {"Architecture": "GemmaForCausalLM", "Task": "MUSR", "Score": 4.852083333333336}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 7.448437499999998}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 5.60885416666667}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 15.291666666666666}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 15.291666666666666}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 4.40703125}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 1.432291666666666}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 6.751822916666666}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 16.985937499999995}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 16.57213541666667}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 14.68385416666667}, {"Architecture": "Phi3ForCausalLM", "Task": "MUSR", "Score": 8.777604166666663}, {"Architecture": "ChatGLMModelM", "Task": "MUSR", "Score": 14.189583333333331}, {"Architecture": "ChatGLMModelM", "Task": "MUSR", "Score": 8.061718749999999}, {"Architecture": "ChatGLMModel", "Task": "MUSR", "Score": 5.232291666666668}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 10.1109375}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 5.252083333333334}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 13.60286458333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.593229166666669}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 11.1109375}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 4.985416666666668}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 11.828645833333336}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 20.940885416666664}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 11.281510416666665}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 10.146354166666669}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 10.685677083333331}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 4.306770833333336}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.979427083333333}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 19.556510416666665}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 18.74088541666666}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 4.053906250000002}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 12.214843750000002}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 10.075520833333334}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 10.942187500000005}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 11.3421875}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 2.165624999999999}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 1.995052083333335}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.0911458333333326}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 2.891145833333335}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 7.793229166666667}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 8.29713541666667}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 9.801041666666668}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 9.489322916666673}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 4.653906250000001}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 15.961979166666667}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 21.2171875}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 13.542187500000002}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 11.2796875}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 19.38541666666666}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 11.51692708333333}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 4.971614583333335}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 6.881510416666668}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 9.916927083333333}, {"Architecture": "GemmaForCausalLM", "Task": "MUSR", "Score": 3.514583333333334}, {"Architecture": "GemmaForCausalLM", "Task": "MUSR", "Score": 2.9283854166666674}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 11.31875}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 17.161979166666665}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 20.69583333333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.334374999999996}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 8.765624999999998}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 12.34453125}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.26953125}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.032291666666666}, {"Architecture": "?", "Task": "MUSR", "Score": 3.73619791666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 16.7734375}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 13.63828125}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 9.82682291666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 4.704947916666668}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 10.2171875}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 5.709114583333332}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 4.379427083333335}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 4.216666666666668}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 7.191406250000001}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 13.334895833333327}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.050260416666669}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 4.036458333333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 13.426822916666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 5.0911458333333375}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 9.44609375}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 17.009375000000002}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 19.02083333333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 11.22682291666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 13.389583333333327}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 14.0640625}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.22265625}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.601041666666662}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.5481770833333326}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 14.030468750000002}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 14.089322916666667}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 13.528906249999997}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 11.070052083333328}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 13.781770833333333}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 14.12890625}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.22265625}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 14.283854166666664}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 18.15052083333333}, {"Architecture": "Phi3ForCausalLM", "Task": "MUSR", "Score": 17.77213541666666}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 17.46640625}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 1.432291666666666}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 4.007031250000002}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 3.873697916666666}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 0.8851562499999998}, {"Architecture": "Qwen2MoeForCausalLM", "Task": "MUSR", "Score": 2.45390625}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 7.636458333333337}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 6.252083333333335}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 5.497135416666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 14.348177083333336}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 16.81119791666666}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 10.316927083333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 5.047916666666663}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.134375000000004}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 14.415364583333334}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 12.432291666666664}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 12.993229166666673}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 15.175781249999998}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 15.8640625}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 4.289322916666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 2.5716145833333326}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 9.950000000000005}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 5.104947916666667}, {"Architecture": "?", "Task": "MUSR", "Score": 9.040625}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 6.475520833333334}, {"Architecture": "JambaForCausalLM", "Task": "MUSR", "Score": 3.7109375}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 7.991406250000002}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 16.25442708333333}, {"Architecture": "?", "Task": "MUSR", "Score": 16.852604166666666}, {"Architecture": "OlmoForCausalLM", "Task": "MUSR", "Score": 9.555989583333334}, {"Architecture": "OlmoForCausalLM", "Task": "MUSR", "Score": 4.3265625}, {"Architecture": "OlmoForCausalLM", "Task": "MUSR", "Score": 2.0833333333333326}, {"Architecture": "OlmoeForCausalLM", "Task": "MUSR", "Score": 3.565625000000001}, {"Architecture": "OlmoeForCausalLM", "Task": "MUSR", "Score": 6.06953125}, {"Architecture": "Phi3ForCausalLM", "Task": "MUSR", "Score": 12.940364583333334}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 10.197395833333337}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 2.18125}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 10.187760416666666}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 12.23463541666667}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 11.805208333333333}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 13.65625}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 19.95052083333333}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 12.856249999999996}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 12.960156250000004}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 14.773958333333333}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 12.97395833333333}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 14.026822916666664}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 11.783593750000003}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 11.703124999999998}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 12.522916666666667}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 12.026822916666667}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 14.499479166666664}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 14.211197916666665}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 12.330729166666671}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 13.0328125}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 4.303125}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 12.597395833333335}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 15.409375000000002}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 11.758333333333336}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 12.60520833333333}, {"Architecture": "Phi3ForCausalLM", "Task": "MUSR", "Score": 14.360156249999998}, {"Architecture": "Phi3ForCausalLM", "Task": "MUSR", "Score": 13.2796875}, {"Architecture": "Phi3ForCausalLM", "Task": "MUSR", "Score": 6.652083333333335}, {"Architecture": "Phi3ForCausalLM", "Task": "MUSR", "Score": 8.858072916666668}, {"Architecture": "Phi3ForCausalLM", "Task": "MUSR", "Score": 16.81302083333333}, {"Architecture": "Phi3ForCausalLM", "Task": "MUSR", "Score": 16.620833333333326}, {"Architecture": "Phi3ForCausalLM", "Task": "MUSR", "Score": 14.95234375}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 15.430989583333336}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 14.840624999999994}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 1.1067708333333328}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 17.53307291666667}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 12.930729166666673}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 10.419010416666667}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 14.48984375}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 13.462239583333336}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 5.199218749999999}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 15.973958333333329}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 1.7578124999999991}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 15.778125000000005}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 15.854427083333327}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 10.842447916666664}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 12.464062500000004}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 4.036458333333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 7.149999999999999}, {"Architecture": "OlmoeForCausalLM", "Task": "MUSR", "Score": 1.47734375}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 5.7992187500000005}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 14.538541666666667}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 15.617187499999998}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 14.758333333333333}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 8.350000000000003}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 4.912760416666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 5.904947916666668}, {"Architecture": "GemmaForCausalLM", "Task": "MUSR", "Score": 4.128385416666667}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 15.617187499999998}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 11.371614583333336}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 14.181770833333331}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 9.979427083333336}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 9.916927083333327}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 6.571614583333336}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 13.236979166666666}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 15.058593749999998}, {"Architecture": "OpenLMModel", "Task": "MUSR", "Score": 7.309114583333334}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 17.220833333333328}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 8.595052083333334}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 8.395052083333335}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 11.673697916666663}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 2.6166666666666667}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 19.185937499999994}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 9.40703125}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 6.58541666666667}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 10.532552083333334}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 4.247916666666669}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.299479166666666}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 12.693489583333337}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 8.80885416666667}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 2.187239583333333}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 5.785416666666667}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 6.142187500000003}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 7.934375000000003}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 8.520572916666667}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 12.979427083333333}, {"Architecture": "GemmaForCausalLM", "Task": "MUSR", "Score": 6.848437499999999}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 11.540364583333336}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 9.501302083333334}, {"Architecture": "Starcoder2ForCausalLM", "Task": "MUSR", "Score": 2.9283854166666674}, {"Architecture": "Starcoder2ForCausalLM", "Task": "MUSR", "Score": 1.432291666666666}, {"Architecture": "Starcoder2ForCausalLM", "Task": "MUSR", "Score": 5.8166666666666655}, {"Architecture": "BloomForCausalLM", "Task": "MUSR", "Score": 3.416666666666666}, {"Architecture": "BloomForCausalLM", "Task": "MUSR", "Score": 6.838281250000001}, {"Architecture": "BloomForCausalLM", "Task": "MUSR", "Score": 7.891145833333333}, {"Architecture": "BloomForCausalLM", "Task": "MUSR", "Score": 8.185416666666667}, {"Architecture": "BloomForCausalLM", "Task": "MUSR", "Score": 1.920572916666666}, {"Architecture": "?", "Task": "MUSR", "Score": 15.518750000000002}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 7.932552083333335}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 12.462239583333336}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 11.942708333333334}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 19.6796875}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 13.658072916666669}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 7.126562500000001}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 6.703125000000001}, {"Architecture": "?", "Task": "MUSR", "Score": 10.876041666666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.385416666666666}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 7.15}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 6.904947916666669}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 6.3031250000000005}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 0.7812499999999996}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 9.501302083333336}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 8.658072916666667}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 20.8484375}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 17.78177083333333}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 14.316927083333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 13.791406250000003}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 23.6953125}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 16.97395833333334}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 13.516927083333336}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 11.414843750000005}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 10.363802083333336}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 13.732552083333337}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 17.042447916666664}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 11.65989583333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 13.348177083333333}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 17.932552083333338}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 15.20703125}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 10.912760416666666}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 0.6184895833333329}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 1.5950520833333328}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 11.146354166666663}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 16.082031249999996}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.608854166666669}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 9.491666666666667}, {"Architecture": "DbrxForCausalLM", "Task": "MUSR", "Score": 12.19921875}, {"Architecture": "GPTJForCausalLM", "Task": "MUSR", "Score": 8.118750000000002}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MUSR", "Score": 5.504947916666668}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MUSR", "Score": 3.22265625}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MUSR", "Score": 2.779427083333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 11.316927083333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 12.563802083333334}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 23.93307291666666}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.755989583333332}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 19.21302083333333}, {"Architecture": "DeepseekForCausalLM", "Task": "MUSR", "Score": 3.355989583333334}, {"Architecture": "DeepseekForCausalLM", "Task": "MUSR", "Score": 5.261718750000001}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 36.37213541666666}, {"Architecture": "?", "Task": "MUSR", "Score": 16.2796875}, {"Architecture": "?", "Task": "MUSR", "Score": 2.24609375}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 2.734375}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 20.87005208333333}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 5.512760416666668}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 9.722916666666668}, {"Architecture": "GPT2LMHeadModel", "Task": "MUSR", "Score": 11.1578125}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 8.171614583333332}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 8.459895833333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 9.664062500000002}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.303124999999996}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 10.377604166666664}, {"Architecture": "Phi3ForCausalLM", "Task": "MUSR", "Score": 8.732552083333331}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 0.2929687499999995}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 11.92838541666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 11.453906250000005}, {"Architecture": "?", "Task": "MUSR", "Score": 7.679687500000001}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 17.091145833333332}, {"Architecture": "Phi3ForCausalLM", "Task": "MUSR", "Score": 11.093489583333332}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 23.72109375}, {"Architecture": "?", "Task": "MUSR", "Score": 22.4171875}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 7.528385416666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 4.824479166666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 4.912760416666669}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 4.763802083333334}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.0460937500000003}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 4.053906250000002}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 4.3500000000000005}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 1.5361979166666664}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 12.109114583333335}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 9.3421875}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 9.652083333333335}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 19.41536458333333}, {"Architecture": "StableLmForCausalLM", "Task": "MUSR", "Score": 2.6617187500000004}, {"Architecture": "OPTForCausalLM", "Task": "MUSR", "Score": 2.0833333333333326}, {"Architecture": "OPTForCausalLM", "Task": "MUSR", "Score": 4.185416666666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 2.24609375}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 10.514583333333334}, {"Architecture": "?", "Task": "MUSR", "Score": 7.9734375}, {"Architecture": "Phi3ForCausalLM", "Task": "MUSR", "Score": 18.51875}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 10.528385416666673}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 11.961979166666667}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 16.088020833333328}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 6.420833333333333}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 17.162499999999994}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 14.482031250000004}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 6.016666666666668}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 6.969791666666668}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 16.471874999999997}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 12.530729166666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 20.962499999999995}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 22.25625}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 24.28567708333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 24.077864583333326}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 1.5950520833333328}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.463541666666668}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 6.58541666666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 17.49114583333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 15.002864583333327}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 1.58125}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 13.720572916666663}, {"Architecture": "GemmaForCausalLM", "Task": "MUSR", "Score": 5.9265625}, {"Architecture": "T5ForConditionalGeneration", "Task": "MUSR", "Score": 3.22265625}, {"Architecture": "T5ForConditionalGeneration", "Task": "MUSR", "Score": 9.007031249999999}, {"Architecture": "T5ForConditionalGeneration", "Task": "MUSR", "Score": 10.36979166666667}, {"Architecture": "T5ForConditionalGeneration", "Task": "MUSR", "Score": 11.328385416666668}, {"Architecture": "T5ForConditionalGeneration", "Task": "MUSR", "Score": 11.85390625}, {"Architecture": "T5ForConditionalGeneration", "Task": "MUSR", "Score": 11.185416666666669}, {"Architecture": "T5ForConditionalGeneration", "Task": "MUSR", "Score": 5.577604166666667}, {"Architecture": "GemmaForCausalLM", "Task": "MUSR", "Score": 2.024479166666666}, {"Architecture": "GemmaForCausalLM", "Task": "MUSR", "Score": 11.510937500000002}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 13.921093749999995}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 9.112760416666667}, {"Architecture": "InternLM2ForCausalLM", "Task": "MUSR", "Score": 11.43046875}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 11.267708333333331}, {"Architecture": "InternLM2ForCausalLM", "Task": "MUSR", "Score": 7.077343750000001}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 7.681510416666669}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 14.29765625}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 9.742187500000002}, {"Architecture": "GemmaForCausalLM", "Task": "MUSR", "Score": 7.555989583333336}, {"Architecture": "GemmaForCausalLM", "Task": "MUSR", "Score": 3.0322916666666675}, {"Architecture": "GemmaForCausalLM", "Task": "MUSR", "Score": 10.979947916666667}, {"Architecture": "GemmaForCausalLM", "Task": "MUSR", "Score": 12.528385416666667}, {"Architecture": "MT5ForConditionalGeneration", "Task": "MUSR", "Score": 2.867708333333334}, {"Architecture": "MT5ForConditionalGeneration", "Task": "MUSR", "Score": 5.91875}, {"Architecture": "MT5ForConditionalGeneration", "Task": "MUSR", "Score": 5.040104166666665}, {"Architecture": "T5ForConditionalGeneration", "Task": "MUSR", "Score": 3.5518229166666675}, {"Architecture": "RecurrentGemmaForCausalLM", "Task": "MUSR", "Score": 3.1049479166666667}, {"Architecture": "RecurrentGemmaForCausalLM", "Task": "MUSR", "Score": 3.624479166666668}, {"Architecture": "RecurrentGemmaForCausalLM", "Task": "MUSR", "Score": 6.599218750000001}, {"Architecture": "RecurrentGemmaForCausalLM", "Task": "MUSR", "Score": 13.771614583333337}, {"Architecture": "SwitchTransformersForConditionalGeneration", "Task": "MUSR", "Score": 1.133333333333333}, {"Architecture": "UMT5ForConditionalGeneration", "Task": "MUSR", "Score": 0.9440104166666662}, {"Architecture": "GPT2LMHeadModel", "Task": "MUSR", "Score": 15.348177083333336}, {"Architecture": "GPT2LMHeadModel", "Task": "MUSR", "Score": 18.33333333333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 13.518749999999995}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 9.540364583333334}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 6.697135416666669}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 9.262239583333336}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 14.905468750000004}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 10.63645833333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 7.887500000000002}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 7.887500000000002}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.332552083333338}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 14.769791666666668}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 6.526562500000002}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 5.232291666666669}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 2.824479166666667}, {"Architecture": "?", "Task": "MUSR", "Score": 2.232291666666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.4166666666666674}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.7421875}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 18.13072916666667}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 6.303125000000004}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 2.8106770833333345}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 1.9656249999999984}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 1.7578124999999991}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 7.483333333333333}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 8.091145833333334}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.148177083333335}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 20.31145833333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 19.2640625}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 13.379947916666673}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 13.877864583333334}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.402864583333334}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.816666666666668}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 12.997395833333336}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 13.405208333333327}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 13.338541666666664}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 11.507291666666667}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 11.17395833333333}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 10.997395833333329}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 12.19739583333333}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 9.309114583333338}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 13.648437500000004}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 12.381770833333336}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 12.766145833333336}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 12.195572916666668}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 13.144531250000004}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 10.225}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 9.858072916666664}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 11.634635416666663}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 8.542187500000004}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 13.648437500000004}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 7.78541666666667}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 8.522916666666669}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 6.83229166666667}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 2.0695312500000003}, {"Architecture": "InternLM2ForCausalLM", "Task": "MUSR", "Score": 8.226822916666668}, {"Architecture": "InternLM2ForCausalLM", "Task": "MUSR", "Score": 4.61484375}, {"Architecture": "InternLM2ForCausalLM", "Task": "MUSR", "Score": 4.424479166666669}, {"Architecture": "InternLM2ForCausalLM", "Task": "MUSR", "Score": 16.744531249999994}, {"Architecture": "InternLM2ForCausalLM", "Task": "MUSR", "Score": 14.35416666666667}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 8.089322916666669}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.77161458333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 6.56796875}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 7.766145833333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 9.330729166666666}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MUSR", "Score": 2.2539062500000013}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 16.897656249999997}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.401041666666663}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 14.628645833333332}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 17.80338541666666}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 10.777604166666672}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 22.28802083333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 11.397395833333336}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 23.621354166666677}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 13.840625}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 24.472395833333337}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 12.877864583333336}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 24.242968750000003}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 13.670052083333337}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 16.344531249999992}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 10.777604166666672}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 20.3546875}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 11.915104166666673}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 21.05859375}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 13.262239583333336}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 22.250781249999992}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 13.136718750000002}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 21.976302083333326}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 12.499479166666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 21.80755208333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 16.991927083333334}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 22.50182291666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 23.709635416666668}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 25.88020833333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 10.14817708333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 10.671875000000002}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 10.477864583333336}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 7.797395833333334}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 7.575781250000001}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 7.738541666666667}, {"Architecture": "Phi3ForCausalLM", "Task": "MUSR", "Score": 15.15234375}, {"Architecture": "Phi3ForCausalLM", "Task": "MUSR", "Score": 12.346354166666671}, {"Architecture": "Phi3ForCausalLM", "Task": "MUSR", "Score": 15.101302083333328}, {"Architecture": "Phi3ForCausalLM", "Task": "MUSR", "Score": 19.468229166666664}, {"Architecture": "Phi3ForCausalLM", "Task": "MUSR", "Score": 12.328385416666668}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 13.885677083333334}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 12.344531250000005}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 7.57760416666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 4.793229166666666}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 9.27552083333333}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 12.113281250000002}, {"Architecture": "?", "Task": "MUSR", "Score": 5.491145833333334}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 7.097135416666668}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 6.032291666666666}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 6.179427083333336}, {"Architecture": "?", "Task": "MUSR", "Score": 3.66171875}, {"Architecture": "?", "Task": "MUSR", "Score": 3.0598958333333326}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.524739583333336}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 14.47005208333333}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 6.509114583333333}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 13.715104166666665}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 4.881510416666667}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 3.0598958333333326}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 3.5932291666666667}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 14.58776041666667}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 15.209374999999996}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 1.7578124999999991}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 1.920572916666666}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 4.379427083333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 6.142187500000001}, {"Architecture": "Phi3ForCausalLM", "Task": "MUSR", "Score": 14.6953125}, {"Architecture": "Phi3ForCausalLM", "Task": "MUSR", "Score": 15.769791666666665}, {"Architecture": "Phi3ForCausalLM", "Task": "MUSR", "Score": 18.30546875}, {"Architecture": "Phi3ForCausalLM", "Task": "MUSR", "Score": 15.638281249999997}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 7.844270833333335}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 4.040104166666668}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 2.114583333333334}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 4.808854166666668}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 5.3109375000000005}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 2.973437500000001}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 2.973437500000001}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 4.091145833333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 5.016666666666668}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 11.42265625}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 4.732552083333332}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 9.47552083333334}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 7.814843749999999}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 20.160156250000004}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 7.532552083333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 5.740364583333334}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 4.297135416666666}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 4.520572916666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 5.69895833333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.195052083333334}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 10.016666666666666}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 12.995052083333334}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 6.228645833333334}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.491666666666665}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.846614583333333}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 9.273697916666668}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.1578125}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.385416666666666}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.483333333333336}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 9.777604166666668}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.27734375}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.7578125}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 2.5578125000000003}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 2.973437500000001}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.81484375}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 1.3734374999999996}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 16.011197916666664}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 10.92057291666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 6.242447916666666}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 1.602864583333335}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 5.401041666666668}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 16.581770833333337}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 17.691145833333334}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.981770833333334}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.407031249999996}, {"Architecture": "GPT2LMHeadModel", "Task": "MUSR", "Score": 12.283333333333331}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 25.787760416666668}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 24.093489583333326}, {"Architecture": "Phi3ForCausalLM", "Task": "MUSR", "Score": 11.351822916666665}, {"Architecture": "Phi3ForCausalLM", "Task": "MUSR", "Score": 13.052083333333334}, {"Architecture": "Phi3ForCausalLM", "Task": "MUSR", "Score": 7.710937500000003}, {"Architecture": "Phi3ForCausalLM", "Task": "MUSR", "Score": 7.644270833333336}, {"Architecture": "Phi3ForCausalLM", "Task": "MUSR", "Score": 13.118749999999997}, {"Architecture": "Phi3SmallForCausalLM", "Task": "MUSR", "Score": 14.49713541666666}, {"Architecture": "Phi3SmallForCausalLM", "Task": "MUSR", "Score": 16.77395833333333}, {"Architecture": "Phi3ForCausalLM", "Task": "MUSR", "Score": 17.326562499999998}, {"Architecture": "Phi3ForCausalLM", "Task": "MUSR", "Score": 10.098958333333334}, {"Architecture": "PhiForCausalLM", "Task": "MUSR", "Score": 3.697135416666667}, {"Architecture": "PhiForCausalLM", "Task": "MUSR", "Score": 3.385416666666666}, {"Architecture": "PhiForCausalLM", "Task": "MUSR", "Score": 13.83697916666666}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 23.39140625}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 9.414843749999996}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 10.275520833333331}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 15.489322916666673}, {"Architecture": "Phi3ForCausalLM", "Task": "MUSR", "Score": 10.112760416666667}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 10.887500000000005}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 9.61484375}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 9.059895833333336}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 8.859895833333338}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 1.0773437500000014}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 8.363802083333333}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 7.462239583333335}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 10.738541666666668}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 6.12838541666667}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 7.608854166666667}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 4.304947916666669}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 10.675520833333335}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 8.363802083333333}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 6.516927083333336}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 8.483333333333333}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 3.001041666666666}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 10.225}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 13.489322916666664}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 7.462239583333335}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 11.073697916666667}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 12.58359375}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 13.6640625}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 15.291666666666664}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 9.316927083333333}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 8.934375000000001}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 10.44609375}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 10.193229166666669}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 5.252083333333334}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.37760416666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 7.534375000000003}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 9.17760416666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.2106770833333336}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 12.893489583333336}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 9.075520833333336}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 10.903124999999996}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 4.008854166666668}, {"Architecture": "PhiForCausalLM", "Task": "MUSR", "Score": 7.710937500000003}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 10.757812500000002}, {"Architecture": "?", "Task": "MUSR", "Score": 3.0598958333333326}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 5.41484375}, {"Architecture": "MPTForCausalLM", "Task": "MUSR", "Score": 2.904947916666668}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 10.15}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 8.92838541666667}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 20.31145833333333}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 17.29765625}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 14.328906249999998}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 16.92109375}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 14.758333333333333}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 11.973958333333329}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 11.485677083333329}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 11.485677083333329}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 13.046093749999995}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 9.795572916666668}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 8.566145833333334}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 14.432812499999995}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 4.1578125}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 16.705468749999994}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 10.04609375}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 6.497135416666668}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 12.089322916666667}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 14.262239583333338}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 8.671875000000004}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 10.966145833333336}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 13.987239583333333}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 14.995572916666662}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 13.203385416666665}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 10.966145833333336}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 12.289322916666665}, {"Architecture": "GPT2LMHeadModel", "Task": "MUSR", "Score": 2.24609375}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 5.714583333333336}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.053906250000002}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.846093750000001}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 6.201041666666668}, {"Architecture": "PhiForCausalLM", "Task": "MUSR", "Score": 8.773958333333335}, {"Architecture": "PhiForCausalLM", "Task": "MUSR", "Score": 10.595572916666669}, {"Architecture": "PhiForCausalLM", "Task": "MUSR", "Score": 9.899479166666667}, {"Architecture": "PhiForCausalLM", "Task": "MUSR", "Score": 10.166145833333337}, {"Architecture": "PhiForCausalLM", "Task": "MUSR", "Score": 9.82682291666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 2.720572916666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 6.757812500000003}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.81666666666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 4.64609375}, {"Architecture": "GemmaForCausalLM", "Task": "MUSR", "Score": 4.120572916666667}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 22.119270833333328}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 19.6796875}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 4.844270833333336}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 5.252083333333334}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 9.43046875}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 8.871875000000001}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 8.879687500000001}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 7.993229166666668}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 9.846093749999996}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 10.699479166666668}, {"Architecture": "NemotronForCausalLM", "Task": "MUSR", "Score": 9.938541666666667}, {"Architecture": "NemotronForCausalLM", "Task": "MUSR", "Score": 9.085677083333335}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 8.944531250000002}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 7.37161458333333}, {"Architecture": "NemotronForCausalLM", "Task": "MUSR", "Score": 4.624479166666667}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 14.140885416666668}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 4.452083333333333}, {"Architecture": "?", "Task": "MUSR", "Score": 5.754166666666666}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 12.977604166666673}, {"Architecture": "GPT2LMHeadModel", "Task": "MUSR", "Score": 15.348177083333336}, {"Architecture": "GPT2LMHeadModel", "Task": "MUSR", "Score": 13.9109375}, {"Architecture": "GPT2LMHeadModel", "Task": "MUSR", "Score": 5.658072916666665}, {"Architecture": "GPT2LMHeadModel", "Task": "MUSR", "Score": 6.155989583333335}, {"Architecture": "GPT2LMHeadModel", "Task": "MUSR", "Score": 4.036458333333333}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 11.746354166666668}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 14.279687500000003}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.181770833333333}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 11.258072916666668}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 13.103125}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 9.916927083333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.285677083333335}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 17.460416666666664}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 19.815364583333327}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 16.88984375}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 18.495833333333334}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 20.69583333333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.271875000000001}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 17.203385416666663}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 4.199218749999999}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 2.0833333333333326}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 17.107291666666665}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 25.11510416666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 22.71328125}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 7.701302083333336}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 6.938541666666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.973958333333334}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 2.7656250000000004}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 9.262239583333336}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 24.21354166666666}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 12.6640625}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 18.805208333333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 2.734375}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 1.8401041666666655}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.565625000000001}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 11.66223958333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 9.099479166666669}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 11.232812499999994}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.036458333333336}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 2.5734375000000025}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 7.842447916666668}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 7.960156250000001}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 5.59140625}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 7.634635416666668}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.909114583333336}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 7.561979166666668}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 10.270052083333336}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 11.852604166666666}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 1.7578124999999991}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 2.83828125}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.9265625000000015}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 5.555989583333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.630468749999999}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 4.4520833333333325}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.240104166666668}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 4.8460937500000005}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 4.201041666666666}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 5.355989583333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 1.47734375}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 5.089322916666668}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 5.369791666666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 5.089322916666668}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.154166666666669}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 7.8502604166666705}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 9.252083333333331}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 9.628645833333332}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 4.836458333333334}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 13.030989583333335}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 4.275520833333334}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 10.034635416666664}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 11.527083333333332}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 8.0328125}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 10.89713541666667}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 5.750000000000001}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 12.785416666666668}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 7.408854166666667}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 6.638281250000001}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 6.416666666666669}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 7.934375000000003}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 9.755989583333331}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.5794270833333326}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 2.091145833333335}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 5.653906250000001}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 10.340364583333338}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 6.154166666666666}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 6.613020833333334}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 12.936718749999995}, {"Architecture": "PhiForCausalLM", "Task": "MUSR", "Score": 3.402864583333334}, {"Architecture": "PhiForCausalLM", "Task": "MUSR", "Score": 3.6106770833333353}, {"Architecture": "PhiForCausalLM", "Task": "MUSR", "Score": 5.044270833333334}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 2.897135416666666}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 12.39322916666667}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 16.415364583333332}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 11.526562500000002}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 10.401041666666664}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 17.807552083333327}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 12.081510416666664}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 17.03697916666666}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 18.3859375}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 14.642447916666669}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 9.769791666666666}, {"Architecture": "AriaForConditionalGeneration", "Task": "MUSR", "Score": 14.05208333333333}, {"Architecture": "PhiForCausalLM", "Task": "MUSR", "Score": 6.969791666666668}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 7.76979166666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 7.76979166666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 9.085677083333335}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 0.7812499999999996}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 10.35234375}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 18.832812499999992}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 24.727083333333336}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 8.554166666666667}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 17.322916666666668}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 12.003385416666667}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 7.822656250000001}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 19.26041666666666}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 10.985416666666664}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 16.03046875}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 4.687499999999999}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 12.50546875}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 14.903645833333329}, {"Architecture": "?", "Task": "MUSR", "Score": 6.683333333333335}, {"Architecture": "?", "Task": "MUSR", "Score": 9.64609375}, {"Architecture": "?", "Task": "MUSR", "Score": 9.864062499999998}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 7.481510416666669}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 4.047916666666668}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 4.765625000000001}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.967968750000002}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.981770833333334}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 0.6184895833333329}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 16.379947916666662}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 12.718749999999996}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 9.991406250000002}, {"Architecture": "?", "Task": "MUSR", "Score": 15.665885416666669}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 14.085677083333332}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 14.124739583333332}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 9.579427083333336}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 6.163802083333335}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 11.785416666666665}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 13.619010416666669}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 15.83046875}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 3.5343750000000003}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 20.025}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 5.59140625}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 5.59140625}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 13.61484375}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 18.65442708333333}, {"Architecture": "StableLmForCausalLM", "Task": "MUSR", "Score": 14.485677083333334}, {"Architecture": "StableLmForCausalLM", "Task": "MUSR", "Score": 7.728385416666669}, {"Architecture": "StableLmForCausalLM", "Task": "MUSR", "Score": 5.791406249999999}, {"Architecture": "StableLmForCausalLM", "Task": "MUSR", "Score": 5.712760416666669}, {"Architecture": "StableLmForCausalLM", "Task": "MUSR", "Score": 5.993229166666668}, {"Architecture": "StableLmForCausalLM", "Task": "MUSR", "Score": 4.422656249999999}, {"Architecture": "StableLmForCausalLM", "Task": "MUSR", "Score": 9.787760416666666}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 6.332552083333334}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 14.140885416666668}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 4.850260416666665}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 4.569791666666666}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 7.940364583333334}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 8.569791666666665}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 12.587239583333336}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 13.328385416666665}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 5.732552083333332}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.532552083333334}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 16.064062499999995}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 12.058072916666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 12.681510416666669}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.873697916666666}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 12.520572916666667}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 11.758333333333336}, {"Architecture": "?", "Task": "MUSR", "Score": 18.65807291666667}, {"Architecture": "?", "Task": "MUSR", "Score": 9.497135416666667}, {"Architecture": "?", "Task": "MUSR", "Score": 8.279687500000003}, {"Architecture": "?", "Task": "MUSR", "Score": 6.716927083333334}, {"Architecture": "?", "Task": "MUSR", "Score": 11.434635416666666}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 7.530729166666667}, {"Architecture": "?", "Task": "MUSR", "Score": 16.744531249999998}, {"Architecture": "?", "Task": "MUSR", "Score": 9.22083333333333}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 2.6244791666666685}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 9.259895833333337}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 13.6796875}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 3.677343750000001}, {"Architecture": "FalconForCausalLM", "Task": "MUSR", "Score": 7.530729166666667}, {"Architecture": "FalconForCausalLM", "Task": "MUSR", "Score": 5.193229166666668}, {"Architecture": "FalconForCausalLM", "Task": "MUSR", "Score": 5.161979166666666}, {"Architecture": "FalconForCausalLM", "Task": "MUSR", "Score": 4.497135416666667}, {"Architecture": "FalconForCausalLM", "Task": "MUSR", "Score": 3.2539062500000004}, {"Architecture": "FalconMambaForCausalLM", "Task": "MUSR", "Score": 10.862239583333334}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 11.864062500000005}, {"Architecture": "GPTJForCausalLM", "Task": "MUSR", "Score": 3.873697916666666}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MUSR", "Score": 1.7578124999999991}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 4.320572916666666}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 9.199218750000002}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MUSR", "Score": 3.0166666666666657}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MUSR", "Score": 1.86171875}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MUSR", "Score": 5.03046875}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MUSR", "Score": 4.001041666666667}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MUSR", "Score": 5.089322916666668}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MUSR", "Score": 6.408854166666669}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 13.795572916666664}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 6.942187500000002}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 4.524739583333332}, {"Architecture": "SolarForCausalLM", "Task": "MUSR", "Score": 15.007031249999995}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 14.772135416666666}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 7.205208333333334}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 5.3421875000000005}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 21.172135416666663}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 17.754166666666666}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 13.850260416666664}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 11.613020833333332}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 7.2640625}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 9.961979166666664}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 9.379427083333336}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 18.432812499999997}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 10.291145833333337}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 9.366145833333334}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 11.681510416666669}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 9.18723958333334}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 4.112760416666666}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 10.062239583333334}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 5.934375}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 12.02265625}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 7.379427083333333}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 9.110937500000004}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 5.193229166666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 8.26770833333333}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 9.950000000000005}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 9.585416666666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 1.6773437499999992}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 1.1067708333333328}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 18.49348958333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 4.291145833333334}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 14.503645833333335}, {"Architecture": "Qwen2ForCausalLM", "Task": "MUSR", "Score": 5.473697916666668}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 11.058072916666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 1.4401041666666683}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 6.3283854166666655}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.077343750000001}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 0.9440104166666662}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 6.62447916666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 13.166145833333337}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 11.773958333333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 16.419010416666666}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 8.195052083333335}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 6.405208333333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 5.483333333333334}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 5.104947916666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 2.291145833333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 5.001041666666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 5.216666666666668}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 6.067708333333335}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 2.328385416666666}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 7.334375000000001}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 2.9794270833333325}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.904947916666666}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.187239583333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 5.1265625}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 4.712760416666668}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 5.630468750000001}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 2.9421875}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.0833333333333326}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 13.750520833333333}, {"Architecture": "GemmaForCausalLM", "Task": "MUSR", "Score": 9.973437500000005}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 7.673697916666668}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 4.5265625000000025}, {"Architecture": "MistralForCausalLM", "Task": "MUSR", "Score": 4.416666666666667}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 11.303125}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 10.31875}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.85390625}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 5.008854166666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 2.7500000000000018}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 3.683333333333333}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 4.8460937500000005}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 5.593229166666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 2.853906249999999}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 4.63828125}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 7.134375000000002}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 9.619010416666669}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 11.003385416666667}, {"Architecture": "LlamaForCausalLM", "Task": "MUSR", "Score": 11.011197916666662}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 9.555989583333336}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 10.303125000000003}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 13.132552083333335}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 7.755989583333336}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 9.836458333333338}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 13.310937499999996}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 11.0953125}, {"Architecture": "Gemma2ForCausalLM", "Task": "MUSR", "Score": 12.18359375}, {"Architecture": "MixtralForCausalLM", "Task": "MUSR", "Score": 8.303124999999996}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 1.8173758865248215}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 40.732121749408975}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 41.21232269503546}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 39.11606087470449}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 39.38386524822696}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 23.823507683215126}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 24.414524231678485}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 32.402482269503544}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 30.72177895981088}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 33.05814125295508}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 33.261303191489354}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 37.90632387706855}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 39.27304964539008}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 34.369459219858165}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 22.12433510638298}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 20.489804964539008}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 22.90004432624113}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 28.59781323877068}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.1334219858156}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 15.83554964539007}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 35.865469858156025}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 24.562278368794324}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 24.562278368794324}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 8.32779255319149}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 15.179890661938533}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 28.08990839243498}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 10.793439716312056}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 12.501846926713949}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 31.80223108747045}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 30.961879432624112}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 24.23906619385342}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 20.75760933806146}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 19.25236406619385}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 17.747118794326237}, {"Architecture": "GPT2LMHeadModel", "Task": "MMLU-PRO", "Score": 3.064051418439715}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 40.90757978723404}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 25.790484633569736}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 26.492316784869978}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 28.34847813238771}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 25.54114952718676}, {"Architecture": "PhiForCausalLM", "Task": "MMLU-PRO", "Score": 16.269577423167846}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 32.35630910165484}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 20.12965425531915}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 35.93934692671394}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 13.397606382978722}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 39.53161938534279}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 33.10431442080379}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 31.876108156028373}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 41.44318853427896}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 24.00820035460993}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 39.84559692671394}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 25.02401004728132}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 24.774674940898343}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 32.89191784869976}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 34.64649822695036}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 24.710032505910167}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 25.26411052009456}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 40.07646276595744}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 24.710032505910167}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 25.26411052009456}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 12.492612293144209}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 24.66385933806146}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 1.1894208037825047}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 1.6603871158392434}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 1.4110520094562635}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 1.337174940898345}, {"Architecture": "T5ForConditionalGeneration", "Task": "MMLU-PRO", "Score": 3.4149674940898342}, {"Architecture": "T5ForConditionalGeneration", "Task": "MMLU-PRO", "Score": 2.6300236406619386}, {"Architecture": "T5ForConditionalGeneration", "Task": "MMLU-PRO", "Score": 2.6300236406619386}, {"Architecture": "T5ForConditionalGeneration", "Task": "MMLU-PRO", "Score": 1.6880910165484628}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 32.393247635933804}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 18.67058215130024}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 30.814125295508276}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 30.37086288416076}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.235002955082745}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.76137706855792}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 30.26004728132387}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 24.682328605200944}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 48.05518617021277}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 18.26425827423168}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 17.359264184397162}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 24.054373522458626}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 29.669030732860524}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 23.98973108747045}, {"Architecture": "CohereForCausalLM", "Task": "MMLU-PRO", "Score": 26.17833924349881}, {"Architecture": "CohereForCausalLM", "Task": "MMLU-PRO", "Score": 14.2010195035461}, {"Architecture": "CohereForCausalLM", "Task": "MMLU-PRO", "Score": 33.242833924349874}, {"Architecture": "CohereForCausalLM", "Task": "MMLU-PRO", "Score": 38.0079048463357}, {"Architecture": "CohereForCausalLM", "Task": "MMLU-PRO", "Score": 26.326093380614655}, {"Architecture": "GemmaForCausalLM", "Task": "MMLU-PRO", "Score": 7.395094562647753}, {"Architecture": "GemmaForCausalLM", "Task": "MMLU-PRO", "Score": 7.385859929078014}, {"Architecture": "GemmaForCausalLM", "Task": "MMLU-PRO", "Score": 7.690602836879433}, {"Architecture": "GemmaForCausalLM", "Task": "MMLU-PRO", "Score": 8.687943262411347}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 24.654624704491724}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 23.91585401891253}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 24.857786643026003}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 41.56323877068557}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 3.701241134751772}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 5.437352245862883}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 5.557402482269504}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 20.00960401891253}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 14.995197990543732}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 38.13718971631205}, {"Architecture": "?", "Task": "MMLU-PRO", "Score": 23.66651891252955}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 24.183658392434985}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 31.395907210401887}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 41.36931146572104}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 31.44208037825059}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 20.05577718676123}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 25.42109929078014}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 25.37492612293144}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 25.319518321513}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 22.21668144208038}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.336583924349878}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 30.40780141843972}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 25.458037825059098}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 23.795803782505907}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 25.6889036643026}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 28.56087470449172}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 26.0582890070922}, {"Architecture": "DeciLMForCausalLM", "Task": "MMLU-PRO", "Score": 18.799867021276597}, {"Architecture": "DeciLMForCausalLM", "Task": "MMLU-PRO", "Score": 17.86716903073286}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 31.017287234042552}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 8.983451536643026}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 8.928043735224584}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 2.990174349881796}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 3.0548167848699745}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 31.96845449172577}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 32.070035460992905}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 32.171616430260045}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 32.171616430260045}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 36.9459219858156}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 31.691415484633573}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 32.89191784869976}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.493572695035457}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 30.39856678486997}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 33.63992316784869}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 33.85231973995272}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 30.33392434988179}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 30.703309692671397}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 31.580599881796683}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.696734633569736}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.93683510638298}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 31.543661347517727}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 31.044991134751776}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 30.80489066193854}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 28.59781323877068}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 28.874852245862886}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 31.672946217494097}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 30.43550531914893}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 28.551640070921984}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.08724881796691}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 23.43565307328605}, {"Architecture": "GPTJForCausalLM", "Task": "MMLU-PRO", "Score": 2.6761968085106376}, {"Architecture": "GPTNeoForCausalLM", "Task": "MMLU-PRO", "Score": 1.8173758865248215}, {"Architecture": "GPTNeoForCausalLM", "Task": "MMLU-PRO", "Score": 0.2844267139479898}, {"Architecture": "GPTNeoForCausalLM", "Task": "MMLU-PRO", "Score": 1.8081412529550824}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MMLU-PRO", "Score": 1.725029550827422}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MMLU-PRO", "Score": 1.2078900709219855}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MMLU-PRO", "Score": 1.3279403073286051}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MMLU-PRO", "Score": 1.521867612293143}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MMLU-PRO", "Score": 1.4202866430260035}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MMLU-PRO", "Score": 1.632683215130022}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 18.162677304964536}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 12.788120567375886}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 22.11510047281324}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 17.728649527186757}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 17.728649527186757}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 22.604536052009458}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 19.123079196217496}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 23.45412234042553}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 24.959367612293143}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 15.79861111111111}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 13.86857269503546}, {"Architecture": "GemmaForCausalLM", "Task": "MMLU-PRO", "Score": 17.636303191489358}, {"Architecture": "?", "Task": "MMLU-PRO", "Score": 23.47259160756501}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 26.03981973995272}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 26.29838947990544}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 28.69939420803782}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 28.25613179669031}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 26.13216607565012}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 28.25613179669031}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 26.917109929078016}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 27.45271867612293}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 25.901300236406616}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 28.00679669030733}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 26.14140070921986}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 20.572916666666664}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 25.513445626477537}, {"Architecture": "GemmaForCausalLM", "Task": "MMLU-PRO", "Score": 14.413416075650115}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 25.965942671394792}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 26.73241725768321}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 26.483082151300238}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 26.16910460992908}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 26.695478723404253}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.050310283687946}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 28.117612293144205}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 28.8102098108747}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 28.034500591016545}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 28.33924349881796}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 1.6419178486997636}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 28.496232269503547}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 39.984116430260045}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 24.202127659574465}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 24.109781323877066}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 27.57276891252955}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 27.44348404255319}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 31.839169621749413}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 25.19023345153664}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 1.512632978723403}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 1.4756944444444438}, {"Architecture": "?", "Task": "MMLU-PRO", "Score": 21.736480496453904}, {"Architecture": "?", "Task": "MMLU-PRO", "Score": 22.59530141843972}, {"Architecture": "?", "Task": "MMLU-PRO", "Score": 20.12041962174941}, {"Architecture": "?", "Task": "MMLU-PRO", "Score": 21.57949172576832}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 24.396054964539008}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 26.898640661938533}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 19.806442080378247}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 17.350029550827426}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 17.28538711583924}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 34.66496749408983}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 17.2761524822695}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 18.67058215130024}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 29.419695626477544}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 22.96468676122932}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 25.57808806146572}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 25.67966903073286}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 26.46461288416076}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 27.979092789598106}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 19.94496158392435}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 19.78797281323877}, {"Architecture": "GemmaForCausalLM", "Task": "MMLU-PRO", "Score": 20.526743498817968}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 39.84559692671394}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 1.6419178486997636}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 1.8450797872340408}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 1.3556442080378246}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 1.9558953900709208}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 1.374113475177304}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 1.8450797872340408}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 30.019946808510632}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 28.00679669030733}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 37.75856973995272}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 1.124778368794326}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 12.889701536643026}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 18.873744089834517}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 18.642878250591018}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 18.522828014184395}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 18.05186170212766}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 25.7350768321513}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 25.46727245862884}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 36.401078605200944}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 34.75731382978724}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 25.236406619385345}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 25.24564125295508}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 24.516105200945624}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 24.414524231678485}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 25.56885342789598}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 22.992390661938536}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.84448877068557}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.26270685579196}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.53051122931442}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.01337174940898}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 28.27460106382979}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.53051122931442}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.604388297872337}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 30.12152777777778}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 32.00539302600473}, {"Architecture": "PhiForCausalLM", "Task": "MMLU-PRO", "Score": 12.898936170212766}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 1.7896719858156025}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 2.2052304964539005}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 1.466459810874704}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 47.140957446808514}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 46.96549940898345}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 47.140957446808514}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 47.24253841607565}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 7.65366430260047}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 19.917257683215126}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 20.268173758865245}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 31.017287234042552}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 22.853871158392437}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 22.770759456264773}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 22.779994089834517}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 22.696882387706854}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 23.47259160756501}, {"Architecture": "ExaoneForCausalLM", "Task": "MMLU-PRO", "Score": 28.63475177304965}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 22.27208924349881}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 26.34456264775413}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 48.757018321512994}, {"Architecture": "GemmaForCausalLM", "Task": "MMLU-PRO", "Score": 1.891252955082742}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 9.77763002364066}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 18.559766548463354}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 21.91193853427896}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 16.204934988179666}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 22.567597517730498}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 2.30681146572104}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 20.72990543735224}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 1.521867612293143}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 1.549571513002364}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 4.089095744680851}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 1.0509013002364058}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 5.280363475177306}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 1.4756944444444438}, {"Architecture": "Phi3ForCausalLM", "Task": "MMLU-PRO", "Score": 32.014627659574465}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 21.1824024822695}, {"Architecture": "?", "Task": "MMLU-PRO", "Score": 24.34988179669031}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 1.198655437352245}, {"Architecture": "Phi3ForCausalLM", "Task": "MMLU-PRO", "Score": 31.811465721040182}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 27.840573286052013}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 27.729757683215126}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 26.150635342789595}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 26.14140070921986}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 26.002881205673763}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.050310283687946}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.650561465721044}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 21.47791075650118}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 24.072842789598106}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 1.5033983451536632}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 26.797059692671397}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 27.10180260047281}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.08724881796691}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 9.362071513002364}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 28.819444444444446}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 42.89302600472813}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 20.702201536643024}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 21.1362293144208}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 22.2905585106383}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 22.23515070921986}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 23.712692080378247}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 21.588726359338057}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 25.1348256501182}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 24.386820330969268}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 22.1058658392435}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 28.865617612293136}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 29.03184101654845}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 14.154846335697396}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 21.35786052009456}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 4.209145981087471}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 22.853871158392437}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 22.86310579196217}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 40.196513002364064}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 31.80223108747045}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 31.700650118203303}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 31.61753841607564}, {"Architecture": "Qwen2MoeForCausalLM", "Task": "MMLU-PRO", "Score": 15.336879432624112}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 31.746823286052013}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 28.514701536643027}, {"Architecture": "Phi3ForCausalLM", "Task": "MMLU-PRO", "Score": 30.50938238770685}, {"Architecture": "Phi3ForCausalLM", "Task": "MMLU-PRO", "Score": 32.61487884160757}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 49.05252659574468}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 29.918365839243503}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 51.3242464539007}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 49.37573877068559}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 46.74386820330969}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 49.05252659574468}, {"Architecture": "Phi3ForCausalLM", "Task": "MMLU-PRO", "Score": 31.26662234042553}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 49.27415780141844}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 32.208554964539005}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 51.305777186761226}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 48.72931442080378}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 46.71616430260048}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 48.4799793144208}, {"Architecture": "Phi3ForCausalLM", "Task": "MMLU-PRO", "Score": 31.42361111111111}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 49.09869976359338}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 29.01337174940898}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 49.7266548463357}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 46.706929669030735}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 33.076610520094555}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 66.690676713948}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 29.79831560283688}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 30.352393617021285}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 30.056885342789595}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 1.1709515366430252}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 1.3464095744680846}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 1.4941637115839237}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 2.3899231678486985}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 2.639258274231678}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 26.649305555555557}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 27.498891843971627}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 17.93181146572104}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 38.20183215130024}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 41.56323877068557}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 6.794843380614658}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MMLU-PRO", "Score": 1.521867612293143}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 7.561317966903072}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 30.41703605200945}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 26.593897754137117}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 26.824763593380613}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 13.499187352245862}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.235002955082745}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 27.905215721040182}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.290410756501185}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 9.685283687943262}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.955304373522463}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 4.763223995271866}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 15.96483451536643}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 4.744754728132387}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 16.094119385342786}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 22.798463356973997}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 21.625664893617017}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 26.316858747044915}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 41.40625}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 23.768099881796687}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 22.392139479905435}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 29.622857565011817}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 22.95545212765957}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 27.314199172576835}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 10.442523640661936}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 14.671985815602836}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 8.789524231678488}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 8.872635933806146}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 21.034648345153663}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 21.26551418439716}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 25.24564125295508}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 23.869680851063837}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 1.798906619385342}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 1.2355939716312052}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 21.108525413711583}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 5.391179078014184}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 17.83946513002364}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 18.36583924349882}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MMLU-PRO", "Score": 1.2540632387706852}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 21.71801122931442}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 25.54114952718676}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 47.82432033096927}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 25.67043439716312}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 25.30104905437352}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 9.334367612293144}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 31.15580673758865}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 40.81523345153664}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 42.16348995271868}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 32.75339834515366}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 39.99335106382979}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 24.30370862884161}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 11.486037234042552}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 37.76780437352246}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 18.070330969267136}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 30.99881796690307}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 30.897236997635936}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 27.34190307328605}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 28.40388593380615}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 23.63881501182033}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 23.149379432624112}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 2.4360963356973997}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 22.94621749408983}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 28.874852245862886}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 27.00945626477541}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 25.439568557919618}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 25.54114952718676}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 25.439568557919618}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 25.54114952718676}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 25.439568557919618}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 25.54114952718676}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 25.439568557919618}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 20.33281619385342}, {"Architecture": "GPTJForCausalLM", "Task": "MMLU-PRO", "Score": 2.039007092198581}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 5.501994680851065}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 3.4149674940898342}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 2.362219267139479}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 9.79609929078014}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 8.928043735224584}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 48.45227541371159}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 42.49593676122932}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 29.37352245862884}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 29.08724881796691}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 38.88519503546098}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 38.41422872340425}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 16.22340425531915}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 15.512337470449172}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 21.293218085106385}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 21.681072695035464}, {"Architecture": "Qwen2MoeForCausalLM", "Task": "MMLU-PRO", "Score": 19.751034278959807}, {"Architecture": "Qwen2MoeForCausalLM", "Task": "MMLU-PRO", "Score": 21.3670951536643}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 7.7552452718676115}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 5.89908392434988}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 17.239213947990542}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 16.675901300236408}, {"Architecture": "Qwen2MoeForCausalLM", "Task": "MMLU-PRO", "Score": 43.51174645390071}, {"Architecture": "Qwen2MoeForCausalLM", "Task": "MMLU-PRO", "Score": 39.725546690307326}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 52.56168735224587}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 48.92324172576833}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 35.366799645390074}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 31.636007683215123}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 36.364140070921984}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 2.186761229314421}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 10.0639036643026}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 7.746010638297871}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 20.609855200945624}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 19.99113475177305}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 47.20559988179669}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 43.382461583924346}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 53.39280437352246}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 51.85062056737589}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 24.479166666666664}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 25.05171394799054}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 55.20279255319149}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 51.29654255319149}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 37.38918439716312}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 36.52112884160757}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 29.770611702127653}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 26.78782505910165}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 42.35741725768321}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 19.086140661938536}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 20.222000591016545}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 3.6365986997635926}, {"Architecture": "LlamaForRewardModelWithGating", "Task": "MMLU-PRO", "Score": 0.8662086288416063}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 25.07941784869976}, {"Architecture": "RwkvForCausalLM", "Task": "MMLU-PRO", "Score": 1.6696217494089831}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 20.859190307328607}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 19.98190011820331}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 26.56619385342789}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 8.946513002364064}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 3.673537234042553}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 12.741947399527188}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 1.7527334515366433}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 1.7434988179669018}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 3.1656323877068555}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 30.59249408983452}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 23.19555260047281}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 18.0149231678487}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 18.3381353427896}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 18.107269503546096}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 24.137485224586285}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 23.407949172576835}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 23.149379432624112}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 25.56885342789598}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 45.598773640661946}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 45.50642730496454}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 30.971114066193856}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 30.758717494089836}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 9.95308806146572}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 24.987071513002363}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 23.140144799054376}, {"Architecture": "GemmaForCausalLM", "Task": "MMLU-PRO", "Score": 24.479166666666664}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 32.16238179669031}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 4.707816193853427}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 2.24216903073286}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 1.7896719858156025}, {"Architecture": "?", "Task": "MMLU-PRO", "Score": 31.885342789598106}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 18.467420212765955}, {"Architecture": "GemmaForCausalLM", "Task": "MMLU-PRO", "Score": 4.43077718676123}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 27.14797576832151}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 21.570257092198577}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 47.399527186761226}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 47.399527186761226}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 45.85734338061466}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 0.9400856973995264}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 2.05747635933806}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 23.39871453900709}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 23.26019503546099}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 23.823507683215126}, {"Architecture": "Phi3ForCausalLM", "Task": "MMLU-PRO", "Score": 31.783761820330973}, {"Architecture": "ChatGLMModelM", "Task": "MMLU-PRO", "Score": 34.94200650118203}, {"Architecture": "ChatGLMModelM", "Task": "MMLU-PRO", "Score": 24.072842789598106}, {"Architecture": "ChatGLMModel", "Task": "MMLU-PRO", "Score": 24.03590425531915}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 22.410608747044915}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 19.62174940898345}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 5.308067375886525}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 9.011155437352246}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 10.507166075650115}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 16.35268912529551}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 19.61251477541371}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 33.83385047281324}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 27.526595744680847}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 46.669991134751776}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 16.50967789598109}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 1.124778368794326}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 0.542996453900708}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 28.671690307328607}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 28.93949468085106}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 30.832594562647756}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 37.92479314420804}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 32.300901300236404}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 31.885342789598106}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 31.395907210401887}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 30.12152777777778}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.90913120567376}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.38275709219858}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.53051122931442}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 18.005688534278956}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 18.836805555555557}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 18.63364361702128}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 18.42124704491726}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.17036052009456}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 10.756501182033098}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 49.19104609929077}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 48.8031914893617}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 31.746823286052013}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 48.16600177304965}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 32.116208628841605}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 12.788120567375886}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 22.733820921985814}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 25.60579196217494}, {"Architecture": "GemmaForCausalLM", "Task": "MMLU-PRO", "Score": 5.206486406619384}, {"Architecture": "GemmaForCausalLM", "Task": "MMLU-PRO", "Score": 21.79188829787234}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 29.44739952718675}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 26.50155141843972}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 40.72288711583924}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 24.257535460992905}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 18.809101654846337}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 34.34175531914893}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 28.20995862884161}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 28.1822547281324}, {"Architecture": "?", "Task": "MMLU-PRO", "Score": 25.10712174940898}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 43.25317671394799}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 43.30858451536643}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.38275709219858}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.58591903073286}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 26.769355791962173}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 21.15469858156028}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 15.632387706855791}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 15.817080378250589}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 26.38150118203309}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 24.229831560283685}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 15.86325354609929}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 13.9701536643026}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 17.054521276595743}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 28.302304964539005}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 26.640070921985814}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 41.14768026004728}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 13.98862293144208}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 23.675753546099287}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 23.25096040189125}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 34.39716312056737}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 1.7896719858156025}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 23.92508865248227}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 1.8450797872340408}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 16.87906323877068}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 27.184914302600472}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 28.736332742316783}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 27.10180260047281}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 29.724438534278963}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 30.9341755319149}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 1.0139627659574466}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 33.335180260047274}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 24.109781323877066}, {"Architecture": "Phi3ForCausalLM", "Task": "MMLU-PRO", "Score": 33.353649527186754}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 35.662307919621746}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 5.298832742316785}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 1.0601359338061456}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 19.36317966903073}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 7.395094562647753}, {"Architecture": "Qwen2MoeForCausalLM", "Task": "MMLU-PRO", "Score": 1.8635490543735225}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 22.47525118203309}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 27.77593085106383}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 30.92494089834515}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 42.96690307328605}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 49.51425827423168}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 27.914450354609933}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 24.27600472813239}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 39.36539598108747}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 40.26115543735224}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 41.83104314420804}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 26.13216607565012}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 46.559175531914896}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 18.23655437352246}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 22.25361997635934}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 1.3556442080378246}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 42.4220596926714}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 13.536125886524822}, {"Architecture": "?", "Task": "MMLU-PRO", "Score": 29.63209219858156}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 39.03294917257684}, {"Architecture": "JambaForCausalLM", "Task": "MMLU-PRO", "Score": 16.574320330969268}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 26.778590425531917}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 30.87876773049646}, {"Architecture": "?", "Task": "MMLU-PRO", "Score": 21.625664893617017}, {"Architecture": "OlmoForCausalLM", "Task": "MMLU-PRO", "Score": 1.9281914893617007}, {"Architecture": "OlmoForCausalLM", "Task": "MMLU-PRO", "Score": 8.724881796690305}, {"Architecture": "OlmoForCausalLM", "Task": "MMLU-PRO", "Score": 1.9189568557919612}, {"Architecture": "OlmoeForCausalLM", "Task": "MMLU-PRO", "Score": 8.216976950354608}, {"Architecture": "OlmoeForCausalLM", "Task": "MMLU-PRO", "Score": 9.73145685579196}, {"Architecture": "Phi3ForCausalLM", "Task": "MMLU-PRO", "Score": 39.623965721040186}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 23.371010638297868}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 25.67043439716312}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 20.111184988179662}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 40.97222222222222}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 25.47650709219858}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 26.0582890070922}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 23.389479905437348}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 23.33407210401891}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 22.586066784869978}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 22.973921394799056}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 23.51876477541371}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 23.167848699763592}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 22.696882387706854}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 22.530658983451534}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 23.23249113475177}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 22.549128250591018}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 23.620345744680847}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 23.33407210401891}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 22.63223995271868}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 22.973921394799056}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 1.8727836879432624}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 22.6137706855792}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 23.749630614657207}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 25.48574172576832}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 22.68764775413712}, {"Architecture": "Phi3ForCausalLM", "Task": "MMLU-PRO", "Score": 42.08037825059102}, {"Architecture": "Phi3ForCausalLM", "Task": "MMLU-PRO", "Score": 40.12263593380615}, {"Architecture": "Phi3ForCausalLM", "Task": "MMLU-PRO", "Score": 8.03228427895981}, {"Architecture": "Phi3ForCausalLM", "Task": "MMLU-PRO", "Score": 7.191932624113473}, {"Architecture": "Phi3ForCausalLM", "Task": "MMLU-PRO", "Score": 41.48936170212765}, {"Architecture": "Phi3ForCausalLM", "Task": "MMLU-PRO", "Score": 38.44193262411347}, {"Architecture": "Phi3ForCausalLM", "Task": "MMLU-PRO", "Score": 41.89568557919622}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 30.010712174940902}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 39.882535460992905}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 1.263297872340425}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 22.807697990543733}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 22.55836288416076}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 26.27068557919622}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 23.084736997635936}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 23.675753546099287}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 0.8939125295508273}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 38.765144799054376}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 10.904255319148934}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 41.68328900709219}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 41.37854609929077}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 22.623005319148938}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 22.64147458628841}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 0.9770242316784856}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 10.885786052009454}, {"Architecture": "OlmoeForCausalLM", "Task": "MMLU-PRO", "Score": 2.4176270685579198}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 23.99896572104019}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 39.95641252955083}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 49.64354314420804}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 41.06456855791962}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 17.211510047281322}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 1.8727836879432624}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 1.8727836879432624}, {"Architecture": "GemmaForCausalLM", "Task": "MMLU-PRO", "Score": 3.3964982269503543}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 49.84670508274232}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 24.08207742316785}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 49.51425827423168}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 24.608451536643024}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 35.976285460992905}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 41.692523640661946}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 36.022458628841605}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 35.606900118203306}, {"Architecture": "OpenLMModel", "Task": "MMLU-PRO", "Score": 23.45412234042553}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 49.46808510638298}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 31.358968676122927}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 31.257387706855795}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 31.96845449172577}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 30.232343380614655}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 48.83089539007093}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 20.600620567375884}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 22.26285460992908}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 29.558215130023648}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 23.823507683215126}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 28.496232269503547}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 22.89080969267139}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 22.21668144208038}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 14.561170212765957}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 22.23515070921986}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 21.75494976359338}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 22.55836288416076}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 17.65477245862884}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 27.43424940898345}, {"Architecture": "GemmaForCausalLM", "Task": "MMLU-PRO", "Score": 18.144208037825056}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 22.392139479905435}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 24.128250591016545}, {"Architecture": "Starcoder2ForCausalLM", "Task": "MMLU-PRO", "Score": 15.032136524822691}, {"Architecture": "Starcoder2ForCausalLM", "Task": "MMLU-PRO", "Score": 7.071882387706856}, {"Architecture": "Starcoder2ForCausalLM", "Task": "MMLU-PRO", "Score": 7.1365248226950335}, {"Architecture": "BloomForCausalLM", "Task": "MMLU-PRO", "Score": 1.198655437352245}, {"Architecture": "BloomForCausalLM", "Task": "MMLU-PRO", "Score": 0.958554964539006}, {"Architecture": "BloomForCausalLM", "Task": "MMLU-PRO", "Score": 1.4756944444444438}, {"Architecture": "BloomForCausalLM", "Task": "MMLU-PRO", "Score": 1.8266105200945613}, {"Architecture": "BloomForCausalLM", "Task": "MMLU-PRO", "Score": 1.1617169030732852}, {"Architecture": "?", "Task": "MMLU-PRO", "Score": 43.35475768321512}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 30.92494089834515}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.94606973995272}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 31.174276004728128}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 31.36820330969267}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 30.167700945626475}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 1.5033983451536632}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 28.08067375886525}, {"Architecture": "?", "Task": "MMLU-PRO", "Score": 29.6413268321513}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 1.9466607565011809}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 31.709884751773053}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 31.109633569739948}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 1.549571513002364}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 23.186317966903072}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 26.677009456264773}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 17.239213947990542}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 46.02356678486997}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 41.84951241134751}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 40.8521719858156}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 19.67715721040189}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 34.77578309692671}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 39.09759160756501}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 32.96579491725768}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 39.50391548463357}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 38.820552600472816}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 39.1622340425532}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 49.680481678487006}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 33.89849290780142}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 40.33503250591017}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 20.231235224586285}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 26.409205082742314}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 12.28021572104019}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 2.6300236406619386}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 27.56353427895981}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 30.34315898345153}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 21.66260342789598}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 27.249556737588648}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.696734633569736}, {"Architecture": "DbrxForCausalLM", "Task": "MMLU-PRO", "Score": 29.807550236406616}, {"Architecture": "GPTJForCausalLM", "Task": "MMLU-PRO", "Score": 2.953235815602837}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MMLU-PRO", "Score": 1.4295212765957446}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MMLU-PRO", "Score": 1.6142139479905429}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MMLU-PRO", "Score": 1.6603871158392434}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 1.8450797872340408}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 25.919769503546096}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 32.70722517730496}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 8.955747635933804}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 12.594193262411348}, {"Architecture": "DeepseekForCausalLM", "Task": "MMLU-PRO", "Score": 5.612810283687943}, {"Architecture": "DeepseekForCausalLM", "Task": "MMLU-PRO", "Score": 10.710328014184398}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 66.80149231678487}, {"Architecture": "?", "Task": "MMLU-PRO", "Score": 32.14391252955083}, {"Architecture": "?", "Task": "MMLU-PRO", "Score": 14.42265070921986}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 14.22872340425532}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 49.49578900709219}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 17.830230496453904}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 17.830230496453904}, {"Architecture": "GPT2LMHeadModel", "Task": "MMLU-PRO", "Score": 2.0759456264775418}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 23.00162529550828}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 23.43565307328605}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 30.38933215130024}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 27.942154255319146}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 28.921025413711572}, {"Architecture": "Phi3ForCausalLM", "Task": "MMLU-PRO", "Score": 36.95515661938535}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 28.413120567375884}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 45.66341607565011}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 45.96815898345154}, {"Architecture": "?", "Task": "MMLU-PRO", "Score": 29.32734929078014}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 47.20559988179669}, {"Architecture": "Phi3ForCausalLM", "Task": "MMLU-PRO", "Score": 42.73603723404255}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 49.20028073286053}, {"Architecture": "?", "Task": "MMLU-PRO", "Score": 49.22798463356975}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 18.44895094562648}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 26.492316784869978}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 26.41843971631205}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 28.311539598108748}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 26.55695921985816}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 24.63615543735224}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 27.54506501182033}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.364287825059105}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 23.41718380614657}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 31.432845744680847}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 32.68875591016548}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 27.979092789598106}, {"Architecture": "StableLmForCausalLM", "Task": "MMLU-PRO", "Score": 3.969045508274229}, {"Architecture": "OPTForCausalLM", "Task": "MMLU-PRO", "Score": 1.1894208037825047}, {"Architecture": "OPTForCausalLM", "Task": "MMLU-PRO", "Score": 1.8173758865248215}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 8.494015957446807}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 19.35394503546099}, {"Architecture": "?", "Task": "MMLU-PRO", "Score": 38.35882092198581}, {"Architecture": "Phi3ForCausalLM", "Task": "MMLU-PRO", "Score": 37.77703900709219}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 46.06050531914893}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 39.328457446808514}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 22.43831264775413}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 27.95138888888889}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 19.67715721040189}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 16.02947695035461}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 31.303560874704488}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 24.03590425531915}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 28.911790780141843}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 24.28523936170213}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 43.00384160756501}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 26.824763593380613}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 27.41578014184397}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 27.44348404255319}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 1.7342641843971618}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 7.265809692671395}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.76137706855792}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 46.62381796690308}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 45.27556146572104}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 20.44363179669031}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 59.349143026004725}, {"Architecture": "GemmaForCausalLM", "Task": "MMLU-PRO", "Score": 3.0917553191489344}, {"Architecture": "T5ForConditionalGeneration", "Task": "MMLU-PRO", "Score": 3.969045508274229}, {"Architecture": "T5ForConditionalGeneration", "Task": "MMLU-PRO", "Score": 7.87529550827423}, {"Architecture": "T5ForConditionalGeneration", "Task": "MMLU-PRO", "Score": 2.5930851063829774}, {"Architecture": "T5ForConditionalGeneration", "Task": "MMLU-PRO", "Score": 12.741947399527188}, {"Architecture": "T5ForConditionalGeneration", "Task": "MMLU-PRO", "Score": 12.686539598108748}, {"Architecture": "T5ForConditionalGeneration", "Task": "MMLU-PRO", "Score": 14.921320921985814}, {"Architecture": "T5ForConditionalGeneration", "Task": "MMLU-PRO", "Score": 16.592789598108748}, {"Architecture": "GemmaForCausalLM", "Task": "MMLU-PRO", "Score": 5.372709810874704}, {"Architecture": "GemmaForCausalLM", "Task": "MMLU-PRO", "Score": 17.5993646572104}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 37.4538268321513}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 38.34958628841608}, {"Architecture": "InternLM2ForCausalLM", "Task": "MMLU-PRO", "Score": 13.111332742316788}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 13.51765661938534}, {"Architecture": "InternLM2ForCausalLM", "Task": "MMLU-PRO", "Score": 17.22074468085106}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 17.53472222222222}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 34.48027482269504}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 31.949985224586293}, {"Architecture": "GemmaForCausalLM", "Task": "MMLU-PRO", "Score": 4.061391843971631}, {"Architecture": "GemmaForCausalLM", "Task": "MMLU-PRO", "Score": 3.9228723404255295}, {"Architecture": "GemmaForCausalLM", "Task": "MMLU-PRO", "Score": 21.644134160756497}, {"Architecture": "GemmaForCausalLM", "Task": "MMLU-PRO", "Score": 7.7183067375886525}, {"Architecture": "MT5ForConditionalGeneration", "Task": "MMLU-PRO", "Score": 0.7738622931442081}, {"Architecture": "MT5ForConditionalGeneration", "Task": "MMLU-PRO", "Score": 1.3648788416075646}, {"Architecture": "MT5ForConditionalGeneration", "Task": "MMLU-PRO", "Score": 1.3279403073286051}, {"Architecture": "T5ForConditionalGeneration", "Task": "MMLU-PRO", "Score": 0.9862588652482256}, {"Architecture": "RecurrentGemmaForCausalLM", "Task": "MMLU-PRO", "Score": 1.9558953900709208}, {"Architecture": "RecurrentGemmaForCausalLM", "Task": "MMLU-PRO", "Score": 4.467715721040189}, {"Architecture": "RecurrentGemmaForCausalLM", "Task": "MMLU-PRO", "Score": 17.830230496453904}, {"Architecture": "RecurrentGemmaForCausalLM", "Task": "MMLU-PRO", "Score": 20.480570330969268}, {"Architecture": "SwitchTransformersForConditionalGeneration", "Task": "MMLU-PRO", "Score": 1.087839834515365}, {"Architecture": "UMT5ForConditionalGeneration", "Task": "MMLU-PRO", "Score": 0.8662086288416063}, {"Architecture": "GPT2LMHeadModel", "Task": "MMLU-PRO", "Score": 1.7712027186761226}, {"Architecture": "GPT2LMHeadModel", "Task": "MMLU-PRO", "Score": 0.0}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 21.56102245862884}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.17036052009456}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.82601950354609}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.4566341607565}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 37.07520685579196}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 31.06346040189125}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.34581855791962}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.38275709219858}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.02260638297872}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 11.421394799054372}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 12.326388888888888}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 13.6469414893617}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 1.595744680851063}, {"Architecture": "?", "Task": "MMLU-PRO", "Score": 9.075797872340424}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.84448877068557}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 30.37086288416076}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 16.712839834515364}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 30.94341016548463}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 10.581043144208037}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 23.084736997635936}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 3.4796099290780127}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 35.32986111111111}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 35.643838652482266}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 26.34456264775413}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 7.616725768321511}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 32.901152482269495}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 23.278664302600472}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 22.9831560283688}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 9.269725177304965}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 14.293365839243496}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 22.95545212765957}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 22.973921394799056}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 23.167848699763592}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 23.62958037825059}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 23.315602836879428}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 21.939642434988176}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 21.413268321513}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 20.18506205673759}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 22.936982860520093}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 22.32749704491725}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 22.90004432624113}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 22.973921394799056}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 23.038563829787236}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 24.183658392434985}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 23.361776004728128}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 23.26019503546099}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 22.336731678486995}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 22.844636524822693}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 16.648197399527188}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 35.847000591016545}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 31.922281323877066}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 1.5680407801418434}, {"Architecture": "InternLM2ForCausalLM", "Task": "MMLU-PRO", "Score": 6.536273640661936}, {"Architecture": "InternLM2ForCausalLM", "Task": "MMLU-PRO", "Score": 9.325132978723405}, {"Architecture": "InternLM2ForCausalLM", "Task": "MMLU-PRO", "Score": 3.322621158392436}, {"Architecture": "InternLM2ForCausalLM", "Task": "MMLU-PRO", "Score": 33.30747635933806}, {"Architecture": "InternLM2ForCausalLM", "Task": "MMLU-PRO", "Score": 30.41703605200945}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 25.458037825059098}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 23.841976950354614}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.47510342789598}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.179595153664305}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 31.700650118203303}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MMLU-PRO", "Score": 1.8727836879432624}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 20.951536643026003}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 23.795803782505907}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 23.54646867612293}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 30.43550531914893}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 30.26928191489361}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 28.14531619385342}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 30.43550531914893}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 26.049054373522463}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.955304373522463}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 25.5042109929078}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.58591903073286}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 25.60579196217494}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.44739952718675}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 30.69407505910165}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.99224290780142}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.01337174940898}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 30.112293144208035}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 28.126846926713934}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.659796099290777}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 27.665115248226947}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.05954491725768}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 27.268026004728128}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.161125886524825}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 15.715499408983453}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 14.05326536643026}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 22.669178486997637}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 23.869680851063837}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 23.814273049645383}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 30.13076241134751}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 28.893321513002363}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 25.790484633569736}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 24.165189125295505}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 23.91585401891253}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 24.23906619385342}, {"Architecture": "Phi3ForCausalLM", "Task": "MMLU-PRO", "Score": 41.8218085106383}, {"Architecture": "Phi3ForCausalLM", "Task": "MMLU-PRO", "Score": 41.07380319148936}, {"Architecture": "Phi3ForCausalLM", "Task": "MMLU-PRO", "Score": 33.205895390070914}, {"Architecture": "Phi3ForCausalLM", "Task": "MMLU-PRO", "Score": 32.63334810874704}, {"Architecture": "Phi3ForCausalLM", "Task": "MMLU-PRO", "Score": 31.96845449172577}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 22.57683215130024}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 23.30636820330969}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 21.90270390070922}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 1.5311022458628842}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 23.96202718676123}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 19.15078309692672}, {"Architecture": "?", "Task": "MMLU-PRO", "Score": 19.98190011820331}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 8.780289598108746}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 10.738031914893616}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 3.802822104018913}, {"Architecture": "?", "Task": "MMLU-PRO", "Score": 14.727393617021276}, {"Architecture": "?", "Task": "MMLU-PRO", "Score": 22.14280437352246}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 30.26928191489361}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 35.847000591016545}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 36.040927895981085}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 35.985520094562645}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 35.791592789598106}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 27.942154255319146}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 27.812869385342783}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 35.51455378250591}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 35.606900118203306}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 35.182106973995275}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 34.821956264775416}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.733673167848696}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.89066193853428}, {"Architecture": "Phi3ForCausalLM", "Task": "MMLU-PRO", "Score": 31.340499408983447}, {"Architecture": "Phi3ForCausalLM", "Task": "MMLU-PRO", "Score": 33.32594562647754}, {"Architecture": "Phi3ForCausalLM", "Task": "MMLU-PRO", "Score": 33.05814125295508}, {"Architecture": "Phi3ForCausalLM", "Task": "MMLU-PRO", "Score": 31.93151595744681}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 26.483082151300238}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 25.66119976359338}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.0410756501182}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.82601950354609}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 30.76795212765957}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 14.2010195035461}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 14.45958924349882}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 13.813164893617024}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 9.306663711583925}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 12.741947399527188}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 10.821143617021276}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 27.942154255319146}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 31.589834515366427}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 30.87876773049646}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 7.65366430260047}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 6.582446808510639}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.94606973995272}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 30.74024822695036}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.70596926713948}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 30.66637115839244}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 39.882535460992905}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 47.80585106382979}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 31.765292553191493}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 3.830526004728132}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 3.969045508274229}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 19.418587470449168}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 10.257830969267138}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 15.309175531914892}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 15.918661347517732}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 30.1954048463357}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 7.644429669030731}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 9.56523345153664}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 2.2606382978723394}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 7.579787234042552}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 16.528147163120565}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 24.386820330969268}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 41.21232269503546}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 46.74386820330969}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 24.553043735224584}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.604388297872337}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 28.791740543735223}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 40.602836879432616}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 47.87972813238771}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 24.950132978723403}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 30.68484042553192}, {"Architecture": "GPT2LMHeadModel", "Task": "MMLU-PRO", "Score": 1.3187056737588652}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 19.437056737588648}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 14.653516548463358}, {"Architecture": "Phi3ForCausalLM", "Task": "MMLU-PRO", "Score": 41.24002659574468}, {"Architecture": "Phi3ForCausalLM", "Task": "MMLU-PRO", "Score": 40.84293735224587}, {"Architecture": "Phi3ForCausalLM", "Task": "MMLU-PRO", "Score": 30.38009751773049}, {"Architecture": "Phi3ForCausalLM", "Task": "MMLU-PRO", "Score": 31.848404255319146}, {"Architecture": "Phi3ForCausalLM", "Task": "MMLU-PRO", "Score": 33.57528073286053}, {"Architecture": "Phi3SmallForCausalLM", "Task": "MMLU-PRO", "Score": 38.783614066193856}, {"Architecture": "Phi3SmallForCausalLM", "Task": "MMLU-PRO", "Score": 38.95907210401891}, {"Architecture": "Phi3ForCausalLM", "Task": "MMLU-PRO", "Score": 40.639775413711575}, {"Architecture": "Phi3ForCausalLM", "Task": "MMLU-PRO", "Score": 32.91038711583924}, {"Architecture": "PhiForCausalLM", "Task": "MMLU-PRO", "Score": 1.798906619385342}, {"Architecture": "PhiForCausalLM", "Task": "MMLU-PRO", "Score": 7.681368203309693}, {"Architecture": "PhiForCausalLM", "Task": "MMLU-PRO", "Score": 18.088800236406616}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 40.64901004728132}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 22.55836288416076}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 22.59530141843972}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 17.386968085106382}, {"Architecture": "Phi3ForCausalLM", "Task": "MMLU-PRO", "Score": 30.352393617021285}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 50.67782210401892}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 25.642730496453904}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 26.002881205673763}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 26.150635342789595}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 8.798758865248226}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 21.699541962174944}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 40.4366134751773}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 23.95279255319149}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 15.715499408983453}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 19.0769060283688}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 23.05703309692672}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 22.36443557919621}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 21.699541962174944}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 27.46195330969267}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 27.969858156028373}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 32.89191784869976}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 34.43410165484633}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 38.70050236406619}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 40.4366134751773}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 29.90913120567376}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 31.663711583924343}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 31.903812056737586}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 23.592641843971627}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 16.36192375886525}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 16.805186170212764}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 50.21609042553191}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 41.48936170212765}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 28.54240543735224}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.650561465721044}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 31.451315011820324}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 30.010712174940902}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 27.812869385342783}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 17.793291962174944}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 31.57136524822695}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 31.128102836879428}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 18.947621158392437}, {"Architecture": "PhiForCausalLM", "Task": "MMLU-PRO", "Score": 17.229979314420802}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 46.93779550827424}, {"Architecture": "?", "Task": "MMLU-PRO", "Score": 1.8635490543735225}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 10.968897754137116}, {"Architecture": "MPTForCausalLM", "Task": "MMLU-PRO", "Score": 2.288342198581559}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 27.979092789598106}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 31.580599881796683}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 29.56744976359338}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 34.748079196217496}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 29.779846335697403}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 22.14280437352246}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 29.19806442080379}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 28.570109338061467}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 28.50546690307328}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 28.65322104018913}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 28.29307033096927}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 34.38792848699764}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 34.711140661938536}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 29.82601950354609}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 10.913489952718674}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 35.4683806146572}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 31.451315011820324}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 26.076758274231683}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 27.785165484633573}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 28.865617612293136}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 28.45005910165484}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 28.46852836879432}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 27.76669621749409}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 29.38275709219858}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 28.616282505910167}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 28.385416666666668}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 28.13608156028369}, {"Architecture": "GPT2LMHeadModel", "Task": "MMLU-PRO", "Score": 1.337174940898345}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 21.42250295508274}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 28.117612293144205}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 28.25613179669031}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 27.67434988179669}, {"Architecture": "PhiForCausalLM", "Task": "MMLU-PRO", "Score": 16.315750591016545}, {"Architecture": "PhiForCausalLM", "Task": "MMLU-PRO", "Score": 16.666666666666664}, {"Architecture": "PhiForCausalLM", "Task": "MMLU-PRO", "Score": 16.888297872340427}, {"Architecture": "PhiForCausalLM", "Task": "MMLU-PRO", "Score": 16.666666666666664}, {"Architecture": "PhiForCausalLM", "Task": "MMLU-PRO", "Score": 15.475398936170212}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 16.36192375886525}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 24.469932033096924}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 22.567597517730498}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 26.03058510638298}, {"Architecture": "GemmaForCausalLM", "Task": "MMLU-PRO", "Score": 1.9281914893617007}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 52.56168735224587}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 51.23190011820331}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 17.082225177304963}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 10.2947695035461}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 1.9004875886524817}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 27.425014775413715}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 24.34064716312057}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 23.648049645390067}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 25.162529550827426}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 19.98190011820331}, {"Architecture": "NemotronForCausalLM", "Task": "MMLU-PRO", "Score": 17.99645390070922}, {"Architecture": "NemotronForCausalLM", "Task": "MMLU-PRO", "Score": 24.229831560283685}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 31.06346040189125}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 33.23359929078014}, {"Architecture": "NemotronForCausalLM", "Task": "MMLU-PRO", "Score": 18.070330969267136}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 23.352541371158388}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 14.561170212765957}, {"Architecture": "?", "Task": "MMLU-PRO", "Score": 25.67966903073286}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 15.106013593380617}, {"Architecture": "GPT2LMHeadModel", "Task": "MMLU-PRO", "Score": 1.7712027186761226}, {"Architecture": "GPT2LMHeadModel", "Task": "MMLU-PRO", "Score": 1.8358451536643017}, {"Architecture": "GPT2LMHeadModel", "Task": "MMLU-PRO", "Score": 1.5772754137115832}, {"Architecture": "GPT2LMHeadModel", "Task": "MMLU-PRO", "Score": 2.020537825059101}, {"Architecture": "GPT2LMHeadModel", "Task": "MMLU-PRO", "Score": 1.457225177304964}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 25.458037825059098}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 23.805038416075647}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 24.765440307328607}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 23.92508865248227}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 15.79861111111111}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 15.83554964539007}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 22.86310579196217}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 35.791592789598106}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 39.86406619385342}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 40.528959810874696}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 41.81257387706855}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 42.86532210401891}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 20.665263002364064}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 16.232638888888886}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 1.6142139479905429}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 6.019134160756501}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 14.496527777777777}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 30.63866725768321}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 12.04011524822695}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 23.066267730496453}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 23.50953014184397}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 21.63489952718676}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 1.383348108747044}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 28.847148345153663}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 51.35195035460993}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 35.19134160756501}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 50.05910165484633}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 1.3187056737588652}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 1.1524822695035457}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 24.248300827423165}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 24.903959810874703}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 25.40263002364066}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 24.589982269503544}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 21.66260342789598}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 21.95811170212766}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 23.093971631205672}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 23.50029550827423}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 22.826167257683213}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 23.140144799054376}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 22.38290484633569}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 20.988475177304963}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 22.92774822695035}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 23.389479905437348}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.465868794326237}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 30.06611997635934}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.613622931442084}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 30.76795212765957}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 28.874852245862886}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.6413268321513}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.40122635933806}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 30.34315898345153}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 28.96719858156028}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 30.82335992907802}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.37352245862884}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 27.582003546099287}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 28.717863475177303}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 27.582003546099287}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 27.655880614657207}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.1334219858156}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 18.34736997635934}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 18.28272754137116}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 19.908023049645383}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 20.794547872340427}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 19.741799645390067}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 15.530806737588652}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 19.78797281323877}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 18.910682624113477}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 18.901447990543733}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 19.42782210401891}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 18.975325059101653}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 20.13888888888889}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 18.467420212765955}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 19.741799645390067}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 18.34736997635934}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 19.963430851063837}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 1.9004875886524817}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 2.0759456264775418}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 30.26004728132387}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 33.05814125295508}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 20.44363179669031}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 12.695774231678486}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 15.595449172576831}, {"Architecture": "PhiForCausalLM", "Task": "MMLU-PRO", "Score": 6.240765366430259}, {"Architecture": "PhiForCausalLM", "Task": "MMLU-PRO", "Score": 12.834293735224584}, {"Architecture": "PhiForCausalLM", "Task": "MMLU-PRO", "Score": 13.85010342789598}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 1.300236406619384}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 35.63460401891253}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 35.13593380614657}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 35.09899527186761}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 35.145168439716315}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 34.692671394799056}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 34.13859338061466}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 33.76920803782505}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 37.84168144208039}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 23.278664302600472}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 28.219193262411352}, {"Architecture": "AriaForConditionalGeneration", "Task": "MMLU-PRO", "Score": 37.83244680851063}, {"Architecture": "PhiForCausalLM", "Task": "MMLU-PRO", "Score": 17.026817375886523}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 21.81959219858156}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 21.976580969267136}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 31.201979905437344}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 9.620641252955084}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 21.35786052009456}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 48.6184988179669}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 54.62101063829788}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 30.67560579196217}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 54.83340721040189}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 38.54351359338061}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 19.104609929078016}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 48.84936465721041}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 19.56634160756501}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 26.547724586288417}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 1.0601359338061456}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 26.70471335697399}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 27.480422576832154}, {"Architecture": "?", "Task": "MMLU-PRO", "Score": 15.133717494089836}, {"Architecture": "?", "Task": "MMLU-PRO", "Score": 33.16895685579196}, {"Architecture": "?", "Task": "MMLU-PRO", "Score": 13.434544917257682}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 19.60328014184397}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 25.98441193853428}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 12.520316193853429}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 14.838209219858156}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 21.94887706855792}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 1.5588061465721037}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 23.61111111111111}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 25.615026595744684}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 11.827718676122933}, {"Architecture": "?", "Task": "MMLU-PRO", "Score": 20.305112293144205}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 22.549128250591018}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 10.51640070921986}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 18.98455969267139}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 19.418587470449168}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 19.01226359338061}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 18.125738770685576}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 26.529255319148938}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 33.19666075650118}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 27.498891843971627}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 31.506722813238763}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 31.24815307328605}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 46.85468380614657}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 25.845892434988176}, {"Architecture": "StableLmForCausalLM", "Task": "MMLU-PRO", "Score": 23.02009456264776}, {"Architecture": "StableLmForCausalLM", "Task": "MMLU-PRO", "Score": 19.27083333333333}, {"Architecture": "StableLmForCausalLM", "Task": "MMLU-PRO", "Score": 5.1510786052009445}, {"Architecture": "StableLmForCausalLM", "Task": "MMLU-PRO", "Score": 6.905658983451536}, {"Architecture": "StableLmForCausalLM", "Task": "MMLU-PRO", "Score": 7.930703309692672}, {"Architecture": "StableLmForCausalLM", "Task": "MMLU-PRO", "Score": 7.432033096926712}, {"Architecture": "StableLmForCausalLM", "Task": "MMLU-PRO", "Score": 8.530954491725769}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 20.646793735224584}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 23.352541371158388}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 1.2078900709219855}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 1.300236406619384}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 31.017287234042552}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 31.165041371158388}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 42.75450650118203}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 51.739804964539005}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 20.40669326241135}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 15.438460401891252}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 21.4594414893617}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 22.826167257683213}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 10.368646572104018}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 4.12603427895981}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 46.780806737588655}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 20.674497635933804}, {"Architecture": "?", "Task": "MMLU-PRO", "Score": 18.98455969267139}, {"Architecture": "?", "Task": "MMLU-PRO", "Score": 20.75760933806146}, {"Architecture": "?", "Task": "MMLU-PRO", "Score": 23.05703309692672}, {"Architecture": "?", "Task": "MMLU-PRO", "Score": 24.31294326241135}, {"Architecture": "?", "Task": "MMLU-PRO", "Score": 24.756205673758867}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 20.240469858156025}, {"Architecture": "?", "Task": "MMLU-PRO", "Score": 18.559766548463354}, {"Architecture": "?", "Task": "MMLU-PRO", "Score": 28.63475177304965}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 15.078309692671397}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 32.494828605200944}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 36.059397163120565}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 32.023862293144205}, {"Architecture": "FalconForCausalLM", "Task": "MMLU-PRO", "Score": 15.438460401891252}, {"Architecture": "FalconForCausalLM", "Task": "MMLU-PRO", "Score": 16.722074468085104}, {"Architecture": "FalconForCausalLM", "Task": "MMLU-PRO", "Score": 14.016326832151298}, {"Architecture": "FalconForCausalLM", "Task": "MMLU-PRO", "Score": 1.392582742316784}, {"Architecture": "FalconForCausalLM", "Task": "MMLU-PRO", "Score": 1.725029550827422}, {"Architecture": "FalconMambaForCausalLM", "Task": "MMLU-PRO", "Score": 14.468823877068557}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 17.57166075650118}, {"Architecture": "GPTJForCausalLM", "Task": "MMLU-PRO", "Score": 6.951832151300234}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MMLU-PRO", "Score": 1.6142139479905429}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 8.530954491725769}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 8.678708628841607}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MMLU-PRO", "Score": 2.186761229314421}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MMLU-PRO", "Score": 1.3464095744680846}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MMLU-PRO", "Score": 3.027112884160755}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MMLU-PRO", "Score": 1.2355939716312052}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MMLU-PRO", "Score": 1.4110520094562635}, {"Architecture": "GPTNeoXForCausalLM", "Task": "MMLU-PRO", "Score": 1.2171247044917255}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 23.19555260047281}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 23.758865248226947}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 1.8727836879432624}, {"Architecture": "SolarForCausalLM", "Task": "MMLU-PRO", "Score": 47.48263888888889}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 23.841976950354614}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 17.137632978723403}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 7.986111111111111}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 21.1362293144208}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 17.322325650118206}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 22.11510047281324}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 23.26942966903073}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 31.848404255319146}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 30.841829196217496}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 43.668735224586285}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 48.68314125295508}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 43.36399231678487}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.12418735224587}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 30.04765070921986}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 25.29181442080378}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 26.18757387706856}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 23.30636820330969}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 28.800975177304966}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 33.5014036643026}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 26.38150118203309}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 22.50295508274231}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 24.146719858156025}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 27.51736111111111}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 19.0769060283688}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 29.81678486997636}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 30.093823877068555}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 1.5772754137115832}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 26.03981973995272}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 1.3187056737588652}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 23.41718380614657}, {"Architecture": "Qwen2ForCausalLM", "Task": "MMLU-PRO", "Score": 6.702497044917257}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 17.423906619385342}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 24.756205673758867}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 26.0582890070922}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 16.297281323877066}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 1.291001773049644}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 16.038711583924346}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 20.877659574468087}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 19.317006501182032}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 20.05577718676123}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 14.265661938534278}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 24.931663711583923}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.84448877068557}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.9645390070922}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 30.019946808510632}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 28.88408687943262}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 30.093823877068555}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.604388297872337}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 30.04765070921986}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 28.10837765957446}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.539745862884164}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.918365839243503}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.53051122931442}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.050310283687946}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.161125886524825}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.12418735224587}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.678265366430256}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 30.17693557919622}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 28.671690307328607}, {"Architecture": "GemmaForCausalLM", "Task": "MMLU-PRO", "Score": 17.266917848699762}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 19.778738179669027}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 17.47931442080378}, {"Architecture": "MistralForCausalLM", "Task": "MMLU-PRO", "Score": 16.989878841607567}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 27.480422576832154}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 27.56353427895981}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 30.17693557919622}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 30.53708628841608}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 30.1954048463357}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.807550236406616}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 30.223108747044915}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 30.38009751773049}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 30.029181442080382}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 29.659796099290777}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 27.997562056737586}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 18.162677304964536}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 28.59781323877068}, {"Architecture": "LlamaForCausalLM", "Task": "MMLU-PRO", "Score": 25.07941784869976}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 35.819296690307326}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 36.89974881796691}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 37.77703900709219}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 34.895833333333336}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 36.91821808510639}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 36.83510638297872}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 36.92745271867612}, {"Architecture": "Gemma2ForCausalLM", "Task": "MMLU-PRO", "Score": 35.33909574468085}, {"Architecture": "MixtralForCausalLM", "Task": "MMLU-PRO", "Score": 20.517508865248228}]}};
      var embedOpt = {"mode": "vega-lite"};

      function showError(el, error){
          el.innerHTML = ('<div style="color:red;">'
                          + '<p>JavaScript Error: ' + error.message + '</p>'
                          + "<p>This usually means there's a typo in your chart specification. "
                          + "See the javascript console for the full traceback.</p>"
                          + '</div>');
          throw error;
      }
      const el = document.getElementById('vis');
      vegaEmbed("#vis", spec, embedOpt)
        .catch(error => showError(el, error));
    })(vegaEmbed);

  </script>
</body>
</html>